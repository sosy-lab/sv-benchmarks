extern void __VERIFIER_error() __attribute__ ((__noreturn__));

/* Generated by CIL v. 1.5.1 */
/* print_CIL_Input is false */

#line 19 "include/uapi/asm-generic/int-ll64.h"
typedef signed char __s8;
#line 20 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned char __u8;
#line 22 "include/uapi/asm-generic/int-ll64.h"
typedef short __s16;
#line 23 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned short __u16;
#line 25 "include/uapi/asm-generic/int-ll64.h"
typedef int __s32;
#line 26 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned int __u32;
#line 29 "include/uapi/asm-generic/int-ll64.h"
typedef long long __s64;
#line 30 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned long long __u64;
#line 15 "include/asm-generic/int-ll64.h"
typedef signed char s8;
#line 16 "include/asm-generic/int-ll64.h"
typedef unsigned char u8;
#line 19 "include/asm-generic/int-ll64.h"
typedef unsigned short u16;
#line 21 "include/asm-generic/int-ll64.h"
typedef int s32;
#line 22 "include/asm-generic/int-ll64.h"
typedef unsigned int u32;
#line 24 "include/asm-generic/int-ll64.h"
typedef long long s64;
#line 25 "include/asm-generic/int-ll64.h"
typedef unsigned long long u64;
#line 14 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef long __kernel_long_t;
#line 15 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef unsigned long __kernel_ulong_t;
#line 27 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef int __kernel_pid_t;
#line 48 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef unsigned int __kernel_uid32_t;
#line 49 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef unsigned int __kernel_gid32_t;
#line 71 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef __kernel_ulong_t __kernel_size_t;
#line 72 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef __kernel_long_t __kernel_ssize_t;
#line 86 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef __kernel_long_t __kernel_off_t;
#line 87 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef long long __kernel_loff_t;
#line 88 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef __kernel_long_t __kernel_time_t;
#line 89 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef __kernel_long_t __kernel_clock_t;
#line 90 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef int __kernel_timer_t;
#line 91 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/posix_types.h"
typedef int __kernel_clockid_t;
#line 33 "include/uapi/linux/types.h"
typedef __u16 __be16;
#line 35 "include/uapi/linux/types.h"
typedef __u32 __be32;
#line 40 "include/uapi/linux/types.h"
typedef __u32 __wsum;
#line 12 "include/linux/types.h"
typedef __u32 __kernel_dev_t;
#line 15 "include/linux/types.h"
typedef __kernel_dev_t dev_t;
#line 18 "include/linux/types.h"
typedef unsigned short umode_t;
#line 19 "include/linux/types.h"
typedef __u32 nlink_t;
#line 20 "include/linux/types.h"
typedef __kernel_off_t off_t;
#line 21 "include/linux/types.h"
typedef __kernel_pid_t pid_t;
#line 26 "include/linux/types.h"
typedef __kernel_clockid_t clockid_t;
#line 29 "include/linux/types.h"
typedef _Bool bool;
#line 31 "include/linux/types.h"
typedef __kernel_uid32_t uid_t;
#line 32 "include/linux/types.h"
typedef __kernel_gid32_t gid_t;
#line 45 "include/linux/types.h"
typedef __kernel_loff_t loff_t;
#line 54 "include/linux/types.h"
typedef __kernel_size_t size_t;
#line 59 "include/linux/types.h"
typedef __kernel_ssize_t ssize_t;
#line 69 "include/linux/types.h"
typedef __kernel_time_t time_t;
#line 102 "include/linux/types.h"
typedef __s32 int32_t;
#line 106 "include/linux/types.h"
typedef __u8 uint8_t;
#line 108 "include/linux/types.h"
typedef __u32 uint32_t;
#line 111 "include/linux/types.h"
typedef __u64 uint64_t;
#line 133 "include/linux/types.h"
typedef unsigned long sector_t;
#line 134 "include/linux/types.h"
typedef unsigned long blkcnt_t;
#line 146 "include/linux/types.h"
typedef u64 dma_addr_t;
#line 157 "include/linux/types.h"
typedef unsigned int gfp_t;
#line 158 "include/linux/types.h"
typedef unsigned int fmode_t;
#line 176 "include/linux/types.h"
struct __anonstruct_atomic_t_6 {
   int counter ;
};
#line 176 "include/linux/types.h"
typedef struct __anonstruct_atomic_t_6 atomic_t;
#line 181 "include/linux/types.h"
struct __anonstruct_atomic64_t_7 {
   long counter ;
};
#line 181 "include/linux/types.h"
typedef struct __anonstruct_atomic64_t_7 atomic64_t;
#line 182 "include/linux/types.h"
struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};
#line 187
struct hlist_node;
#line 187 "include/linux/types.h"
struct hlist_head {
   struct hlist_node *first ;
};
#line 191 "include/linux/types.h"
struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};
#line 202 "include/linux/types.h"
struct callback_head {
   struct callback_head *next ;
   void (*func)(struct callback_head * ) ;
};
#line 55 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/alternative.h"
struct module;
#line 310 "include/linux/printk.h"
struct file_operations;
#line 325 "include/linux/printk.h"
struct _ddebug {
   char const   *modname ;
   char const   *function ;
   char const   *filename ;
   char const   *format ;
   unsigned int lineno : 18 ;
   unsigned char flags ;
};
#line 48 "include/linux/dynamic_debug.h"
struct device;
#line 54
struct net_device;
#line 23 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/sysinfo.h"
struct completion;
#line 24
struct pt_regs;
#line 351 "include/linux/kernel.h"
struct pid;
#line 14 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
typedef u16 __ticket_t;
#line 15 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
typedef u32 __ticketpair_t;
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
struct __raw_tickets {
   __ticket_t head ;
   __ticket_t tail ;
};
#line 26 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
union __anonunion_ldv_2023_8 {
   __ticketpair_t head_tail ;
   struct __raw_tickets tickets ;
};
#line 26 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
struct arch_spinlock {
   union __anonunion_ldv_2023_8 ldv_2023 ;
};
#line 27 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
typedef struct arch_spinlock arch_spinlock_t;
#line 33 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/rwlock.h"
struct __anonstruct_ldv_2030_10 {
   u32 read ;
   s32 write ;
};
#line 33 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/rwlock.h"
union __anonunion_arch_rwlock_t_9 {
   s64 lock ;
   struct __anonstruct_ldv_2030_10 ldv_2030 ;
};
#line 33 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/rwlock.h"
typedef union __anonunion_arch_rwlock_t_9 arch_rwlock_t;
#line 34
struct task_struct;
#line 35
struct lockdep_map;
#line 18 "include/linux/lockdep.h"
struct mm_struct;
#line 58 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page_types.h"
struct pt_regs {
   unsigned long r15 ;
   unsigned long r14 ;
   unsigned long r13 ;
   unsigned long r12 ;
   unsigned long bp ;
   unsigned long bx ;
   unsigned long r11 ;
   unsigned long r10 ;
   unsigned long r9 ;
   unsigned long r8 ;
   unsigned long ax ;
   unsigned long cx ;
   unsigned long dx ;
   unsigned long si ;
   unsigned long di ;
   unsigned long orig_ax ;
   unsigned long ip ;
   unsigned long cs ;
   unsigned long flags ;
   unsigned long sp ;
   unsigned long ss ;
};
#line 125 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/ptrace.h"
struct __anonstruct_ldv_2147_12 {
   unsigned int a ;
   unsigned int b ;
};
#line 125 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/ptrace.h"
struct __anonstruct_ldv_2162_13 {
   u16 limit0 ;
   u16 base0 ;
   unsigned char base1 ;
   unsigned char type : 4 ;
   unsigned char s : 1 ;
   unsigned char dpl : 2 ;
   unsigned char p : 1 ;
   unsigned char limit : 4 ;
   unsigned char avl : 1 ;
   unsigned char l : 1 ;
   unsigned char d : 1 ;
   unsigned char g : 1 ;
   unsigned char base2 ;
};
#line 125 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/ptrace.h"
union __anonunion_ldv_2163_11 {
   struct __anonstruct_ldv_2147_12 ldv_2147 ;
   struct __anonstruct_ldv_2162_13 ldv_2162 ;
};
#line 125 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/ptrace.h"
struct desc_struct {
   union __anonunion_ldv_2163_11 ldv_2163 ;
};
#line 13 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pgtable_64_types.h"
typedef unsigned long pgdval_t;
#line 14 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pgtable_64_types.h"
typedef unsigned long pgprotval_t;
#line 18 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pgtable_64_types.h"
struct pgprot {
   pgprotval_t pgprot ;
};
#line 192 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pgtable_types.h"
typedef struct pgprot pgprot_t;
#line 194 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pgtable_types.h"
struct __anonstruct_pgd_t_15 {
   pgdval_t pgd ;
};
#line 194 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pgtable_types.h"
typedef struct __anonstruct_pgd_t_15 pgd_t;
#line 282
struct page;
#line 282 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pgtable_types.h"
typedef struct page *pgtable_t;
#line 290
struct file;
#line 305
struct seq_file;
#line 335
struct thread_struct;
#line 337
struct cpumask;
#line 300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/ptrace.h"
struct kernel_vm86_regs {
   struct pt_regs pt ;
   unsigned short es ;
   unsigned short __esh ;
   unsigned short ds ;
   unsigned short __dsh ;
   unsigned short fs ;
   unsigned short __fsh ;
   unsigned short gs ;
   unsigned short __gsh ;
};
#line 203 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/vm86.h"
union __anonunion_ldv_2766_18 {
   struct pt_regs *regs ;
   struct kernel_vm86_regs *vm86 ;
};
#line 203 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/vm86.h"
struct math_emu_info {
   long ___orig_eip ;
   union __anonunion_ldv_2766_18 ldv_2766 ;
};
#line 96 "include/linux/bug.h"
struct cpumask {
   unsigned long bits[64U] ;
};
#line 14 "include/linux/cpumask.h"
typedef struct cpumask cpumask_t;
#line 648 "include/linux/cpumask.h"
typedef struct cpumask *cpumask_var_t;
#line 233 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/special_insns.h"
struct exec_domain;
#line 26 "include/linux/personality.h"
struct map_segment;
#line 26 "include/linux/personality.h"
struct exec_domain {
   char const   *name ;
   void (*handler)(int  , struct pt_regs * ) ;
   unsigned char pers_low ;
   unsigned char pers_high ;
   unsigned long *signal_map ;
   unsigned long *signal_invmap ;
   struct map_segment *err_map ;
   struct map_segment *socktype_map ;
   struct map_segment *sockopt_map ;
   struct map_segment *af_map ;
   struct module *module ;
   struct exec_domain *next ;
};
#line 166 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct seq_operations;
#line 300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct i387_fsave_struct {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};
#line 318 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct __anonstruct_ldv_5121_23 {
   u64 rip ;
   u64 rdp ;
};
#line 318 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct __anonstruct_ldv_5127_24 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};
#line 318 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
union __anonunion_ldv_5128_22 {
   struct __anonstruct_ldv_5121_23 ldv_5121 ;
   struct __anonstruct_ldv_5127_24 ldv_5127 ;
};
#line 318 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
union __anonunion_ldv_5137_25 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};
#line 318 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct i387_fxsave_struct {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion_ldv_5128_22 ldv_5128 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion_ldv_5137_25 ldv_5137 ;
};
#line 352 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct i387_soft_struct {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct math_emu_info *info ;
   u32 entry_eip ;
};
#line 373 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct ymmh_struct {
   u32 ymmh_space[64U] ;
};
#line 378 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct xsave_hdr_struct {
   u64 xstate_bv ;
   u64 reserved1[2U] ;
   u64 reserved2[5U] ;
};
#line 384 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct xsave_struct {
   struct i387_fxsave_struct i387 ;
   struct xsave_hdr_struct xsave_hdr ;
   struct ymmh_struct ymmh ;
};
#line 390 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
union thread_xstate {
   struct i387_fsave_struct fsave ;
   struct i387_fxsave_struct fxsave ;
   struct i387_soft_struct soft ;
   struct xsave_struct xsave ;
};
#line 398 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct fpu {
   unsigned int last_cpu ;
   unsigned int has_fpu ;
   union thread_xstate *state ;
};
#line 445
struct kmem_cache;
#line 446
struct perf_event;
#line 447 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp0 ;
   unsigned long sp ;
   unsigned long usersp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
   unsigned short gsindex ;
   unsigned long fs ;
   unsigned long gs ;
   struct perf_event *ptrace_bps[4U] ;
   unsigned long debugreg6 ;
   unsigned long ptrace_dr7 ;
   unsigned long cr2 ;
   unsigned long trap_nr ;
   unsigned long error_code ;
   struct fpu fpu ;
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
   unsigned int io_bitmap_max ;
};
#line 588 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct __anonstruct_mm_segment_t_27 {
   unsigned long seg ;
};
#line 588 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
typedef struct __anonstruct_mm_segment_t_27 mm_segment_t;
#line 23 "include/asm-generic/atomic-long.h"
typedef atomic64_t atomic_long_t;
#line 55 "include/linux/debug_locks.h"
struct stack_trace {
   unsigned int nr_entries ;
   unsigned int max_entries ;
   unsigned long *entries ;
   int skip ;
};
#line 26 "include/linux/stacktrace.h"
struct lockdep_subclass_key {
   char __one_byte ;
} __attribute__((__packed__)) ;
#line 53 "include/linux/lockdep.h"
struct lock_class_key {
   struct lockdep_subclass_key subkeys[8U] ;
};
#line 59 "include/linux/lockdep.h"
struct lock_class {
   struct list_head hash_entry ;
   struct list_head lock_entry ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
   unsigned int dep_gen_id ;
   unsigned long usage_mask ;
   struct stack_trace usage_traces[13U] ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   unsigned int version ;
   unsigned long ops ;
   char const   *name ;
   int name_version ;
   unsigned long contention_point[4U] ;
   unsigned long contending_point[4U] ;
};
#line 144 "include/linux/lockdep.h"
struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache[2U] ;
   char const   *name ;
   int cpu ;
   unsigned long ip ;
};
#line 205 "include/linux/lockdep.h"
struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned short class_idx : 13 ;
   unsigned char irq_context : 2 ;
   unsigned char trylock : 1 ;
   unsigned char read : 2 ;
   unsigned char check : 2 ;
   unsigned char hardirqs_off : 1 ;
   unsigned short references : 11 ;
};
#line 574 "include/linux/lockdep.h"
struct raw_spinlock {
   arch_spinlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
#line 32 "include/linux/spinlock_types.h"
typedef struct raw_spinlock raw_spinlock_t;
#line 33 "include/linux/spinlock_types.h"
struct __anonstruct_ldv_5956_29 {
   u8 __padding[24U] ;
   struct lockdep_map dep_map ;
};
#line 33 "include/linux/spinlock_types.h"
union __anonunion_ldv_5957_28 {
   struct raw_spinlock rlock ;
   struct __anonstruct_ldv_5956_29 ldv_5956 ;
};
#line 33 "include/linux/spinlock_types.h"
struct spinlock {
   union __anonunion_ldv_5957_28 ldv_5957 ;
};
#line 76 "include/linux/spinlock_types.h"
typedef struct spinlock spinlock_t;
#line 23 "include/linux/rwlock_types.h"
struct __anonstruct_rwlock_t_30 {
   arch_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
#line 23 "include/linux/rwlock_types.h"
typedef struct __anonstruct_rwlock_t_30 rwlock_t;
#line 23 "include/linux/rwlock_types.h"
struct mutex {
   atomic_t count ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct task_struct *owner ;
   char const   *name ;
   void *magic ;
   struct lockdep_map dep_map ;
};
#line 63 "include/linux/mutex.h"
struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   void *magic ;
};
#line 112 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
struct timespec;
#line 113
struct compat_timespec;
#line 114 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
struct __anonstruct_futex_32 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
   u32 *uaddr2 ;
};
#line 114 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
struct __anonstruct_nanosleep_33 {
   clockid_t clockid ;
   struct timespec *rmtp ;
   struct compat_timespec *compat_rmtp ;
   u64 expires ;
};
#line 114
struct pollfd;
#line 114 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
struct __anonstruct_poll_34 {
   struct pollfd *ufds ;
   int nfds ;
   int has_timeout ;
   unsigned long tv_sec ;
   unsigned long tv_nsec ;
};
#line 114 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
union __anonunion_ldv_6276_31 {
   struct __anonstruct_futex_32 futex ;
   struct __anonstruct_nanosleep_33 nanosleep ;
   struct __anonstruct_poll_34 poll ;
};
#line 114 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
struct restart_block {
   long (*fn)(struct restart_block * ) ;
   union __anonunion_ldv_6276_31 ldv_6276 ;
};
#line 52 "include/linux/thread_info.h"
struct thread_info {
   struct task_struct *task ;
   struct exec_domain *exec_domain ;
   __u32 flags ;
   __u32 status ;
   __u32 cpu ;
   int preempt_count ;
   mm_segment_t addr_limit ;
   struct restart_block restart_block ;
   void *sysenter_return ;
   unsigned char sig_on_uaccess_error : 1 ;
   unsigned char uaccess_err : 1 ;
};
#line 394 "include/linux/spinlock.h"
struct vm_area_struct;
#line 36 "include/linux/seqlock.h"
struct __anonstruct_seqlock_t_35 {
   unsigned int sequence ;
   spinlock_t lock ;
};
#line 36 "include/linux/seqlock.h"
typedef struct __anonstruct_seqlock_t_35 seqlock_t;
#line 110 "include/linux/seqlock.h"
struct seqcount {
   unsigned int sequence ;
};
#line 121 "include/linux/seqlock.h"
typedef struct seqcount seqcount_t;
#line 254 "include/linux/seqlock.h"
struct timespec {
   __kernel_time_t tv_sec ;
   long tv_nsec ;
};
#line 313 "include/linux/jiffies.h"
union ktime {
   s64 tv64 ;
};
#line 59 "include/linux/ktime.h"
typedef union ktime ktime_t;
#line 105 "include/linux/debugobjects.h"
struct tvec_base;
#line 106 "include/linux/debugobjects.h"
struct timer_list {
   struct list_head entry ;
   unsigned long expires ;
   struct tvec_base *base ;
   void (*function)(unsigned long  ) ;
   unsigned long data ;
   int slack ;
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
   struct lockdep_map lockdep_map ;
};
#line 254 "include/linux/timer.h"
struct hrtimer;
#line 255
enum hrtimer_restart;
#line 267
struct work_struct;
#line 50 "include/linux/workqueue.h"
struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct * ) ;
   struct lockdep_map lockdep_map ;
};
#line 96 "include/linux/workqueue.h"
struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
   int cpu ;
};
#line 18 "include/linux/smp.h"
struct call_single_data {
   struct list_head list ;
   void (*func)(void * ) ;
   void *info ;
   u16 flags ;
   u16 priv ;
};
#line 11 "include/linux/wait.h"
struct __wait_queue;
#line 11 "include/linux/wait.h"
typedef struct __wait_queue wait_queue_t;
#line 14 "include/linux/wait.h"
struct __wait_queue {
   unsigned int flags ;
   void *private ;
   int (*func)(wait_queue_t * , unsigned int  , int  , void * ) ;
   struct list_head task_list ;
};
#line 32 "include/linux/wait.h"
struct __wait_queue_head {
   spinlock_t lock ;
   struct list_head task_list ;
};
#line 37 "include/linux/wait.h"
typedef struct __wait_queue_head wait_queue_head_t;
#line 813 "include/linux/wait.h"
struct completion {
   unsigned int done ;
   wait_queue_head_t wait ;
};
#line 46 "include/linux/pm.h"
struct pm_message {
   int event ;
};
#line 52 "include/linux/pm.h"
typedef struct pm_message pm_message_t;
#line 53 "include/linux/pm.h"
struct dev_pm_ops {
   int (*prepare)(struct device * ) ;
   void (*complete)(struct device * ) ;
   int (*suspend)(struct device * ) ;
   int (*resume)(struct device * ) ;
   int (*freeze)(struct device * ) ;
   int (*thaw)(struct device * ) ;
   int (*poweroff)(struct device * ) ;
   int (*restore)(struct device * ) ;
   int (*suspend_late)(struct device * ) ;
   int (*resume_early)(struct device * ) ;
   int (*freeze_late)(struct device * ) ;
   int (*thaw_early)(struct device * ) ;
   int (*poweroff_late)(struct device * ) ;
   int (*restore_early)(struct device * ) ;
   int (*suspend_noirq)(struct device * ) ;
   int (*resume_noirq)(struct device * ) ;
   int (*freeze_noirq)(struct device * ) ;
   int (*thaw_noirq)(struct device * ) ;
   int (*poweroff_noirq)(struct device * ) ;
   int (*restore_noirq)(struct device * ) ;
   int (*runtime_suspend)(struct device * ) ;
   int (*runtime_resume)(struct device * ) ;
   int (*runtime_idle)(struct device * ) ;
};
#line 289
enum rpm_status {
    RPM_ACTIVE = 0,
    RPM_RESUMING = 1,
    RPM_SUSPENDED = 2,
    RPM_SUSPENDING = 3
} ;
#line 296
enum rpm_request {
    RPM_REQ_NONE = 0,
    RPM_REQ_IDLE = 1,
    RPM_REQ_SUSPEND = 2,
    RPM_REQ_AUTOSUSPEND = 3,
    RPM_REQ_RESUME = 4
} ;
#line 304
struct wakeup_source;
#line 494 "include/linux/pm.h"
struct pm_subsys_data {
   spinlock_t lock ;
   unsigned int refcount ;
};
#line 499
struct dev_pm_qos_request;
#line 499
struct pm_qos_constraints;
#line 499 "include/linux/pm.h"
struct dev_pm_info {
   pm_message_t power_state ;
   unsigned char can_wakeup : 1 ;
   unsigned char async_suspend : 1 ;
   bool is_prepared ;
   bool is_suspended ;
   bool ignore_children ;
   bool early_init ;
   spinlock_t lock ;
   struct list_head entry ;
   struct completion completion ;
   struct wakeup_source *wakeup ;
   bool wakeup_path ;
   bool syscore ;
   struct timer_list suspend_timer ;
   unsigned long timer_expires ;
   struct work_struct work ;
   wait_queue_head_t wait_queue ;
   atomic_t usage_count ;
   atomic_t child_count ;
   unsigned char disable_depth : 3 ;
   unsigned char idle_notification : 1 ;
   unsigned char request_pending : 1 ;
   unsigned char deferred_resume : 1 ;
   unsigned char run_wake : 1 ;
   unsigned char runtime_auto : 1 ;
   unsigned char no_callbacks : 1 ;
   unsigned char irq_safe : 1 ;
   unsigned char use_autosuspend : 1 ;
   unsigned char timer_autosuspends : 1 ;
   enum rpm_request request ;
   enum rpm_status runtime_status ;
   int runtime_error ;
   int autosuspend_delay ;
   unsigned long last_busy ;
   unsigned long active_jiffies ;
   unsigned long suspended_jiffies ;
   unsigned long accounting_timestamp ;
   struct dev_pm_qos_request *pq_req ;
   struct pm_subsys_data *subsys_data ;
   struct pm_qos_constraints *constraints ;
};
#line 558 "include/linux/pm.h"
struct dev_pm_domain {
   struct dev_pm_ops ops ;
};
#line 98 "include/linux/nodemask.h"
struct __anonstruct_nodemask_t_100 {
   unsigned long bits[16U] ;
};
#line 98 "include/linux/nodemask.h"
typedef struct __anonstruct_nodemask_t_100 nodemask_t;
#line 22 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/mmu.h"
struct __anonstruct_mm_context_t_101 {
   void *ldt ;
   int size ;
   unsigned short ia32_compat ;
   struct mutex lock ;
   void *vdso ;
};
#line 22 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/mmu.h"
typedef struct __anonstruct_mm_context_t_101 mm_context_t;
#line 68 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/xen/hypervisor.h"
struct bio_vec;
#line 721 "include/linux/mmzone.h"
struct rw_semaphore;
#line 722 "include/linux/mmzone.h"
struct rw_semaphore {
   long count ;
   raw_spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct lockdep_map dep_map ;
};
#line 189 "include/linux/rcupdate.h"
struct notifier_block;
#line 269 "include/linux/srcu.h"
struct notifier_block {
   int (*notifier_call)(struct notifier_block * , unsigned long  , void * ) ;
   struct notifier_block *next ;
   int priority ;
};
#line 60 "include/linux/notifier.h"
struct blocking_notifier_head {
   struct rw_semaphore rwsem ;
   struct notifier_block *head ;
};
#line 855 "include/linux/mmzone.h"
struct ctl_table;
#line 345 "include/linux/irq.h"
struct proc_dir_entry;
#line 189 "include/linux/hardirq.h"
struct hlist_nulls_node;
#line 189 "include/linux/hardirq.h"
struct hlist_nulls_head {
   struct hlist_nulls_node *first ;
};
#line 20 "include/linux/list_nulls.h"
struct hlist_nulls_node {
   struct hlist_nulls_node *next ;
   struct hlist_nulls_node **pprev ;
};
#line 85 "include/linux/list_nulls.h"
struct plist_head {
   struct list_head node_list ;
};
#line 84 "include/linux/plist.h"
struct plist_node {
   int prio ;
   struct list_head prio_list ;
   struct list_head node_list ;
};
#line 64 "include/linux/miscdevice.h"
struct sock;
#line 65
struct kobject;
#line 66
enum kobj_ns_type {
    KOBJ_NS_TYPE_NONE = 0,
    KOBJ_NS_TYPE_NET = 1,
    KOBJ_NS_TYPES = 2
} ;
#line 72 "include/linux/miscdevice.h"
struct kobj_ns_type_operations {
   enum kobj_ns_type type ;
   void *(*grab_current_ns)(void) ;
   void const   *(*netlink_ns)(struct sock * ) ;
   void const   *(*initial_ns)(void) ;
   void (*drop_ns)(void * ) ;
};
#line 57 "include/linux/kobject_ns.h"
struct attribute {
   char const   *name ;
   umode_t mode ;
   bool ignore_lockdep ;
   struct lock_class_key *key ;
   struct lock_class_key skey ;
};
#line 34 "include/linux/sysfs.h"
struct attribute_group {
   char const   *name ;
   umode_t (*is_visible)(struct kobject * , struct attribute * , int  ) ;
   struct attribute **attrs ;
};
#line 63 "include/linux/sysfs.h"
struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                   loff_t  , size_t  ) ;
   ssize_t (*write)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                    loff_t  , size_t  ) ;
   int (*mmap)(struct file * , struct kobject * , struct bin_attribute * , struct vm_area_struct * ) ;
};
#line 110 "include/linux/sysfs.h"
struct sysfs_ops {
   ssize_t (*show)(struct kobject * , struct attribute * , char * ) ;
   ssize_t (*store)(struct kobject * , struct attribute * , char const   * , size_t  ) ;
   void const   *(*namespace)(struct kobject * , struct attribute  const  * ) ;
};
#line 129
struct sysfs_dirent;
#line 194 "include/linux/sysfs.h"
struct kref {
   atomic_t refcount ;
};
#line 49 "include/linux/kobject.h"
struct kset;
#line 49
struct kobj_type;
#line 49 "include/linux/kobject.h"
struct kobject {
   char const   *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct sysfs_dirent *sd ;
   struct kref kref ;
   unsigned char state_initialized : 1 ;
   unsigned char state_in_sysfs : 1 ;
   unsigned char state_add_uevent_sent : 1 ;
   unsigned char state_remove_uevent_sent : 1 ;
   unsigned char uevent_suppress : 1 ;
};
#line 107 "include/linux/kobject.h"
struct kobj_type {
   void (*release)(struct kobject * ) ;
   struct sysfs_ops  const  *sysfs_ops ;
   struct attribute **default_attrs ;
   struct kobj_ns_type_operations  const  *(*child_ns_type)(struct kobject * ) ;
   void const   *(*namespace)(struct kobject * ) ;
};
#line 115 "include/linux/kobject.h"
struct kobj_uevent_env {
   char *envp[32U] ;
   int envp_idx ;
   char buf[2048U] ;
   int buflen ;
};
#line 122 "include/linux/kobject.h"
struct kset_uevent_ops {
   int (* const  filter)(struct kset * , struct kobject * ) ;
   char const   *(* const  name)(struct kset * , struct kobject * ) ;
   int (* const  uevent)(struct kset * , struct kobject * , struct kobj_uevent_env * ) ;
};
#line 139 "include/linux/kobject.h"
struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops  const  *uevent_ops ;
};
#line 215
struct klist_node;
#line 37 "include/linux/klist.h"
struct klist_node {
   void *n_klist ;
   struct list_head n_node ;
   struct kref n_ref ;
};
#line 67 "include/linux/klist.h"
struct ratelimit_state {
   raw_spinlock_t lock ;
   int interval ;
   int burst ;
   int printed ;
   int missed ;
   unsigned long begin ;
};
#line 42 "include/linux/ratelimit.h"
struct dma_map_ops;
#line 42 "include/linux/ratelimit.h"
struct dev_archdata {
   void *acpi_handle ;
   struct dma_map_ops *dma_ops ;
   void *iommu ;
};
#line 17 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/device.h"
struct device_private;
#line 18
struct device_driver;
#line 19
struct driver_private;
#line 20
struct class;
#line 21
struct subsys_private;
#line 22
struct bus_type;
#line 23
struct device_node;
#line 24
struct iommu_ops;
#line 25
struct iommu_group;
#line 26 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/device.h"
struct bus_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct bus_type * , char * ) ;
   ssize_t (*store)(struct bus_type * , char const   * , size_t  ) ;
};
#line 53 "include/linux/device.h"
struct device_attribute;
#line 53
struct driver_attribute;
#line 53 "include/linux/device.h"
struct bus_type {
   char const   *name ;
   char const   *dev_name ;
   struct device *dev_root ;
   struct bus_attribute *bus_attrs ;
   struct device_attribute *dev_attrs ;
   struct driver_attribute *drv_attrs ;
   int (*match)(struct device * , struct device_driver * ) ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct iommu_ops *iommu_ops ;
   struct subsys_private *p ;
};
#line 127
struct device_type;
#line 184
struct of_device_id;
#line 184 "include/linux/device.h"
struct device_driver {
   char const   *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const   *mod_name ;
   bool suppress_bind_attrs ;
   struct of_device_id  const  *of_match_table ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct attribute_group  const  **groups ;
   struct dev_pm_ops  const  *pm ;
   struct driver_private *p ;
};
#line 247 "include/linux/device.h"
struct driver_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device_driver * , char * ) ;
   ssize_t (*store)(struct device_driver * , char const   * , size_t  ) ;
};
#line 301
struct class_attribute;
#line 301 "include/linux/device.h"
struct class {
   char const   *name ;
   struct module *owner ;
   struct class_attribute *class_attrs ;
   struct device_attribute *dev_attrs ;
   struct bin_attribute *dev_bin_attrs ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * ) ;
   void (*class_release)(struct class * ) ;
   void (*dev_release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct kobj_ns_type_operations  const  *ns_type ;
   void const   *(*namespace)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct subsys_private *p ;
};
#line 396 "include/linux/device.h"
struct class_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct class * , struct class_attribute * , char * ) ;
   ssize_t (*store)(struct class * , struct class_attribute * , char const   * , size_t  ) ;
   void const   *(*namespace)(struct class * , struct class_attribute  const  * ) ;
};
#line 449 "include/linux/device.h"
struct device_type {
   char const   *name ;
   struct attribute_group  const  **groups ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * ) ;
   void (*release)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
};
#line 476 "include/linux/device.h"
struct device_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device * , struct device_attribute * , char * ) ;
   ssize_t (*store)(struct device * , struct device_attribute * , char const   * ,
                    size_t  ) ;
};
#line 568 "include/linux/device.h"
struct device_dma_parameters {
   unsigned int max_segment_size ;
   unsigned long segment_boundary_mask ;
};
#line 578
struct dma_coherent_mem;
#line 578 "include/linux/device.h"
struct device {
   struct device *parent ;
   struct device_private *p ;
   struct kobject kobj ;
   char const   *init_name ;
   struct device_type  const  *type ;
   struct mutex mutex ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *platform_data ;
   struct dev_pm_info power ;
   struct dev_pm_domain *pm_domain ;
   int numa_node ;
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct dev_archdata archdata ;
   struct device_node *of_node ;
   dev_t devt ;
   u32 id ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct klist_node knode_class ;
   struct class *class ;
   struct attribute_group  const  **groups ;
   void (*release)(struct device * ) ;
   struct iommu_group *iommu_group ;
};
#line 703 "include/linux/device.h"
struct wakeup_source {
   char const   *name ;
   struct list_head entry ;
   spinlock_t lock ;
   struct timer_list timer ;
   unsigned long timer_expires ;
   ktime_t total_time ;
   ktime_t max_time ;
   ktime_t last_time ;
   ktime_t start_prevent_time ;
   ktime_t prevent_sleep_time ;
   unsigned long event_count ;
   unsigned long active_count ;
   unsigned long relax_count ;
   unsigned long expire_count ;
   unsigned long wakeup_count ;
   bool active ;
   bool autosleep_enabled ;
};
#line 1076 "include/linux/device.h"
struct pm_qos_request {
   struct plist_node node ;
   int pm_qos_class ;
   struct delayed_work work ;
};
#line 35 "include/linux/pm_qos.h"
struct dev_pm_qos_request {
   struct plist_node node ;
   struct device *dev ;
};
#line 40
enum pm_qos_type {
    PM_QOS_UNITIALIZED = 0,
    PM_QOS_MAX = 1,
    PM_QOS_MIN = 2
} ;
#line 46 "include/linux/pm_qos.h"
struct pm_qos_constraints {
   struct plist_head list ;
   s32 target_value ;
   s32 default_value ;
   enum pm_qos_type type ;
   struct blocking_notifier_head *notifiers ;
};
#line 457 "include/linux/rculist.h"
struct iovec {
   void *iov_base ;
   __kernel_size_t iov_len ;
};
#line 38 "include/linux/uio.h"
struct rb_node {
   unsigned long __rb_parent_color ;
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};
#line 40 "include/linux/rbtree.h"
struct rb_root {
   struct rb_node *rb_node ;
};
#line 88
struct inode;
#line 42 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/uprobes.h"
struct arch_uprobe_task {
   unsigned long saved_scratch_register ;
   unsigned int saved_trap_nr ;
   unsigned int saved_tf ;
};
#line 48 "include/linux/uprobes.h"
enum uprobe_task_state {
    UTASK_RUNNING = 0,
    UTASK_SSTEP = 1,
    UTASK_SSTEP_ACK = 2,
    UTASK_SSTEP_TRAPPED = 3
} ;
#line 55
struct uprobe;
#line 55 "include/linux/uprobes.h"
struct uprobe_task {
   enum uprobe_task_state state ;
   struct arch_uprobe_task autask ;
   struct uprobe *active_uprobe ;
   unsigned long xol_vaddr ;
   unsigned long vaddr ;
};
#line 69 "include/linux/uprobes.h"
struct xol_area {
   wait_queue_head_t wq ;
   atomic_t slot_count ;
   unsigned long *bitmap ;
   struct page *page ;
   unsigned long vaddr ;
};
#line 88 "include/linux/uprobes.h"
struct uprobes_state {
   struct xol_area *xol_area ;
};
#line 112
struct address_space;
#line 113 "include/linux/uprobes.h"
union __anonunion_ldv_14711_130 {
   unsigned long index ;
   void *freelist ;
   bool pfmemalloc ;
};
#line 113 "include/linux/uprobes.h"
struct __anonstruct_ldv_14721_134 {
   unsigned short inuse ;
   unsigned short objects : 15 ;
   unsigned char frozen : 1 ;
};
#line 113 "include/linux/uprobes.h"
union __anonunion_ldv_14723_133 {
   atomic_t _mapcount ;
   struct __anonstruct_ldv_14721_134 ldv_14721 ;
   int units ;
};
#line 113 "include/linux/uprobes.h"
struct __anonstruct_ldv_14725_132 {
   union __anonunion_ldv_14723_133 ldv_14723 ;
   atomic_t _count ;
};
#line 113 "include/linux/uprobes.h"
union __anonunion_ldv_14726_131 {
   unsigned long counters ;
   struct __anonstruct_ldv_14725_132 ldv_14725 ;
};
#line 113 "include/linux/uprobes.h"
struct __anonstruct_ldv_14727_129 {
   union __anonunion_ldv_14711_130 ldv_14711 ;
   union __anonunion_ldv_14726_131 ldv_14726 ;
};
#line 113 "include/linux/uprobes.h"
struct __anonstruct_ldv_14734_136 {
   struct page *next ;
   int pages ;
   int pobjects ;
};
#line 113
struct slab;
#line 113 "include/linux/uprobes.h"
struct __anonstruct_ldv_14740_137 {
   struct kmem_cache *slab_cache ;
   struct slab *slab_page ;
};
#line 113 "include/linux/uprobes.h"
union __anonunion_ldv_14741_135 {
   struct list_head lru ;
   struct __anonstruct_ldv_14734_136 ldv_14734 ;
   struct list_head list ;
   struct __anonstruct_ldv_14740_137 ldv_14740 ;
};
#line 113 "include/linux/uprobes.h"
union __anonunion_ldv_14746_138 {
   unsigned long private ;
   struct kmem_cache *slab ;
   struct page *first_page ;
};
#line 113 "include/linux/uprobes.h"
struct page {
   unsigned long flags ;
   struct address_space *mapping ;
   struct __anonstruct_ldv_14727_129 ldv_14727 ;
   union __anonunion_ldv_14741_135 ldv_14741 ;
   union __anonunion_ldv_14746_138 ldv_14746 ;
   unsigned long debug_flags ;
};
#line 170 "include/linux/mm_types.h"
struct page_frag {
   struct page *page ;
   __u32 offset ;
   __u32 size ;
};
#line 218 "include/linux/mm_types.h"
struct __anonstruct_linear_140 {
   struct rb_node rb ;
   unsigned long rb_subtree_last ;
};
#line 218 "include/linux/mm_types.h"
union __anonunion_shared_139 {
   struct __anonstruct_linear_140 linear ;
   struct list_head nonlinear ;
};
#line 218
struct anon_vma;
#line 218
struct vm_operations_struct;
#line 218
struct mempolicy;
#line 218 "include/linux/mm_types.h"
struct vm_area_struct {
   struct mm_struct *vm_mm ;
   unsigned long vm_start ;
   unsigned long vm_end ;
   struct vm_area_struct *vm_next ;
   struct vm_area_struct *vm_prev ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
   struct rb_node vm_rb ;
   union __anonunion_shared_139 shared ;
   struct list_head anon_vma_chain ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct  const  *vm_ops ;
   unsigned long vm_pgoff ;
   struct file *vm_file ;
   void *vm_private_data ;
   struct mempolicy *vm_policy ;
};
#line 278 "include/linux/mm_types.h"
struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};
#line 284 "include/linux/mm_types.h"
struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};
#line 297 "include/linux/mm_types.h"
struct mm_rss_stat {
   atomic_long_t count[3U] ;
};
#line 310
struct linux_binfmt;
#line 310
struct mmu_notifier_mm;
#line 310 "include/linux/mm_types.h"
struct mm_struct {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   struct vm_area_struct *mmap_cache ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   void (*unmap_area)(struct mm_struct * , unsigned long  ) ;
   unsigned long mmap_base ;
   unsigned long task_size ;
   unsigned long cached_hole_size ;
   unsigned long free_area_cache ;
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   int map_count ;
   spinlock_t page_table_lock ;
   struct rw_semaphore mmap_sem ;
   struct list_head mmlist ;
   unsigned long hiwater_rss ;
   unsigned long hiwater_vm ;
   unsigned long total_vm ;
   unsigned long locked_vm ;
   unsigned long pinned_vm ;
   unsigned long shared_vm ;
   unsigned long exec_vm ;
   unsigned long stack_vm ;
   unsigned long def_flags ;
   unsigned long nr_ptes ;
   unsigned long start_code ;
   unsigned long end_code ;
   unsigned long start_data ;
   unsigned long end_data ;
   unsigned long start_brk ;
   unsigned long brk ;
   unsigned long start_stack ;
   unsigned long arg_start ;
   unsigned long arg_end ;
   unsigned long env_start ;
   unsigned long env_end ;
   unsigned long saved_auxv[44U] ;
   struct mm_rss_stat rss_stat ;
   struct linux_binfmt *binfmt ;
   cpumask_var_t cpu_vm_mask_var ;
   mm_context_t context ;
   unsigned long flags ;
   struct core_state *core_state ;
   spinlock_t ioctx_lock ;
   struct hlist_head ioctx_list ;
   struct task_struct *owner ;
   struct file *exe_file ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
   pgtable_t pmd_huge_pte ;
   struct cpumask cpumask_allocation ;
   struct uprobes_state uprobes_state ;
};
#line 93 "include/linux/bit_spinlock.h"
struct shrink_control {
   gfp_t gfp_mask ;
   unsigned long nr_to_scan ;
};
#line 14 "include/linux/shrinker.h"
struct shrinker {
   int (*shrink)(struct shrinker * , struct shrink_control * ) ;
   int seeks ;
   long batch ;
   struct list_head list ;
   atomic_long_t nr_in_batch ;
};
#line 43
struct file_ra_state;
#line 44
struct user_struct;
#line 45
struct writeback_control;
#line 157 "include/linux/mm.h"
struct vm_fault {
   unsigned int flags ;
   unsigned long pgoff ;
   void *virtual_address ;
   struct page *page ;
};
#line 181 "include/linux/mm.h"
struct vm_operations_struct {
   void (*open)(struct vm_area_struct * ) ;
   void (*close)(struct vm_area_struct * ) ;
   int (*fault)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*page_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*access)(struct vm_area_struct * , unsigned long  , void * , int  , int  ) ;
   int (*set_policy)(struct vm_area_struct * , struct mempolicy * ) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct * , unsigned long  ) ;
   int (*migrate)(struct vm_area_struct * , nodemask_t const   * , nodemask_t const   * ,
                  unsigned long  ) ;
   int (*remap_pages)(struct vm_area_struct * , unsigned long  , unsigned long  ,
                      unsigned long  ) ;
};
#line 1689 "include/linux/mm.h"
struct scatterlist {
   unsigned long sg_magic ;
   unsigned long page_link ;
   unsigned int offset ;
   unsigned int length ;
   dma_addr_t dma_address ;
   unsigned int dma_length ;
};
#line 17 "include/asm-generic/scatterlist.h"
struct sg_table {
   struct scatterlist *sgl ;
   unsigned int nents ;
   unsigned int orig_nents ;
};
#line 37 "include/linux/dmaengine.h"
typedef s32 dma_cookie_t;
#line 1024 "include/linux/dmaengine.h"
struct dql {
   unsigned int num_queued ;
   unsigned int adj_limit ;
   unsigned int last_obj_cnt ;
   unsigned int limit ;
   unsigned int num_completed ;
   unsigned int prev_ovlimit ;
   unsigned int prev_num_queued ;
   unsigned int prev_last_obj_cnt ;
   unsigned int lowest_slack ;
   unsigned long slack_start_time ;
   unsigned int max_limit ;
   unsigned int min_limit ;
   unsigned int slack_hold_time ;
};
#line 83 "include/linux/highuid.h"
struct user_namespace;
#line 46 "include/linux/uidgid.h"
typedef uid_t kuid_t;
#line 47 "include/linux/uidgid.h"
typedef gid_t kgid_t;
#line 197 "include/linux/uidgid.h"
struct kstat {
   u64 ino ;
   dev_t dev ;
   umode_t mode ;
   unsigned int nlink ;
   kuid_t uid ;
   kgid_t gid ;
   dev_t rdev ;
   loff_t size ;
   struct timespec atime ;
   struct timespec mtime ;
   struct timespec ctime ;
   unsigned long blksize ;
   unsigned long long blocks ;
};
#line 23 "include/linux/sem.h"
struct sem_undo_list;
#line 23 "include/linux/sem.h"
struct sysv_sem {
   struct sem_undo_list *undo_list ;
};
#line 11 "include/uapi/linux/socket.h"
typedef unsigned short __kernel_sa_family_t;
#line 12 "include/uapi/linux/socket.h"
struct __kernel_sockaddr_storage {
   __kernel_sa_family_t ss_family ;
   char __data[126U] ;
};
#line 18
struct cred;
#line 23 "include/linux/socket.h"
typedef __kernel_sa_family_t sa_family_t;
#line 24 "include/linux/socket.h"
struct sockaddr {
   sa_family_t sa_family ;
   char sa_data[14U] ;
};
#line 38 "include/linux/socket.h"
struct msghdr {
   void *msg_name ;
   int msg_namelen ;
   struct iovec *msg_iov ;
   __kernel_size_t msg_iovlen ;
   void *msg_control ;
   __kernel_size_t msg_controllen ;
   unsigned int msg_flags ;
};
#line 41 "include/linux/hdlc/ioctl.h"
struct __anonstruct_sync_serial_settings_142 {
   unsigned int clock_rate ;
   unsigned int clock_type ;
   unsigned short loopback ;
};
#line 41 "include/linux/hdlc/ioctl.h"
typedef struct __anonstruct_sync_serial_settings_142 sync_serial_settings;
#line 48 "include/linux/hdlc/ioctl.h"
struct __anonstruct_te1_settings_143 {
   unsigned int clock_rate ;
   unsigned int clock_type ;
   unsigned short loopback ;
   unsigned int slot_map ;
};
#line 48 "include/linux/hdlc/ioctl.h"
typedef struct __anonstruct_te1_settings_143 te1_settings;
#line 53 "include/linux/hdlc/ioctl.h"
struct __anonstruct_raw_hdlc_proto_144 {
   unsigned short encoding ;
   unsigned short parity ;
};
#line 53 "include/linux/hdlc/ioctl.h"
typedef struct __anonstruct_raw_hdlc_proto_144 raw_hdlc_proto;
#line 63 "include/linux/hdlc/ioctl.h"
struct __anonstruct_fr_proto_145 {
   unsigned int t391 ;
   unsigned int t392 ;
   unsigned int n391 ;
   unsigned int n392 ;
   unsigned int n393 ;
   unsigned short lmi ;
   unsigned short dce ;
};
#line 63 "include/linux/hdlc/ioctl.h"
typedef struct __anonstruct_fr_proto_145 fr_proto;
#line 67 "include/linux/hdlc/ioctl.h"
struct __anonstruct_fr_proto_pvc_146 {
   unsigned int dlci ;
};
#line 67 "include/linux/hdlc/ioctl.h"
typedef struct __anonstruct_fr_proto_pvc_146 fr_proto_pvc;
#line 72 "include/linux/hdlc/ioctl.h"
struct __anonstruct_fr_proto_pvc_info_147 {
   unsigned int dlci ;
   char master[16U] ;
};
#line 72 "include/linux/hdlc/ioctl.h"
typedef struct __anonstruct_fr_proto_pvc_info_147 fr_proto_pvc_info;
#line 77 "include/linux/hdlc/ioctl.h"
struct __anonstruct_cisco_proto_148 {
   unsigned int interval ;
   unsigned int timeout ;
};
#line 77 "include/linux/hdlc/ioctl.h"
typedef struct __anonstruct_cisco_proto_148 cisco_proto;
#line 93 "include/linux/hdlc/ioctl.h"
struct ifmap {
   unsigned long mem_start ;
   unsigned long mem_end ;
   unsigned short base_addr ;
   unsigned char irq ;
   unsigned char dma ;
   unsigned char port ;
};
#line 150 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/if.h"
union __anonunion_ifs_ifsu_149 {
   raw_hdlc_proto *raw_hdlc ;
   cisco_proto *cisco ;
   fr_proto *fr ;
   fr_proto_pvc *fr_pvc ;
   fr_proto_pvc_info *fr_pvc_info ;
   sync_serial_settings *sync ;
   te1_settings *te1 ;
};
#line 150 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/if.h"
struct if_settings {
   unsigned int type ;
   unsigned int size ;
   union __anonunion_ifs_ifsu_149 ifs_ifsu ;
};
#line 168 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/if.h"
union __anonunion_ifr_ifrn_150 {
   char ifrn_name[16U] ;
};
#line 168 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/if.h"
union __anonunion_ifr_ifru_151 {
   struct sockaddr ifru_addr ;
   struct sockaddr ifru_dstaddr ;
   struct sockaddr ifru_broadaddr ;
   struct sockaddr ifru_netmask ;
   struct sockaddr ifru_hwaddr ;
   short ifru_flags ;
   int ifru_ivalue ;
   int ifru_mtu ;
   struct ifmap ifru_map ;
   char ifru_slave[16U] ;
   char ifru_newname[16U] ;
   void *ifru_data ;
   struct if_settings ifru_settings ;
};
#line 168 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/if.h"
struct ifreq {
   union __anonunion_ifr_ifrn_150 ifr_ifrn ;
   union __anonunion_ifr_ifru_151 ifr_ifru ;
};
#line 91 "include/linux/kdev_t.h"
struct hlist_bl_node;
#line 91 "include/linux/kdev_t.h"
struct hlist_bl_head {
   struct hlist_bl_node *first ;
};
#line 36 "include/linux/list_bl.h"
struct hlist_bl_node {
   struct hlist_bl_node *next ;
   struct hlist_bl_node **pprev ;
};
#line 114 "include/linux/rculist_bl.h"
struct nameidata;
#line 115
struct path;
#line 116
struct vfsmount;
#line 117 "include/linux/rculist_bl.h"
struct __anonstruct_ldv_18552_154 {
   u32 hash ;
   u32 len ;
};
#line 117 "include/linux/rculist_bl.h"
union __anonunion_ldv_18554_153 {
   struct __anonstruct_ldv_18552_154 ldv_18552 ;
   u64 hash_len ;
};
#line 117 "include/linux/rculist_bl.h"
struct qstr {
   union __anonunion_ldv_18554_153 ldv_18554 ;
   unsigned char const   *name ;
};
#line 87 "include/linux/dcache.h"
struct dentry_operations;
#line 87
struct super_block;
#line 87 "include/linux/dcache.h"
union __anonunion_d_u_155 {
   struct list_head d_child ;
   struct callback_head d_rcu ;
};
#line 87 "include/linux/dcache.h"
struct dentry {
   unsigned int d_flags ;
   seqcount_t d_seq ;
   struct hlist_bl_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct inode *d_inode ;
   unsigned char d_iname[32U] ;
   unsigned int d_count ;
   spinlock_t d_lock ;
   struct dentry_operations  const  *d_op ;
   struct super_block *d_sb ;
   unsigned long d_time ;
   void *d_fsdata ;
   struct list_head d_lru ;
   union __anonunion_d_u_155 d_u ;
   struct list_head d_subdirs ;
   struct hlist_node d_alias ;
};
#line 138 "include/linux/dcache.h"
struct dentry_operations {
   int (*d_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_hash)(struct dentry  const  * , struct inode  const  * , struct qstr * ) ;
   int (*d_compare)(struct dentry  const  * , struct inode  const  * , struct dentry  const  * ,
                    struct inode  const  * , unsigned int  , char const   * , struct qstr  const  * ) ;
   int (*d_delete)(struct dentry  const  * ) ;
   void (*d_release)(struct dentry * ) ;
   void (*d_prune)(struct dentry * ) ;
   void (*d_iput)(struct dentry * , struct inode * ) ;
   char *(*d_dname)(struct dentry * , char * , int  ) ;
   struct vfsmount *(*d_automount)(struct path * ) ;
   int (*d_manage)(struct dentry * , bool  ) ;
};
#line 419 "include/linux/dcache.h"
struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};
#line 58 "include/linux/radix-tree.h"
struct radix_tree_node;
#line 58 "include/linux/radix-tree.h"
struct radix_tree_root {
   unsigned int height ;
   gfp_t gfp_mask ;
   struct radix_tree_node *rnode ;
};
#line 380
enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_PGID = 1,
    PIDTYPE_SID = 2,
    PIDTYPE_MAX = 3
} ;
#line 387
struct pid_namespace;
#line 387 "include/linux/radix-tree.h"
struct upid {
   int nr ;
   struct pid_namespace *ns ;
   struct hlist_node pid_chain ;
};
#line 56 "include/linux/pid.h"
struct pid {
   atomic_t count ;
   unsigned int level ;
   struct hlist_head tasks[3U] ;
   struct callback_head rcu ;
   struct upid numbers[1U] ;
};
#line 68 "include/linux/pid.h"
struct pid_link {
   struct hlist_node node ;
   struct pid *pid ;
};
#line 22 "include/linux/capability.h"
struct kernel_cap_struct {
   __u32 cap[2U] ;
};
#line 25 "include/linux/capability.h"
typedef struct kernel_cap_struct kernel_cap_t;
#line 45 "include/linux/semaphore.h"
struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};
#line 38 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/fiemap.h"
enum migrate_mode {
    MIGRATE_ASYNC = 0,
    MIGRATE_SYNC_LIGHT = 1,
    MIGRATE_SYNC = 2
} ;
#line 44 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/fiemap.h"
struct percpu_rw_semaphore {
   unsigned int *counters ;
   bool locked ;
   struct mutex mtx ;
};
#line 82 "include/linux/percpu-rwsem.h"
struct bio_set;
#line 83
struct bio;
#line 84
struct bio_integrity_payload;
#line 85
struct block_device;
#line 86
struct io_context;
#line 87
struct cgroup_subsys_state;
#line 19 "include/linux/blk_types.h"
typedef void bio_end_io_t(struct bio * , int  );
#line 21 "include/linux/blk_types.h"
struct bio_vec {
   struct page *bv_page ;
   unsigned int bv_len ;
   unsigned int bv_offset ;
};
#line 30 "include/linux/blk_types.h"
struct bio {
   sector_t bi_sector ;
   struct bio *bi_next ;
   struct block_device *bi_bdev ;
   unsigned long bi_flags ;
   unsigned long bi_rw ;
   unsigned short bi_vcnt ;
   unsigned short bi_idx ;
   unsigned int bi_phys_segments ;
   unsigned int bi_size ;
   unsigned int bi_seg_front_size ;
   unsigned int bi_seg_back_size ;
   bio_end_io_t *bi_end_io ;
   void *bi_private ;
   struct io_context *bi_ioc ;
   struct cgroup_subsys_state *bi_css ;
   struct bio_integrity_payload *bi_integrity ;
   unsigned int bi_max_vecs ;
   atomic_t bi_cnt ;
   struct bio_vec *bi_io_vec ;
   struct bio_set *bi_pool ;
   struct bio_vec bi_inline_vecs[0U] ;
};
#line 56 "include/uapi/linux/fs.h"
struct export_operations;
#line 57
struct hd_geometry;
#line 58
struct kiocb;
#line 59
struct pipe_inode_info;
#line 60
struct poll_table_struct;
#line 61
struct kstatfs;
#line 62
struct swap_info_struct;
#line 64 "include/linux/fs.h"
struct iattr {
   unsigned int ia_valid ;
   umode_t ia_mode ;
   kuid_t ia_uid ;
   kgid_t ia_gid ;
   loff_t ia_size ;
   struct timespec ia_atime ;
   struct timespec ia_mtime ;
   struct timespec ia_ctime ;
   struct file *ia_file ;
};
#line 240 "include/linux/fs.h"
struct percpu_counter {
   raw_spinlock_t lock ;
   s64 count ;
   struct list_head list ;
   s32 *counters ;
};
#line 176 "include/linux/percpu_counter.h"
struct fs_disk_quota {
   __s8 d_version ;
   __s8 d_flags ;
   __u16 d_fieldmask ;
   __u32 d_id ;
   __u64 d_blk_hardlimit ;
   __u64 d_blk_softlimit ;
   __u64 d_ino_hardlimit ;
   __u64 d_ino_softlimit ;
   __u64 d_bcount ;
   __u64 d_icount ;
   __s32 d_itimer ;
   __s32 d_btimer ;
   __u16 d_iwarns ;
   __u16 d_bwarns ;
   __s32 d_padding2 ;
   __u64 d_rtb_hardlimit ;
   __u64 d_rtb_softlimit ;
   __u64 d_rtbcount ;
   __s32 d_rtbtimer ;
   __u16 d_rtbwarns ;
   __s16 d_padding3 ;
   char d_padding4[8U] ;
};
#line 75 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dqblk_xfs.h"
struct fs_qfilestat {
   __u64 qfs_ino ;
   __u64 qfs_nblks ;
   __u32 qfs_nextents ;
};
#line 150 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dqblk_xfs.h"
typedef struct fs_qfilestat fs_qfilestat_t;
#line 151 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dqblk_xfs.h"
struct fs_quota_stat {
   __s8 qs_version ;
   __u16 qs_flags ;
   __s8 qs_pad ;
   fs_qfilestat_t qs_uquota ;
   fs_qfilestat_t qs_gquota ;
   __u32 qs_incoredqs ;
   __s32 qs_btimelimit ;
   __s32 qs_itimelimit ;
   __s32 qs_rtbtimelimit ;
   __u16 qs_bwarnlimit ;
   __u16 qs_iwarnlimit ;
};
#line 165
struct dquot;
#line 19 "include/linux/projid.h"
typedef __kernel_uid32_t projid_t;
#line 36 "include/linux/projid.h"
typedef projid_t kprojid_t;
#line 119 "include/uapi/linux/quota.h"
struct if_dqinfo {
   __u64 dqi_bgrace ;
   __u64 dqi_igrace ;
   __u32 dqi_flags ;
   __u32 dqi_valid ;
};
#line 152
enum quota_type {
    USRQUOTA = 0,
    GRPQUOTA = 1,
    PRJQUOTA = 2
} ;
#line 60 "include/linux/quota.h"
typedef long long qsize_t;
#line 61 "include/linux/quota.h"
union __anonunion_ldv_19713_157 {
   kuid_t uid ;
   kgid_t gid ;
   kprojid_t projid ;
};
#line 61 "include/linux/quota.h"
struct kqid {
   union __anonunion_ldv_19713_157 ldv_19713 ;
   enum quota_type type ;
};
#line 178 "include/linux/quota.h"
struct mem_dqblk {
   qsize_t dqb_bhardlimit ;
   qsize_t dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   qsize_t dqb_rsvspace ;
   qsize_t dqb_ihardlimit ;
   qsize_t dqb_isoftlimit ;
   qsize_t dqb_curinodes ;
   time_t dqb_btime ;
   time_t dqb_itime ;
};
#line 200
struct quota_format_type;
#line 201 "include/linux/quota.h"
struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
   unsigned int dqi_bgrace ;
   unsigned int dqi_igrace ;
   qsize_t dqi_maxblimit ;
   qsize_t dqi_maxilimit ;
   void *dqi_priv ;
};
#line 264 "include/linux/quota.h"
struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   atomic_t dq_count ;
   wait_queue_head_t dq_wait_unused ;
   struct super_block *dq_sb ;
   struct kqid dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
   struct mem_dqblk dq_dqb ;
};
#line 291 "include/linux/quota.h"
struct quota_format_ops {
   int (*check_quota_file)(struct super_block * , int  ) ;
   int (*read_file_info)(struct super_block * , int  ) ;
   int (*write_file_info)(struct super_block * , int  ) ;
   int (*free_file_info)(struct super_block * , int  ) ;
   int (*read_dqblk)(struct dquot * ) ;
   int (*commit_dqblk)(struct dquot * ) ;
   int (*release_dqblk)(struct dquot * ) ;
};
#line 302 "include/linux/quota.h"
struct dquot_operations {
   int (*write_dquot)(struct dquot * ) ;
   struct dquot *(*alloc_dquot)(struct super_block * , int  ) ;
   void (*destroy_dquot)(struct dquot * ) ;
   int (*acquire_dquot)(struct dquot * ) ;
   int (*release_dquot)(struct dquot * ) ;
   int (*mark_dirty)(struct dquot * ) ;
   int (*write_info)(struct super_block * , int  ) ;
   qsize_t *(*get_reserved_space)(struct inode * ) ;
};
#line 316 "include/linux/quota.h"
struct quotactl_ops {
   int (*quota_on)(struct super_block * , int  , int  , struct path * ) ;
   int (*quota_on_meta)(struct super_block * , int  , int  ) ;
   int (*quota_off)(struct super_block * , int  ) ;
   int (*quota_sync)(struct super_block * , int  ) ;
   int (*get_info)(struct super_block * , int  , struct if_dqinfo * ) ;
   int (*set_info)(struct super_block * , int  , struct if_dqinfo * ) ;
   int (*get_dqblk)(struct super_block * , struct kqid  , struct fs_disk_quota * ) ;
   int (*set_dqblk)(struct super_block * , struct kqid  , struct fs_disk_quota * ) ;
   int (*get_xstate)(struct super_block * , struct fs_quota_stat * ) ;
   int (*set_xstate)(struct super_block * , unsigned int  , int  ) ;
};
#line 332 "include/linux/quota.h"
struct quota_format_type {
   int qf_fmt_id ;
   struct quota_format_ops  const  *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};
#line 378 "include/linux/quota.h"
struct quota_info {
   unsigned int flags ;
   struct mutex dqio_mutex ;
   struct mutex dqonoff_mutex ;
   struct rw_semaphore dqptr_sem ;
   struct inode *files[2U] ;
   struct mem_dqinfo info[2U] ;
   struct quota_format_ops  const  *ops[2U] ;
};
#line 339 "include/linux/fs.h"
union __anonunion_arg_159 {
   char *buf ;
   void *data ;
};
#line 339 "include/linux/fs.h"
struct __anonstruct_read_descriptor_t_158 {
   size_t written ;
   size_t count ;
   union __anonunion_arg_159 arg ;
   int error ;
};
#line 339 "include/linux/fs.h"
typedef struct __anonstruct_read_descriptor_t_158 read_descriptor_t;
#line 342 "include/linux/fs.h"
struct address_space_operations {
   int (*writepage)(struct page * , struct writeback_control * ) ;
   int (*readpage)(struct file * , struct page * ) ;
   int (*writepages)(struct address_space * , struct writeback_control * ) ;
   int (*set_page_dirty)(struct page * ) ;
   int (*readpages)(struct file * , struct address_space * , struct list_head * ,
                    unsigned int  ) ;
   int (*write_begin)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                      unsigned int  , struct page ** , void ** ) ;
   int (*write_end)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                    unsigned int  , struct page * , void * ) ;
   sector_t (*bmap)(struct address_space * , sector_t  ) ;
   void (*invalidatepage)(struct page * , unsigned long  ) ;
   int (*releasepage)(struct page * , gfp_t  ) ;
   void (*freepage)(struct page * ) ;
   ssize_t (*direct_IO)(int  , struct kiocb * , struct iovec  const  * , loff_t  ,
                        unsigned long  ) ;
   int (*get_xip_mem)(struct address_space * , unsigned long  , int  , void ** , unsigned long * ) ;
   int (*migratepage)(struct address_space * , struct page * , struct page * , enum migrate_mode  ) ;
   int (*launder_page)(struct page * ) ;
   int (*is_partially_uptodate)(struct page * , read_descriptor_t * , unsigned long  ) ;
   int (*error_remove_page)(struct address_space * , struct page * ) ;
   int (*swap_activate)(struct swap_info_struct * , struct file * , sector_t * ) ;
   void (*swap_deactivate)(struct file * ) ;
};
#line 401
struct backing_dev_info;
#line 402 "include/linux/fs.h"
struct address_space {
   struct inode *host ;
   struct radix_tree_root page_tree ;
   spinlock_t tree_lock ;
   unsigned int i_mmap_writable ;
   struct rb_root i_mmap ;
   struct list_head i_mmap_nonlinear ;
   struct mutex i_mmap_mutex ;
   unsigned long nrpages ;
   unsigned long writeback_index ;
   struct address_space_operations  const  *a_ops ;
   unsigned long flags ;
   struct backing_dev_info *backing_dev_info ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   struct address_space *assoc_mapping ;
};
#line 423
struct request_queue;
#line 424
struct hd_struct;
#line 424
struct gendisk;
#line 424 "include/linux/fs.h"
struct block_device {
   dev_t bd_dev ;
   int bd_openers ;
   struct inode *bd_inode ;
   struct super_block *bd_super ;
   struct mutex bd_mutex ;
   struct list_head bd_inodes ;
   void *bd_claiming ;
   void *bd_holder ;
   int bd_holders ;
   bool bd_write_holder ;
   struct list_head bd_holder_disks ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
   int bd_invalidated ;
   struct gendisk *bd_disk ;
   struct request_queue *bd_queue ;
   struct list_head bd_list ;
   unsigned long bd_private ;
   int bd_fsfreeze_count ;
   struct mutex bd_fsfreeze_mutex ;
   struct percpu_rw_semaphore bd_block_size_semaphore ;
};
#line 498
struct posix_acl;
#line 499
struct inode_operations;
#line 499 "include/linux/fs.h"
union __anonunion_ldv_20148_160 {
   unsigned int const   i_nlink ;
   unsigned int __i_nlink ;
};
#line 499 "include/linux/fs.h"
union __anonunion_ldv_20168_161 {
   struct hlist_head i_dentry ;
   struct callback_head i_rcu ;
};
#line 499
struct file_lock;
#line 499
struct cdev;
#line 499 "include/linux/fs.h"
union __anonunion_ldv_20184_162 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
};
#line 499 "include/linux/fs.h"
struct inode {
   umode_t i_mode ;
   unsigned short i_opflags ;
   kuid_t i_uid ;
   kgid_t i_gid ;
   unsigned int i_flags ;
   struct posix_acl *i_acl ;
   struct posix_acl *i_default_acl ;
   struct inode_operations  const  *i_op ;
   struct super_block *i_sb ;
   struct address_space *i_mapping ;
   void *i_security ;
   unsigned long i_ino ;
   union __anonunion_ldv_20148_160 ldv_20148 ;
   dev_t i_rdev ;
   loff_t i_size ;
   struct timespec i_atime ;
   struct timespec i_mtime ;
   struct timespec i_ctime ;
   spinlock_t i_lock ;
   unsigned short i_bytes ;
   unsigned int i_blkbits ;
   blkcnt_t i_blocks ;
   unsigned long i_state ;
   struct mutex i_mutex ;
   unsigned long dirtied_when ;
   struct hlist_node i_hash ;
   struct list_head i_wb_list ;
   struct list_head i_lru ;
   struct list_head i_sb_list ;
   union __anonunion_ldv_20168_161 ldv_20168 ;
   u64 i_version ;
   atomic_t i_count ;
   atomic_t i_dio_count ;
   atomic_t i_writecount ;
   struct file_operations  const  *i_fop ;
   struct file_lock *i_flock ;
   struct address_space i_data ;
   struct dquot *i_dquot[2U] ;
   struct list_head i_devices ;
   union __anonunion_ldv_20184_162 ldv_20184 ;
   __u32 i_generation ;
   __u32 i_fsnotify_mask ;
   struct hlist_head i_fsnotify_marks ;
   atomic_t i_readcount ;
   void *i_private ;
};
#line 727 "include/linux/fs.h"
struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   kuid_t uid ;
   kuid_t euid ;
   int signum ;
};
#line 735 "include/linux/fs.h"
struct file_ra_state {
   unsigned long start ;
   unsigned int size ;
   unsigned int async_size ;
   unsigned int ra_pages ;
   unsigned int mmap_miss ;
   loff_t prev_pos ;
};
#line 758 "include/linux/fs.h"
union __anonunion_f_u_163 {
   struct list_head fu_list ;
   struct callback_head fu_rcuhead ;
};
#line 758 "include/linux/fs.h"
struct file {
   union __anonunion_f_u_163 f_u ;
   struct path f_path ;
   struct file_operations  const  *f_op ;
   spinlock_t f_lock ;
   int f_sb_list_cpu ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
   fmode_t f_mode ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   struct cred  const  *f_cred ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   struct list_head f_tfile_llink ;
   struct address_space *f_mapping ;
   unsigned long f_mnt_write_state ;
};
#line 901
struct files_struct;
#line 901 "include/linux/fs.h"
typedef struct files_struct *fl_owner_t;
#line 902 "include/linux/fs.h"
struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
};
#line 907 "include/linux/fs.h"
struct lock_manager_operations {
   int (*lm_compare_owner)(struct file_lock * , struct file_lock * ) ;
   void (*lm_notify)(struct file_lock * ) ;
   int (*lm_grant)(struct file_lock * , struct file_lock * , int  ) ;
   void (*lm_break)(struct file_lock * ) ;
   int (*lm_change)(struct file_lock ** , int  ) ;
};
#line 919
struct net;
#line 924
struct nlm_lockowner;
#line 925 "include/linux/fs.h"
struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};
#line 14 "include/linux/nfs_fs_i.h"
struct nfs4_lock_state;
#line 15 "include/linux/nfs_fs_i.h"
struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};
#line 19
struct fasync_struct;
#line 19 "include/linux/nfs_fs_i.h"
struct __anonstruct_afs_165 {
   struct list_head link ;
   int state ;
};
#line 19 "include/linux/nfs_fs_i.h"
union __anonunion_fl_u_164 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_165 afs ;
};
#line 19 "include/linux/nfs_fs_i.h"
struct file_lock {
   struct file_lock *fl_next ;
   struct list_head fl_link ;
   struct list_head fl_block ;
   fl_owner_t fl_owner ;
   unsigned int fl_flags ;
   unsigned char fl_type ;
   unsigned int fl_pid ;
   struct pid *fl_nspid ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
   unsigned long fl_downgrade_time ;
   struct file_lock_operations  const  *fl_ops ;
   struct lock_manager_operations  const  *fl_lmops ;
   union __anonunion_fl_u_164 fl_u ;
};
#line 1011 "include/linux/fs.h"
struct fasync_struct {
   spinlock_t fa_lock ;
   int magic ;
   int fa_fd ;
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
   struct callback_head fa_rcu ;
};
#line 1217 "include/linux/fs.h"
struct sb_writers {
   struct percpu_counter counter[3U] ;
   wait_queue_head_t wait ;
   int frozen ;
   wait_queue_head_t wait_unfrozen ;
   struct lockdep_map lock_map[3U] ;
};
#line 1233
struct file_system_type;
#line 1233
struct super_operations;
#line 1233
struct xattr_handler;
#line 1233
struct mtd_info;
#line 1233 "include/linux/fs.h"
struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned char s_blocksize_bits ;
   unsigned long s_blocksize ;
   loff_t s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations  const  *s_op ;
   struct dquot_operations  const  *dq_op ;
   struct quotactl_ops  const  *s_qcop ;
   struct export_operations  const  *s_export_op ;
   unsigned long s_flags ;
   unsigned long s_magic ;
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   int s_count ;
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler  const  **s_xattr ;
   struct list_head s_inodes ;
   struct hlist_bl_head s_anon ;
   struct list_head *s_files ;
   struct list_head s_mounts ;
   struct list_head s_dentry_lru ;
   int s_nr_dentry_unused ;
   spinlock_t s_inode_lru_lock ;
   struct list_head s_inode_lru ;
   int s_nr_inodes_unused ;
   struct block_device *s_bdev ;
   struct backing_dev_info *s_bdi ;
   struct mtd_info *s_mtd ;
   struct hlist_node s_instances ;
   struct quota_info s_dquot ;
   struct sb_writers s_writers ;
   char s_id[32U] ;
   u8 s_uuid[16U] ;
   void *s_fs_info ;
   unsigned int s_max_links ;
   fmode_t s_mode ;
   u32 s_time_gran ;
   struct mutex s_vfs_rename_mutex ;
   char *s_subtype ;
   char *s_options ;
   struct dentry_operations  const  *s_d_op ;
   int cleancache_poolid ;
   struct shrinker s_shrink ;
   atomic_long_t s_remove_count ;
   int s_readonly_remount ;
};
#line 1474 "include/linux/fs.h"
struct fiemap_extent_info {
   unsigned int fi_flags ;
   unsigned int fi_extents_mapped ;
   unsigned int fi_extents_max ;
   struct fiemap_extent *fi_extents_start ;
};
#line 1512
struct block_device_operations;
#line 1513 "include/linux/fs.h"
struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file * , loff_t  , int  ) ;
   ssize_t (*read)(struct file * , char * , size_t  , loff_t * ) ;
   ssize_t (*write)(struct file * , char const   * , size_t  , loff_t * ) ;
   ssize_t (*aio_read)(struct kiocb * , struct iovec  const  * , unsigned long  ,
                       loff_t  ) ;
   ssize_t (*aio_write)(struct kiocb * , struct iovec  const  * , unsigned long  ,
                        loff_t  ) ;
   int (*readdir)(struct file * , void * , int (*)(void * , char const   * , int  ,
                                                   loff_t  , u64  , unsigned int  ) ) ;
   unsigned int (*poll)(struct file * , struct poll_table_struct * ) ;
   long (*unlocked_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   long (*compat_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   int (*mmap)(struct file * , struct vm_area_struct * ) ;
   int (*open)(struct inode * , struct file * ) ;
   int (*flush)(struct file * , fl_owner_t  ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*fsync)(struct file * , loff_t  , loff_t  , int  ) ;
   int (*aio_fsync)(struct kiocb * , int  ) ;
   int (*fasync)(int  , struct file * , int  ) ;
   int (*lock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*sendpage)(struct file * , struct page * , int  , size_t  , loff_t * ,
                       int  ) ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   int (*check_flags)(int  ) ;
   int (*flock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*splice_write)(struct pipe_inode_info * , struct file * , loff_t * , size_t  ,
                           unsigned int  ) ;
   ssize_t (*splice_read)(struct file * , loff_t * , struct pipe_inode_info * , size_t  ,
                          unsigned int  ) ;
   int (*setlease)(struct file * , long  , struct file_lock ** ) ;
   long (*fallocate)(struct file * , int  , loff_t  , loff_t  ) ;
};
#line 1548 "include/linux/fs.h"
struct inode_operations {
   struct dentry *(*lookup)(struct inode * , struct dentry * , unsigned int  ) ;
   void *(*follow_link)(struct dentry * , struct nameidata * ) ;
   int (*permission)(struct inode * , int  ) ;
   struct posix_acl *(*get_acl)(struct inode * , int  ) ;
   int (*readlink)(struct dentry * , char * , int  ) ;
   void (*put_link)(struct dentry * , struct nameidata * , void * ) ;
   int (*create)(struct inode * , struct dentry * , umode_t  , bool  ) ;
   int (*link)(struct dentry * , struct inode * , struct dentry * ) ;
   int (*unlink)(struct inode * , struct dentry * ) ;
   int (*symlink)(struct inode * , struct dentry * , char const   * ) ;
   int (*mkdir)(struct inode * , struct dentry * , umode_t  ) ;
   int (*rmdir)(struct inode * , struct dentry * ) ;
   int (*mknod)(struct inode * , struct dentry * , umode_t  , dev_t  ) ;
   int (*rename)(struct inode * , struct dentry * , struct inode * , struct dentry * ) ;
   void (*truncate)(struct inode * ) ;
   int (*setattr)(struct dentry * , struct iattr * ) ;
   int (*getattr)(struct vfsmount * , struct dentry * , struct kstat * ) ;
   int (*setxattr)(struct dentry * , char const   * , void const   * , size_t  , int  ) ;
   ssize_t (*getxattr)(struct dentry * , char const   * , void * , size_t  ) ;
   ssize_t (*listxattr)(struct dentry * , char * , size_t  ) ;
   int (*removexattr)(struct dentry * , char const   * ) ;
   int (*fiemap)(struct inode * , struct fiemap_extent_info * , u64  , u64  ) ;
   int (*update_time)(struct inode * , struct timespec * , int  ) ;
   int (*atomic_open)(struct inode * , struct dentry * , struct file * , unsigned int  ,
                      umode_t  , int * ) ;
};
#line 1595 "include/linux/fs.h"
struct super_operations {
   struct inode *(*alloc_inode)(struct super_block * ) ;
   void (*destroy_inode)(struct inode * ) ;
   void (*dirty_inode)(struct inode * , int  ) ;
   int (*write_inode)(struct inode * , struct writeback_control * ) ;
   int (*drop_inode)(struct inode * ) ;
   void (*evict_inode)(struct inode * ) ;
   void (*put_super)(struct super_block * ) ;
   int (*sync_fs)(struct super_block * , int  ) ;
   int (*freeze_fs)(struct super_block * ) ;
   int (*unfreeze_fs)(struct super_block * ) ;
   int (*statfs)(struct dentry * , struct kstatfs * ) ;
   int (*remount_fs)(struct super_block * , int * , char * ) ;
   void (*umount_begin)(struct super_block * ) ;
   int (*show_options)(struct seq_file * , struct dentry * ) ;
   int (*show_devname)(struct seq_file * , struct dentry * ) ;
   int (*show_path)(struct seq_file * , struct dentry * ) ;
   int (*show_stats)(struct seq_file * , struct dentry * ) ;
   ssize_t (*quota_read)(struct super_block * , int  , char * , size_t  , loff_t  ) ;
   ssize_t (*quota_write)(struct super_block * , int  , char const   * , size_t  ,
                          loff_t  ) ;
   int (*bdev_try_to_free_page)(struct super_block * , struct page * , gfp_t  ) ;
   int (*nr_cached_objects)(struct super_block * ) ;
   void (*free_cached_objects)(struct super_block * , int  ) ;
};
#line 1808 "include/linux/fs.h"
struct file_system_type {
   char const   *name ;
   int fs_flags ;
   struct dentry *(*mount)(struct file_system_type * , int  , char const   * , void * ) ;
   void (*kill_sb)(struct super_block * ) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct hlist_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key s_vfs_rename_key ;
   struct lock_class_key s_writers_key[3U] ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
};
#line 44 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/aio_abi.h"
struct io_event {
   __u64 data ;
   __u64 obj ;
   __s64 res ;
   __s64 res2 ;
};
#line 7 "include/asm-generic/cputime.h"
typedef unsigned long cputime_t;
#line 15
struct siginfo;
#line 32 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
struct __anonstruct_sigset_t_166 {
   unsigned long sig[1U] ;
};
#line 32 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
typedef struct __anonstruct_sigset_t_166 sigset_t;
#line 17 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/signal-defs.h"
typedef void __signalfn_t(int  );
#line 18 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/signal-defs.h"
typedef __signalfn_t *__sighandler_t;
#line 20 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/signal-defs.h"
typedef void __restorefn_t(void);
#line 21 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/asm-generic/signal-defs.h"
typedef __restorefn_t *__sigrestore_t;
#line 130 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
struct sigaction {
   __sighandler_t sa_handler ;
   unsigned long sa_flags ;
   __sigrestore_t sa_restorer ;
   sigset_t sa_mask ;
};
#line 177 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
struct k_sigaction {
   struct sigaction sa ;
};
#line 189 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
union sigval {
   int sival_int ;
   void *sival_ptr ;
};
#line 10 "include/uapi/asm-generic/siginfo.h"
typedef union sigval sigval_t;
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__kill_168 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__timer_169 {
   __kernel_timer_t _tid ;
   int _overrun ;
   char _pad[0U] ;
   sigval_t _sigval ;
   int _sys_private ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__rt_170 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   sigval_t _sigval ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigchld_171 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   int _status ;
   __kernel_clock_t _utime ;
   __kernel_clock_t _stime ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigfault_172 {
   void *_addr ;
   short _addr_lsb ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigpoll_173 {
   long _band ;
   int _fd ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigsys_174 {
   void *_call_addr ;
   int _syscall ;
   unsigned int _arch ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
union __anonunion__sifields_167 {
   int _pad[28U] ;
   struct __anonstruct__kill_168 _kill ;
   struct __anonstruct__timer_169 _timer ;
   struct __anonstruct__rt_170 _rt ;
   struct __anonstruct__sigchld_171 _sigchld ;
   struct __anonstruct__sigfault_172 _sigfault ;
   struct __anonstruct__sigpoll_173 _sigpoll ;
   struct __anonstruct__sigsys_174 _sigsys ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct siginfo {
   int si_signo ;
   int si_errno ;
   int si_code ;
   union __anonunion__sifields_167 _sifields ;
};
#line 109 "include/uapi/asm-generic/siginfo.h"
typedef struct siginfo siginfo_t;
#line 21 "include/linux/signal.h"
struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};
#line 46 "include/uapi/linux/seccomp.h"
struct seccomp_filter;
#line 47 "include/uapi/linux/seccomp.h"
struct seccomp {
   int mode ;
   struct seccomp_filter *filter ;
};
#line 38 "include/linux/rtmutex.h"
struct rt_mutex_waiter;
#line 41 "include/uapi/linux/resource.h"
struct rlimit {
   unsigned long rlim_cur ;
   unsigned long rlim_max ;
};
#line 11 "include/linux/resource.h"
struct timerqueue_node {
   struct rb_node node ;
   ktime_t expires ;
};
#line 12 "include/linux/timerqueue.h"
struct timerqueue_head {
   struct rb_root head ;
   struct timerqueue_node *next ;
};
#line 50
struct hrtimer_clock_base;
#line 51
struct hrtimer_cpu_base;
#line 60
enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
} ;
#line 65 "include/linux/timerqueue.h"
struct hrtimer {
   struct timerqueue_node node ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer * ) ;
   struct hrtimer_clock_base *base ;
   unsigned long state ;
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
};
#line 132 "include/linux/hrtimer.h"
struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   int index ;
   clockid_t clockid ;
   struct timerqueue_head active ;
   ktime_t resolution ;
   ktime_t (*get_time)(void) ;
   ktime_t softirq_time ;
   ktime_t offset ;
};
#line 162 "include/linux/hrtimer.h"
struct hrtimer_cpu_base {
   raw_spinlock_t lock ;
   unsigned int active_bases ;
   unsigned int clock_was_set ;
   ktime_t expires_next ;
   int hres_active ;
   int hang_detected ;
   unsigned long nr_events ;
   unsigned long nr_retries ;
   unsigned long nr_hangs ;
   ktime_t max_hang_time ;
   struct hrtimer_clock_base clock_base[3U] ;
};
#line 460 "include/linux/hrtimer.h"
struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};
#line 45 "include/linux/task_io_accounting.h"
struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
   unsigned long max ;
};
#line 835 "include/uapi/linux/sysctl.h"
struct nsproxy;
#line 836
struct ctl_table_root;
#line 837
struct ctl_table_header;
#line 838
struct ctl_dir;
#line 39 "include/linux/sysctl.h"
typedef int proc_handler(struct ctl_table * , int  , void * , size_t * , loff_t * );
#line 59 "include/linux/sysctl.h"
struct ctl_table_poll {
   atomic_t event ;
   wait_queue_head_t wait ;
};
#line 98 "include/linux/sysctl.h"
struct ctl_table {
   char const   *procname ;
   void *data ;
   int maxlen ;
   umode_t mode ;
   struct ctl_table *child ;
   proc_handler *proc_handler ;
   struct ctl_table_poll *poll ;
   void *extra1 ;
   void *extra2 ;
};
#line 119 "include/linux/sysctl.h"
struct ctl_node {
   struct rb_node node ;
   struct ctl_table_header *header ;
};
#line 124 "include/linux/sysctl.h"
struct __anonstruct_ldv_23754_178 {
   struct ctl_table *ctl_table ;
   int used ;
   int count ;
   int nreg ;
};
#line 124 "include/linux/sysctl.h"
union __anonunion_ldv_23756_177 {
   struct __anonstruct_ldv_23754_178 ldv_23754 ;
   struct callback_head rcu ;
};
#line 124
struct ctl_table_set;
#line 124 "include/linux/sysctl.h"
struct ctl_table_header {
   union __anonunion_ldv_23756_177 ldv_23756 ;
   struct completion *unregistering ;
   struct ctl_table *ctl_table_arg ;
   struct ctl_table_root *root ;
   struct ctl_table_set *set ;
   struct ctl_dir *parent ;
   struct ctl_node *node ;
};
#line 145 "include/linux/sysctl.h"
struct ctl_dir {
   struct ctl_table_header header ;
   struct rb_root root ;
};
#line 151 "include/linux/sysctl.h"
struct ctl_table_set {
   int (*is_seen)(struct ctl_table_set * ) ;
   struct ctl_dir dir ;
};
#line 156 "include/linux/sysctl.h"
struct ctl_table_root {
   struct ctl_table_set default_set ;
   struct ctl_table_set *(*lookup)(struct ctl_table_root * , struct nsproxy * ) ;
   int (*permissions)(struct ctl_table_root * , struct nsproxy * , struct ctl_table * ) ;
};
#line 30 "include/linux/key.h"
typedef int32_t key_serial_t;
#line 33 "include/linux/key.h"
typedef uint32_t key_perm_t;
#line 34
struct key;
#line 35
struct signal_struct;
#line 36
struct key_type;
#line 38
struct keyring_list;
#line 116 "include/linux/key.h"
union __anonunion_ldv_23835_179 {
   struct list_head graveyard_link ;
   struct rb_node serial_node ;
};
#line 116
struct key_user;
#line 116 "include/linux/key.h"
union __anonunion_ldv_23844_180 {
   time_t expiry ;
   time_t revoked_at ;
};
#line 116 "include/linux/key.h"
union __anonunion_type_data_181 {
   struct list_head link ;
   unsigned long x[2U] ;
   void *p[2U] ;
   int reject_error ;
};
#line 116 "include/linux/key.h"
union __anonunion_payload_182 {
   unsigned long value ;
   void *rcudata ;
   void *data ;
   struct keyring_list *subscriptions ;
};
#line 116 "include/linux/key.h"
struct key {
   atomic_t usage ;
   key_serial_t serial ;
   union __anonunion_ldv_23835_179 ldv_23835 ;
   struct key_type *type ;
   struct rw_semaphore sem ;
   struct key_user *user ;
   void *security ;
   union __anonunion_ldv_23844_180 ldv_23844 ;
   time_t last_used_at ;
   kuid_t uid ;
   kgid_t gid ;
   key_perm_t perm ;
   unsigned short quotalen ;
   unsigned short datalen ;
   unsigned long flags ;
   char *description ;
   union __anonunion_type_data_181 type_data ;
   union __anonunion_payload_182 payload ;
};
#line 322
struct audit_context;
#line 27 "include/linux/selinux.h"
struct group_info {
   atomic_t usage ;
   int ngroups ;
   int nblocks ;
   kgid_t small_block[32U] ;
   kgid_t *blocks[0U] ;
};
#line 78 "include/linux/cred.h"
struct thread_group_cred {
   atomic_t usage ;
   pid_t tgid ;
   spinlock_t lock ;
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct callback_head rcu ;
};
#line 92 "include/linux/cred.h"
struct cred {
   atomic_t usage ;
   atomic_t subscribers ;
   void *put_addr ;
   unsigned int magic ;
   kuid_t uid ;
   kgid_t gid ;
   kuid_t suid ;
   kgid_t sgid ;
   kuid_t euid ;
   kgid_t egid ;
   kuid_t fsuid ;
   kgid_t fsgid ;
   unsigned int securebits ;
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_bset ;
   unsigned char jit_keyring ;
   struct key *thread_keyring ;
   struct key *request_key_auth ;
   struct thread_group_cred *tgcred ;
   void *security ;
   struct user_struct *user ;
   struct user_namespace *user_ns ;
   struct group_info *group_info ;
   struct callback_head rcu ;
};
#line 358
struct llist_node;
#line 64 "include/linux/llist.h"
struct llist_node {
   struct llist_node *next ;
};
#line 185
struct futex_pi_state;
#line 186
struct robust_list_head;
#line 187
struct bio_list;
#line 188
struct fs_struct;
#line 189
struct perf_event_context;
#line 190
struct blk_plug;
#line 111 "include/linux/sched.h"
struct cfs_rq;
#line 112
struct task_group;
#line 347
struct kioctx;
#line 348 "include/linux/sched.h"
union __anonunion_ki_obj_183 {
   void *user ;
   struct task_struct *tsk ;
};
#line 348
struct eventfd_ctx;
#line 348 "include/linux/sched.h"
struct kiocb {
   struct list_head ki_run_list ;
   unsigned long ki_flags ;
   int ki_users ;
   unsigned int ki_key ;
   struct file *ki_filp ;
   struct kioctx *ki_ctx ;
   int (*ki_cancel)(struct kiocb * , struct io_event * ) ;
   ssize_t (*ki_retry)(struct kiocb * ) ;
   void (*ki_dtor)(struct kiocb * ) ;
   union __anonunion_ki_obj_183 ki_obj ;
   __u64 ki_user_data ;
   loff_t ki_pos ;
   void *private ;
   unsigned short ki_opcode ;
   size_t ki_nbytes ;
   char *ki_buf ;
   size_t ki_left ;
   struct iovec ki_inline_vec ;
   struct iovec *ki_iovec ;
   unsigned long ki_nr_segs ;
   unsigned long ki_cur_seg ;
   struct list_head ki_list ;
   struct list_head ki_batch ;
   struct eventfd_ctx *ki_eventfd ;
};
#line 161 "include/linux/aio.h"
struct aio_ring_info {
   unsigned long mmap_base ;
   unsigned long mmap_size ;
   struct page **ring_pages ;
   spinlock_t ring_lock ;
   long nr_pages ;
   unsigned int nr ;
   unsigned int tail ;
   struct page *internal_pages[8U] ;
};
#line 181 "include/linux/aio.h"
struct kioctx {
   atomic_t users ;
   int dead ;
   struct mm_struct *mm ;
   unsigned long user_id ;
   struct hlist_node list ;
   wait_queue_head_t wait ;
   spinlock_t ctx_lock ;
   int reqs_active ;
   struct list_head active_reqs ;
   struct list_head run_list ;
   unsigned int max_reqs ;
   struct aio_ring_info ring_info ;
   struct delayed_work wq ;
   struct callback_head callback_head ;
};
#line 368 "include/linux/sched.h"
struct sighand_struct {
   atomic_t count ;
   struct k_sigaction action[64U] ;
   spinlock_t siglock ;
   wait_queue_head_t signalfd_wqh ;
};
#line 420 "include/linux/sched.h"
struct pacct_struct {
   int ac_flag ;
   long ac_exitcode ;
   unsigned long ac_mem ;
   cputime_t ac_utime ;
   cputime_t ac_stime ;
   unsigned long ac_minflt ;
   unsigned long ac_majflt ;
};
#line 428 "include/linux/sched.h"
struct cpu_itimer {
   cputime_t expires ;
   cputime_t incr ;
   u32 error ;
   u32 incr_error ;
};
#line 435 "include/linux/sched.h"
struct task_cputime {
   cputime_t utime ;
   cputime_t stime ;
   unsigned long long sum_exec_runtime ;
};
#line 452 "include/linux/sched.h"
struct thread_group_cputimer {
   struct task_cputime cputime ;
   int running ;
   raw_spinlock_t lock ;
};
#line 488
struct autogroup;
#line 489
struct tty_struct;
#line 489
struct taskstats;
#line 489
struct tty_audit_buf;
#line 489 "include/linux/sched.h"
struct signal_struct {
   atomic_t sigcnt ;
   atomic_t live ;
   int nr_threads ;
   wait_queue_head_t wait_chldexit ;
   struct task_struct *curr_target ;
   struct sigpending shared_pending ;
   int group_exit_code ;
   int notify_count ;
   struct task_struct *group_exit_task ;
   int group_stop_count ;
   unsigned int flags ;
   unsigned char is_child_subreaper : 1 ;
   unsigned char has_child_subreaper : 1 ;
   struct list_head posix_timers ;
   struct hrtimer real_timer ;
   struct pid *leader_pid ;
   ktime_t it_real_incr ;
   struct cpu_itimer it[2U] ;
   struct thread_group_cputimer cputimer ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct pid *tty_old_pgrp ;
   int leader ;
   struct tty_struct *tty ;
   struct autogroup *autogroup ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t cutime ;
   cputime_t cstime ;
   cputime_t gtime ;
   cputime_t cgtime ;
   cputime_t prev_utime ;
   cputime_t prev_stime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   unsigned long cnvcsw ;
   unsigned long cnivcsw ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   unsigned long cmin_flt ;
   unsigned long cmaj_flt ;
   unsigned long inblock ;
   unsigned long oublock ;
   unsigned long cinblock ;
   unsigned long coublock ;
   unsigned long maxrss ;
   unsigned long cmaxrss ;
   struct task_io_accounting ioac ;
   unsigned long long sum_sched_runtime ;
   struct rlimit rlim[16U] ;
   struct pacct_struct pacct ;
   struct taskstats *stats ;
   unsigned int audit_tty ;
   struct tty_audit_buf *tty_audit_buf ;
   struct rw_semaphore group_rwsem ;
   int oom_score_adj ;
   int oom_score_adj_min ;
   struct mutex cred_guard_mutex ;
};
#line 664 "include/linux/sched.h"
struct user_struct {
   atomic_t __count ;
   atomic_t processes ;
   atomic_t files ;
   atomic_t sigpending ;
   atomic_t inotify_watches ;
   atomic_t inotify_devs ;
   atomic_t fanotify_listeners ;
   atomic_long_t epoll_watches ;
   unsigned long mq_bytes ;
   unsigned long locked_shm ;
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   kuid_t uid ;
   atomic_long_t locked_vm ;
};
#line 708
struct reclaim_state;
#line 709 "include/linux/sched.h"
struct sched_info {
   unsigned long pcount ;
   unsigned long long run_delay ;
   unsigned long long last_arrival ;
   unsigned long long last_queued ;
};
#line 724 "include/linux/sched.h"
struct task_delay_info {
   spinlock_t lock ;
   unsigned int flags ;
   struct timespec blkio_start ;
   struct timespec blkio_end ;
   u64 blkio_delay ;
   u64 swapin_delay ;
   u32 blkio_count ;
   u32 swapin_count ;
   struct timespec freepages_start ;
   struct timespec freepages_end ;
   u64 freepages_delay ;
   u32 freepages_count ;
};
#line 1024
struct uts_namespace;
#line 1025
struct rq;
#line 1026 "include/linux/sched.h"
struct sched_class {
   struct sched_class  const  *next ;
   void (*enqueue_task)(struct rq * , struct task_struct * , int  ) ;
   void (*dequeue_task)(struct rq * , struct task_struct * , int  ) ;
   void (*yield_task)(struct rq * ) ;
   bool (*yield_to_task)(struct rq * , struct task_struct * , bool  ) ;
   void (*check_preempt_curr)(struct rq * , struct task_struct * , int  ) ;
   struct task_struct *(*pick_next_task)(struct rq * ) ;
   void (*put_prev_task)(struct rq * , struct task_struct * ) ;
   int (*select_task_rq)(struct task_struct * , int  , int  ) ;
   void (*pre_schedule)(struct rq * , struct task_struct * ) ;
   void (*post_schedule)(struct rq * ) ;
   void (*task_waking)(struct task_struct * ) ;
   void (*task_woken)(struct rq * , struct task_struct * ) ;
   void (*set_cpus_allowed)(struct task_struct * , struct cpumask  const  * ) ;
   void (*rq_online)(struct rq * ) ;
   void (*rq_offline)(struct rq * ) ;
   void (*set_curr_task)(struct rq * ) ;
   void (*task_tick)(struct rq * , struct task_struct * , int  ) ;
   void (*task_fork)(struct task_struct * ) ;
   void (*switched_from)(struct rq * , struct task_struct * ) ;
   void (*switched_to)(struct rq * , struct task_struct * ) ;
   void (*prio_changed)(struct rq * , struct task_struct * , int  ) ;
   unsigned int (*get_rr_interval)(struct rq * , struct task_struct * ) ;
   void (*task_move_group)(struct task_struct * , int  ) ;
};
#line 1092 "include/linux/sched.h"
struct load_weight {
   unsigned long weight ;
   unsigned long inv_weight ;
};
#line 1097 "include/linux/sched.h"
struct sched_statistics {
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 iowait_count ;
   u64 iowait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
};
#line 1132 "include/linux/sched.h"
struct sched_entity {
   struct load_weight load ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 nr_migrations ;
   struct sched_statistics statistics ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
};
#line 1158
struct rt_rq;
#line 1158 "include/linux/sched.h"
struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
   unsigned int time_slice ;
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};
#line 1181
struct mem_cgroup;
#line 1181 "include/linux/sched.h"
struct memcg_batch_info {
   int do_batch ;
   struct mem_cgroup *memcg ;
   unsigned long nr_pages ;
   unsigned long memsw_nr_pages ;
};
#line 1544
struct css_set;
#line 1544
struct compat_robust_list_head;
#line 1544 "include/linux/sched.h"
struct task_struct {
   long volatile   state ;
   void *stack ;
   atomic_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
   struct llist_node wake_entry ;
   int on_cpu ;
   int on_rq ;
   int prio ;
   int static_prio ;
   int normal_prio ;
   unsigned int rt_priority ;
   struct sched_class  const  *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct task_group *sched_task_group ;
   struct hlist_head preempt_notifiers ;
   unsigned char fpu_counter ;
   unsigned int policy ;
   int nr_cpus_allowed ;
   cpumask_t cpus_allowed ;
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct plist_node pushable_tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   unsigned char brk_randomized : 1 ;
   int exit_state ;
   int exit_code ;
   int exit_signal ;
   int pdeath_signal ;
   unsigned int jobctl ;
   unsigned int personality ;
   unsigned char did_exec : 1 ;
   unsigned char in_execve : 1 ;
   unsigned char in_iowait : 1 ;
   unsigned char no_new_privs : 1 ;
   unsigned char sched_reset_on_fork : 1 ;
   unsigned char sched_contributes_to_load : 1 ;
   pid_t pid ;
   pid_t tgid ;
   unsigned long stack_canary ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid_link pids[3U] ;
   struct list_head thread_group ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t utimescaled ;
   cputime_t stimescaled ;
   cputime_t gtime ;
   cputime_t prev_utime ;
   cputime_t prev_stime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   struct timespec start_time ;
   struct timespec real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct cred  const  *real_cred ;
   struct cred  const  *cred ;
   char comm[16U] ;
   int link_count ;
   int total_link_count ;
   struct sysv_sem sysvsem ;
   unsigned long last_switch_count ;
   struct thread_struct thread ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
   size_t sas_ss_size ;
   int (*notifier)(void * ) ;
   void *notifier_data ;
   sigset_t *notifier_mask ;
   struct callback_head *task_works ;
   struct audit_context *audit_context ;
   kuid_t loginuid ;
   unsigned int sessionid ;
   struct seccomp seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   raw_spinlock_t pi_lock ;
   struct plist_head pi_waiters ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
   unsigned long hardirq_enable_ip ;
   unsigned long hardirq_disable_ip ;
   unsigned int hardirq_enable_event ;
   unsigned int hardirq_disable_event ;
   int hardirqs_enabled ;
   int hardirq_context ;
   unsigned long softirq_disable_ip ;
   unsigned long softirq_enable_ip ;
   unsigned int softirq_disable_event ;
   unsigned int softirq_enable_event ;
   int softirqs_enabled ;
   int softirq_context ;
   u64 curr_chain_key ;
   int lockdep_depth ;
   unsigned int lockdep_recursion ;
   struct held_lock held_locks[48U] ;
   gfp_t lockdep_reclaim_gfp ;
   void *journal_info ;
   struct bio_list *bio_list ;
   struct blk_plug *plug ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   unsigned long ptrace_message ;
   siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   cputime_t acct_timexpd ;
   nodemask_t mems_allowed ;
   seqcount_t mems_allowed_seq ;
   int cpuset_mem_spread_rotor ;
   int cpuset_slab_spread_rotor ;
   struct css_set *cgroups ;
   struct list_head cg_list ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct perf_event_context *perf_event_ctxp[2U] ;
   struct mutex perf_event_mutex ;
   struct list_head perf_event_list ;
   struct mempolicy *mempolicy ;
   short il_next ;
   short pref_node_fork ;
   struct callback_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct page_frag task_frag ;
   struct task_delay_info *delays ;
   int make_it_fail ;
   int nr_dirtied ;
   int nr_dirtied_pause ;
   unsigned long dirty_paused_when ;
   int latency_record_count ;
   struct latency_record latency_record[32U] ;
   unsigned long timer_slack_ns ;
   unsigned long default_timer_slack_ns ;
   unsigned long trace ;
   unsigned long trace_recursion ;
   struct memcg_batch_info memcg_batch ;
   atomic_t ptrace_bp_refcnt ;
   struct uprobe_task *utask ;
};
#line 18 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
typedef s32 compat_time_t;
#line 39 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
typedef s32 compat_long_t;
#line 44 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
typedef u32 compat_uptr_t;
#line 45 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
struct compat_timespec {
   compat_time_t tv_sec ;
   s32 tv_nsec ;
};
#line 220 "include/linux/compat.h"
struct compat_robust_list {
   compat_uptr_t next ;
};
#line 224 "include/linux/compat.h"
struct compat_robust_list_head {
   struct compat_robust_list list ;
   compat_long_t futex_offset ;
   compat_uptr_t list_op_pending ;
};
#line 74 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/archrandom.h"
enum ldv_22060 {
    SS_FREE = 0,
    SS_UNCONNECTED = 1,
    SS_CONNECTING = 2,
    SS_CONNECTED = 3,
    SS_DISCONNECTING = 4
} ;
#line 53 "include/uapi/linux/net.h"
typedef enum ldv_22060 socket_state;
#line 70 "include/uapi/linux/net.h"
struct socket_wq {
   wait_queue_head_t wait ;
   struct fasync_struct *fasync_list ;
   struct callback_head rcu ;
};
#line 93 "include/linux/net.h"
struct proto_ops;
#line 93 "include/linux/net.h"
struct socket {
   socket_state state ;
   short type ;
   unsigned long flags ;
   struct socket_wq *wq ;
   struct file *file ;
   struct sock *sk ;
   struct proto_ops  const  *ops ;
};
#line 119 "include/linux/net.h"
struct proto_ops {
   int family ;
   struct module *owner ;
   int (*release)(struct socket * ) ;
   int (*bind)(struct socket * , struct sockaddr * , int  ) ;
   int (*connect)(struct socket * , struct sockaddr * , int  , int  ) ;
   int (*socketpair)(struct socket * , struct socket * ) ;
   int (*accept)(struct socket * , struct socket * , int  ) ;
   int (*getname)(struct socket * , struct sockaddr * , int * , int  ) ;
   unsigned int (*poll)(struct file * , struct socket * , struct poll_table_struct * ) ;
   int (*ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*compat_ioctl)(struct socket * , unsigned int  , unsigned long  ) ;
   int (*listen)(struct socket * , int  ) ;
   int (*shutdown)(struct socket * , int  ) ;
   int (*setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct socket * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct socket * , int  , int  , char * , int * ) ;
   int (*sendmsg)(struct kiocb * , struct socket * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct kiocb * , struct socket * , struct msghdr * , size_t  , int  ) ;
   int (*mmap)(struct file * , struct socket * , struct vm_area_struct * ) ;
   ssize_t (*sendpage)(struct socket * , struct page * , int  , size_t  , int  ) ;
   ssize_t (*splice_read)(struct socket * , loff_t * , struct pipe_inode_info * ,
                          size_t  , unsigned int  ) ;
   void (*set_peek_off)(struct sock * , int  ) ;
};
#line 88 "include/linux/kmemleak.h"
struct kmem_cache_cpu {
   void **freelist ;
   unsigned long tid ;
   struct page *page ;
   struct page *partial ;
   unsigned int stat[26U] ;
};
#line 54 "include/linux/slub_def.h"
struct kmem_cache_node {
   spinlock_t list_lock ;
   unsigned long nr_partial ;
   struct list_head partial ;
   atomic_long_t nr_slabs ;
   atomic_long_t total_objects ;
   struct list_head full ;
};
#line 65 "include/linux/slub_def.h"
struct kmem_cache_order_objects {
   unsigned long x ;
};
#line 75 "include/linux/slub_def.h"
struct kmem_cache {
   struct kmem_cache_cpu *cpu_slab ;
   unsigned long flags ;
   unsigned long min_partial ;
   int size ;
   int object_size ;
   int offset ;
   int cpu_partial ;
   struct kmem_cache_order_objects oo ;
   struct kmem_cache_order_objects max ;
   struct kmem_cache_order_objects min ;
   gfp_t allocflags ;
   int refcount ;
   void (*ctor)(void * ) ;
   int inuse ;
   int align ;
   int reserved ;
   char const   *name ;
   struct list_head list ;
   struct kobject kobj ;
   int remote_node_defrag_ratio ;
   struct kmem_cache_node *node[1024U] ;
};
#line 161 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/checksum_64.h"
struct in6_addr;
#line 108 "include/net/checksum.h"
struct sk_buff;
#line 133 "include/net/checksum.h"
struct dma_attrs {
   unsigned long flags[1U] ;
};
#line 69 "include/linux/dma-attrs.h"
enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3
} ;
#line 76 "include/linux/dma-attrs.h"
struct dma_map_ops {
   void *(*alloc)(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
   void (*free)(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
   int (*mmap)(struct device * , struct vm_area_struct * , void * , dma_addr_t  ,
               size_t  , struct dma_attrs * ) ;
   int (*get_sgtable)(struct device * , struct sg_table * , void * , dma_addr_t  ,
                      size_t  , struct dma_attrs * ) ;
   dma_addr_t (*map_page)(struct device * , struct page * , unsigned long  , size_t  ,
                          enum dma_data_direction  , struct dma_attrs * ) ;
   void (*unmap_page)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ,
                      struct dma_attrs * ) ;
   int (*map_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                 struct dma_attrs * ) ;
   void (*unmap_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                    struct dma_attrs * ) ;
   void (*sync_single_for_cpu)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_single_for_device)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_sg_for_cpu)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   void (*sync_sg_for_device)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   int (*mapping_error)(struct device * , dma_addr_t  ) ;
   int (*dma_supported)(struct device * , u64  ) ;
   int (*set_dma_mask)(struct device * , u64  ) ;
   int is_phys ;
};
#line 15 "include/linux/netdev_features.h"
typedef u64 netdev_features_t;
#line 56 "include/linux/netdev_features.h"
struct nf_conntrack {
   atomic_t use ;
};
#line 116 "include/linux/skbuff.h"
struct nf_bridge_info {
   atomic_t use ;
   unsigned int mask ;
   struct net_device *physindev ;
   struct net_device *physoutdev ;
   unsigned long data[4U] ;
};
#line 126 "include/linux/skbuff.h"
struct sk_buff_head {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   __u32 qlen ;
   spinlock_t lock ;
};
#line 315 "include/linux/skbuff.h"
typedef unsigned int sk_buff_data_t;
#line 316
struct sec_path;
#line 316 "include/linux/skbuff.h"
struct __anonstruct_ldv_28250_201 {
   __u16 csum_start ;
   __u16 csum_offset ;
};
#line 316 "include/linux/skbuff.h"
union __anonunion_ldv_28251_200 {
   __wsum csum ;
   struct __anonstruct_ldv_28250_201 ldv_28250 ;
};
#line 316 "include/linux/skbuff.h"
union __anonunion_ldv_28289_202 {
   __u32 mark ;
   __u32 dropcount ;
   __u32 avail_size ;
};
#line 316 "include/linux/skbuff.h"
struct sk_buff {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   ktime_t tstamp ;
   struct sock *sk ;
   struct net_device *dev ;
   char cb[48U] ;
   unsigned long _skb_refdst ;
   struct sec_path *sp ;
   unsigned int len ;
   unsigned int data_len ;
   __u16 mac_len ;
   __u16 hdr_len ;
   union __anonunion_ldv_28251_200 ldv_28251 ;
   __u32 priority ;
   unsigned char local_df : 1 ;
   unsigned char cloned : 1 ;
   unsigned char ip_summed : 2 ;
   unsigned char nohdr : 1 ;
   unsigned char nfctinfo : 3 ;
   unsigned char pkt_type : 3 ;
   unsigned char fclone : 2 ;
   unsigned char ipvs_property : 1 ;
   unsigned char peeked : 1 ;
   unsigned char nf_trace : 1 ;
   __be16 protocol ;
   void (*destructor)(struct sk_buff * ) ;
   struct nf_conntrack *nfct ;
   struct sk_buff *nfct_reasm ;
   struct nf_bridge_info *nf_bridge ;
   int skb_iif ;
   __u32 rxhash ;
   __u16 vlan_tci ;
   __u16 tc_index ;
   __u16 tc_verd ;
   __u16 queue_mapping ;
   unsigned char ndisc_nodetype : 2 ;
   unsigned char pfmemalloc : 1 ;
   unsigned char ooo_okay : 1 ;
   unsigned char l4_rxhash : 1 ;
   unsigned char wifi_acked_valid : 1 ;
   unsigned char wifi_acked : 1 ;
   unsigned char no_fcs : 1 ;
   unsigned char head_frag : 1 ;
   dma_cookie_t dma_cookie ;
   __u32 secmark ;
   union __anonunion_ldv_28289_202 ldv_28289 ;
   sk_buff_data_t transport_header ;
   sk_buff_data_t network_header ;
   sk_buff_data_t mac_header ;
   sk_buff_data_t tail ;
   sk_buff_data_t end ;
   unsigned char *head ;
   unsigned char *data ;
   unsigned int truesize ;
   atomic_t users ;
};
#line 528
struct dst_entry;
#line 563
struct rtable;
#line 2658 "include/linux/skbuff.h"
struct ethhdr {
   unsigned char h_dest[6U] ;
   unsigned char h_source[6U] ;
   __be16 h_proto ;
};
#line 35 "include/linux/if_ether.h"
struct ethtool_cmd {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertising ;
   __u16 speed ;
   __u8 duplex ;
   __u8 port ;
   __u8 phy_address ;
   __u8 transceiver ;
   __u8 autoneg ;
   __u8 mdio_support ;
   __u32 maxtxpkt ;
   __u32 maxrxpkt ;
   __u16 speed_hi ;
   __u8 eth_tp_mdix ;
   __u8 eth_tp_mdix_ctrl ;
   __u32 lp_advertising ;
   __u32 reserved[2U] ;
};
#line 65 "include/uapi/linux/ethtool.h"
struct ethtool_drvinfo {
   __u32 cmd ;
   char driver[32U] ;
   char version[32U] ;
   char fw_version[32U] ;
   char bus_info[32U] ;
   char reserved1[32U] ;
   char reserved2[12U] ;
   __u32 n_priv_flags ;
   __u32 n_stats ;
   __u32 testinfo_len ;
   __u32 eedump_len ;
   __u32 regdump_len ;
};
#line 105 "include/uapi/linux/ethtool.h"
struct ethtool_wolinfo {
   __u32 cmd ;
   __u32 supported ;
   __u32 wolopts ;
   __u8 sopass[6U] ;
};
#line 120 "include/uapi/linux/ethtool.h"
struct ethtool_regs {
   __u32 cmd ;
   __u32 version ;
   __u32 len ;
   __u8 data[0U] ;
};
#line 128 "include/uapi/linux/ethtool.h"
struct ethtool_eeprom {
   __u32 cmd ;
   __u32 magic ;
   __u32 offset ;
   __u32 len ;
   __u8 data[0U] ;
};
#line 137 "include/uapi/linux/ethtool.h"
struct ethtool_eee {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertised ;
   __u32 lp_advertised ;
   __u32 eee_active ;
   __u32 eee_enabled ;
   __u32 tx_lpi_enabled ;
   __u32 tx_lpi_timer ;
   __u32 reserved[2U] ;
};
#line 166 "include/uapi/linux/ethtool.h"
struct ethtool_modinfo {
   __u32 cmd ;
   __u32 type ;
   __u32 eeprom_len ;
   __u32 reserved[8U] ;
};
#line 183 "include/uapi/linux/ethtool.h"
struct ethtool_coalesce {
   __u32 cmd ;
   __u32 rx_coalesce_usecs ;
   __u32 rx_max_coalesced_frames ;
   __u32 rx_coalesce_usecs_irq ;
   __u32 rx_max_coalesced_frames_irq ;
   __u32 tx_coalesce_usecs ;
   __u32 tx_max_coalesced_frames ;
   __u32 tx_coalesce_usecs_irq ;
   __u32 tx_max_coalesced_frames_irq ;
   __u32 stats_block_coalesce_usecs ;
   __u32 use_adaptive_rx_coalesce ;
   __u32 use_adaptive_tx_coalesce ;
   __u32 pkt_rate_low ;
   __u32 rx_coalesce_usecs_low ;
   __u32 rx_max_coalesced_frames_low ;
   __u32 tx_coalesce_usecs_low ;
   __u32 tx_max_coalesced_frames_low ;
   __u32 pkt_rate_high ;
   __u32 rx_coalesce_usecs_high ;
   __u32 rx_max_coalesced_frames_high ;
   __u32 tx_coalesce_usecs_high ;
   __u32 tx_max_coalesced_frames_high ;
   __u32 rate_sample_interval ;
};
#line 281 "include/uapi/linux/ethtool.h"
struct ethtool_ringparam {
   __u32 cmd ;
   __u32 rx_max_pending ;
   __u32 rx_mini_max_pending ;
   __u32 rx_jumbo_max_pending ;
   __u32 tx_max_pending ;
   __u32 rx_pending ;
   __u32 rx_mini_pending ;
   __u32 rx_jumbo_pending ;
   __u32 tx_pending ;
};
#line 303 "include/uapi/linux/ethtool.h"
struct ethtool_channels {
   __u32 cmd ;
   __u32 max_rx ;
   __u32 max_tx ;
   __u32 max_other ;
   __u32 max_combined ;
   __u32 rx_count ;
   __u32 tx_count ;
   __u32 other_count ;
   __u32 combined_count ;
};
#line 331 "include/uapi/linux/ethtool.h"
struct ethtool_pauseparam {
   __u32 cmd ;
   __u32 autoneg ;
   __u32 rx_pause ;
   __u32 tx_pause ;
};
#line 382 "include/uapi/linux/ethtool.h"
struct ethtool_test {
   __u32 cmd ;
   __u32 flags ;
   __u32 reserved ;
   __u32 len ;
   __u64 data[0U] ;
};
#line 404 "include/uapi/linux/ethtool.h"
struct ethtool_stats {
   __u32 cmd ;
   __u32 n_stats ;
   __u64 data[0U] ;
};
#line 425 "include/uapi/linux/ethtool.h"
struct ethtool_tcpip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be16 psrc ;
   __be16 pdst ;
   __u8 tos ;
};
#line 458 "include/uapi/linux/ethtool.h"
struct ethtool_ah_espip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 spi ;
   __u8 tos ;
};
#line 474 "include/uapi/linux/ethtool.h"
struct ethtool_usrip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 l4_4_bytes ;
   __u8 tos ;
   __u8 ip_ver ;
   __u8 proto ;
};
#line 494 "include/uapi/linux/ethtool.h"
union ethtool_flow_union {
   struct ethtool_tcpip4_spec tcp_ip4_spec ;
   struct ethtool_tcpip4_spec udp_ip4_spec ;
   struct ethtool_tcpip4_spec sctp_ip4_spec ;
   struct ethtool_ah_espip4_spec ah_ip4_spec ;
   struct ethtool_ah_espip4_spec esp_ip4_spec ;
   struct ethtool_usrip4_spec usr_ip4_spec ;
   struct ethhdr ether_spec ;
   __u8 hdata[60U] ;
};
#line 505 "include/uapi/linux/ethtool.h"
struct ethtool_flow_ext {
   __be16 vlan_etype ;
   __be16 vlan_tci ;
   __be32 data[2U] ;
};
#line 511 "include/uapi/linux/ethtool.h"
struct ethtool_rx_flow_spec {
   __u32 flow_type ;
   union ethtool_flow_union h_u ;
   struct ethtool_flow_ext h_ext ;
   union ethtool_flow_union m_u ;
   struct ethtool_flow_ext m_ext ;
   __u64 ring_cookie ;
   __u32 location ;
};
#line 536 "include/uapi/linux/ethtool.h"
struct ethtool_rxnfc {
   __u32 cmd ;
   __u32 flow_type ;
   __u64 data ;
   struct ethtool_rx_flow_spec fs ;
   __u32 rule_cnt ;
   __u32 rule_locs[0U] ;
};
#line 670 "include/uapi/linux/ethtool.h"
struct ethtool_flash {
   __u32 cmd ;
   __u32 region ;
   char data[128U] ;
};
#line 678 "include/uapi/linux/ethtool.h"
struct ethtool_dump {
   __u32 cmd ;
   __u32 version ;
   __u32 flag ;
   __u32 len ;
   __u8 data[0U] ;
};
#line 754 "include/uapi/linux/ethtool.h"
struct ethtool_ts_info {
   __u32 cmd ;
   __u32 so_timestamping ;
   __s32 phc_index ;
   __u32 tx_types ;
   __u32 tx_reserved[3U] ;
   __u32 rx_filters ;
   __u32 rx_reserved[3U] ;
};
#line 44 "include/linux/ethtool.h"
enum ethtool_phys_id_state {
    ETHTOOL_ID_INACTIVE = 0,
    ETHTOOL_ID_ACTIVE = 1,
    ETHTOOL_ID_ON = 2,
    ETHTOOL_ID_OFF = 3
} ;
#line 79 "include/linux/ethtool.h"
struct ethtool_ops {
   int (*get_settings)(struct net_device * , struct ethtool_cmd * ) ;
   int (*set_settings)(struct net_device * , struct ethtool_cmd * ) ;
   void (*get_drvinfo)(struct net_device * , struct ethtool_drvinfo * ) ;
   int (*get_regs_len)(struct net_device * ) ;
   void (*get_regs)(struct net_device * , struct ethtool_regs * , void * ) ;
   void (*get_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   u32 (*get_msglevel)(struct net_device * ) ;
   void (*set_msglevel)(struct net_device * , u32  ) ;
   int (*nway_reset)(struct net_device * ) ;
   u32 (*get_link)(struct net_device * ) ;
   int (*get_eeprom_len)(struct net_device * ) ;
   int (*get_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   int (*set_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   void (*get_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   int (*set_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   void (*get_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   int (*set_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   void (*self_test)(struct net_device * , struct ethtool_test * , u64 * ) ;
   void (*get_strings)(struct net_device * , u32  , u8 * ) ;
   int (*set_phys_id)(struct net_device * , enum ethtool_phys_id_state  ) ;
   void (*get_ethtool_stats)(struct net_device * , struct ethtool_stats * , u64 * ) ;
   int (*begin)(struct net_device * ) ;
   void (*complete)(struct net_device * ) ;
   u32 (*get_priv_flags)(struct net_device * ) ;
   int (*set_priv_flags)(struct net_device * , u32  ) ;
   int (*get_sset_count)(struct net_device * , int  ) ;
   int (*get_rxnfc)(struct net_device * , struct ethtool_rxnfc * , u32 * ) ;
   int (*set_rxnfc)(struct net_device * , struct ethtool_rxnfc * ) ;
   int (*flash_device)(struct net_device * , struct ethtool_flash * ) ;
   int (*reset)(struct net_device * , u32 * ) ;
   u32 (*get_rxfh_indir_size)(struct net_device * ) ;
   int (*get_rxfh_indir)(struct net_device * , u32 * ) ;
   int (*set_rxfh_indir)(struct net_device * , u32 const   * ) ;
   void (*get_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*set_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*get_dump_flag)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_dump_data)(struct net_device * , struct ethtool_dump * , void * ) ;
   int (*set_dump)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_ts_info)(struct net_device * , struct ethtool_ts_info * ) ;
   int (*get_module_info)(struct net_device * , struct ethtool_modinfo * ) ;
   int (*get_module_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*set_eee)(struct net_device * , struct ethtool_eee * ) ;
};
#line 249
struct prot_inuse;
#line 250 "include/linux/ethtool.h"
struct netns_core {
   struct ctl_table_header *sysctl_hdr ;
   int sysctl_somaxconn ;
   struct prot_inuse *inuse ;
};
#line 38 "include/net/snmp.h"
struct u64_stats_sync {

};
#line 138 "include/linux/u64_stats_sync.h"
struct ipstats_mib {
   u64 mibs[31U] ;
   struct u64_stats_sync syncp ;
};
#line 61 "include/net/snmp.h"
struct icmp_mib {
   unsigned long mibs[27U] ;
};
#line 67 "include/net/snmp.h"
struct icmpmsg_mib {
   atomic_long_t mibs[512U] ;
};
#line 72 "include/net/snmp.h"
struct icmpv6_mib {
   unsigned long mibs[5U] ;
};
#line 79 "include/net/snmp.h"
struct icmpv6_mib_device {
   atomic_long_t mibs[5U] ;
};
#line 83 "include/net/snmp.h"
struct icmpv6msg_mib {
   atomic_long_t mibs[512U] ;
};
#line 89 "include/net/snmp.h"
struct icmpv6msg_mib_device {
   atomic_long_t mibs[512U] ;
};
#line 93 "include/net/snmp.h"
struct tcp_mib {
   unsigned long mibs[15U] ;
};
#line 100 "include/net/snmp.h"
struct udp_mib {
   unsigned long mibs[7U] ;
};
#line 106 "include/net/snmp.h"
struct linux_mib {
   unsigned long mibs[92U] ;
};
#line 112 "include/net/snmp.h"
struct linux_xfrm_mib {
   unsigned long mibs[27U] ;
};
#line 118 "include/net/snmp.h"
struct netns_mib {
   struct tcp_mib *tcp_statistics[1U] ;
   struct ipstats_mib *ip_statistics[1U] ;
   struct linux_mib *net_statistics[1U] ;
   struct udp_mib *udp_statistics[1U] ;
   struct udp_mib *udplite_statistics[1U] ;
   struct icmp_mib *icmp_statistics[1U] ;
   struct icmpmsg_mib *icmpmsg_statistics ;
   struct proc_dir_entry *proc_net_devsnmp6 ;
   struct udp_mib *udp_stats_in6[1U] ;
   struct udp_mib *udplite_stats_in6[1U] ;
   struct ipstats_mib *ipv6_statistics[1U] ;
   struct icmpv6_mib *icmpv6_statistics[1U] ;
   struct icmpv6msg_mib *icmpv6msg_statistics ;
   struct linux_xfrm_mib *xfrm_statistics[1U] ;
};
#line 26 "include/net/netns/mib.h"
struct netns_unix {
   int sysctl_max_dgram_qlen ;
   struct ctl_table_header *ctl ;
};
#line 12 "include/net/netns/unix.h"
struct netns_packet {
   struct mutex sklist_lock ;
   struct hlist_head sklist ;
};
#line 14 "include/net/netns/packet.h"
struct netns_frags {
   int nqueues ;
   atomic_t mem ;
   struct list_head lru_list ;
   int timeout ;
   int high_thresh ;
   int low_thresh ;
};
#line 74 "include/net/inet_frag.h"
struct tcpm_hash_bucket;
#line 75
struct ipv4_devconf;
#line 76
struct fib_rules_ops;
#line 77
struct fib_table;
#line 78
struct inet_peer_base;
#line 78
struct xt_table;
#line 78 "include/net/inet_frag.h"
struct netns_ipv4 {
   struct ctl_table_header *forw_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *ipv4_hdr ;
   struct ctl_table_header *route_hdr ;
   struct ipv4_devconf *devconf_all ;
   struct ipv4_devconf *devconf_dflt ;
   struct fib_rules_ops *rules_ops ;
   bool fib_has_custom_rules ;
   struct fib_table *fib_local ;
   struct fib_table *fib_main ;
   struct fib_table *fib_default ;
   int fib_num_tclassid_users ;
   struct hlist_head *fib_table_hash ;
   struct sock *fibnl ;
   struct sock **icmp_sk ;
   struct inet_peer_base *peers ;
   struct tcpm_hash_bucket *tcp_metrics_hash ;
   unsigned int tcp_metrics_hash_log ;
   struct netns_frags frags ;
   struct xt_table *iptable_filter ;
   struct xt_table *iptable_mangle ;
   struct xt_table *iptable_raw ;
   struct xt_table *arptable_filter ;
   struct xt_table *iptable_security ;
   struct xt_table *nat_table ;
   int sysctl_icmp_echo_ignore_all ;
   int sysctl_icmp_echo_ignore_broadcasts ;
   int sysctl_icmp_ignore_bogus_error_responses ;
   int sysctl_icmp_ratelimit ;
   int sysctl_icmp_ratemask ;
   int sysctl_icmp_errors_use_inbound_ifaddr ;
   kgid_t sysctl_ping_group_range[2U] ;
   long sysctl_tcp_mem[3U] ;
   atomic_t dev_addr_genid ;
   struct list_head mr_tables ;
   struct fib_rules_ops *mr_rules_ops ;
};
#line 77 "include/net/netns/ipv4.h"
struct neighbour;
#line 77 "include/net/netns/ipv4.h"
struct dst_ops {
   unsigned short family ;
   __be16 protocol ;
   unsigned int gc_thresh ;
   int (*gc)(struct dst_ops * ) ;
   struct dst_entry *(*check)(struct dst_entry * , __u32  ) ;
   unsigned int (*default_advmss)(struct dst_entry  const  * ) ;
   unsigned int (*mtu)(struct dst_entry  const  * ) ;
   u32 *(*cow_metrics)(struct dst_entry * , unsigned long  ) ;
   void (*destroy)(struct dst_entry * ) ;
   void (*ifdown)(struct dst_entry * , struct net_device * , int  ) ;
   struct dst_entry *(*negative_advice)(struct dst_entry * ) ;
   void (*link_failure)(struct sk_buff * ) ;
   void (*update_pmtu)(struct dst_entry * , struct sock * , struct sk_buff * , u32  ) ;
   void (*redirect)(struct dst_entry * , struct sock * , struct sk_buff * ) ;
   int (*local_out)(struct sk_buff * ) ;
   struct neighbour *(*neigh_lookup)(struct dst_entry  const  * , struct sk_buff * ,
                                     void const   * ) ;
   struct kmem_cache *kmem_cachep ;
   struct percpu_counter pcpuc_entries ;
};
#line 73 "include/net/dst_ops.h"
struct netns_sysctl_ipv6 {
   struct ctl_table_header *hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *icmp_hdr ;
   struct ctl_table_header *frags_hdr ;
   int bindv6only ;
   int flush_delay ;
   int ip6_rt_max_size ;
   int ip6_rt_gc_min_interval ;
   int ip6_rt_gc_timeout ;
   int ip6_rt_gc_interval ;
   int ip6_rt_gc_elasticity ;
   int ip6_rt_mtu_expires ;
   int ip6_rt_min_advmss ;
   int icmpv6_time ;
};
#line 31 "include/net/netns/ipv6.h"
struct ipv6_devconf;
#line 31
struct rt6_info;
#line 31
struct rt6_statistics;
#line 31
struct fib6_table;
#line 31 "include/net/netns/ipv6.h"
struct netns_ipv6 {
   struct netns_sysctl_ipv6 sysctl ;
   struct ipv6_devconf *devconf_all ;
   struct ipv6_devconf *devconf_dflt ;
   struct inet_peer_base *peers ;
   struct netns_frags frags ;
   struct xt_table *ip6table_filter ;
   struct xt_table *ip6table_mangle ;
   struct xt_table *ip6table_raw ;
   struct xt_table *ip6table_security ;
   struct xt_table *ip6table_nat ;
   struct rt6_info *ip6_null_entry ;
   struct rt6_statistics *rt6_stats ;
   struct timer_list ip6_fib_timer ;
   struct hlist_head *fib_table_hash ;
   struct fib6_table *fib6_main_tbl ;
   struct dst_ops ip6_dst_ops ;
   unsigned int ip6_rt_gc_expire ;
   unsigned long ip6_rt_last_gc ;
   struct rt6_info *ip6_prohibit_entry ;
   struct rt6_info *ip6_blk_hole_entry ;
   struct fib6_table *fib6_local_tbl ;
   struct fib_rules_ops *fib6_rules_ops ;
   struct sock **icmp_sk ;
   struct sock *ndisc_sk ;
   struct sock *tcp_sk ;
   struct sock *igmp_sk ;
   struct list_head mr6_tables ;
   struct fib_rules_ops *mr6_rules_ops ;
};
#line 72 "include/net/netns/ipv6.h"
struct netns_nf_frag {
   struct netns_sysctl_ipv6 sysctl ;
   struct netns_frags frags ;
};
#line 80
struct sctp_mib;
#line 81 "include/net/netns/ipv6.h"
struct netns_sctp {
   struct sctp_mib *sctp_statistics[1U] ;
   struct proc_dir_entry *proc_net_sctp ;
   struct ctl_table_header *sysctl_header ;
   struct sock *ctl_sock ;
   struct list_head local_addr_list ;
   struct list_head addr_waitq ;
   struct timer_list addr_wq_timer ;
   struct list_head auto_asconf_splist ;
   spinlock_t addr_wq_lock ;
   spinlock_t local_addr_lock ;
   unsigned int rto_initial ;
   unsigned int rto_min ;
   unsigned int rto_max ;
   int rto_alpha ;
   int rto_beta ;
   int max_burst ;
   int cookie_preserve_enable ;
   unsigned int valid_cookie_life ;
   unsigned int sack_timeout ;
   unsigned int hb_interval ;
   int max_retrans_association ;
   int max_retrans_path ;
   int max_retrans_init ;
   int pf_retrans ;
   int sndbuf_policy ;
   int rcvbuf_policy ;
   int default_auto_asconf ;
   int addip_enable ;
   int addip_noauth ;
   int prsctp_enable ;
   int auth_enable ;
   int scope_policy ;
   int rwnd_upd_shift ;
   unsigned long max_autoclose ;
};
#line 130 "include/net/netns/sctp.h"
struct netns_dccp {
   struct sock *v4_ctl_sk ;
   struct sock *v6_ctl_sk ;
};
#line 104 "include/linux/in.h"
union __anonunion_in6_u_205 {
   __u8 u6_addr8[16U] ;
   __be16 u6_addr16[8U] ;
   __be32 u6_addr32[4U] ;
};
#line 104 "include/linux/in.h"
struct in6_addr {
   union __anonunion_in6_u_205 in6_u ;
};
#line 46 "include/linux/proc_fs.h"
typedef int read_proc_t(char * , char ** , off_t  , int  , int * , void * );
#line 48 "include/linux/proc_fs.h"
typedef int write_proc_t(struct file * , char const   * , unsigned long  , void * );
#line 49 "include/linux/proc_fs.h"
struct proc_dir_entry {
   unsigned int low_ino ;
   umode_t mode ;
   nlink_t nlink ;
   kuid_t uid ;
   kgid_t gid ;
   loff_t size ;
   struct inode_operations  const  *proc_iops ;
   struct file_operations  const  *proc_fops ;
   struct proc_dir_entry *next ;
   struct proc_dir_entry *parent ;
   struct proc_dir_entry *subdir ;
   void *data ;
   read_proc_t *read_proc ;
   write_proc_t *write_proc ;
   atomic_t count ;
   int pde_users ;
   struct completion *pde_unload_completion ;
   struct list_head pde_openers ;
   spinlock_t pde_unload_lock ;
   u8 namelen ;
   char name[] ;
};
#line 326 "include/linux/netfilter.h"
struct nlattr;
#line 341
struct ebt_table;
#line 342 "include/linux/netfilter.h"
struct netns_xt {
   struct list_head tables[13U] ;
   struct ebt_table *broute_table ;
   struct ebt_table *frame_filter ;
   struct ebt_table *frame_nat ;
};
#line 32 "include/linux/netfilter/nf_conntrack_tcp.h"
struct nf_proto_net {
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
   struct ctl_table_header *ctl_compat_header ;
   struct ctl_table *ctl_compat_table ;
   unsigned int users ;
};
#line 23 "include/net/netns/conntrack.h"
struct nf_generic_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
#line 28 "include/net/netns/conntrack.h"
struct nf_tcp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[14U] ;
   unsigned int tcp_loose ;
   unsigned int tcp_be_liberal ;
   unsigned int tcp_max_retrans ;
};
#line 42 "include/net/netns/conntrack.h"
struct nf_udp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[2U] ;
};
#line 47 "include/net/netns/conntrack.h"
struct nf_icmp_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
#line 52 "include/net/netns/conntrack.h"
struct nf_ip_net {
   struct nf_generic_net generic ;
   struct nf_tcp_net tcp ;
   struct nf_udp_net udp ;
   struct nf_icmp_net icmp ;
   struct nf_icmp_net icmpv6 ;
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
};
#line 63
struct ip_conntrack_stat;
#line 63
struct nf_ct_event_notifier;
#line 63
struct nf_exp_event_notifier;
#line 63 "include/net/netns/conntrack.h"
struct netns_ct {
   atomic_t count ;
   unsigned int expect_count ;
   unsigned int htable_size ;
   struct kmem_cache *nf_conntrack_cachep ;
   struct hlist_nulls_head *hash ;
   struct hlist_head *expect_hash ;
   struct hlist_nulls_head unconfirmed ;
   struct hlist_nulls_head dying ;
   struct ip_conntrack_stat *stat ;
   struct nf_ct_event_notifier *nf_conntrack_event_cb ;
   struct nf_exp_event_notifier *nf_expect_event_cb ;
   int sysctl_events ;
   unsigned int sysctl_events_retry_timeout ;
   int sysctl_acct ;
   int sysctl_tstamp ;
   int sysctl_checksum ;
   unsigned int sysctl_log_invalid ;
   int sysctl_auto_assign_helper ;
   bool auto_assign_helper_warned ;
   struct nf_ip_net nf_ct_proto ;
   struct hlist_head *nat_bysource ;
   unsigned int nat_htable_size ;
   struct ctl_table_header *sysctl_header ;
   struct ctl_table_header *acct_sysctl_header ;
   struct ctl_table_header *tstamp_sysctl_header ;
   struct ctl_table_header *event_sysctl_header ;
   struct ctl_table_header *helper_sysctl_header ;
   char *slabname ;
};
#line 486 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/xfrm.h"
struct xfrm_policy_hash {
   struct hlist_head *table ;
   unsigned int hmask ;
};
#line 16 "include/net/netns/xfrm.h"
struct netns_xfrm {
   struct list_head state_all ;
   struct hlist_head *state_bydst ;
   struct hlist_head *state_bysrc ;
   struct hlist_head *state_byspi ;
   unsigned int state_hmask ;
   unsigned int state_num ;
   struct work_struct state_hash_work ;
   struct hlist_head state_gc_list ;
   struct work_struct state_gc_work ;
   wait_queue_head_t km_waitq ;
   struct list_head policy_all ;
   struct hlist_head *policy_byidx ;
   unsigned int policy_idx_hmask ;
   struct hlist_head policy_inexact[6U] ;
   struct xfrm_policy_hash policy_bydst[6U] ;
   unsigned int policy_count[6U] ;
   struct work_struct policy_hash_work ;
   struct sock *nlsk ;
   struct sock *nlsk_stash ;
   u32 sysctl_aevent_etime ;
   u32 sysctl_aevent_rseqth ;
   int sysctl_larval_drop ;
   u32 sysctl_acq_expires ;
   struct ctl_table_header *sysctl_hdr ;
   struct dst_ops xfrm4_dst_ops ;
   struct dst_ops xfrm6_dst_ops ;
};
#line 62
struct net_generic;
#line 63
struct netns_ipvs;
#line 64 "include/net/netns/xfrm.h"
struct net {
   atomic_t passive ;
   atomic_t count ;
   spinlock_t rules_mod_lock ;
   struct list_head list ;
   struct list_head cleanup_list ;
   struct list_head exit_list ;
   struct proc_dir_entry *proc_net ;
   struct proc_dir_entry *proc_net_stat ;
   struct ctl_table_set sysctls ;
   struct sock *rtnl ;
   struct sock *genl_sock ;
   struct list_head dev_base_head ;
   struct hlist_head *dev_name_head ;
   struct hlist_head *dev_index_head ;
   unsigned int dev_base_seq ;
   int ifindex ;
   struct list_head rules_ops ;
   struct net_device *loopback_dev ;
   struct netns_core core ;
   struct netns_mib mib ;
   struct netns_packet packet ;
   struct netns_unix unx ;
   struct netns_ipv4 ipv4 ;
   struct netns_ipv6 ipv6 ;
   struct netns_sctp sctp ;
   struct netns_dccp dccp ;
   struct netns_xt xt ;
   struct netns_ct ct ;
   struct netns_nf_frag nf_frag ;
   struct sock *nfnl ;
   struct sock *nfnl_stash ;
   struct sk_buff_head wext_nlevents ;
   struct net_generic *gen ;
   struct netns_xfrm xfrm ;
   struct netns_ipvs *ipvs ;
   struct sock *diag_nlsk ;
   atomic_t rt_genid ;
};
#line 115 "include/net/net_namespace.h"
struct seq_file {
   char *buf ;
   size_t size ;
   size_t from ;
   size_t count ;
   loff_t index ;
   loff_t read_pos ;
   u64 version ;
   struct mutex lock ;
   struct seq_operations  const  *op ;
   int poll_event ;
   void *private ;
};
#line 34 "include/linux/seq_file.h"
struct seq_operations {
   void *(*start)(struct seq_file * , loff_t * ) ;
   void (*stop)(struct seq_file * , void * ) ;
   void *(*next)(struct seq_file * , void * , loff_t * ) ;
   int (*show)(struct seq_file * , void * ) ;
};
#line 330 "include/net/net_namespace.h"
struct dsa_chip_data {
   struct device *mii_bus ;
   int sw_addr ;
   char *port_names[12U] ;
   s8 *rtable ;
};
#line 46 "include/net/dsa.h"
struct dsa_platform_data {
   struct device *netdev ;
   int nr_chips ;
   struct dsa_chip_data *chip ;
};
#line 61
struct dsa_switch;
#line 61 "include/net/dsa.h"
struct dsa_switch_tree {
   struct dsa_platform_data *pd ;
   struct net_device *master_netdev ;
   __be16 tag_protocol ;
   s8 cpu_switch ;
   s8 cpu_port ;
   int link_poll_needed ;
   struct work_struct link_poll_work ;
   struct timer_list link_poll_timer ;
   struct dsa_switch *ds[4U] ;
};
#line 94
struct dsa_switch_driver;
#line 94
struct mii_bus;
#line 94 "include/net/dsa.h"
struct dsa_switch {
   struct dsa_switch_tree *dst ;
   int index ;
   struct dsa_chip_data *pd ;
   struct dsa_switch_driver *drv ;
   struct mii_bus *master_mii_bus ;
   u32 dsa_port_mask ;
   u32 phys_port_mask ;
   struct mii_bus *slave_mii_bus ;
   struct net_device *ports[12U] ;
};
#line 146 "include/net/dsa.h"
struct dsa_switch_driver {
   struct list_head list ;
   __be16 tag_protocol ;
   int priv_size ;
   char *(*probe)(struct mii_bus * , int  ) ;
   int (*setup)(struct dsa_switch * ) ;
   int (*set_addr)(struct dsa_switch * , u8 * ) ;
   int (*phy_read)(struct dsa_switch * , int  , int  ) ;
   int (*phy_write)(struct dsa_switch * , int  , int  , u16  ) ;
   void (*poll_link)(struct dsa_switch * ) ;
   void (*get_strings)(struct dsa_switch * , int  , uint8_t * ) ;
   void (*get_ethtool_stats)(struct dsa_switch * , int  , uint64_t * ) ;
   int (*get_sset_count)(struct dsa_switch * ) ;
};
#line 200 "include/net/dsa.h"
struct ieee_ets {
   __u8 willing ;
   __u8 ets_cap ;
   __u8 cbs ;
   __u8 tc_tx_bw[8U] ;
   __u8 tc_rx_bw[8U] ;
   __u8 tc_tsa[8U] ;
   __u8 prio_tc[8U] ;
   __u8 tc_reco_bw[8U] ;
   __u8 tc_reco_tsa[8U] ;
   __u8 reco_prio_tc[8U] ;
};
#line 69 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dcbnl.h"
struct ieee_maxrate {
   __u64 tc_maxrate[8U] ;
};
#line 80 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dcbnl.h"
struct ieee_pfc {
   __u8 pfc_cap ;
   __u8 pfc_en ;
   __u8 mbc ;
   __u16 delay ;
   __u64 requests[8U] ;
   __u64 indications[8U] ;
};
#line 100 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dcbnl.h"
struct cee_pg {
   __u8 willing ;
   __u8 error ;
   __u8 pg_en ;
   __u8 tcs_supported ;
   __u8 pg_bw[8U] ;
   __u8 prio_pg[8U] ;
};
#line 123 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dcbnl.h"
struct cee_pfc {
   __u8 willing ;
   __u8 error ;
   __u8 pfc_en ;
   __u8 tcs_supported ;
};
#line 138 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dcbnl.h"
struct dcb_app {
   __u8 selector ;
   __u8 priority ;
   __u16 protocol ;
};
#line 167 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/dcbnl.h"
struct dcb_peer_app_info {
   __u8 willing ;
   __u8 error ;
};
#line 41 "include/net/dcbnl.h"
struct dcbnl_rtnl_ops {
   int (*ieee_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_setets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_getmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_setmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_setpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_getapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_setapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_delapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_peer_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_peer_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   u8 (*getstate)(struct net_device * ) ;
   u8 (*setstate)(struct net_device * , u8  ) ;
   void (*getpermhwaddr)(struct net_device * , u8 * ) ;
   void (*setpgtccfgtx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgtx)(struct net_device * , int  , u8  ) ;
   void (*setpgtccfgrx)(struct net_device * , int  , u8  , u8  , u8  , u8  ) ;
   void (*setpgbwgcfgrx)(struct net_device * , int  , u8  ) ;
   void (*getpgtccfgtx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgtx)(struct net_device * , int  , u8 * ) ;
   void (*getpgtccfgrx)(struct net_device * , int  , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgrx)(struct net_device * , int  , u8 * ) ;
   void (*setpfccfg)(struct net_device * , int  , u8  ) ;
   void (*getpfccfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setall)(struct net_device * ) ;
   u8 (*getcap)(struct net_device * , int  , u8 * ) ;
   int (*getnumtcs)(struct net_device * , int  , u8 * ) ;
   int (*setnumtcs)(struct net_device * , int  , u8  ) ;
   u8 (*getpfcstate)(struct net_device * ) ;
   void (*setpfcstate)(struct net_device * , u8  ) ;
   void (*getbcncfg)(struct net_device * , int  , u32 * ) ;
   void (*setbcncfg)(struct net_device * , int  , u32  ) ;
   void (*getbcnrp)(struct net_device * , int  , u8 * ) ;
   void (*setbcnrp)(struct net_device * , int  , u8  ) ;
   u8 (*setapp)(struct net_device * , u8  , u16  , u8  ) ;
   u8 (*getapp)(struct net_device * , u8  , u16  ) ;
   u8 (*getfeatcfg)(struct net_device * , int  , u8 * ) ;
   u8 (*setfeatcfg)(struct net_device * , int  , u8  ) ;
   u8 (*getdcbx)(struct net_device * ) ;
   u8 (*setdcbx)(struct net_device * , u8  ) ;
   int (*peer_getappinfo)(struct net_device * , struct dcb_peer_app_info * , u16 * ) ;
   int (*peer_getapptable)(struct net_device * , struct dcb_app * ) ;
   int (*cee_peer_getpg)(struct net_device * , struct cee_pg * ) ;
   int (*cee_peer_getpfc)(struct net_device * , struct cee_pfc * ) ;
};
#line 103 "include/net/dcbnl.h"
struct taskstats {
   __u16 version ;
   __u32 ac_exitcode ;
   __u8 ac_flag ;
   __u8 ac_nice ;
   __u64 cpu_count ;
   __u64 cpu_delay_total ;
   __u64 blkio_count ;
   __u64 blkio_delay_total ;
   __u64 swapin_count ;
   __u64 swapin_delay_total ;
   __u64 cpu_run_real_total ;
   __u64 cpu_run_virtual_total ;
   char ac_comm[32U] ;
   __u8 ac_sched ;
   __u8 ac_pad[3U] ;
   __u32 ac_uid ;
   __u32 ac_gid ;
   __u32 ac_pid ;
   __u32 ac_ppid ;
   __u32 ac_btime ;
   __u64 ac_etime ;
   __u64 ac_utime ;
   __u64 ac_stime ;
   __u64 ac_minflt ;
   __u64 ac_majflt ;
   __u64 coremem ;
   __u64 virtmem ;
   __u64 hiwater_rss ;
   __u64 hiwater_vm ;
   __u64 read_char ;
   __u64 write_char ;
   __u64 read_syscalls ;
   __u64 write_syscalls ;
   __u64 read_bytes ;
   __u64 write_bytes ;
   __u64 cancelled_write_bytes ;
   __u64 nvcsw ;
   __u64 nivcsw ;
   __u64 ac_utimescaled ;
   __u64 ac_stimescaled ;
   __u64 cpu_scaled_run_real_total ;
   __u64 freepages_count ;
   __u64 freepages_delay_total ;
};
#line 55 "include/linux/prio_heap.h"
struct idr_layer {
   unsigned long bitmap ;
   struct idr_layer *ary[64U] ;
   int count ;
   int layer ;
   struct callback_head callback_head ;
};
#line 58 "include/linux/idr.h"
struct idr {
   struct idr_layer *top ;
   struct idr_layer *id_free ;
   int layers ;
   int id_free_cnt ;
   spinlock_t lock ;
};
#line 154 "include/linux/idr.h"
struct xattr_handler {
   char const   *prefix ;
   int flags ;
   size_t (*list)(struct dentry * , char * , size_t  , char const   * , size_t  ,
                  int  ) ;
   int (*get)(struct dentry * , char const   * , void * , size_t  , int  ) ;
   int (*set)(struct dentry * , char const   * , void const   * , size_t  , int  ,
              int  ) ;
};
#line 53 "include/linux/xattr.h"
struct simple_xattrs {
   struct list_head head ;
   spinlock_t lock ;
};
#line 98
struct cgroupfs_root;
#line 99
struct cgroup_subsys;
#line 100
struct cgroup;
#line 101
struct css_id;
#line 62 "include/linux/cgroup.h"
struct cgroup_subsys_state {
   struct cgroup *cgroup ;
   atomic_t refcnt ;
   unsigned long flags ;
   struct css_id *id ;
   struct work_struct dput_work ;
};
#line 147 "include/linux/cgroup.h"
struct cgroup {
   unsigned long flags ;
   atomic_t count ;
   struct list_head sibling ;
   struct list_head children ;
   struct list_head files ;
   struct cgroup *parent ;
   struct dentry *dentry ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct cgroupfs_root *root ;
   struct cgroup *top_cgroup ;
   struct list_head css_sets ;
   struct list_head allcg_node ;
   struct list_head cft_q_node ;
   struct list_head release_list ;
   struct list_head pidlists ;
   struct mutex pidlist_mutex ;
   struct callback_head callback_head ;
   struct list_head event_list ;
   spinlock_t event_list_lock ;
   struct simple_xattrs xattrs ;
};
#line 220 "include/linux/cgroup.h"
struct css_set {
   atomic_t refcount ;
   struct hlist_node hlist ;
   struct list_head tasks ;
   struct list_head cg_links ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct callback_head callback_head ;
};
#line 264 "include/linux/cgroup.h"
struct cgroup_map_cb {
   int (*fill)(struct cgroup_map_cb * , char const   * , u64  ) ;
   void *state ;
};
#line 274 "include/linux/cgroup.h"
struct cftype {
   char name[64U] ;
   int private ;
   umode_t mode ;
   size_t max_write_len ;
   unsigned int flags ;
   struct simple_xattrs xattrs ;
   int (*open)(struct inode * , struct file * ) ;
   ssize_t (*read)(struct cgroup * , struct cftype * , struct file * , char * , size_t  ,
                   loff_t * ) ;
   u64 (*read_u64)(struct cgroup * , struct cftype * ) ;
   s64 (*read_s64)(struct cgroup * , struct cftype * ) ;
   int (*read_map)(struct cgroup * , struct cftype * , struct cgroup_map_cb * ) ;
   int (*read_seq_string)(struct cgroup * , struct cftype * , struct seq_file * ) ;
   ssize_t (*write)(struct cgroup * , struct cftype * , struct file * , char const   * ,
                    size_t  , loff_t * ) ;
   int (*write_u64)(struct cgroup * , struct cftype * , u64  ) ;
   int (*write_s64)(struct cgroup * , struct cftype * , s64  ) ;
   int (*write_string)(struct cgroup * , struct cftype * , char const   * ) ;
   int (*trigger)(struct cgroup * , unsigned int  ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*register_event)(struct cgroup * , struct cftype * , struct eventfd_ctx * ,
                         char const   * ) ;
   void (*unregister_event)(struct cgroup * , struct cftype * , struct eventfd_ctx * ) ;
};
#line 391 "include/linux/cgroup.h"
struct cftype_set {
   struct list_head node ;
   struct cftype *cfts ;
};
#line 440
struct cgroup_taskset;
#line 450 "include/linux/cgroup.h"
struct cgroup_subsys {
   struct cgroup_subsys_state *(*create)(struct cgroup * ) ;
   int (*pre_destroy)(struct cgroup * ) ;
   void (*destroy)(struct cgroup * ) ;
   int (*can_attach)(struct cgroup * , struct cgroup_taskset * ) ;
   void (*cancel_attach)(struct cgroup * , struct cgroup_taskset * ) ;
   void (*attach)(struct cgroup * , struct cgroup_taskset * ) ;
   void (*fork)(struct task_struct * ) ;
   void (*exit)(struct cgroup * , struct cgroup * , struct task_struct * ) ;
   void (*post_clone)(struct cgroup * ) ;
   void (*bind)(struct cgroup * ) ;
   int subsys_id ;
   int active ;
   int disabled ;
   int early_init ;
   bool use_id ;
   bool __DEPRECATED_clear_css_refs ;
   bool broken_hierarchy ;
   bool warned_broken_hierarchy ;
   char const   *name ;
   struct cgroupfs_root *root ;
   struct list_head sibling ;
   struct idr idr ;
   spinlock_t id_lock ;
   struct list_head cftsets ;
   struct cftype *base_cftypes ;
   struct cftype_set base_cftset ;
   struct module *module ;
};
#line 642 "include/linux/cgroup.h"
struct netprio_map {
   struct callback_head rcu ;
   u32 priomap_len ;
   u32 priomap[] ;
};
#line 99 "include/linux/security.h"
struct xfrm_policy;
#line 100
struct xfrm_state;
#line 120
struct request_sock;
#line 3031
struct mnt_namespace;
#line 3032
struct ipc_namespace;
#line 3033 "include/linux/security.h"
struct nsproxy {
   atomic_t count ;
   struct uts_namespace *uts_ns ;
   struct ipc_namespace *ipc_ns ;
   struct mnt_namespace *mnt_ns ;
   struct pid_namespace *pid_ns ;
   struct net *net_ns ;
};
#line 40 "include/uapi/linux/netlink.h"
struct nlmsghdr {
   __u32 nlmsg_len ;
   __u16 nlmsg_type ;
   __u16 nlmsg_flags ;
   __u32 nlmsg_seq ;
   __u32 nlmsg_pid ;
};
#line 117 "include/uapi/linux/netlink.h"
struct nlattr {
   __u16 nla_len ;
   __u16 nla_type ;
};
#line 77 "include/linux/netlink.h"
struct netlink_callback {
   struct sk_buff *skb ;
   struct nlmsghdr  const  *nlh ;
   int (*dump)(struct sk_buff * , struct netlink_callback * ) ;
   int (*done)(struct netlink_callback * ) ;
   void *data ;
   struct module *module ;
   u16 family ;
   u16 min_dump_alloc ;
   unsigned int prev_seq ;
   unsigned int seq ;
   long args[6U] ;
};
#line 137 "include/linux/netlink.h"
struct ndmsg {
   __u8 ndm_family ;
   __u8 ndm_pad1 ;
   __u16 ndm_pad2 ;
   __s32 ndm_ifindex ;
   __u16 ndm_state ;
   __u8 ndm_flags ;
   __u8 ndm_type ;
};
#line 39 "include/uapi/linux/if_link.h"
struct rtnl_link_stats64 {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 rx_errors ;
   __u64 tx_errors ;
   __u64 rx_dropped ;
   __u64 tx_dropped ;
   __u64 multicast ;
   __u64 collisions ;
   __u64 rx_length_errors ;
   __u64 rx_over_errors ;
   __u64 rx_crc_errors ;
   __u64 rx_frame_errors ;
   __u64 rx_fifo_errors ;
   __u64 rx_missed_errors ;
   __u64 tx_aborted_errors ;
   __u64 tx_carrier_errors ;
   __u64 tx_fifo_errors ;
   __u64 tx_heartbeat_errors ;
   __u64 tx_window_errors ;
   __u64 rx_compressed ;
   __u64 tx_compressed ;
};
#line 423 "include/uapi/linux/if_link.h"
struct ifla_vf_info {
   __u32 vf ;
   __u8 mac[32U] ;
   __u32 vlan ;
   __u32 qos ;
   __u32 tx_rate ;
   __u32 spoofchk ;
};
#line 26 "include/linux/if_link.h"
struct netpoll_info;
#line 27
struct phy_device;
#line 28
struct wireless_dev;
#line 29
enum netdev_tx {
    __NETDEV_TX_MIN = (-0x7FFFFFFF-1),
    NETDEV_TX_OK = 0,
    NETDEV_TX_BUSY = 16,
    NETDEV_TX_LOCKED = 32
} ;
#line 111 "include/linux/netdevice.h"
typedef enum netdev_tx netdev_tx_t;
#line 130 "include/linux/netdevice.h"
struct net_device_stats {
   unsigned long rx_packets ;
   unsigned long tx_packets ;
   unsigned long rx_bytes ;
   unsigned long tx_bytes ;
   unsigned long rx_errors ;
   unsigned long tx_errors ;
   unsigned long rx_dropped ;
   unsigned long tx_dropped ;
   unsigned long multicast ;
   unsigned long collisions ;
   unsigned long rx_length_errors ;
   unsigned long rx_over_errors ;
   unsigned long rx_crc_errors ;
   unsigned long rx_frame_errors ;
   unsigned long rx_fifo_errors ;
   unsigned long rx_missed_errors ;
   unsigned long tx_aborted_errors ;
   unsigned long tx_carrier_errors ;
   unsigned long tx_fifo_errors ;
   unsigned long tx_heartbeat_errors ;
   unsigned long tx_window_errors ;
   unsigned long rx_compressed ;
   unsigned long tx_compressed ;
};
#line 193
struct neigh_parms;
#line 213 "include/linux/netdevice.h"
struct netdev_hw_addr_list {
   struct list_head list ;
   int count ;
};
#line 218 "include/linux/netdevice.h"
struct hh_cache {
   u16 hh_len ;
   u16 __pad ;
   seqlock_t hh_lock ;
   unsigned long hh_data[16U] ;
};
#line 247 "include/linux/netdevice.h"
struct header_ops {
   int (*create)(struct sk_buff * , struct net_device * , unsigned short  , void const   * ,
                 void const   * , unsigned int  ) ;
   int (*parse)(struct sk_buff  const  * , unsigned char * ) ;
   int (*rebuild)(struct sk_buff * ) ;
   int (*cache)(struct neighbour  const  * , struct hh_cache * , __be16  ) ;
   void (*cache_update)(struct hh_cache * , struct net_device  const  * , unsigned char const   * ) ;
};
#line 339
enum rx_handler_result {
    RX_HANDLER_CONSUMED = 0,
    RX_HANDLER_ANOTHER = 1,
    RX_HANDLER_EXACT = 2,
    RX_HANDLER_PASS = 3
} ;
#line 387 "include/linux/netdevice.h"
typedef enum rx_handler_result rx_handler_result_t;
#line 388 "include/linux/netdevice.h"
typedef rx_handler_result_t rx_handler_func_t(struct sk_buff ** );
#line 496
struct Qdisc;
#line 496 "include/linux/netdevice.h"
struct netdev_queue {
   struct net_device *dev ;
   struct Qdisc *qdisc ;
   struct Qdisc *qdisc_sleeping ;
   struct kobject kobj ;
   int numa_node ;
   spinlock_t _xmit_lock ;
   int xmit_lock_owner ;
   unsigned long trans_start ;
   unsigned long trans_timeout ;
   unsigned long state ;
   struct dql dql ;
};
#line 560 "include/linux/netdevice.h"
struct rps_map {
   unsigned int len ;
   struct callback_head rcu ;
   u16 cpus[0U] ;
};
#line 572 "include/linux/netdevice.h"
struct rps_dev_flow {
   u16 cpu ;
   u16 filter ;
   unsigned int last_qtail ;
};
#line 584 "include/linux/netdevice.h"
struct rps_dev_flow_table {
   unsigned int mask ;
   struct callback_head rcu ;
   struct work_struct free_work ;
   struct rps_dev_flow flows[0U] ;
};
#line 636 "include/linux/netdevice.h"
struct netdev_rx_queue {
   struct rps_map *rps_map ;
   struct rps_dev_flow_table *rps_flow_table ;
   struct kobject kobj ;
   struct net_device *dev ;
};
#line 646 "include/linux/netdevice.h"
struct xps_map {
   unsigned int len ;
   unsigned int alloc_len ;
   struct callback_head rcu ;
   u16 queues[0U] ;
};
#line 659 "include/linux/netdevice.h"
struct xps_dev_maps {
   struct callback_head rcu ;
   struct xps_map *cpu_map[0U] ;
};
#line 670 "include/linux/netdevice.h"
struct netdev_tc_txq {
   u16 count ;
   u16 offset ;
};
#line 681 "include/linux/netdevice.h"
struct netdev_fcoe_hbainfo {
   char manufacturer[64U] ;
   char serial_number[64U] ;
   char hardware_version[64U] ;
   char driver_version[64U] ;
   char optionrom_version[64U] ;
   char firmware_version[64U] ;
   char model[256U] ;
   char model_description[256U] ;
};
#line 697 "include/linux/netdevice.h"
struct net_device_ops {
   int (*ndo_init)(struct net_device * ) ;
   void (*ndo_uninit)(struct net_device * ) ;
   int (*ndo_open)(struct net_device * ) ;
   int (*ndo_stop)(struct net_device * ) ;
   netdev_tx_t (*ndo_start_xmit)(struct sk_buff * , struct net_device * ) ;
   u16 (*ndo_select_queue)(struct net_device * , struct sk_buff * ) ;
   void (*ndo_change_rx_flags)(struct net_device * , int  ) ;
   void (*ndo_set_rx_mode)(struct net_device * ) ;
   int (*ndo_set_mac_address)(struct net_device * , void * ) ;
   int (*ndo_validate_addr)(struct net_device * ) ;
   int (*ndo_do_ioctl)(struct net_device * , struct ifreq * , int  ) ;
   int (*ndo_set_config)(struct net_device * , struct ifmap * ) ;
   int (*ndo_change_mtu)(struct net_device * , int  ) ;
   int (*ndo_neigh_setup)(struct net_device * , struct neigh_parms * ) ;
   void (*ndo_tx_timeout)(struct net_device * ) ;
   struct rtnl_link_stats64 *(*ndo_get_stats64)(struct net_device * , struct rtnl_link_stats64 * ) ;
   struct net_device_stats *(*ndo_get_stats)(struct net_device * ) ;
   int (*ndo_vlan_rx_add_vid)(struct net_device * , unsigned short  ) ;
   int (*ndo_vlan_rx_kill_vid)(struct net_device * , unsigned short  ) ;
   void (*ndo_poll_controller)(struct net_device * ) ;
   int (*ndo_netpoll_setup)(struct net_device * , struct netpoll_info * , gfp_t  ) ;
   void (*ndo_netpoll_cleanup)(struct net_device * ) ;
   int (*ndo_set_vf_mac)(struct net_device * , int  , u8 * ) ;
   int (*ndo_set_vf_vlan)(struct net_device * , int  , u16  , u8  ) ;
   int (*ndo_set_vf_tx_rate)(struct net_device * , int  , int  ) ;
   int (*ndo_set_vf_spoofchk)(struct net_device * , int  , bool  ) ;
   int (*ndo_get_vf_config)(struct net_device * , int  , struct ifla_vf_info * ) ;
   int (*ndo_set_vf_port)(struct net_device * , int  , struct nlattr ** ) ;
   int (*ndo_get_vf_port)(struct net_device * , int  , struct sk_buff * ) ;
   int (*ndo_setup_tc)(struct net_device * , u8  ) ;
   int (*ndo_fcoe_enable)(struct net_device * ) ;
   int (*ndo_fcoe_disable)(struct net_device * ) ;
   int (*ndo_fcoe_ddp_setup)(struct net_device * , u16  , struct scatterlist * , unsigned int  ) ;
   int (*ndo_fcoe_ddp_done)(struct net_device * , u16  ) ;
   int (*ndo_fcoe_ddp_target)(struct net_device * , u16  , struct scatterlist * ,
                              unsigned int  ) ;
   int (*ndo_fcoe_get_hbainfo)(struct net_device * , struct netdev_fcoe_hbainfo * ) ;
   int (*ndo_fcoe_get_wwn)(struct net_device * , u64 * , int  ) ;
   int (*ndo_rx_flow_steer)(struct net_device * , struct sk_buff  const  * , u16  ,
                            u32  ) ;
   int (*ndo_add_slave)(struct net_device * , struct net_device * ) ;
   int (*ndo_del_slave)(struct net_device * , struct net_device * ) ;
   netdev_features_t (*ndo_fix_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_set_features)(struct net_device * , netdev_features_t  ) ;
   int (*ndo_neigh_construct)(struct neighbour * ) ;
   void (*ndo_neigh_destroy)(struct neighbour * ) ;
   int (*ndo_fdb_add)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const   * ,
                      u16  ) ;
   int (*ndo_fdb_del)(struct ndmsg * , struct net_device * , unsigned char const   * ) ;
   int (*ndo_fdb_dump)(struct sk_buff * , struct netlink_callback * , struct net_device * ,
                       int  ) ;
};
#line 1013
struct iw_handler_def;
#line 1013
struct iw_public_data;
#line 1013
struct vlan_info;
#line 1013
struct in_device;
#line 1013
struct dn_dev;
#line 1013
struct inet6_dev;
#line 1013
struct cpu_rmap;
#line 1013
struct pcpu_lstats;
#line 1013
struct pcpu_tstats;
#line 1013
struct pcpu_dstats;
#line 1013 "include/linux/netdevice.h"
union __anonunion_ldv_35542_214 {
   void *ml_priv ;
   struct pcpu_lstats *lstats ;
   struct pcpu_tstats *tstats ;
   struct pcpu_dstats *dstats ;
};
#line 1013
struct garp_port;
#line 1013
struct rtnl_link_ops;
#line 1013 "include/linux/netdevice.h"
struct net_device {
   char name[16U] ;
   struct hlist_node name_hlist ;
   char *ifalias ;
   unsigned long mem_end ;
   unsigned long mem_start ;
   unsigned long base_addr ;
   unsigned int irq ;
   unsigned long state ;
   struct list_head dev_list ;
   struct list_head napi_list ;
   struct list_head unreg_list ;
   netdev_features_t features ;
   netdev_features_t hw_features ;
   netdev_features_t wanted_features ;
   netdev_features_t vlan_features ;
   int ifindex ;
   int iflink ;
   struct net_device_stats stats ;
   atomic_long_t rx_dropped ;
   struct iw_handler_def  const  *wireless_handlers ;
   struct iw_public_data *wireless_data ;
   struct net_device_ops  const  *netdev_ops ;
   struct ethtool_ops  const  *ethtool_ops ;
   struct header_ops  const  *header_ops ;
   unsigned int flags ;
   unsigned int priv_flags ;
   unsigned short gflags ;
   unsigned short padded ;
   unsigned char operstate ;
   unsigned char link_mode ;
   unsigned char if_port ;
   unsigned char dma ;
   unsigned int mtu ;
   unsigned short type ;
   unsigned short hard_header_len ;
   unsigned short needed_headroom ;
   unsigned short needed_tailroom ;
   unsigned char perm_addr[32U] ;
   unsigned char addr_assign_type ;
   unsigned char addr_len ;
   unsigned char neigh_priv_len ;
   unsigned short dev_id ;
   spinlock_t addr_list_lock ;
   struct netdev_hw_addr_list uc ;
   struct netdev_hw_addr_list mc ;
   bool uc_promisc ;
   unsigned int promiscuity ;
   unsigned int allmulti ;
   struct vlan_info *vlan_info ;
   struct dsa_switch_tree *dsa_ptr ;
   void *atalk_ptr ;
   struct in_device *ip_ptr ;
   struct dn_dev *dn_ptr ;
   struct inet6_dev *ip6_ptr ;
   void *ax25_ptr ;
   struct wireless_dev *ieee80211_ptr ;
   unsigned long last_rx ;
   struct net_device *master ;
   unsigned char *dev_addr ;
   struct netdev_hw_addr_list dev_addrs ;
   unsigned char broadcast[32U] ;
   struct kset *queues_kset ;
   struct netdev_rx_queue *_rx ;
   unsigned int num_rx_queues ;
   unsigned int real_num_rx_queues ;
   struct cpu_rmap *rx_cpu_rmap ;
   rx_handler_func_t *rx_handler ;
   void *rx_handler_data ;
   struct netdev_queue *ingress_queue ;
   struct netdev_queue *_tx ;
   unsigned int num_tx_queues ;
   unsigned int real_num_tx_queues ;
   struct Qdisc *qdisc ;
   unsigned long tx_queue_len ;
   spinlock_t tx_global_lock ;
   struct xps_dev_maps *xps_maps ;
   unsigned long trans_start ;
   int watchdog_timeo ;
   struct timer_list watchdog_timer ;
   int *pcpu_refcnt ;
   struct list_head todo_list ;
   struct hlist_node index_hlist ;
   struct list_head link_watch_list ;
   unsigned char reg_state ;
   bool dismantle ;
   unsigned short rtnl_link_state ;
   void (*destructor)(struct net_device * ) ;
   struct netpoll_info *npinfo ;
   struct net *nd_net ;
   union __anonunion_ldv_35542_214 ldv_35542 ;
   struct garp_port *garp_port ;
   struct device dev ;
   struct attribute_group  const  *sysfs_groups[4U] ;
   struct rtnl_link_ops  const  *rtnl_link_ops ;
   unsigned int gso_max_size ;
   u16 gso_max_segs ;
   struct dcbnl_rtnl_ops  const  *dcbnl_ops ;
   u8 num_tc ;
   struct netdev_tc_txq tc_to_txq[16U] ;
   u8 prio_tc_map[16U] ;
   unsigned int fcoe_ddp_xid ;
   struct netprio_map *priomap ;
   struct phy_device *phydev ;
   struct lock_class_key *qdisc_tx_busylock ;
   int group ;
   struct pm_qos_request pm_qos_req ;
};
#line 402 "include/linux/memcontrol.h"
struct res_counter {
   unsigned long long usage ;
   unsigned long long max_usage ;
   unsigned long long limit ;
   unsigned long long soft_limit ;
   unsigned long long failcnt ;
   spinlock_t lock ;
   struct res_counter *parent ;
};
#line 228 "include/linux/res_counter.h"
struct sock_filter {
   __u16 code ;
   __u8 jt ;
   __u8 jf ;
   __u32 k ;
};
#line 19 "include/linux/filter.h"
struct sk_filter {
   atomic_t refcnt ;
   unsigned int len ;
   unsigned int (*bpf_func)(struct sk_buff  const  * , struct sock_filter  const  * ) ;
   struct callback_head rcu ;
   struct sock_filter insns[0U] ;
};
#line 101 "include/linux/rculist_nulls.h"
struct pollfd {
   int fd ;
   short events ;
   short revents ;
};
#line 32 "include/linux/poll.h"
struct poll_table_struct {
   void (*_qproc)(struct file * , wait_queue_head_t * , struct poll_table_struct * ) ;
   unsigned long _key ;
};
#line 89 "include/linux/rtnetlink.h"
struct nla_policy {
   u16 type ;
   u16 len ;
};
#line 27 "include/net/rtnetlink.h"
struct rtnl_link_ops {
   struct list_head list ;
   char const   *kind ;
   size_t priv_size ;
   void (*setup)(struct net_device * ) ;
   int maxtype ;
   struct nla_policy  const  *policy ;
   int (*validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*newlink)(struct net * , struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   int (*changelink)(struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   void (*dellink)(struct net_device * , struct list_head * ) ;
   size_t (*get_size)(struct net_device  const  * ) ;
   int (*fill_info)(struct sk_buff * , struct net_device  const  * ) ;
   size_t (*get_xstats_size)(struct net_device  const  * ) ;
   int (*fill_xstats)(struct sk_buff * , struct net_device  const  * ) ;
   unsigned int (*get_num_tx_queues)(void) ;
   unsigned int (*get_num_rx_queues)(void) ;
};
#line 133
struct neigh_table;
#line 133 "include/net/rtnetlink.h"
struct neigh_parms {
   struct net *net ;
   struct net_device *dev ;
   struct neigh_parms *next ;
   int (*neigh_setup)(struct neighbour * ) ;
   void (*neigh_cleanup)(struct neighbour * ) ;
   struct neigh_table *tbl ;
   void *sysctl_table ;
   int dead ;
   atomic_t refcnt ;
   struct callback_head callback_head ;
   int base_reachable_time ;
   int retrans_time ;
   int gc_staletime ;
   int reachable_time ;
   int delay_probe_time ;
   int queue_len_bytes ;
   int ucast_probes ;
   int app_probes ;
   int mcast_probes ;
   int anycast_delay ;
   int proxy_delay ;
   int proxy_qlen ;
   int locktime ;
};
#line 71 "include/net/neighbour.h"
struct neigh_statistics {
   unsigned long allocs ;
   unsigned long destroys ;
   unsigned long hash_grows ;
   unsigned long res_failed ;
   unsigned long lookups ;
   unsigned long hits ;
   unsigned long rcv_probes_mcast ;
   unsigned long rcv_probes_ucast ;
   unsigned long periodic_gc_runs ;
   unsigned long forced_gc_runs ;
   unsigned long unres_discards ;
};
#line 90
struct neigh_ops;
#line 90 "include/net/neighbour.h"
struct neighbour {
   struct neighbour *next ;
   struct neigh_table *tbl ;
   struct neigh_parms *parms ;
   unsigned long confirmed ;
   unsigned long updated ;
   rwlock_t lock ;
   atomic_t refcnt ;
   struct sk_buff_head arp_queue ;
   unsigned int arp_queue_len_bytes ;
   struct timer_list timer ;
   unsigned long used ;
   atomic_t probes ;
   __u8 flags ;
   __u8 nud_state ;
   __u8 type ;
   __u8 dead ;
   seqlock_t ha_lock ;
   unsigned char ha[32U] ;
   struct hh_cache hh ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   struct neigh_ops  const  *ops ;
   struct callback_head rcu ;
   struct net_device *dev ;
   u8 primary_key[0U] ;
};
#line 119 "include/net/neighbour.h"
struct neigh_ops {
   int family ;
   void (*solicit)(struct neighbour * , struct sk_buff * ) ;
   void (*error_report)(struct neighbour * , struct sk_buff * ) ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   int (*connected_output)(struct neighbour * , struct sk_buff * ) ;
};
#line 127 "include/net/neighbour.h"
struct pneigh_entry {
   struct pneigh_entry *next ;
   struct net *net ;
   struct net_device *dev ;
   u8 flags ;
   u8 key[0U] ;
};
#line 137 "include/net/neighbour.h"
struct neigh_hash_table {
   struct neighbour **hash_buckets ;
   unsigned int hash_shift ;
   __u32 hash_rnd[4U] ;
   struct callback_head rcu ;
};
#line 150 "include/net/neighbour.h"
struct neigh_table {
   struct neigh_table *next ;
   int family ;
   int entry_size ;
   int key_len ;
   __u32 (*hash)(void const   * , struct net_device  const  * , __u32 * ) ;
   int (*constructor)(struct neighbour * ) ;
   int (*pconstructor)(struct pneigh_entry * ) ;
   void (*pdestructor)(struct pneigh_entry * ) ;
   void (*proxy_redo)(struct sk_buff * ) ;
   char *id ;
   struct neigh_parms parms ;
   int gc_interval ;
   int gc_thresh1 ;
   int gc_thresh2 ;
   int gc_thresh3 ;
   unsigned long last_flush ;
   struct delayed_work gc_work ;
   struct timer_list proxy_timer ;
   struct sk_buff_head proxy_queue ;
   atomic_t entries ;
   rwlock_t lock ;
   unsigned long last_rand ;
   struct neigh_statistics *stats ;
   struct neigh_hash_table *nht ;
   struct pneigh_entry **phash_buckets ;
};
#line 406 "include/net/neighbour.h"
union __anonunion_ldv_38387_219 {
   unsigned long expires ;
   struct dst_entry *from ;
};
#line 406
struct dn_route;
#line 406 "include/net/neighbour.h"
union __anonunion_ldv_38412_220 {
   struct dst_entry *next ;
   struct rtable *rt_next ;
   struct rt6_info *rt6_next ;
   struct dn_route *dn_next ;
};
#line 406 "include/net/neighbour.h"
struct dst_entry {
   struct callback_head callback_head ;
   struct dst_entry *child ;
   struct net_device *dev ;
   struct dst_ops *ops ;
   unsigned long _metrics ;
   union __anonunion_ldv_38387_219 ldv_38387 ;
   struct dst_entry *path ;
   void *__pad0 ;
   struct xfrm_state *xfrm ;
   int (*input)(struct sk_buff * ) ;
   int (*output)(struct sk_buff * ) ;
   unsigned short flags ;
   unsigned short pending_confirm ;
   short error ;
   short obsolete ;
   unsigned short header_len ;
   unsigned short trailer_len ;
   __u32 tclassid ;
   long __pad_to_align_refcnt[2U] ;
   atomic_t __refcnt ;
   int __use ;
   unsigned long lastuse ;
   union __anonunion_ldv_38412_220 ldv_38412 ;
};
#line 123 "include/net/sock.h"
struct __anonstruct_socket_lock_t_221 {
   spinlock_t slock ;
   int owned ;
   wait_queue_head_t wq ;
   struct lockdep_map dep_map ;
};
#line 123 "include/net/sock.h"
typedef struct __anonstruct_socket_lock_t_221 socket_lock_t;
#line 123
struct proto;
#line 124 "include/net/sock.h"
union __anonunion_ldv_38627_222 {
   unsigned int skc_hash ;
   __u16 skc_u16hashes[2U] ;
};
#line 124 "include/net/sock.h"
union __anonunion_ldv_38635_223 {
   struct hlist_node skc_bind_node ;
   struct hlist_nulls_node skc_portaddr_node ;
};
#line 124 "include/net/sock.h"
union __anonunion_ldv_38642_224 {
   struct hlist_node skc_node ;
   struct hlist_nulls_node skc_nulls_node ;
};
#line 124 "include/net/sock.h"
struct sock_common {
   __be32 skc_daddr ;
   __be32 skc_rcv_saddr ;
   union __anonunion_ldv_38627_222 ldv_38627 ;
   unsigned short skc_family ;
   unsigned char volatile   skc_state ;
   unsigned char skc_reuse ;
   int skc_bound_dev_if ;
   union __anonunion_ldv_38635_223 ldv_38635 ;
   struct proto *skc_prot ;
   struct net *skc_net ;
   int skc_dontcopy_begin[0U] ;
   union __anonunion_ldv_38642_224 ldv_38642 ;
   int skc_tx_queue_mapping ;
   atomic_t skc_refcnt ;
   int skc_dontcopy_end[0U] ;
};
#line 190
struct cg_proto;
#line 191 "include/net/sock.h"
struct __anonstruct_sk_backlog_225 {
   atomic_t rmem_alloc ;
   int len ;
   struct sk_buff *head ;
   struct sk_buff *tail ;
};
#line 191 "include/net/sock.h"
struct sock {
   struct sock_common __sk_common ;
   socket_lock_t sk_lock ;
   struct sk_buff_head sk_receive_queue ;
   struct __anonstruct_sk_backlog_225 sk_backlog ;
   int sk_forward_alloc ;
   __u32 sk_rxhash ;
   atomic_t sk_drops ;
   int sk_rcvbuf ;
   struct sk_filter *sk_filter ;
   struct socket_wq *sk_wq ;
   struct sk_buff_head sk_async_wait_queue ;
   struct xfrm_policy *sk_policy[2U] ;
   unsigned long sk_flags ;
   struct dst_entry *sk_rx_dst ;
   struct dst_entry *sk_dst_cache ;
   spinlock_t sk_dst_lock ;
   atomic_t sk_wmem_alloc ;
   atomic_t sk_omem_alloc ;
   int sk_sndbuf ;
   struct sk_buff_head sk_write_queue ;
   unsigned char sk_shutdown : 2 ;
   unsigned char sk_no_check : 2 ;
   unsigned char sk_userlocks : 4 ;
   unsigned char sk_protocol ;
   unsigned short sk_type ;
   int sk_wmem_queued ;
   gfp_t sk_allocation ;
   netdev_features_t sk_route_caps ;
   netdev_features_t sk_route_nocaps ;
   int sk_gso_type ;
   unsigned int sk_gso_max_size ;
   u16 sk_gso_max_segs ;
   int sk_rcvlowat ;
   unsigned long sk_lingertime ;
   struct sk_buff_head sk_error_queue ;
   struct proto *sk_prot_creator ;
   rwlock_t sk_callback_lock ;
   int sk_err ;
   int sk_err_soft ;
   unsigned short sk_ack_backlog ;
   unsigned short sk_max_ack_backlog ;
   __u32 sk_priority ;
   __u32 sk_cgrp_prioidx ;
   struct pid *sk_peer_pid ;
   struct cred  const  *sk_peer_cred ;
   long sk_rcvtimeo ;
   long sk_sndtimeo ;
   void *sk_protinfo ;
   struct timer_list sk_timer ;
   ktime_t sk_stamp ;
   struct socket *sk_socket ;
   void *sk_user_data ;
   struct page_frag sk_frag ;
   struct sk_buff *sk_send_head ;
   __s32 sk_peek_off ;
   int sk_write_pending ;
   void *sk_security ;
   __u32 sk_mark ;
   u32 sk_classid ;
   struct cg_proto *sk_cgrp ;
   void (*sk_state_change)(struct sock * ) ;
   void (*sk_data_ready)(struct sock * , int  ) ;
   void (*sk_write_space)(struct sock * ) ;
   void (*sk_error_report)(struct sock * ) ;
   int (*sk_backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*sk_destruct)(struct sock * ) ;
};
#line 840
struct request_sock_ops;
#line 841
struct timewait_sock_ops;
#line 842
struct inet_hashinfo;
#line 843
struct raw_hashinfo;
#line 844
struct udp_table;
#line 844 "include/net/sock.h"
union __anonunion_h_226 {
   struct inet_hashinfo *hashinfo ;
   struct udp_table *udp_table ;
   struct raw_hashinfo *raw_hash ;
};
#line 844 "include/net/sock.h"
struct proto {
   void (*close)(struct sock * , long  ) ;
   int (*connect)(struct sock * , struct sockaddr * , int  ) ;
   int (*disconnect)(struct sock * , int  ) ;
   struct sock *(*accept)(struct sock * , int  , int * ) ;
   int (*ioctl)(struct sock * , int  , unsigned long  ) ;
   int (*init)(struct sock * ) ;
   void (*destroy)(struct sock * ) ;
   void (*shutdown)(struct sock * , int  ) ;
   int (*setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_setsockopt)(struct sock * , int  , int  , char * , unsigned int  ) ;
   int (*compat_getsockopt)(struct sock * , int  , int  , char * , int * ) ;
   int (*compat_ioctl)(struct sock * , unsigned int  , unsigned long  ) ;
   int (*sendmsg)(struct kiocb * , struct sock * , struct msghdr * , size_t  ) ;
   int (*recvmsg)(struct kiocb * , struct sock * , struct msghdr * , size_t  , int  ,
                  int  , int * ) ;
   int (*sendpage)(struct sock * , struct page * , int  , size_t  , int  ) ;
   int (*bind)(struct sock * , struct sockaddr * , int  ) ;
   int (*backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*release_cb)(struct sock * ) ;
   void (*mtu_reduced)(struct sock * ) ;
   void (*hash)(struct sock * ) ;
   void (*unhash)(struct sock * ) ;
   void (*rehash)(struct sock * ) ;
   int (*get_port)(struct sock * , unsigned short  ) ;
   void (*clear_sk)(struct sock * , int  ) ;
   unsigned int inuse_idx ;
   void (*enter_memory_pressure)(struct sock * ) ;
   atomic_long_t *memory_allocated ;
   struct percpu_counter *sockets_allocated ;
   int *memory_pressure ;
   long *sysctl_mem ;
   int *sysctl_wmem ;
   int *sysctl_rmem ;
   int max_header ;
   bool no_autobind ;
   struct kmem_cache *slab ;
   unsigned int obj_size ;
   int slab_flags ;
   struct percpu_counter *orphan_count ;
   struct request_sock_ops *rsk_prot ;
   struct timewait_sock_ops *twsk_prot ;
   union __anonunion_h_226 h ;
   struct module *owner ;
   char name[32U] ;
   struct list_head node ;
   int (*init_cgroup)(struct mem_cgroup * , struct cgroup_subsys * ) ;
   void (*destroy_cgroup)(struct mem_cgroup * ) ;
   struct cg_proto *(*proto_cgroup)(struct mem_cgroup * ) ;
};
#line 970 "include/net/sock.h"
struct cg_proto {
   void (*enter_memory_pressure)(struct sock * ) ;
   struct res_counter *memory_allocated ;
   struct percpu_counter *sockets_allocated ;
   int *memory_pressure ;
   long *sysctl_mem ;
   unsigned long flags ;
   struct mem_cgroup *memcg ;
};
#line 55 "include/linux/drbd.h"
enum drbd_io_error_p {
    EP_PASS_ON = 0,
    EP_CALL_HELPER = 1,
    EP_DETACH = 2
} ;
#line 183
enum drbd_conns {
    C_STANDALONE = 0,
    C_DISCONNECTING = 1,
    C_UNCONNECTED = 2,
    C_TIMEOUT = 3,
    C_BROKEN_PIPE = 4,
    C_NETWORK_FAILURE = 5,
    C_PROTOCOL_ERROR = 6,
    C_TEAR_DOWN = 7,
    C_WF_CONNECTION = 8,
    C_WF_REPORT_PARAMS = 9,
    C_CONNECTED = 10,
    C_STARTING_SYNC_S = 11,
    C_STARTING_SYNC_T = 12,
    C_WF_BITMAP_S = 13,
    C_WF_BITMAP_T = 14,
    C_WF_SYNC_UUID = 15,
    C_SYNC_SOURCE = 16,
    C_SYNC_TARGET = 17,
    C_VERIFY_S = 18,
    C_VERIFY_T = 19,
    C_PAUSED_SYNC_S = 20,
    C_PAUSED_SYNC_T = 21,
    C_AHEAD = 22,
    C_BEHIND = 23,
    C_MASK = 31
} ;
#line 211
enum drbd_disk_state {
    D_DISKLESS = 0,
    D_ATTACHING = 1,
    D_FAILED = 2,
    D_NEGOTIATING = 3,
    D_INCONSISTENT = 4,
    D_OUTDATED = 5,
    D_UNKNOWN = 6,
    D_CONSISTENT = 7,
    D_UP_TO_DATE = 8,
    D_MASK = 15
} ;
#line 224 "include/linux/drbd.h"
struct __anonstruct_ldv_40024_227 {
   unsigned char role : 2 ;
   unsigned char peer : 2 ;
   unsigned char conn : 5 ;
   unsigned char disk : 4 ;
   unsigned char pdsk : 4 ;
   unsigned char susp : 1 ;
   unsigned char aftr_isp : 1 ;
   unsigned char peer_isp : 1 ;
   unsigned char user_isp : 1 ;
   unsigned char susp_nod : 1 ;
   unsigned char susp_fen : 1 ;
   unsigned short _pad : 9 ;
};
#line 224 "include/linux/drbd.h"
union drbd_state {
   struct __anonstruct_ldv_40024_227 ldv_40024 ;
   unsigned int i ;
};
#line 296
enum drbd_state_rv {
    SS_CW_NO_NEED = 4,
    SS_CW_SUCCESS = 3,
    SS_NOTHING_TO_DO = 2,
    SS_SUCCESS = 1,
    SS_UNKNOWN_ERROR = 0,
    SS_TWO_PRIMARIES = -1,
    SS_NO_UP_TO_DATE_DISK = -2,
    SS_NO_LOCAL_DISK = -4,
    SS_NO_REMOTE_DISK = -5,
    SS_CONNECTED_OUTDATES = -6,
    SS_PRIMARY_NOP = -7,
    SS_RESYNC_RUNNING = -8,
    SS_ALREADY_STANDALONE = -9,
    SS_CW_FAILED_BY_PEER = -10,
    SS_IS_DISKLESS = -11,
    SS_DEVICE_IN_USE = -12,
    SS_NO_NET_CONFIG = -13,
    SS_NO_VERIFY_ALG = -14,
    SS_NEED_CONNECTION = -15,
    SS_LOWER_THAN_OUTDATED = -16,
    SS_NOT_SUPPORTED = -17,
    SS_IN_TRANSIENT_STATE = -18,
    SS_CONCURRENT_ST_CHG = -19,
    SS_O_VOL_PEER_PRI = -20,
    SS_AFTER_LAST_ERROR = -21
} ;
#line 346
struct crypto_ablkcipher;
#line 347
struct crypto_async_request;
#line 348
struct crypto_aead;
#line 349
struct crypto_blkcipher;
#line 350
struct crypto_hash;
#line 351
struct crypto_rng;
#line 352
struct crypto_tfm;
#line 353
struct crypto_type;
#line 354
struct aead_givcrypt_request;
#line 355
struct skcipher_givcrypt_request;
#line 129 "include/linux/crypto.h"
struct crypto_async_request {
   struct list_head list ;
   void (*complete)(struct crypto_async_request * , int  ) ;
   void *data ;
   struct crypto_tfm *tfm ;
   u32 flags ;
};
#line 138 "include/linux/crypto.h"
struct ablkcipher_request {
   struct crypto_async_request base ;
   unsigned int nbytes ;
   void *info ;
   struct scatterlist *src ;
   struct scatterlist *dst ;
   void *__ctx[] ;
};
#line 151 "include/linux/crypto.h"
struct aead_request {
   struct crypto_async_request base ;
   unsigned int assoclen ;
   unsigned int cryptlen ;
   u8 *iv ;
   struct scatterlist *assoc ;
   struct scatterlist *src ;
   struct scatterlist *dst ;
   void *__ctx[] ;
};
#line 177 "include/linux/crypto.h"
struct blkcipher_desc {
   struct crypto_blkcipher *tfm ;
   void *info ;
   u32 flags ;
};
#line 191 "include/linux/crypto.h"
struct hash_desc {
   struct crypto_hash *tfm ;
   u32 flags ;
};
#line 196 "include/linux/crypto.h"
struct ablkcipher_alg {
   int (*setkey)(struct crypto_ablkcipher * , u8 const   * , unsigned int  ) ;
   int (*encrypt)(struct ablkcipher_request * ) ;
   int (*decrypt)(struct ablkcipher_request * ) ;
   int (*givencrypt)(struct skcipher_givcrypt_request * ) ;
   int (*givdecrypt)(struct skcipher_givcrypt_request * ) ;
   char const   *geniv ;
   unsigned int min_keysize ;
   unsigned int max_keysize ;
   unsigned int ivsize ;
};
#line 215 "include/linux/crypto.h"
struct aead_alg {
   int (*setkey)(struct crypto_aead * , u8 const   * , unsigned int  ) ;
   int (*setauthsize)(struct crypto_aead * , unsigned int  ) ;
   int (*encrypt)(struct aead_request * ) ;
   int (*decrypt)(struct aead_request * ) ;
   int (*givencrypt)(struct aead_givcrypt_request * ) ;
   int (*givdecrypt)(struct aead_givcrypt_request * ) ;
   char const   *geniv ;
   unsigned int ivsize ;
   unsigned int maxauthsize ;
};
#line 230 "include/linux/crypto.h"
struct blkcipher_alg {
   int (*setkey)(struct crypto_tfm * , u8 const   * , unsigned int  ) ;
   int (*encrypt)(struct blkcipher_desc * , struct scatterlist * , struct scatterlist * ,
                  unsigned int  ) ;
   int (*decrypt)(struct blkcipher_desc * , struct scatterlist * , struct scatterlist * ,
                  unsigned int  ) ;
   char const   *geniv ;
   unsigned int min_keysize ;
   unsigned int max_keysize ;
   unsigned int ivsize ;
};
#line 247 "include/linux/crypto.h"
struct cipher_alg {
   unsigned int cia_min_keysize ;
   unsigned int cia_max_keysize ;
   int (*cia_setkey)(struct crypto_tfm * , u8 const   * , unsigned int  ) ;
   void (*cia_encrypt)(struct crypto_tfm * , u8 * , u8 const   * ) ;
   void (*cia_decrypt)(struct crypto_tfm * , u8 * , u8 const   * ) ;
};
#line 256 "include/linux/crypto.h"
struct compress_alg {
   int (*coa_compress)(struct crypto_tfm * , u8 const   * , unsigned int  , u8 * ,
                       unsigned int * ) ;
   int (*coa_decompress)(struct crypto_tfm * , u8 const   * , unsigned int  , u8 * ,
                         unsigned int * ) ;
};
#line 262 "include/linux/crypto.h"
struct rng_alg {
   int (*rng_make_random)(struct crypto_rng * , u8 * , unsigned int  ) ;
   int (*rng_reset)(struct crypto_rng * , u8 * , unsigned int  ) ;
   unsigned int seedsize ;
};
#line 271 "include/linux/crypto.h"
union __anonunion_cra_u_228 {
   struct ablkcipher_alg ablkcipher ;
   struct aead_alg aead ;
   struct blkcipher_alg blkcipher ;
   struct cipher_alg cipher ;
   struct compress_alg compress ;
   struct rng_alg rng ;
};
#line 271 "include/linux/crypto.h"
struct crypto_alg {
   struct list_head cra_list ;
   struct list_head cra_users ;
   u32 cra_flags ;
   unsigned int cra_blocksize ;
   unsigned int cra_ctxsize ;
   unsigned int cra_alignmask ;
   int cra_priority ;
   atomic_t cra_refcnt ;
   char cra_name[64U] ;
   char cra_driver_name[64U] ;
   struct crypto_type  const  *cra_type ;
   union __anonunion_cra_u_228 cra_u ;
   int (*cra_init)(struct crypto_tfm * ) ;
   void (*cra_exit)(struct crypto_tfm * ) ;
   void (*cra_destroy)(struct crypto_alg * ) ;
   struct module *cra_module ;
};
#line 325 "include/linux/crypto.h"
struct ablkcipher_tfm {
   int (*setkey)(struct crypto_ablkcipher * , u8 const   * , unsigned int  ) ;
   int (*encrypt)(struct ablkcipher_request * ) ;
   int (*decrypt)(struct ablkcipher_request * ) ;
   int (*givencrypt)(struct skcipher_givcrypt_request * ) ;
   int (*givdecrypt)(struct skcipher_givcrypt_request * ) ;
   struct crypto_ablkcipher *base ;
   unsigned int ivsize ;
   unsigned int reqsize ;
};
#line 345 "include/linux/crypto.h"
struct aead_tfm {
   int (*setkey)(struct crypto_aead * , u8 const   * , unsigned int  ) ;
   int (*encrypt)(struct aead_request * ) ;
   int (*decrypt)(struct aead_request * ) ;
   int (*givencrypt)(struct aead_givcrypt_request * ) ;
   int (*givdecrypt)(struct aead_givcrypt_request * ) ;
   struct crypto_aead *base ;
   unsigned int ivsize ;
   unsigned int authsize ;
   unsigned int reqsize ;
};
#line 360 "include/linux/crypto.h"
struct blkcipher_tfm {
   void *iv ;
   int (*setkey)(struct crypto_tfm * , u8 const   * , unsigned int  ) ;
   int (*encrypt)(struct blkcipher_desc * , struct scatterlist * , struct scatterlist * ,
                  unsigned int  ) ;
   int (*decrypt)(struct blkcipher_desc * , struct scatterlist * , struct scatterlist * ,
                  unsigned int  ) ;
};
#line 369 "include/linux/crypto.h"
struct cipher_tfm {
   int (*cit_setkey)(struct crypto_tfm * , u8 const   * , unsigned int  ) ;
   void (*cit_encrypt_one)(struct crypto_tfm * , u8 * , u8 const   * ) ;
   void (*cit_decrypt_one)(struct crypto_tfm * , u8 * , u8 const   * ) ;
};
#line 377 "include/linux/crypto.h"
struct hash_tfm {
   int (*init)(struct hash_desc * ) ;
   int (*update)(struct hash_desc * , struct scatterlist * , unsigned int  ) ;
   int (*final)(struct hash_desc * , u8 * ) ;
   int (*digest)(struct hash_desc * , struct scatterlist * , unsigned int  , u8 * ) ;
   int (*setkey)(struct crypto_hash * , u8 const   * , unsigned int  ) ;
   unsigned int digestsize ;
};
#line 389 "include/linux/crypto.h"
struct compress_tfm {
   int (*cot_compress)(struct crypto_tfm * , u8 const   * , unsigned int  , u8 * ,
                       unsigned int * ) ;
   int (*cot_decompress)(struct crypto_tfm * , u8 const   * , unsigned int  , u8 * ,
                         unsigned int * ) ;
};
#line 396 "include/linux/crypto.h"
struct rng_tfm {
   int (*rng_gen_random)(struct crypto_rng * , u8 * , unsigned int  ) ;
   int (*rng_reset)(struct crypto_rng * , u8 * , unsigned int  ) ;
};
#line 404 "include/linux/crypto.h"
union __anonunion_crt_u_229 {
   struct ablkcipher_tfm ablkcipher ;
   struct aead_tfm aead ;
   struct blkcipher_tfm blkcipher ;
   struct cipher_tfm cipher ;
   struct hash_tfm hash ;
   struct compress_tfm compress ;
   struct rng_tfm rng ;
};
#line 404 "include/linux/crypto.h"
struct crypto_tfm {
   u32 crt_flags ;
   union __anonunion_crt_u_229 crt_u ;
   void (*exit)(struct crypto_tfm * ) ;
   struct crypto_alg *__crt_alg ;
   void *__crt_ctx[] ;
};
#line 433 "include/linux/crypto.h"
struct crypto_ablkcipher {
   struct crypto_tfm base ;
};
#line 437 "include/linux/crypto.h"
struct crypto_aead {
   struct crypto_tfm base ;
};
#line 441 "include/linux/crypto.h"
struct crypto_blkcipher {
   struct crypto_tfm base ;
};
#line 453 "include/linux/crypto.h"
struct crypto_hash {
   struct crypto_tfm base ;
};
#line 457 "include/linux/crypto.h"
struct crypto_rng {
   struct crypto_tfm base ;
};
#line 169 "include/linux/jhash.h"
struct request_values {

};
#line 172 "include/linux/jhash.h"
struct request_sock_ops {
   int family ;
   int obj_size ;
   struct kmem_cache *slab ;
   char *slab_name ;
   int (*rtx_syn_ack)(struct sock * , struct request_sock * , struct request_values * ) ;
   void (*send_ack)(struct sock * , struct sk_buff * , struct request_sock * ) ;
   void (*send_reset)(struct sock * , struct sk_buff * ) ;
   void (*destructor)(struct request_sock * ) ;
   void (*syn_ack_timeout)(struct sock * , struct request_sock * ) ;
};
#line 50 "include/net/request_sock.h"
struct request_sock {
   struct request_sock *dl_next ;
   u16 mss ;
   u8 retrans ;
   u8 cookie_ts ;
   u32 window_clamp ;
   u32 rcv_wnd ;
   u32 ts_recent ;
   unsigned long expires ;
   struct request_sock_ops  const  *rsk_ops ;
   struct sock *sk ;
   u32 secid ;
   u32 peer_secid ;
};
#line 371 "include/net/inet_connection_sock.h"
struct timewait_sock_ops {
   struct kmem_cache *twsk_slab ;
   char *twsk_slab_name ;
   unsigned int twsk_obj_size ;
   int (*twsk_unique)(struct sock * , struct sock * , void * ) ;
   void (*twsk_destructor)(struct sock * ) ;
};
#line 80 "include/linux/genhd.h"
struct disk_stats {
   unsigned long sectors[2U] ;
   unsigned long ios[2U] ;
   unsigned long merges[2U] ;
   unsigned long ticks[2U] ;
   unsigned long io_ticks ;
   unsigned long time_in_queue ;
};
#line 89 "include/linux/genhd.h"
struct partition_meta_info {
   char uuid[37U] ;
   u8 volname[64U] ;
};
#line 101 "include/linux/genhd.h"
struct hd_struct {
   sector_t start_sect ;
   sector_t nr_sects ;
   seqcount_t nr_sects_seq ;
   sector_t alignment_offset ;
   unsigned int discard_alignment ;
   struct device __dev ;
   struct kobject *holder_dir ;
   int policy ;
   int partno ;
   struct partition_meta_info *info ;
   int make_it_fail ;
   unsigned long stamp ;
   atomic_t in_flight[2U] ;
   struct disk_stats *dkstats ;
   atomic_t ref ;
   struct callback_head callback_head ;
};
#line 155 "include/linux/genhd.h"
struct disk_part_tbl {
   struct callback_head callback_head ;
   int len ;
   struct hd_struct *last_lookup ;
   struct hd_struct *part[] ;
};
#line 162
struct disk_events;
#line 163
struct timer_rand_state;
#line 163
struct blk_integrity;
#line 163 "include/linux/genhd.h"
struct gendisk {
   int major ;
   int first_minor ;
   int minors ;
   char disk_name[32U] ;
   char *(*devnode)(struct gendisk * , umode_t * ) ;
   unsigned int events ;
   unsigned int async_events ;
   struct disk_part_tbl *part_tbl ;
   struct hd_struct part0 ;
   struct block_device_operations  const  *fops ;
   struct request_queue *queue ;
   void *private_data ;
   int flags ;
   struct device *driverfs_dev ;
   struct kobject *slave_dir ;
   struct timer_rand_state *random ;
   atomic_t sync_io ;
   struct disk_events *ev ;
   struct blk_integrity *integrity ;
   int node_id ;
};
#line 71 "include/linux/flex_proportions.h"
struct fprop_local_percpu {
   struct percpu_counter events ;
   unsigned int period ;
   raw_spinlock_t lock ;
};
#line 11 "include/linux/writeback.h"
enum writeback_sync_modes {
    WB_SYNC_NONE = 0,
    WB_SYNC_ALL = 1
} ;
#line 54 "include/linux/writeback.h"
struct writeback_control {
   long nr_to_write ;
   long pages_skipped ;
   loff_t range_start ;
   loff_t range_end ;
   enum writeback_sync_modes sync_mode ;
   unsigned char for_kupdate : 1 ;
   unsigned char for_background : 1 ;
   unsigned char tagged_writepages : 1 ;
   unsigned char for_reclaim : 1 ;
   unsigned char range_cyclic : 1 ;
};
#line 81
struct bdi_writeback;
#line 39 "include/linux/backing-dev.h"
typedef int congested_fn(void * , int  );
#line 48 "include/linux/backing-dev.h"
struct bdi_writeback {
   struct backing_dev_info *bdi ;
   unsigned int nr ;
   unsigned long last_old_flush ;
   unsigned long last_active ;
   struct task_struct *task ;
   struct timer_list wakeup_timer ;
   struct list_head b_dirty ;
   struct list_head b_io ;
   struct list_head b_more_io ;
   spinlock_t list_lock ;
};
#line 65 "include/linux/backing-dev.h"
struct backing_dev_info {
   struct list_head bdi_list ;
   unsigned long ra_pages ;
   unsigned long state ;
   unsigned int capabilities ;
   congested_fn *congested_fn ;
   void *congested_data ;
   char *name ;
   struct percpu_counter bdi_stat[4U] ;
   unsigned long bw_time_stamp ;
   unsigned long dirtied_stamp ;
   unsigned long written_stamp ;
   unsigned long write_bandwidth ;
   unsigned long avg_write_bandwidth ;
   unsigned long dirty_ratelimit ;
   unsigned long balanced_dirty_ratelimit ;
   struct fprop_local_percpu completions ;
   int dirty_exceeded ;
   unsigned int min_ratio ;
   unsigned int max_ratio ;
   unsigned int max_prop_frac ;
   struct bdi_writeback wb ;
   spinlock_t wb_lock ;
   struct list_head work_list ;
   struct device *dev ;
   struct timer_list laptop_mode_wb_timer ;
   struct dentry *debug_dir ;
   struct dentry *debug_stats ;
};
#line 11 "include/linux/mempool.h"
typedef void *mempool_alloc_t(gfp_t  , void * );
#line 12 "include/linux/mempool.h"
typedef void mempool_free_t(void * , void * );
#line 13 "include/linux/mempool.h"
struct mempool_s {
   spinlock_t lock ;
   int min_nr ;
   int curr_nr ;
   void **elements ;
   void *pool_data ;
   mempool_alloc_t *alloc ;
   mempool_free_t *free ;
   wait_queue_head_t wait ;
};
#line 24 "include/linux/mempool.h"
typedef struct mempool_s mempool_t;
#line 77 "include/linux/mempool.h"
union __anonunion_ldv_43454_236 {
   struct list_head q_node ;
   struct kmem_cache *__rcu_icq_cache ;
};
#line 77 "include/linux/mempool.h"
union __anonunion_ldv_43458_237 {
   struct hlist_node ioc_node ;
   struct callback_head __rcu_head ;
};
#line 77 "include/linux/mempool.h"
struct io_cq {
   struct request_queue *q ;
   struct io_context *ioc ;
   union __anonunion_ldv_43454_236 ldv_43454 ;
   union __anonunion_ldv_43458_237 ldv_43458 ;
   unsigned int flags ;
};
#line 92 "include/linux/iocontext.h"
struct io_context {
   atomic_long_t refcount ;
   atomic_t active_ref ;
   atomic_t nr_tasks ;
   spinlock_t lock ;
   unsigned short ioprio ;
   int nr_batch_requests ;
   unsigned long last_waited ;
   struct radix_tree_root icq_tree ;
   struct io_cq *icq_hint ;
   struct hlist_head icq_list ;
   struct work_struct release_work ;
};
#line 91 "include/linux/bio.h"
struct bio_integrity_payload {
   struct bio *bip_bio ;
   sector_t bip_sector ;
   void *bip_buf ;
   bio_end_io_t *bip_end_io ;
   unsigned int bip_size ;
   unsigned short bip_slab ;
   unsigned short bip_vcnt ;
   unsigned short bip_idx ;
   struct work_struct bip_work ;
   struct bio_vec bip_vec[0U] ;
};
#line 296 "include/linux/bio.h"
struct bio_set {
   struct kmem_cache *bio_slab ;
   unsigned int front_pad ;
   mempool_t *bio_pool ;
   mempool_t *bio_integrity_pool ;
   mempool_t *bvec_pool ;
};
#line 415 "include/linux/bio.h"
struct bio_list {
   struct bio *head ;
   struct bio *tail ;
};
#line 63 "include/uapi/linux/bsg.h"
struct bsg_class_device {
   struct device *class_dev ;
   struct device *parent ;
   int minor ;
   struct request_queue *queue ;
   struct kref ref ;
   void (*release)(struct device * ) ;
};
#line 22 "include/linux/bsg.h"
struct elevator_queue;
#line 25
struct request;
#line 27
struct bsg_job;
#line 28
struct blkcg_gq;
#line 47 "include/linux/blkdev.h"
typedef void rq_end_io_fn(struct request * , int  );
#line 48 "include/linux/blkdev.h"
struct request_list {
   struct request_queue *q ;
   struct blkcg_gq *blkg ;
   int count[2U] ;
   int starved[2U] ;
   mempool_t *rq_pool ;
   wait_queue_head_t wait[2U] ;
   unsigned int flags ;
};
#line 67
enum rq_cmd_type_bits {
    REQ_TYPE_FS = 1,
    REQ_TYPE_BLOCK_PC = 2,
    REQ_TYPE_SENSE = 3,
    REQ_TYPE_PM_SUSPEND = 4,
    REQ_TYPE_PM_RESUME = 5,
    REQ_TYPE_PM_SHUTDOWN = 6,
    REQ_TYPE_SPECIAL = 7,
    REQ_TYPE_ATA_TASKFILE = 8,
    REQ_TYPE_ATA_PC = 9
} ;
#line 79 "include/linux/blkdev.h"
union __anonunion_ldv_43905_238 {
   struct rb_node rb_node ;
   void *completion_data ;
};
#line 79 "include/linux/blkdev.h"
struct __anonstruct_elv_240 {
   struct io_cq *icq ;
   void *priv[2U] ;
};
#line 79 "include/linux/blkdev.h"
struct __anonstruct_flush_241 {
   unsigned int seq ;
   struct list_head list ;
   rq_end_io_fn *saved_end_io ;
};
#line 79 "include/linux/blkdev.h"
union __anonunion_ldv_43916_239 {
   struct __anonstruct_elv_240 elv ;
   struct __anonstruct_flush_241 flush ;
};
#line 79 "include/linux/blkdev.h"
struct request {
   struct list_head queuelist ;
   struct call_single_data csd ;
   struct request_queue *q ;
   unsigned int cmd_flags ;
   enum rq_cmd_type_bits cmd_type ;
   unsigned long atomic_flags ;
   int cpu ;
   unsigned int __data_len ;
   sector_t __sector ;
   struct bio *bio ;
   struct bio *biotail ;
   struct hlist_node hash ;
   union __anonunion_ldv_43905_238 ldv_43905 ;
   union __anonunion_ldv_43916_239 ldv_43916 ;
   struct gendisk *rq_disk ;
   struct hd_struct *part ;
   unsigned long start_time ;
   struct request_list *rl ;
   unsigned long long start_time_ns ;
   unsigned long long io_start_time_ns ;
   unsigned short nr_phys_segments ;
   unsigned short nr_integrity_segments ;
   unsigned short ioprio ;
   int ref_count ;
   void *special ;
   char *buffer ;
   int tag ;
   int errors ;
   unsigned char __cmd[16U] ;
   unsigned char *cmd ;
   unsigned short cmd_len ;
   unsigned int extra_len ;
   unsigned int sense_len ;
   unsigned int resid_len ;
   void *sense ;
   unsigned long deadline ;
   struct list_head timeout_list ;
   unsigned int timeout ;
   int retries ;
   rq_end_io_fn *end_io ;
   void *end_io_data ;
   struct request *next_rq ;
};
#line 10 "include/linux/elevator.h"
typedef int elevator_merge_fn(struct request_queue * , struct request ** , struct bio * );
#line 13 "include/linux/elevator.h"
typedef void elevator_merge_req_fn(struct request_queue * , struct request * , struct request * );
#line 15 "include/linux/elevator.h"
typedef void elevator_merged_fn(struct request_queue * , struct request * , int  );
#line 17 "include/linux/elevator.h"
typedef int elevator_allow_merge_fn(struct request_queue * , struct request * , struct bio * );
#line 19 "include/linux/elevator.h"
typedef void elevator_bio_merged_fn(struct request_queue * , struct request * , struct bio * );
#line 22 "include/linux/elevator.h"
typedef int elevator_dispatch_fn(struct request_queue * , int  );
#line 24 "include/linux/elevator.h"
typedef void elevator_add_req_fn(struct request_queue * , struct request * );
#line 25 "include/linux/elevator.h"
typedef struct request *elevator_request_list_fn(struct request_queue * , struct request * );
#line 26 "include/linux/elevator.h"
typedef void elevator_completed_req_fn(struct request_queue * , struct request * );
#line 27 "include/linux/elevator.h"
typedef int elevator_may_queue_fn(struct request_queue * , int  );
#line 29 "include/linux/elevator.h"
typedef void elevator_init_icq_fn(struct io_cq * );
#line 30 "include/linux/elevator.h"
typedef void elevator_exit_icq_fn(struct io_cq * );
#line 31 "include/linux/elevator.h"
typedef int elevator_set_req_fn(struct request_queue * , struct request * , struct bio * ,
                                gfp_t  );
#line 33 "include/linux/elevator.h"
typedef void elevator_put_req_fn(struct request * );
#line 34 "include/linux/elevator.h"
typedef void elevator_activate_req_fn(struct request_queue * , struct request * );
#line 35 "include/linux/elevator.h"
typedef void elevator_deactivate_req_fn(struct request_queue * , struct request * );
#line 37 "include/linux/elevator.h"
typedef int elevator_init_fn(struct request_queue * );
#line 38 "include/linux/elevator.h"
typedef void elevator_exit_fn(struct elevator_queue * );
#line 39 "include/linux/elevator.h"
struct elevator_ops {
   elevator_merge_fn *elevator_merge_fn ;
   elevator_merged_fn *elevator_merged_fn ;
   elevator_merge_req_fn *elevator_merge_req_fn ;
   elevator_allow_merge_fn *elevator_allow_merge_fn ;
   elevator_bio_merged_fn *elevator_bio_merged_fn ;
   elevator_dispatch_fn *elevator_dispatch_fn ;
   elevator_add_req_fn *elevator_add_req_fn ;
   elevator_activate_req_fn *elevator_activate_req_fn ;
   elevator_deactivate_req_fn *elevator_deactivate_req_fn ;
   elevator_completed_req_fn *elevator_completed_req_fn ;
   elevator_request_list_fn *elevator_former_req_fn ;
   elevator_request_list_fn *elevator_latter_req_fn ;
   elevator_init_icq_fn *elevator_init_icq_fn ;
   elevator_exit_icq_fn *elevator_exit_icq_fn ;
   elevator_set_req_fn *elevator_set_req_fn ;
   elevator_put_req_fn *elevator_put_req_fn ;
   elevator_may_queue_fn *elevator_may_queue_fn ;
   elevator_init_fn *elevator_init_fn ;
   elevator_exit_fn *elevator_exit_fn ;
};
#line 69 "include/linux/elevator.h"
struct elv_fs_entry {
   struct attribute attr ;
   ssize_t (*show)(struct elevator_queue * , char * ) ;
   ssize_t (*store)(struct elevator_queue * , char const   * , size_t  ) ;
};
#line 77 "include/linux/elevator.h"
struct elevator_type {
   struct kmem_cache *icq_cache ;
   struct elevator_ops ops ;
   size_t icq_size ;
   size_t icq_align ;
   struct elv_fs_entry *elevator_attrs ;
   char elevator_name[16U] ;
   struct module *elevator_owner ;
   char icq_cache_name[21U] ;
   struct list_head list ;
};
#line 98 "include/linux/elevator.h"
struct elevator_queue {
   struct elevator_type *type ;
   void *elevator_data ;
   struct kobject kobj ;
   struct mutex sysfs_lock ;
   struct hlist_head *hash ;
   unsigned char registered : 1 ;
};
#line 217 "include/linux/blkdev.h"
typedef void request_fn_proc(struct request_queue * );
#line 218 "include/linux/blkdev.h"
typedef void make_request_fn(struct request_queue * , struct bio * );
#line 219 "include/linux/blkdev.h"
typedef int prep_rq_fn(struct request_queue * , struct request * );
#line 220 "include/linux/blkdev.h"
typedef void unprep_rq_fn(struct request_queue * , struct request * );
#line 221 "include/linux/blkdev.h"
struct bvec_merge_data {
   struct block_device *bi_bdev ;
   sector_t bi_sector ;
   unsigned int bi_size ;
   unsigned long bi_rw ;
};
#line 229 "include/linux/blkdev.h"
typedef int merge_bvec_fn(struct request_queue * , struct bvec_merge_data * , struct bio_vec * );
#line 231 "include/linux/blkdev.h"
typedef void softirq_done_fn(struct request * );
#line 232 "include/linux/blkdev.h"
typedef int dma_drain_needed_fn(struct request * );
#line 233 "include/linux/blkdev.h"
typedef int lld_busy_fn(struct request_queue * );
#line 234 "include/linux/blkdev.h"
typedef int bsg_job_fn(struct bsg_job * );
#line 235
enum blk_eh_timer_return {
    BLK_EH_NOT_HANDLED = 0,
    BLK_EH_HANDLED = 1,
    BLK_EH_RESET_TIMER = 2
} ;
#line 242 "include/linux/blkdev.h"
typedef enum blk_eh_timer_return rq_timed_out_fn(struct request * );
#line 248 "include/linux/blkdev.h"
struct blk_queue_tag {
   struct request **tag_index ;
   unsigned long *tag_map ;
   int busy ;
   int max_depth ;
   int real_max_depth ;
   atomic_t refcnt ;
};
#line 257 "include/linux/blkdev.h"
struct queue_limits {
   unsigned long bounce_pfn ;
   unsigned long seg_boundary_mask ;
   unsigned int max_hw_sectors ;
   unsigned int max_sectors ;
   unsigned int max_segment_size ;
   unsigned int physical_block_size ;
   unsigned int alignment_offset ;
   unsigned int io_min ;
   unsigned int io_opt ;
   unsigned int max_discard_sectors ;
   unsigned int max_write_same_sectors ;
   unsigned int discard_granularity ;
   unsigned int discard_alignment ;
   unsigned short logical_block_size ;
   unsigned short max_segments ;
   unsigned short max_integrity_segments ;
   unsigned char misaligned ;
   unsigned char discard_misaligned ;
   unsigned char cluster ;
   unsigned char discard_zeroes_data ;
};
#line 286
struct throtl_data;
#line 286 "include/linux/blkdev.h"
struct request_queue {
   struct list_head queue_head ;
   struct request *last_merge ;
   struct elevator_queue *elevator ;
   int nr_rqs[2U] ;
   int nr_rqs_elvpriv ;
   struct request_list root_rl ;
   request_fn_proc *request_fn ;
   make_request_fn *make_request_fn ;
   prep_rq_fn *prep_rq_fn ;
   unprep_rq_fn *unprep_rq_fn ;
   merge_bvec_fn *merge_bvec_fn ;
   softirq_done_fn *softirq_done_fn ;
   rq_timed_out_fn *rq_timed_out_fn ;
   dma_drain_needed_fn *dma_drain_needed ;
   lld_busy_fn *lld_busy_fn ;
   sector_t end_sector ;
   struct request *boundary_rq ;
   struct delayed_work delay_work ;
   struct backing_dev_info backing_dev_info ;
   void *queuedata ;
   unsigned long queue_flags ;
   int id ;
   gfp_t bounce_gfp ;
   spinlock_t __queue_lock ;
   spinlock_t *queue_lock ;
   struct kobject kobj ;
   unsigned long nr_requests ;
   unsigned int nr_congestion_on ;
   unsigned int nr_congestion_off ;
   unsigned int nr_batching ;
   unsigned int dma_drain_size ;
   void *dma_drain_buffer ;
   unsigned int dma_pad_mask ;
   unsigned int dma_alignment ;
   struct blk_queue_tag *queue_tags ;
   struct list_head tag_busy_list ;
   unsigned int nr_sorted ;
   unsigned int in_flight[2U] ;
   unsigned int rq_timeout ;
   struct timer_list timeout ;
   struct list_head timeout_list ;
   struct list_head icq_list ;
   unsigned long blkcg_pols[1U] ;
   struct blkcg_gq *root_blkg ;
   struct list_head blkg_list ;
   struct queue_limits limits ;
   unsigned int sg_timeout ;
   unsigned int sg_reserved_size ;
   int node ;
   unsigned int flush_flags ;
   unsigned char flush_not_queueable : 1 ;
   unsigned char flush_queue_delayed : 1 ;
   unsigned char flush_pending_idx : 1 ;
   unsigned char flush_running_idx : 1 ;
   unsigned long flush_pending_since ;
   struct list_head flush_queue[2U] ;
   struct list_head flush_data_in_flight ;
   struct request flush_rq ;
   struct mutex sysfs_lock ;
   int bypass_depth ;
   bsg_job_fn *bsg_job_fn ;
   int bsg_job_size ;
   struct bsg_class_device bsg_dev ;
   struct list_head all_q_node ;
   struct throtl_data *td ;
};
#line 952 "include/linux/blkdev.h"
struct blk_plug {
   unsigned long magic ;
   struct list_head list ;
   struct list_head cb_list ;
   unsigned int should_sort ;
};
#line 1299 "include/linux/blkdev.h"
struct blk_integrity_exchg {
   void *prot_buf ;
   void *data_buf ;
   sector_t sector ;
   unsigned int data_size ;
   unsigned short sector_size ;
   char const   *disk_name ;
};
#line 1331 "include/linux/blkdev.h"
typedef void integrity_gen_fn(struct blk_integrity_exchg * );
#line 1332 "include/linux/blkdev.h"
typedef int integrity_vrfy_fn(struct blk_integrity_exchg * );
#line 1333 "include/linux/blkdev.h"
typedef void integrity_set_tag_fn(void * , void * , unsigned int  );
#line 1334 "include/linux/blkdev.h"
typedef void integrity_get_tag_fn(void * , void * , unsigned int  );
#line 1335 "include/linux/blkdev.h"
struct blk_integrity {
   integrity_gen_fn *generate_fn ;
   integrity_vrfy_fn *verify_fn ;
   integrity_set_tag_fn *set_tag_fn ;
   integrity_get_tag_fn *get_tag_fn ;
   unsigned short flags ;
   unsigned short tuple_size ;
   unsigned short sector_size ;
   unsigned short tag_size ;
   char const   *name ;
   struct kobject kobj ;
};
#line 1394 "include/linux/blkdev.h"
struct block_device_operations {
   int (*open)(struct block_device * , fmode_t  ) ;
   int (*release)(struct gendisk * , fmode_t  ) ;
   int (*ioctl)(struct block_device * , fmode_t  , unsigned int  , unsigned long  ) ;
   int (*compat_ioctl)(struct block_device * , fmode_t  , unsigned int  , unsigned long  ) ;
   int (*direct_access)(struct block_device * , sector_t  , void ** , unsigned long * ) ;
   unsigned int (*check_events)(struct gendisk * , unsigned int  ) ;
   int (*media_changed)(struct gendisk * ) ;
   void (*unlock_native_capacity)(struct gendisk * ) ;
   int (*revalidate_disk)(struct gendisk * ) ;
   int (*getgeo)(struct block_device * , struct hd_geometry * ) ;
   void (*swap_slot_free_notify)(struct block_device * , unsigned long  ) ;
   struct module *owner ;
};
#line 160 "include/uapi/linux/ipv6.h"
struct ipv6_devconf {
   __s32 forwarding ;
   __s32 hop_limit ;
   __s32 mtu6 ;
   __s32 accept_ra ;
   __s32 accept_redirects ;
   __s32 autoconf ;
   __s32 dad_transmits ;
   __s32 rtr_solicits ;
   __s32 rtr_solicit_interval ;
   __s32 rtr_solicit_delay ;
   __s32 force_mld_version ;
   __s32 use_tempaddr ;
   __s32 temp_valid_lft ;
   __s32 temp_prefered_lft ;
   __s32 regen_max_retry ;
   __s32 max_desync_factor ;
   __s32 max_addresses ;
   __s32 accept_ra_defrtr ;
   __s32 accept_ra_pinfo ;
   __s32 accept_ra_rtr_pref ;
   __s32 rtr_probe_interval ;
   __s32 accept_ra_rt_info_max_plen ;
   __s32 proxy_ndp ;
   __s32 accept_source_route ;
   __s32 optimistic_dad ;
   __s32 mc_forwarding ;
   __s32 disable_ipv6 ;
   __s32 accept_dad ;
   __s32 force_tllao ;
   void *sysctl ;
};
#line 97 "include/net/if_inet6.h"
struct ip6_sf_list {
   struct ip6_sf_list *sf_next ;
   struct in6_addr sf_addr ;
   unsigned long sf_count[2U] ;
   unsigned char sf_gsresp ;
   unsigned char sf_oldin ;
   unsigned char sf_crcount ;
};
#line 106 "include/net/if_inet6.h"
struct ifmcaddr6 {
   struct in6_addr mca_addr ;
   struct inet6_dev *idev ;
   struct ifmcaddr6 *next ;
   struct ip6_sf_list *mca_sources ;
   struct ip6_sf_list *mca_tomb ;
   unsigned int mca_sfmode ;
   unsigned char mca_crcount ;
   unsigned long mca_sfcount[2U] ;
   struct timer_list mca_timer ;
   unsigned int mca_flags ;
   int mca_users ;
   atomic_t mca_refcnt ;
   spinlock_t mca_lock ;
   unsigned long mca_cstamp ;
   unsigned long mca_tstamp ;
};
#line 138 "include/net/if_inet6.h"
struct ifacaddr6 {
   struct in6_addr aca_addr ;
   struct inet6_dev *aca_idev ;
   struct rt6_info *aca_rt ;
   struct ifacaddr6 *aca_next ;
   int aca_users ;
   atomic_t aca_refcnt ;
   spinlock_t aca_lock ;
   unsigned long aca_cstamp ;
   unsigned long aca_tstamp ;
};
#line 150 "include/net/if_inet6.h"
struct ipv6_devstat {
   struct proc_dir_entry *proc_dir_entry ;
   struct ipstats_mib *ipv6[1U] ;
   struct icmpv6_mib_device *icmpv6dev ;
   struct icmpv6msg_mib_device *icmpv6msgdev ;
};
#line 161 "include/net/if_inet6.h"
struct inet6_dev {
   struct net_device *dev ;
   struct list_head addr_list ;
   struct ifmcaddr6 *mc_list ;
   struct ifmcaddr6 *mc_tomb ;
   spinlock_t mc_lock ;
   unsigned char mc_qrv ;
   unsigned char mc_gq_running ;
   unsigned char mc_ifc_count ;
   unsigned long mc_v1_seen ;
   unsigned long mc_maxdelay ;
   struct timer_list mc_gq_timer ;
   struct timer_list mc_ifc_timer ;
   struct ifacaddr6 *ac_list ;
   rwlock_t lock ;
   atomic_t refcnt ;
   __u32 if_flags ;
   int dead ;
   u8 rndid[8U] ;
   struct timer_list regen_timer ;
   struct list_head tempaddr_list ;
   struct neigh_parms *nd_parms ;
   struct inet6_dev *next ;
   struct ipv6_devconf cnf ;
   struct ipv6_devstat stats ;
   unsigned long tstamp ;
   struct callback_head rcu ;
};
#line 732 "include/net/ipv6.h"
union __anonunion_ldv_46571_248 {
   __be32 a4 ;
   __be32 a6[4U] ;
};
#line 732 "include/net/ipv6.h"
struct inetpeer_addr_base {
   union __anonunion_ldv_46571_248 ldv_46571 ;
};
#line 24 "include/net/inetpeer.h"
struct inetpeer_addr {
   struct inetpeer_addr_base addr ;
   __u16 family ;
};
#line 29 "include/net/inetpeer.h"
union __anonunion_ldv_46586_249 {
   struct list_head gc_list ;
   struct callback_head gc_rcu ;
};
#line 29 "include/net/inetpeer.h"
struct __anonstruct_ldv_46591_251 {
   atomic_t rid ;
   atomic_t ip_id_count ;
};
#line 29 "include/net/inetpeer.h"
union __anonunion_ldv_46594_250 {
   struct __anonstruct_ldv_46591_251 ldv_46591 ;
   struct callback_head rcu ;
   struct inet_peer *gc_next ;
};
#line 29 "include/net/inetpeer.h"
struct inet_peer {
   struct inet_peer *avl_left ;
   struct inet_peer *avl_right ;
   struct inetpeer_addr daddr ;
   __u32 avl_height ;
   u32 metrics[14U] ;
   u32 rate_tokens ;
   unsigned long rate_last ;
   union __anonunion_ldv_46586_249 ldv_46586 ;
   union __anonunion_ldv_46594_250 ldv_46594 ;
   __u32 dtime ;
   atomic_t refcnt ;
};
#line 61 "include/net/inetpeer.h"
struct inet_peer_base {
   struct inet_peer *root ;
   seqlock_t lock ;
   u32 flush_seq ;
   int total ;
};
#line 50 "/work/ldvuser/novikov/inst/current/envs/linux/linux/include/uapi/linux/route.h"
struct rtable {
   struct dst_entry dst ;
   int rt_genid ;
   unsigned int rt_flags ;
   __u16 rt_type ;
   __u8 rt_is_input ;
   __u8 rt_uses_gateway ;
   int rt_iif ;
   __be32 rt_gateway ;
   u32 rt_pmtu ;
   struct list_head rt_uncached ;
};
#line 316 "include/net/route.h"
struct inet_ehash_bucket {
   struct hlist_nulls_head chain ;
   struct hlist_nulls_head twchain ;
};
#line 94 "include/net/inet_hashtables.h"
struct inet_bind_hashbucket {
   spinlock_t lock ;
   struct hlist_head chain ;
};
#line 102 "include/net/inet_hashtables.h"
struct inet_listen_hashbucket {
   spinlock_t lock ;
   struct hlist_nulls_head head ;
};
#line 114 "include/net/inet_hashtables.h"
struct inet_hashinfo {
   struct inet_ehash_bucket *ehash ;
   spinlock_t *ehash_locks ;
   unsigned int ehash_mask ;
   unsigned int ehash_locks_mask ;
   struct inet_bind_hashbucket *bhash ;
   unsigned int bhash_size ;
   struct kmem_cache *bind_bucket_cachep ;
   struct inet_listen_hashbucket listening_hash[32U] ;
   atomic_t bsockets ;
};
#line 1716 "include/net/tcp.h"
struct lc_element {
   struct hlist_node colision ;
   struct list_head list ;
   unsigned int refcnt ;
   unsigned int lc_index ;
   unsigned int lc_number ;
   unsigned int lc_new_number ;
};
#line 175 "include/linux/lru_cache.h"
struct lru_cache {
   struct list_head lru ;
   struct list_head free ;
   struct list_head in_use ;
   struct list_head to_be_changed ;
   struct kmem_cache *lc_cache ;
   size_t element_size ;
   size_t element_off ;
   unsigned int nr_elements ;
   unsigned int max_pending_changes ;
   unsigned int pending_changes ;
   unsigned int used ;
   unsigned long hits ;
   unsigned long misses ;
   unsigned long starving ;
   unsigned long locked ;
   unsigned long changed ;
   unsigned long flags ;
   void *lc_private ;
   char const   *name ;
   struct hlist_head *lc_slot ;
   struct lc_element **lc_element ;
};
#line 99 "include/linux/drbd_genl.h"
struct disk_conf {
   char backing_dev[128U] ;
   __u32 backing_dev_len ;
   char meta_dev[128U] ;
   __u32 meta_dev_len ;
   __s32 meta_dev_idx ;
   __u64 disk_size ;
   __u32 max_bio_bvecs ;
   __u32 on_io_error ;
   __u32 fencing ;
   __u32 resync_rate ;
   __s32 resync_after ;
   __u32 al_extents ;
   __u32 c_plan_ahead ;
   __u32 c_delay_target ;
   __u32 c_fill_target ;
   __u32 c_max_rate ;
   __u32 c_min_rate ;
   char disk_barrier ;
   char disk_flushes ;
   char disk_drain ;
   char md_flushes ;
   __u32 disk_timeout ;
   __u32 read_balancing ;
   char al_updates ;
};
#line 106 "include/linux/drbd_genl.h"
struct res_opts {
   char cpu_mask[32U] ;
   __u32 cpu_mask_len ;
   __u32 on_no_data ;
};
#line 139 "include/linux/drbd_genl.h"
struct net_conf {
   char shared_secret[64U] ;
   __u32 shared_secret_len ;
   char cram_hmac_alg[64U] ;
   __u32 cram_hmac_alg_len ;
   char integrity_alg[64U] ;
   __u32 integrity_alg_len ;
   char verify_alg[64U] ;
   __u32 verify_alg_len ;
   char csums_alg[64U] ;
   __u32 csums_alg_len ;
   __u32 wire_protocol ;
   __u32 connect_int ;
   __u32 timeout ;
   __u32 ping_int ;
   __u32 ping_timeo ;
   __u32 sndbuf_size ;
   __u32 rcvbuf_size ;
   __u32 ko_count ;
   __u32 max_buffers ;
   __u32 max_epoch_size ;
   __u32 unplug_watermark ;
   __u32 after_sb_0p ;
   __u32 after_sb_1p ;
   __u32 after_sb_2p ;
   __u32 rr_conflict ;
   __u32 on_congestion ;
   __u32 cong_fill ;
   __u32 cong_extents ;
   char two_primaries ;
   char discard_my_data ;
   char tcp_cork ;
   char always_asbp ;
   char tentative ;
   char use_rle ;
};
#line 375
struct drbd_conf;
#line 376
struct drbd_tconn;
#line 377
enum chg_state_flags {
    CS_HARD = 1,
    CS_VERBOSE = 2,
    CS_WAIT_COMPLETE = 4,
    CS_SERIALIZE = 8,
    CS_ORDERED = 12,
    CS_LOCAL_ONLY = 16,
    CS_DC_ROLE = 32,
    CS_DC_PEER = 64,
    CS_DC_CONN = 128,
    CS_DC_DISK = 256,
    CS_DC_PDSK = 512,
    CS_DC_SUSP = 1024,
    CS_DC_MASK = 992,
    CS_IGN_OUTD_FAIL = 2048
} ;
#line 394 "include/linux/drbd_genl.h"
struct __anonstruct_ldv_49522_255 {
   unsigned char role : 2 ;
   unsigned char peer : 2 ;
   unsigned char conn : 5 ;
   unsigned char disk : 4 ;
   unsigned char pdsk : 4 ;
   unsigned char _unused : 1 ;
   unsigned char aftr_isp : 1 ;
   unsigned char peer_isp : 1 ;
   unsigned char user_isp : 1 ;
   unsigned short _pad : 11 ;
};
#line 394 "include/linux/drbd_genl.h"
union drbd_dev_state {
   struct __anonstruct_ldv_49522_255 ldv_49522 ;
   unsigned int i ;
};
#line 499 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
enum drbd_thread_state {
    NONE = 0,
    RUNNING = 1,
    EXITING = 2,
    RESTARTING = 3
} ;
#line 506 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_thread {
   spinlock_t t_lock ;
   struct task_struct *task ;
   struct completion stop ;
   enum drbd_thread_state t_state ;
   int (*function)(struct drbd_thread * ) ;
   struct drbd_tconn *tconn ;
   int reset_cpu_mask ;
   char name[9U] ;
};
#line 534 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
union __anonunion_ldv_49807_256 {
   struct drbd_conf *mdev ;
   struct drbd_tconn *tconn ;
};
#line 534 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_work {
   struct list_head list ;
   int (*cb)(struct drbd_work * , int  ) ;
   union __anonunion_ldv_49807_256 ldv_49807 ;
};
#line 580 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_epoch {
   struct drbd_tconn *tconn ;
   struct list_head list ;
   unsigned int barrier_nr ;
   atomic_t epoch_size ;
   atomic_t active ;
   unsigned long flags ;
};
#line 662
struct drbd_bitmap;
#line 663
enum bm_flag {
    BM_P_VMALLOCED = 65536,
    BM_LOCKED_MASK = 15,
    BM_DONT_CLEAR = 1,
    BM_DONT_SET = 2,
    BM_DONT_TEST = 4,
    BM_IS_LOCKED = 8,
    BM_LOCKED_TEST_ALLOWED = 11,
    BM_LOCKED_SET_ALLOWED = 9,
    BM_LOCKED_CHANGE_ALLOWED = 8
} ;
#line 675 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_work_queue {
   struct list_head q ;
   spinlock_t q_lock ;
   wait_queue_head_t q_wait ;
};
#line 736 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_socket {
   struct mutex mutex ;
   struct socket *socket ;
   void *sbuf ;
   void *rbuf ;
};
#line 745 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_md {
   u64 md_offset ;
   u64 la_size_sect ;
   spinlock_t uuid_lock ;
   u64 uuid[4U] ;
   u64 device_uuid ;
   u32 flags ;
   u32 md_size_sect ;
   s32 al_offset ;
   s32 bm_offset ;
};
#line 759 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_backing_dev {
   struct block_device *backing_bdev ;
   struct block_device *md_bdev ;
   struct drbd_md md ;
   struct disk_conf *disk_conf ;
   sector_t known_size ;
};
#line 772 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_md_io {
   unsigned int done ;
   int error ;
};
#line 777 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct bm_io_work {
   struct drbd_work w ;
   char *why ;
   enum bm_flag flags ;
   int (*io_fn)(struct drbd_conf * ) ;
   void (*done)(struct drbd_conf * , int  ) ;
};
#line 785
enum write_ordering_e {
    WO_none = 0,
    WO_drain_io = 1,
    WO_bdev_flush = 2
} ;
#line 791 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct fifo_buffer {
   unsigned int head_index ;
   unsigned int size ;
   int total ;
   int values[0U] ;
};
#line 815 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct __anonstruct_send_258 {
   bool seen_any_write_yet ;
   int current_epoch_nr ;
   unsigned int current_epoch_writes ;
};
#line 815 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_tconn {
   char *name ;
   struct list_head all_tconn ;
   struct kref kref ;
   struct idr volumes ;
   enum drbd_conns cstate ;
   unsigned char susp : 1 ;
   unsigned char susp_nod : 1 ;
   unsigned char susp_fen : 1 ;
   struct mutex cstate_mutex ;
   unsigned long flags ;
   struct net_conf *net_conf ;
   struct mutex conf_update ;
   wait_queue_head_t ping_wait ;
   struct res_opts res_opts ;
   struct __kernel_sockaddr_storage my_addr ;
   int my_addr_len ;
   struct __kernel_sockaddr_storage peer_addr ;
   int peer_addr_len ;
   struct drbd_socket data ;
   struct drbd_socket meta ;
   int agreed_pro_version ;
   unsigned long last_received ;
   unsigned int ko_count ;
   spinlock_t req_lock ;
   struct list_head transfer_log ;
   struct crypto_hash *cram_hmac_tfm ;
   struct crypto_hash *integrity_tfm ;
   struct crypto_hash *peer_integrity_tfm ;
   struct crypto_hash *csums_tfm ;
   struct crypto_hash *verify_tfm ;
   void *int_dig_in ;
   void *int_dig_vv ;
   struct drbd_epoch *current_epoch ;
   spinlock_t epoch_lock ;
   unsigned int epochs ;
   enum write_ordering_e write_ordering ;
   atomic_t current_tle_nr ;
   unsigned int current_tle_writes ;
   unsigned long last_reconnect_jif ;
   struct drbd_thread receiver ;
   struct drbd_thread worker ;
   struct drbd_thread asender ;
   cpumask_var_t cpu_mask ;
   struct drbd_work_queue sender_work ;
   struct __anonstruct_send_258 send ;
};
#line 893 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_conf {
   struct drbd_tconn *tconn ;
   int vnr ;
   struct kref kref ;
   unsigned long flags ;
   struct drbd_backing_dev *ldev ;
   sector_t p_size ;
   struct request_queue *rq_queue ;
   struct block_device *this_bdev ;
   struct gendisk *vdisk ;
   unsigned long last_reattach_jif ;
   struct drbd_work resync_work ;
   struct drbd_work unplug_work ;
   struct drbd_work go_diskless ;
   struct drbd_work md_sync_work ;
   struct drbd_work start_resync_work ;
   struct timer_list resync_timer ;
   struct timer_list md_sync_timer ;
   struct timer_list start_resync_timer ;
   struct timer_list request_timer ;
   union drbd_state new_state_tmp ;
   union drbd_dev_state state ;
   wait_queue_head_t misc_wait ;
   wait_queue_head_t state_wait ;
   unsigned int send_cnt ;
   unsigned int recv_cnt ;
   unsigned int read_cnt ;
   unsigned int writ_cnt ;
   unsigned int al_writ_cnt ;
   unsigned int bm_writ_cnt ;
   atomic_t ap_bio_cnt ;
   atomic_t ap_pending_cnt ;
   atomic_t rs_pending_cnt ;
   atomic_t unacked_cnt ;
   atomic_t local_cnt ;
   struct rb_root read_requests ;
   struct rb_root write_requests ;
   unsigned long rs_total ;
   unsigned long rs_failed ;
   unsigned long rs_start ;
   unsigned long rs_paused ;
   unsigned long rs_same_csum ;
   unsigned long rs_mark_left[8U] ;
   unsigned long rs_mark_time[8U] ;
   int rs_last_mark ;
   unsigned long rs_last_bcast ;
   sector_t ov_start_sector ;
   sector_t ov_stop_sector ;
   sector_t ov_position ;
   sector_t ov_last_oos_start ;
   sector_t ov_last_oos_size ;
   unsigned long ov_left ;
   struct drbd_bitmap *bitmap ;
   unsigned long bm_resync_fo ;
   struct lru_cache *resync ;
   unsigned int resync_locked ;
   unsigned int resync_wenr ;
   int open_cnt ;
   u64 *p_uuid ;
   struct list_head active_ee ;
   struct list_head sync_ee ;
   struct list_head done_ee ;
   struct list_head read_ee ;
   struct list_head net_ee ;
   int next_barrier_nr ;
   struct list_head resync_reads ;
   atomic_t pp_in_use ;
   atomic_t pp_in_use_by_net ;
   wait_queue_head_t ee_wait ;
   struct page *md_io_page ;
   struct drbd_md_io md_io ;
   atomic_t md_io_in_use ;
   spinlock_t al_lock ;
   wait_queue_head_t al_wait ;
   struct lru_cache *act_log ;
   unsigned int al_tr_number ;
   int al_tr_cycle ;
   int al_tr_pos ;
   wait_queue_head_t seq_wait ;
   atomic_t packet_seq ;
   unsigned int peer_seq ;
   spinlock_t peer_seq_lock ;
   unsigned int minor ;
   unsigned long comm_bm_set ;
   struct bm_io_work bm_io_work ;
   u64 ed_uuid ;
   struct mutex own_state_mutex ;
   struct mutex *state_mutex ;
   char congestion_reason ;
   atomic_t rs_sect_in ;
   atomic_t rs_sect_ev ;
   int rs_last_sect_ev ;
   int rs_last_events ;
   int c_sync_rate ;
   struct fifo_buffer *rs_plan_s ;
   int rs_in_flight ;
   atomic_t ap_in_flight ;
   unsigned int peer_max_bio_size ;
   unsigned int local_max_bio_size ;
};
#line 1666
enum drbd_force_detach_flags {
    DRBD_READ_ERROR = 0,
    DRBD_WRITE_ERROR = 1,
    DRBD_META_IO_ERROR = 2,
    DRBD_FORCE_DETACH = 3
} ;
#line 2335 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_bitmap {
   struct page **bm_pages ;
   spinlock_t bm_lock ;
   unsigned long bm_set ;
   unsigned long bm_bits ;
   size_t bm_words ;
   size_t bm_number_of_pages ;
   sector_t bm_dev_capacity ;
   struct mutex bm_change ;
   wait_queue_head_t bm_io_wait ;
   enum bm_flag bm_flags ;
   char *bm_why ;
   struct task_struct *bm_task ;
};
#line 1005 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
struct bm_aio_ctx {
   struct drbd_conf *mdev ;
   atomic_t in_flight ;
   unsigned int done ;
   unsigned int flags ;
   int error ;
   struct kref kref ;
};
#line 1814 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
typedef int ldv_func_ret_type___2;
#line 1896 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
typedef int ldv_func_ret_type___10;
#line 18 "include/asm-generic/int-ll64.h"
typedef short s16;
#line 157 "include/linux/init.h"
typedef void (*ctor_fn_t)(void);
#line 306 "include/linux/bitmap.h"
struct bug_entry {
   int bug_addr_disp ;
   int file_disp ;
   unsigned short line ;
   unsigned short flags ;
};
#line 195 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/paravirt.h"
struct static_key;
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 15 "include/uapi/linux/elf.h"
typedef __u64 Elf64_Addr;
#line 16 "include/uapi/linux/elf.h"
typedef __u16 Elf64_Half;
#line 20 "include/uapi/linux/elf.h"
typedef __u32 Elf64_Word;
#line 21 "include/uapi/linux/elf.h"
typedef __u64 Elf64_Xword;
#line 190 "include/uapi/linux/elf.h"
struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
   unsigned char st_other ;
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};
#line 198 "include/uapi/linux/elf.h"
typedef struct elf64_sym Elf64_Sym;
#line 215 "include/linux/kobject.h"
struct kernel_param;
#line 216 "include/linux/kobject.h"
struct kernel_param_ops {
   int (*set)(char const   * , struct kernel_param  const  * ) ;
   int (*get)(char * , struct kernel_param  const  * ) ;
   void (*free)(void * ) ;
};
#line 49 "include/linux/moduleparam.h"
struct kparam_string;
#line 49
struct kparam_array;
#line 49 "include/linux/moduleparam.h"
union __anonunion_ldv_13750_134 {
   void *arg ;
   struct kparam_string  const  *str ;
   struct kparam_array  const  *arr ;
};
#line 49 "include/linux/moduleparam.h"
struct kernel_param {
   char const   *name ;
   struct kernel_param_ops  const  *ops ;
   u16 perm ;
   s16 level ;
   union __anonunion_ldv_13750_134 ldv_13750 ;
};
#line 61 "include/linux/moduleparam.h"
struct kparam_string {
   unsigned int maxlen ;
   char *string ;
};
#line 67 "include/linux/moduleparam.h"
struct kparam_array {
   unsigned int max ;
   unsigned int elemsize ;
   unsigned int *num ;
   struct kernel_param_ops  const  *ops ;
   void *elem ;
};
#line 459 "include/linux/moduleparam.h"
struct static_key {
   atomic_t enabled ;
};
#line 210 "include/linux/jump_label.h"
struct tracepoint;
#line 211 "include/linux/jump_label.h"
struct tracepoint_func {
   void *func ;
   void *data ;
};
#line 29 "include/linux/tracepoint.h"
struct tracepoint {
   char const   *name ;
   struct static_key key ;
   void (*regfunc)(void) ;
   void (*unregfunc)(void) ;
   struct tracepoint_func *funcs ;
};
#line 86 "include/linux/tracepoint.h"
struct kernel_symbol {
   unsigned long value ;
   char const   *name ;
};
#line 27 "include/linux/export.h"
struct mod_arch_specific {

};
#line 37 "include/linux/module.h"
struct module_param_attrs;
#line 37 "include/linux/module.h"
struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
};
#line 46 "include/linux/module.h"
struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute * , struct module_kobject * , char * ) ;
   ssize_t (*store)(struct module_attribute * , struct module_kobject * , char const   * ,
                    size_t  ) ;
   void (*setup)(struct module * , char const   * ) ;
   int (*test)(struct module * ) ;
   void (*free)(struct module * ) ;
};
#line 72
struct exception_table_entry;
#line 201
enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2
} ;
#line 207 "include/linux/module.h"
struct module_ref {
   unsigned long incs ;
   unsigned long decs ;
};
#line 222
struct module_sect_attrs;
#line 222
struct module_notes_attrs;
#line 222
struct ftrace_event_call;
#line 222 "include/linux/module.h"
struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const   *version ;
   char const   *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol  const  *syms ;
   unsigned long const   *crcs ;
   unsigned int num_syms ;
   struct kernel_param *kp ;
   unsigned int num_kp ;
   unsigned int num_gpl_syms ;
   struct kernel_symbol  const  *gpl_syms ;
   unsigned long const   *gpl_crcs ;
   struct kernel_symbol  const  *unused_syms ;
   unsigned long const   *unused_crcs ;
   unsigned int num_unused_syms ;
   unsigned int num_unused_gpl_syms ;
   struct kernel_symbol  const  *unused_gpl_syms ;
   unsigned long const   *unused_gpl_crcs ;
   struct kernel_symbol  const  *gpl_future_syms ;
   unsigned long const   *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
   unsigned int num_exentries ;
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   void *module_init ;
   void *module_core ;
   unsigned int init_size ;
   unsigned int core_size ;
   unsigned int init_text_size ;
   unsigned int core_text_size ;
   unsigned int init_ro_size ;
   unsigned int core_ro_size ;
   struct mod_arch_specific arch ;
   unsigned int taints ;
   unsigned int num_bugs ;
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   Elf64_Sym *symtab ;
   Elf64_Sym *core_symtab ;
   unsigned int num_symtab ;
   unsigned int core_num_syms ;
   char *strtab ;
   char *core_strtab ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   char *args ;
   void *percpu ;
   unsigned int percpu_size ;
   unsigned int num_tracepoints ;
   struct tracepoint * const  *tracepoints_ptrs ;
   unsigned int num_trace_bprintk_fmt ;
   char const   **trace_bprintk_fmt_start ;
   struct ftrace_event_call **trace_events ;
   unsigned int num_trace_events ;
   struct list_head source_list ;
   struct list_head target_list ;
   struct task_struct *waiter ;
   void (*exit)(void) ;
   struct module_ref *refptr ;
   ctor_fn_t (**ctors)(void) ;
   unsigned int num_ctors ;
};
#line 72 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/smap.h"
struct exception_table_entry {
   int insn ;
   int fixup ;
};
#line 241 "include/linux/proc_fs.h"
struct proc_ns_operations {
   char const   *name ;
   int type ;
   void *(*get)(struct task_struct * ) ;
   void (*put)(void * ) ;
   int (*install)(struct nsproxy * , void * ) ;
};
#line 254 "include/linux/proc_fs.h"
union proc_op {
   int (*proc_get_link)(struct dentry * , struct path * ) ;
   int (*proc_read)(struct task_struct * , char * ) ;
   int (*proc_show)(struct seq_file * , struct pid_namespace * , struct pid * , struct task_struct * ) ;
};
#line 260 "include/linux/proc_fs.h"
struct proc_inode {
   struct pid *pid ;
   int fd ;
   union proc_op op ;
   struct proc_dir_entry *pde ;
   struct ctl_table_header *sysctl ;
   struct ctl_table *sysctl_entry ;
   void *ns ;
   struct proc_ns_operations  const  *ns_ops ;
   struct inode vfs_inode ;
};
#line 176 "include/linux/drbd.h"
enum drbd_role {
    R_UNKNOWN = 0,
    R_PRIMARY = 1,
    R_SECONDARY = 2,
    R_MASK = 3
} ;
#line 1153 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct bm_extent {
   int rs_left ;
   int rs_failed ;
   unsigned long flags ;
   struct lc_element lce ;
};
#line 622 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
typedef int ldv_func_ret_type___6;
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 113 "include/linux/drbd.h"
enum drbd_ret_code {
    ERR_CODE_BASE = 100,
    NO_ERROR = 101,
    ERR_LOCAL_ADDR = 102,
    ERR_PEER_ADDR = 103,
    ERR_OPEN_DISK = 104,
    ERR_OPEN_MD_DISK = 105,
    ERR_DISK_NOT_BDEV = 107,
    ERR_MD_NOT_BDEV = 108,
    ERR_DISK_TOO_SMALL = 111,
    ERR_MD_DISK_TOO_SMALL = 112,
    ERR_BDCLAIM_DISK = 114,
    ERR_BDCLAIM_MD_DISK = 115,
    ERR_MD_IDX_INVALID = 116,
    ERR_IO_MD_DISK = 118,
    ERR_MD_INVALID = 119,
    ERR_AUTH_ALG = 120,
    ERR_AUTH_ALG_ND = 121,
    ERR_NOMEM = 122,
    ERR_DISCARD_IMPOSSIBLE = 123,
    ERR_DISK_CONFIGURED = 124,
    ERR_NET_CONFIGURED = 125,
    ERR_MANDATORY_TAG = 126,
    ERR_MINOR_INVALID = 127,
    ERR_INTR = 129,
    ERR_RESIZE_RESYNC = 130,
    ERR_NO_PRIMARY = 131,
    ERR_RESYNC_AFTER = 132,
    ERR_RESYNC_AFTER_CYCLE = 133,
    ERR_PAUSE_IS_SET = 134,
    ERR_PAUSE_IS_CLEAR = 135,
    ERR_PACKET_NR = 137,
    ERR_NO_DISK = 138,
    ERR_NOT_PROTO_C = 139,
    ERR_NOMEM_BITMAP = 140,
    ERR_INTEGRITY_ALG = 141,
    ERR_INTEGRITY_ALG_ND = 142,
    ERR_CPU_MASK_PARSE = 143,
    ERR_CSUMS_ALG = 144,
    ERR_CSUMS_ALG_ND = 145,
    ERR_VERIFY_ALG = 146,
    ERR_VERIFY_ALG_ND = 147,
    ERR_CSUMS_RESYNC_RUNNING = 148,
    ERR_VERIFY_RUNNING = 149,
    ERR_DATA_NOT_CURRENT = 150,
    ERR_CONNECTED = 151,
    ERR_PERM = 152,
    ERR_NEED_APV_93 = 153,
    ERR_STONITH_AND_PROT_A = 154,
    ERR_CONG_NOT_PROTO_A = 155,
    ERR_PIC_AFTER_DEP = 156,
    ERR_PIC_PEER_DEP = 157,
    ERR_RES_NOT_KNOWN = 158,
    ERR_RES_IN_USE = 159,
    ERR_MINOR_CONFIGURED = 160,
    ERR_MINOR_EXISTS = 161,
    ERR_INVALID_REQUEST = 162,
    ERR_NEED_APV_100 = 163,
    ERR_NEED_ALLOW_TWO_PRI = 164,
    ERR_MD_UNCLEAN = 165,
    AFTER_LAST_ERR_CODE = 166
} ;
#line 169 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
enum drbd_packet {
    P_DATA = 0,
    P_DATA_REPLY = 1,
    P_RS_DATA_REPLY = 2,
    P_BARRIER = 3,
    P_BITMAP = 4,
    P_BECOME_SYNC_TARGET = 5,
    P_BECOME_SYNC_SOURCE = 6,
    P_UNPLUG_REMOTE = 7,
    P_DATA_REQUEST = 8,
    P_RS_DATA_REQUEST = 9,
    P_SYNC_PARAM = 10,
    P_PROTOCOL = 11,
    P_UUIDS = 12,
    P_SIZES = 13,
    P_STATE = 14,
    P_SYNC_UUID = 15,
    P_AUTH_CHALLENGE = 16,
    P_AUTH_RESPONSE = 17,
    P_STATE_CHG_REQ = 18,
    P_PING = 19,
    P_PING_ACK = 20,
    P_RECV_ACK = 21,
    P_WRITE_ACK = 22,
    P_RS_WRITE_ACK = 23,
    P_SUPERSEDED = 24,
    P_NEG_ACK = 25,
    P_NEG_DREPLY = 26,
    P_NEG_RS_DREPLY = 27,
    P_BARRIER_ACK = 28,
    P_STATE_CHG_REPLY = 29,
    P_OV_REQUEST = 30,
    P_OV_REPLY = 31,
    P_OV_RESULT = 32,
    P_CSUM_RS_REQUEST = 33,
    P_RS_IS_IN_SYNC = 34,
    P_SYNC_PARAM89 = 35,
    P_COMPRESSED_BITMAP = 36,
    P_DELAY_PROBE = 39,
    P_OUT_OF_SYNC = 40,
    P_RS_CANCEL = 41,
    P_CONN_ST_CHG_REQ = 42,
    P_CONN_ST_CHG_REPLY = 43,
    P_RETRY_WRITE = 44,
    P_PROTOCOL_UPDATE = 45,
    P_MAY_IGNORE = 256,
    P_MAX_OPT_CMD = 257,
    P_INITIAL_META = 65521,
    P_INITIAL_DATA = 65522,
    P_CONNECTION_FEATURES = 65534
} ;
#line 376 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_barrier {
   u32 barrier ;
   u32 pad ;
};
#line 543 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_interval {
   struct rb_node rb ;
   sector_t sector ;
   unsigned int size ;
   sector_t end ;
   signed char local : 1 ;
   signed char waiting : 1 ;
};
#line 547 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_request {
   struct drbd_work w ;
   struct bio *private_bio ;
   struct drbd_interval i ;
   unsigned int epoch ;
   struct list_head tl_requests ;
   struct bio *master_bio ;
   unsigned long start_time ;
   atomic_t completion_ref ;
   struct kref kref ;
   unsigned int rq_state ;
};
#line 600 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_wq_barrier {
   struct drbd_work w ;
   struct completion done ;
};
#line 606 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct digest_info {
   int digest_size ;
   void *digest ;
};
#line 611 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
union __anonunion_ldv_50726_262 {
   u64 block_id ;
   struct digest_info *digest ;
};
#line 611 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct drbd_peer_request {
   struct drbd_work w ;
   struct drbd_epoch *epoch ;
   struct page *pages ;
   atomic_t pending_bios ;
   struct drbd_interval i ;
   unsigned long flags ;
   union __anonunion_ldv_50726_262 ldv_50726 ;
};
#line 48 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_wrappers.h"
enum drbd_req_event {
    CREATED = 0,
    TO_BE_SENT = 1,
    TO_BE_SUBMITTED = 2,
    QUEUE_FOR_NET_WRITE = 3,
    QUEUE_FOR_NET_READ = 4,
    QUEUE_FOR_SEND_OOS = 5,
    SEND_CANCELED = 6,
    SEND_FAILED = 7,
    HANDED_OVER_TO_NETWORK = 8,
    OOS_HANDED_TO_NETWORK = 9,
    CONNECTION_LOST_WHILE_PENDING = 10,
    READ_RETRY_REMOTE_CANCELED = 11,
    RECV_ACKED_BY_PEER = 12,
    WRITE_ACKED_BY_PEER = 13,
    WRITE_ACKED_BY_PEER_AND_SIS = 14,
    CONFLICT_RESOLVED = 15,
    POSTPONE_WRITE = 16,
    NEG_ACKED = 17,
    BARRIER_ACKED = 18,
    DATA_RECEIVED = 19,
    READ_COMPLETED_WITH_ERROR = 20,
    READ_AHEAD_COMPLETED_WITH_ERROR = 21,
    WRITE_COMPLETED_WITH_ERROR = 22,
    ABORT_DISK_IO = 23,
    COMPLETED_OK = 24,
    RESEND = 25,
    FAIL_FROZEN_DISK_IO = 26,
    RESTART_FROZEN_DISK_IO = 27,
    NOTHING = 28
} ;
#line 261 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
struct bio_and_error {
   struct bio *bio ;
   int error ;
};
#line 2154 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
typedef int ldv_func_ret_type___12;
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 21 "include/uapi/linux/uio.h"
struct kvec {
   void *iov_base ;
   size_t iov_len ;
};
#line 35 "include/net/netns/dccp.h"
struct in_addr {
   __be32 s_addr ;
};
#line 182 "include/uapi/linux/in.h"
struct sockaddr_in {
   __kernel_sa_family_t sin_family ;
   __be16 sin_port ;
   struct in_addr sin_addr ;
   unsigned char __pad[8U] ;
};
#line 37 "include/uapi/linux/in6.h"
struct sockaddr_in6 {
   unsigned short sin6_family ;
   __be16 sin6_port ;
   __be32 sin6_flowinfo ;
   struct in6_addr sin6_addr ;
   __u32 sin6_scope_id ;
};
#line 74 "include/linux/drbd.h"
enum drbd_after_sb_p {
    ASB_DISCONNECT = 0,
    ASB_DISCARD_YOUNGER_PRI = 1,
    ASB_DISCARD_OLDER_PRI = 2,
    ASB_DISCARD_ZERO_CHG = 3,
    ASB_DISCARD_LEAST_CHG = 4,
    ASB_DISCARD_LOCAL = 5,
    ASB_DISCARD_REMOTE = 6,
    ASB_CONSENSUS = 7,
    ASB_DISCARD_SECONDARY = 8,
    ASB_CALL_HELPER = 9,
    ASB_VIOLENTLY = 10
} ;
#line 237 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct bm_xfer_ctx {
   unsigned long bm_bits ;
   unsigned long bm_words ;
   unsigned long bit_offset ;
   unsigned long word_offset ;
   unsigned int packets[2U] ;
   unsigned int bytes[2U] ;
};
#line 271 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_header80 {
   u32 magic ;
   u16 command ;
   u16 length ;
};
#line 297 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_header95 {
   u16 magic ;
   u16 command ;
   u32 length ;
};
#line 304 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_header100 {
   u32 magic ;
   u16 volume ;
   u16 command ;
   u32 length ;
   u32 pad ;
};
#line 314 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_data {
   u64 sector ;
   u64 block_id ;
   u32 seq_num ;
   u32 dp_flags ;
};
#line 332 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_block_ack {
   u64 sector ;
   u64 block_id ;
   u32 blksize ;
   u32 seq_num ;
};
#line 347 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_block_req {
   u64 sector ;
   u64 block_id ;
   u32 blksize ;
   u32 pad ;
};
#line 354 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_connection_features {
   u32 protocol_min ;
   u32 feature_flags ;
   u32 protocol_max ;
   u32 _pad ;
   u64 reserved[7U] ;
};
#line 381 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_barrier_ack {
   u32 barrier ;
   u32 set_size ;
};
#line 400 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_rs_param_95 {
   u32 resync_rate ;
   char verify_alg[64U] ;
   char csums_alg[64U] ;
   u32 c_plan_ahead ;
   u32 c_delay_target ;
   u32 c_fill_target ;
   u32 c_max_rate ;
};
#line 415 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_protocol {
   u32 protocol ;
   u32 after_sb_0p ;
   u32 after_sb_1p ;
   u32 after_sb_2p ;
   u32 conn_flags ;
   u32 two_primaries ;
   char integrity_alg[0U] ;
};
#line 427 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_uuids {
   u64 uuid[6U] ;
};
#line 432 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_rs_uuid {
   u64 uuid ;
};
#line 436 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_sizes {
   u64 d_size ;
   u64 u_size ;
   u64 c_size ;
   u32 max_bio_size ;
   u16 queue_order_type ;
   u16 dds_flags ;
};
#line 445 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_state {
   u32 state ;
};
#line 449 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_req_state {
   u32 mask ;
   u32 val ;
};
#line 454 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_req_state_reply {
   u32 retcode ;
};
#line 468 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_block_desc {
   u64 sector ;
   u32 blksize ;
   u32 pad ;
};
#line 474
enum drbd_bitmap_code {
    RLE_VLI_Bits = 2
} ;
#line 478 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct p_compressed_bm {
   u8 encoding ;
   u8 code[0U] ;
};
#line 593
enum epoch_event {
    EV_PUT = 0,
    EV_GOT_BARRIER_NR = 1,
    EV_BECAME_LAST = 2,
    EV_CLEANUP = 32
} ;
#line 1051
enum dds_flags {
    DDSF_FORCED = 1,
    DDSF_NO_RESYNC = 2
} ;
#line 1434
enum determine_dev_size {
    dev_size_error = -1,
    unchanged = 0,
    shrunk = 1,
    grew = 2
} ;
#line 190 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
struct bitstream_cursor {
   u8 *b ;
   unsigned int bit ;
};
#line 225 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
struct bitstream {
   struct bitstream_cursor cur ;
   unsigned char *buf ;
   size_t buf_len ;
   unsigned int pad_bits ;
};
#line 350 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
struct packet_info {
   enum drbd_packet cmd ;
   unsigned int size ;
   unsigned int vnr ;
   void *data ;
};
#line 145 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
enum finish_epoch {
    FE_STILL_LIVE = 0,
    FE_DESTROYED = 1,
    FE_RECYCLED = 2
} ;
#line 741 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
struct accept_wait_data {
   struct drbd_tconn *tconn ;
   struct socket *s_listen ;
   struct completion door_bell ;
   void (*original_sk_state_change)(struct sock * ) ;
};
#line 4432 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
struct data_cmd {
   int expect_payload ;
   size_t pkt_size ;
   int (*fn)(struct drbd_tconn * , struct packet_info * ) ;
};
#line 5309 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
struct asender_cmd {
   size_t pkt_size ;
   int (*fn)(struct drbd_tconn * , struct packet_info * ) ;
};
#line 5860 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
typedef int ldv_func_ret_type___27;
#line 5872 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
typedef int ldv_func_ret_type___28;
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 93 "include/linux/drbd.h"
enum drbd_on_congestion {
    OC_BLOCK = 0,
    OC_PULL_AHEAD = 1,
    OC_DISCONNECT = 2
} ;
#line 99
enum drbd_read_balancing {
    RB_PREFER_LOCAL = 0,
    RB_PREFER_REMOTE = 1,
    RB_ROUND_ROBIN = 2,
    RB_LEAST_PENDING = 3,
    RB_CONGESTED_REMOTE = 4,
    RB_32K_STRIPING = 5,
    RB_64K_STRIPING = 6,
    RB_128K_STRIPING = 7,
    RB_256K_STRIPING = 8,
    RB_512K_STRIPING = 9,
    RB_1M_STRIPING = 10
} ;
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 34 "include/linux/drbd_genl_api.h"
enum drbd_state_info_bcast_reason {
    SIB_GET_STATUS_REPLY = 1,
    SIB_STATE_CHANGE = 2,
    SIB_HELPER_PRE = 3,
    SIB_HELPER_POST = 4,
    SIB_SYNC_PROGRESS = 5
} ;
#line 1598 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct __anonstruct_ldv_50737_260 {
   char *helper_name ;
   unsigned int helper_exit_code ;
};
#line 1598 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct __anonstruct_ldv_50741_261 {
   union drbd_state os ;
   union drbd_state ns ;
};
#line 1598 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
union __anonunion_ldv_50742_259 {
   struct __anonstruct_ldv_50737_260 ldv_50737 ;
   struct __anonstruct_ldv_50741_261 ldv_50741 ;
};
#line 1598 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct sib_info {
   enum drbd_state_info_bcast_reason sib_reason ;
   union __anonunion_ldv_50742_259 ldv_50742 ;
};
#line 53 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_wrappers.h"
struct al_transaction_on_disk {
   __be32 magic ;
   __be32 tr_number ;
   __be32 crc32c ;
   __be16 transaction_type ;
   __be16 n_updates ;
   __be16 context_size ;
   __be16 context_start_slot_nr ;
   __be32 __reserved[4U] ;
   __be16 update_slot_nr[64U] ;
   __be32 update_extent_nr[64U] ;
   __be32 context[919U] ;
};
#line 183 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
struct update_odbm_work {
   struct drbd_work w ;
   unsigned int enr ;
};
#line 188 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
struct update_al_work {
   struct drbd_work w ;
   struct completion event ;
   int err ;
};
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 266
struct workqueue_struct;
#line 64 "include/uapi/linux/net.h"
enum sock_shutdown_cmd {
    SHUT_RD = 0,
    SHUT_WR = 1,
    SHUT_RDWR = 2
} ;
#line 2284 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct retry_worker {
   struct workqueue_struct *wq ;
   struct work_struct worker ;
   spinlock_t lock ;
   struct list_head writes ;
};
#line 2927 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct meta_data_on_disk {
   u64 la_size ;
   u64 uuid[4U] ;
   u64 device_uuid ;
   u64 reserved_u64_1 ;
   u32 flags ;
   u32 magic ;
   u32 md_size_sect ;
   u32 al_offset ;
   u32 al_nr_extents ;
   u32 bm_offset ;
   u32 bm_bytes_per_bit ;
   u32 la_peer_max_bio_size ;
   u32 reserved_u32[3U] ;
};
#line 3568 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct fault_random_state {
   unsigned long state ;
   unsigned long count ;
};
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 255
enum hrtimer_restart;
#line 38 "include/linux/kmod.h"
struct subprocess_info {
   struct work_struct work ;
   struct completion *complete ;
   char *path ;
   char **argv ;
   char **envp ;
   int wait ;
   int retval ;
   int (*init)(struct subprocess_info * , struct cred * ) ;
   void (*cleanup)(struct subprocess_info * ) ;
   void *data ;
};
#line 39 "include/linux/kobject.h"
enum kobject_action {
    KOBJ_ADD = 0,
    KOBJ_REMOVE = 1,
    KOBJ_CHANGE = 2,
    KOBJ_MOVE = 3,
    KOBJ_ONLINE = 4,
    KOBJ_OFFLINE = 5,
    KOBJ_MAX = 6
} ;
#line 84 "include/linux/nsproxy.h"
struct scm_creds {
   u32 pid ;
   kuid_t uid ;
   kgid_t gid ;
};
#line 17 "include/linux/netlink.h"
struct netlink_skb_parms {
   struct scm_creds creds ;
   __u32 portid ;
   __u32 dst_group ;
   struct sock *ssk ;
};
#line 61 "include/linux/drbd.h"
enum drbd_fencing_p {
    FP_NOT_AVAIL = -1,
    FP_DONT_CARE = 0,
    FP_RESOURCE = 1,
    FP_STONITH = 2
} ;
#line 56 "include/linux/prefetch.h"
union __anonunion_ldv_49826_259 {
   __u32 flags ;
   __s32 ret_code ;
};
#line 56 "include/linux/prefetch.h"
struct drbd_genlmsghdr {
   __u32 minor ;
   union __anonunion_ldv_49826_259 ldv_49826 ;
};
#line 42 "include/linux/drbd_genl_api.h"
struct genlmsghdr {
   __u8 cmd ;
   __u8 version ;
   __u16 reserved ;
};
#line 89 "include/linux/drbd_genl.h"
struct drbd_cfg_context {
   __u32 ctx_volume ;
   char ctx_resource_name[128U] ;
   __u32 ctx_resource_name_len ;
   char ctx_my_addr[128U] ;
   __u32 ctx_my_addr_len ;
   char ctx_peer_addr[128U] ;
   __u32 ctx_peer_addr_len ;
};
#line 144 "include/linux/drbd_genl.h"
struct set_role_parms {
   char assume_uptodate ;
};
#line 178 "include/linux/drbd_genl.h"
struct resize_parms {
   __u64 resize_size ;
   char resize_force ;
   char no_resync ;
};
#line 182 "include/linux/drbd_genl.h"
struct state_info {
   __u32 sib_reason ;
   __u32 current_state ;
   __u64 capacity ;
   __u64 ed_uuid ;
   __u32 prev_state ;
   __u32 new_state ;
   char uuids[32U] ;
   __u32 uuids_len ;
   __u32 disk_flags ;
   __u64 bits_total ;
   __u64 bits_oos ;
   __u64 bits_rs_total ;
   __u64 bits_rs_failed ;
   char helper[32U] ;
   __u32 helper_len ;
   __u32 helper_exit_code ;
   __u64 send_cnt ;
   __u64 recv_cnt ;
   __u64 read_cnt ;
   __u64 writ_cnt ;
   __u64 al_writ_cnt ;
   __u64 bm_writ_cnt ;
   __u32 ap_bio_cnt ;
   __u32 ap_pending_cnt ;
   __u32 rs_pending_cnt ;
};
#line 188 "include/linux/drbd_genl.h"
struct start_ov_parms {
   __u64 ov_start_sector ;
   __u64 ov_stop_sector ;
};
#line 228 "include/linux/drbd_genl.h"
struct new_c_uuid_parms {
   char clear_bm ;
};
#line 233 "include/linux/drbd_genl.h"
struct timeout_parms {
   __u32 timeout_type ;
};
#line 237 "include/linux/drbd_genl.h"
struct disconnect_parms {
   char force_disconnect ;
};
#line 241 "include/linux/drbd_genl.h"
struct detach_parms {
   char force_detach ;
};
#line 138 "include/linux/kthread.h"
struct genl_family;
#line 138 "include/linux/kthread.h"
struct genl_multicast_group {
   struct genl_family *family ;
   struct list_head list ;
   char name[16U] ;
   u32 id ;
};
#line 24 "include/net/genetlink.h"
struct genl_ops;
#line 25
struct genl_info;
#line 26 "include/net/genetlink.h"
struct genl_family {
   unsigned int id ;
   unsigned int hdrsize ;
   char name[16U] ;
   unsigned int version ;
   unsigned int maxattr ;
   bool netnsok ;
   int (*pre_doit)(struct genl_ops * , struct sk_buff * , struct genl_info * ) ;
   void (*post_doit)(struct genl_ops * , struct sk_buff * , struct genl_info * ) ;
   struct nlattr **attrbuf ;
   struct list_head ops_list ;
   struct list_head family_list ;
   struct list_head mcast_groups ;
};
#line 64 "include/net/genetlink.h"
struct genl_info {
   u32 snd_seq ;
   u32 snd_portid ;
   struct nlmsghdr *nlhdr ;
   struct genlmsghdr *genlhdr ;
   void *userhdr ;
   struct nlattr **attrs ;
   struct net *_net ;
   void *user_ptr[2U] ;
};
#line 98 "include/net/genetlink.h"
struct genl_ops {
   u8 cmd ;
   u8 internal_flags ;
   unsigned int flags ;
   struct nla_policy  const  *policy ;
   int (*doit)(struct sk_buff * , struct genl_info * ) ;
   int (*dumpit)(struct sk_buff * , struct netlink_callback * ) ;
   int (*done)(struct netlink_callback * ) ;
   struct list_head ops_list ;
};
#line 170 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
struct drbd_config_context {
   unsigned int minor ;
   unsigned int volume ;
   char *resource_name ;
   struct nlattr *my_addr ;
   struct nlattr *peer_addr ;
   struct sk_buff *reply_skb ;
   struct drbd_genlmsghdr *reply_dh ;
   struct drbd_conf *mdev ;
   struct drbd_tconn *tconn ;
};
#line 1941 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
struct crypto {
   struct crypto_hash *verify_tfm ;
   struct crypto_hash *csums_tfm ;
   struct crypto_hash *cram_hmac_tfm ;
   struct crypto_hash *integrity_tfm ;
};
#line 83 "include/linux/rbtree.h"
struct rb_augment_callbacks {
   void (*propagate)(struct rb_node * , struct rb_node * ) ;
   void (*copy)(struct rb_node * , struct rb_node * ) ;
   void (*rotate)(struct rb_node * , struct rb_node * ) ;
};
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 121 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
struct after_state_chg_work {
   struct drbd_work w ;
   union drbd_state os ;
   union drbd_state ns ;
   enum chg_state_flags flags ;
   struct completion *done ;
};
#line 129
enum sanitize_state_warnings {
    NO_WARNING = 0,
    ABORTED_ONLINE_VERIFY = 1,
    ABORTED_RESYNC = 2,
    CONNECTION_LOST_NEGOTIATING = 3,
    IMPLICITLY_UPGRADED_DISK = 4,
    IMPLICITLY_UPGRADED_PDSK = 5
} ;
#line 1592 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
struct after_conn_state_chg_work {
   struct drbd_work w ;
   enum drbd_conns oc ;
   union drbd_state ns_min ;
   union drbd_state ns_max ;
   enum chg_state_flags flags ;
};
#line 1997 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
typedef int ldv_func_ret_type___4;
#line 255 "include/linux/timer.h"
enum hrtimer_restart;
#line 1 "<compiler builtins>"
long __builtin_expect(long exp , long c ) ;
#line 62 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static void set_bit(unsigned int nr , unsigned long volatile   *addr ) 
{ 


  {
#line 70
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
#line 72
  return;
}
}
#line 100 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static void clear_bit(int nr , unsigned long volatile   *addr ) 
{ 


  {
#line 107
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr));
#line 109
  return;
}
}
#line 121 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static void clear_bit_unlock(unsigned int nr , unsigned long volatile   *addr ) 
{ 


  {
#line 123
  __asm__  volatile   ("": : : "memory");
#line 124
  clear_bit((int )nr, addr);
#line 125
  return;
}
}
#line 197 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int test_and_set_bit(int nr , unsigned long volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 201
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %2,%1\n\tsbb %0,%0": "=r" (oldbit),
                       "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
#line 204
  return (oldbit);
}
}
#line 229 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int __test_and_set_bit(int nr , unsigned long volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 233
  __asm__  ("bts %2,%1\n\tsbb %0,%0": "=r" (oldbit), "+m" (*((long volatile   *)addr)): "Ir" (nr));
#line 237
  return (oldbit);
}
}
#line 248 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int test_and_clear_bit(int nr , unsigned long volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 252
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %2,%1\n\tsbb %0,%0": "=r" (oldbit),
                       "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
#line 256
  return (oldbit);
}
}
#line 275 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int __test_and_clear_bit(int nr , unsigned long volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 279
  __asm__  volatile   ("btr %2,%1\n\tsbb %0,%0": "=r" (oldbit), "+m" (*((long volatile   *)addr)): "Ir" (nr));
#line 283
  return (oldbit);
}
}
#line 318 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int constant_test_bit(unsigned int nr , unsigned long const volatile   *addr ) 
{ 


  {
#line 320
  return ((int )((unsigned long )*(addr + (unsigned long )(nr / 64U)) >> ((int )nr & 63)) & 1);
}
}
#line 324 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int variable_test_bit(int nr , unsigned long const volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 328
  __asm__  volatile   ("bt %2,%1\n\tsbb %0,%0": "=r" (oldbit): "m" (*((unsigned long *)addr)),
                       "Ir" (nr));
#line 333
  return (oldbit);
}
}
#line 11 "include/asm-generic/bitops/find.h"
extern unsigned long find_next_bit(unsigned long const   * , unsigned long  , unsigned long  ) ;
#line 22
extern unsigned long find_next_zero_bit(unsigned long const   * , unsigned long  ,
                                        unsigned long  ) ;
#line 45 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/arch_hweight.h"
__inline static unsigned long __arch_hweight64(__u64 w ) 
{ 
  unsigned long res ;

  {
#line 47
  res = 0UL;
#line 53
  __asm__  ("661:\n\tcall __sw_hweight64\n662:\n.pushsection .altinstructions,\"a\"\n .long 661b - .\n .long 6631f - .\n .word (4*32+23)\n .byte 662b-661b\n .byte 6641f-6631f\n.popsection\n.pushsection .discard,\"aw\",@progbits\n .byte 0xff + (6641f-6631f) - (662b-661b)\n.popsection\n.pushsection .altinstr_replacement, \"ax\"\n6631:\n\t.byte 0xf3,0x48,0x0f,0xb8,0xc7\n6641:\n\t.popsection": "=a" (res): "D" (w));
#line 58
  return (res);
}
}
#line 11 "include/asm-generic/bitops/le.h"
__inline static unsigned long find_next_zero_bit_le(void const   *addr , unsigned long size ,
                                                    unsigned long offset ) 
{ 
  unsigned long tmp ;

  {
#line 14
  tmp = find_next_zero_bit((unsigned long const   *)addr, size, offset);
#line 14
  return (tmp);
}
}
#line 17 "include/asm-generic/bitops/le.h"
__inline static unsigned long find_next_bit_le(void const   *addr , unsigned long size ,
                                               unsigned long offset ) 
{ 
  unsigned long tmp ;

  {
#line 20
  tmp = find_next_bit((unsigned long const   *)addr, size, offset);
#line 20
  return (tmp);
}
}
#line 52 "include/asm-generic/bitops/le.h"
__inline static int test_bit_le(int nr , void const   *addr ) 
{ 
  int tmp ;

  {
#line 54
  tmp = variable_test_bit(nr, (unsigned long const volatile   *)addr);
#line 54
  return (tmp);
}
}
#line 87 "include/asm-generic/bitops/le.h"
__inline static int __test_and_set_bit_le(int nr , void *addr ) 
{ 
  int tmp ;

  {
#line 89
  tmp = __test_and_set_bit(nr, (unsigned long volatile   *)addr);
#line 89
  return (tmp);
}
}
#line 92 "include/asm-generic/bitops/le.h"
__inline static int __test_and_clear_bit_le(int nr , void *addr ) 
{ 
  int tmp ;

  {
#line 94
  tmp = __test_and_clear_bit(nr, (unsigned long volatile   *)addr);
#line 94
  return (tmp);
}
}
#line 64 "include/linux/bitops.h"
__inline static unsigned long hweight_long(unsigned long w ) 
{ 
  unsigned long tmp ;

  {
#line 66
  tmp = __arch_hweight64((__u64 )w);
#line 66
  return (tmp);
}
}
#line 119 "include/linux/printk.h"
extern int printk(char const   *  , ...) ;
#line 53 "include/linux/dynamic_debug.h"
extern int __dynamic_dev_dbg(struct _ddebug * , struct device  const  * , char const   * 
                             , ...) ;
#line 150 "include/linux/kernel.h"
extern void __might_sleep(char const   * , int  , int  ) ;
#line 55 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page_64_types.h"
extern void copy_page(void * , void * ) ;
#line 88 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/percpu.h"
extern void __bad_percpu_size(void) ;
#line 10 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/current.h"
extern struct task_struct *current_task ;
#line 12 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/current.h"
__inline static struct task_struct *get_current(void) 
{ 
  struct task_struct *pfo_ret__ ;

  {
#line 14
  switch (8UL) {
  case 1UL: 
#line 14
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_2860;
  case 2UL: 
#line 14
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_2860;
  case 4UL: 
#line 14
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_2860;
  case 8UL: 
#line 14
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_2860;
  default: 
#line 14
  __bad_percpu_size();
  }
  ldv_2860: ;
#line 14
  return (pfo_ret__);
}
}
#line 55 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/string_64.h"
extern void *memset(void * , int  , size_t  ) ;
#line 71 "include/asm-generic/bug.h"
extern void warn_slowpath_null(char const   * , int const    ) ;
#line 15 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/cmpxchg.h"
extern void __xadd_wrong_size(void) ;
#line 23 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static int atomic_read(atomic_t const   *v ) 
{ 


  {
#line 25
  return ((int )*((int volatile   *)(& v->counter)));
}
}
#line 47 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static void atomic_add(int i , atomic_t *v ) 
{ 


  {
#line 49
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; addl %1,%0": "+m" (v->counter): "ir" (i));
#line 51
  return;
}
}
#line 77 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static int atomic_sub_and_test(int i , atomic_t *v ) 
{ 
  unsigned char c ;

  {
#line 81
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; subl %2,%0; sete %1": "+m" (v->counter),
                       "=qm" (c): "ir" (i): "memory");
#line 84
  return ((int )c);
}
}
#line 93 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static void atomic_inc(atomic_t *v ) 
{ 


  {
#line 95
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; incl %0": "+m" (v->counter));
#line 97
  return;
}
}
#line 119 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static int atomic_dec_and_test(atomic_t *v ) 
{ 
  unsigned char c ;

  {
#line 123
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0; sete %1": "+m" (v->counter),
                       "=qm" (c): : "memory");
#line 126
  return ((unsigned int )c != 0U);
}
}
#line 173 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static int atomic_add_return(int i , atomic_t *v ) 
{ 
  int __ret ;

  {
#line 182
  __ret = i;
#line 182
  switch (4UL) {
  case 1UL: 
#line 182
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; xaddb %b0, %1\n": "+q" (__ret),
                       "+m" (v->counter): : "memory", "cc");
#line 182
  goto ldv_5470;
  case 2UL: 
#line 182
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; xaddw %w0, %1\n": "+r" (__ret),
                       "+m" (v->counter): : "memory", "cc");
#line 182
  goto ldv_5470;
  case 4UL: 
#line 182
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; xaddl %0, %1\n": "+r" (__ret),
                       "+m" (v->counter): : "memory", "cc");
#line 182
  goto ldv_5470;
  case 8UL: 
#line 182
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; xaddq %q0, %1\n": "+r" (__ret),
                       "+m" (v->counter): : "memory", "cc");
#line 182
  goto ldv_5470;
  default: 
#line 182
  __xadd_wrong_size();
  }
  ldv_5470: ;
#line 182
  return (__ret + i);
}
}
#line 201 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static int atomic_sub_return(int i , atomic_t *v ) 
{ 
  int tmp ;

  {
#line 203
  tmp = atomic_add_return(- i, v);
#line 203
  return (tmp);
}
}
#line 333 "include/linux/lockdep.h"
extern void lock_acquire(struct lockdep_map * , unsigned int  , int  , int  , int  ,
                         struct lockdep_map * , unsigned long  ) ;
#line 337
extern void lock_release(struct lockdep_map * , int  , unsigned long  ) ;
#line 342
extern int lock_is_held(struct lockdep_map * ) ;
#line 573
extern void lockdep_rcu_suspicious(char const   * , int const    , char const   * ) ;
#line 115 "include/linux/mutex.h"
extern void __mutex_init(struct mutex * , char const   * , struct lock_class_key * ) ;
#line 168
extern int mutex_trylock(struct mutex * ) ;
#line 171
int ldv_mutex_trylock_4(struct mutex *ldv_func_arg1 ) ;
#line 175
int ldv_mutex_trylock_12(struct mutex *ldv_func_arg1 ) ;
#line 177
extern void mutex_unlock(struct mutex * ) ;
#line 180
void ldv_mutex_unlock_2(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_5(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_7(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_9(struct mutex *ldv_func_arg1 ) ;
#line 196
void ldv_mutex_unlock_11(struct mutex *ldv_func_arg1 ) ;
#line 200
void ldv_mutex_unlock_14(struct mutex *ldv_func_arg1 ) ;
#line 7 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
extern void mutex_lock(struct mutex * ) ;
#line 10
void ldv_mutex_lock_1(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_3(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_6(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_8(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_10(struct mutex *ldv_func_arg1 ) ;
#line 30
void ldv_mutex_lock_13(struct mutex *ldv_func_arg1 ) ;
#line 35
void ldv_mutex_lock_bm_change_of_drbd_bitmap(struct mutex *lock ) ;
#line 36
int ldv_mutex_trylock_bm_change_of_drbd_bitmap(struct mutex *lock ) ;
#line 39
void ldv_mutex_unlock_bm_change_of_drbd_bitmap(struct mutex *lock ) ;
#line 51
void ldv_mutex_lock_cred_guard_mutex_of_signal_struct(struct mutex *lock ) ;
#line 55
void ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(struct mutex *lock ) ;
#line 75
void ldv_mutex_lock_lock(struct mutex *lock ) ;
#line 79
void ldv_mutex_unlock_lock(struct mutex *lock ) ;
#line 83
void ldv_mutex_lock_mtx_of_percpu_rw_semaphore(struct mutex *lock ) ;
#line 87
void ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(struct mutex *lock ) ;
#line 91
void ldv_mutex_lock_mutex_of_device(struct mutex *lock ) ;
#line 92
int ldv_mutex_trylock_mutex_of_device(struct mutex *lock ) ;
#line 95
void ldv_mutex_unlock_mutex_of_device(struct mutex *lock ) ;
#line 206 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
extern unsigned long kernel_stack ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6299;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6299;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6299;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6299;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6299: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 93 "include/linux/spinlock.h"
extern void __raw_spin_lock_init(raw_spinlock_t * , char const   * , struct lock_class_key * ) ;
#line 29 "include/linux/spinlock_api_smp.h"
extern void _raw_spin_lock_irq(raw_spinlock_t * ) ;
#line 32
extern unsigned long _raw_spin_lock_irqsave(raw_spinlock_t * ) ;
#line 41
extern void _raw_spin_unlock_irq(raw_spinlock_t * ) ;
#line 43
extern void _raw_spin_unlock_irqrestore(raw_spinlock_t * , unsigned long  ) ;
#line 18 "include/linux/rwlock_api_smp.h"
extern void _raw_read_lock(rwlock_t * ) ;
#line 30
extern void _raw_read_unlock(rwlock_t * ) ;
#line 272 "include/linux/spinlock.h"
__inline static raw_spinlock_t *spinlock_check(spinlock_t *lock ) 
{ 


  {
#line 274
  return (& lock->ldv_5957.rlock);
}
}
#line 308 "include/linux/spinlock.h"
__inline static void spin_lock_irq(spinlock_t *lock ) 
{ 


  {
#line 310
  _raw_spin_lock_irq(& lock->ldv_5957.rlock);
#line 311
  return;
}
}
#line 333 "include/linux/spinlock.h"
__inline static void spin_unlock_irq(spinlock_t *lock ) 
{ 


  {
#line 335
  _raw_spin_unlock_irq(& lock->ldv_5957.rlock);
#line 336
  return;
}
}
#line 338 "include/linux/spinlock.h"
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) 
{ 


  {
#line 340
  _raw_spin_unlock_irqrestore(& lock->ldv_5957.rlock, flags);
#line 341
  return;
}
}
#line 62 "include/linux/vmalloc.h"
extern void *__vmalloc(unsigned long  , gfp_t  , pgprot_t  ) ;
#line 66
extern void vfree(void const   * ) ;
#line 77 "include/linux/jiffies.h"
extern unsigned long volatile   jiffies ;
#line 63 "include/linux/wait.h"
extern void __init_waitqueue_head(wait_queue_head_t * , char const   * , struct lock_class_key * ) ;
#line 139
extern void __wake_up(wait_queue_head_t * , unsigned int  , int  , void * ) ;
#line 732
extern void prepare_to_wait(wait_queue_head_t * , wait_queue_t * , int  ) ;
#line 734
extern void finish_wait(wait_queue_head_t * , wait_queue_t * ) ;
#line 737
extern int autoremove_wake_function(wait_queue_t * , unsigned int  , int  , void * ) ;
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 273
extern int rcu_is_cpu_idle(void) ;
#line 277
extern bool rcu_lockdep_current_cpu_online(void) ;
#line 287 "include/linux/rcupdate.h"
__inline static void rcu_lock_acquire(struct lockdep_map *map ) 
{ 


  {
#line 289
  lock_acquire(map, 0U, 0, 2, 1, 0, (unsigned long )((void *)0));
#line 291
  return;
}
}
#line 292 "include/linux/rcupdate.h"
__inline static void rcu_lock_release(struct lockdep_map *map ) 
{ 


  {
#line 294
  lock_release(map, 1, (unsigned long )((void *)0));
#line 296
  return;
}
}
#line 297
extern struct lockdep_map rcu_lock_map ;
#line 300
extern int debug_lockdep_rcu_enabled(void) ;
#line 322 "include/linux/rcupdate.h"
__inline static int rcu_read_lock_held(void) 
{ 
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 324
  tmp = debug_lockdep_rcu_enabled();
#line 324
  if (tmp == 0) {
#line 325
    return (1);
  } else {

  }
#line 326
  tmp___0 = rcu_is_cpu_idle();
#line 326
  if (tmp___0 != 0) {
#line 327
    return (0);
  } else {

  }
#line 328
  tmp___1 = rcu_lockdep_current_cpu_online();
#line 328
  if (tmp___1) {
#line 328
    tmp___2 = 0;
  } else {
#line 328
    tmp___2 = 1;
  }
#line 328
  if (tmp___2) {
#line 329
    return (0);
  } else {

  }
#line 330
  tmp___3 = lock_is_held(& rcu_lock_map);
#line 330
  return (tmp___3);
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock();
#line 763
  return;
}
}
#line 323 "include/linux/gfp.h"
extern struct page *alloc_pages_current(gfp_t  , unsigned int  ) ;
#line 326 "include/linux/gfp.h"
__inline static struct page *alloc_pages(gfp_t gfp_mask , unsigned int order ) 
{ 
  struct page *tmp ;

  {
#line 328
  tmp = alloc_pages_current(gfp_mask, order);
#line 328
  return (tmp);
}
}
#line 359
extern void __free_pages(struct page * , unsigned int  ) ;
#line 64 "include/linux/kref.h"
__inline static int kref_sub(struct kref *kref , unsigned int count , void (*release)(struct kref * ) ) 
{ 
  int __ret_warn_on ;
  long tmp ;
  int tmp___0 ;

  {
#line 67
  __ret_warn_on = (unsigned long )release == (unsigned long )((void (*)(struct kref * ))0);
#line 67
  tmp = __builtin_expect(__ret_warn_on != 0, 0L);
#line 67
  if (tmp != 0L) {
#line 67
    warn_slowpath_null("include/linux/kref.h", 67);
  } else {

  }
#line 67
  __builtin_expect(__ret_warn_on != 0, 0L);
#line 69
  tmp___0 = atomic_sub_and_test((int )count, & kref->refcount);
#line 69
  if (tmp___0 != 0) {
#line 70
    (*release)(kref);
#line 71
    return (1);
  } else {

  }
#line 73
  return (0);
}
}
#line 93 "include/linux/kref.h"
__inline static int kref_put(struct kref *kref , void (*release)(struct kref * ) ) 
{ 
  int tmp ;

  {
#line 95
  tmp = kref_sub(kref, 1U, release);
#line 95
  return (tmp);
}
}
#line 41 "include/linux/ratelimit.h"
extern int ___ratelimit(struct ratelimit_state * , char const   * ) ;
#line 917 "include/linux/device.h"
extern int dev_alert(struct device  const  * , char const   *  , ...) ;
#line 921
extern int dev_err(struct device  const  * , char const   *  , ...) ;
#line 923
extern int dev_warn(struct device  const  * , char const   *  , ...) ;
#line 927
extern int _dev_info(struct device  const  * , char const   *  , ...) ;
#line 741 "include/linux/mm.h"
__inline static void *lowmem_page_address(struct page  const  *page ) 
{ 


  {
#line 743
  return ((void *)((unsigned long )((unsigned long long )(((long )page + 24189255811072L) / 64L) << 12) + 0xffff880000000000UL));
}
}
#line 2355 "include/linux/fs.h"
extern void submit_bio(int  , struct bio * ) ;
#line 324 "include/linux/sched.h"
extern void schedule(void) ;
#line 2596
extern int _cond_resched(void) ;
#line 185 "include/linux/slab.h"
extern void kfree(void const   * ) ;
#line 220 "include/linux/slub_def.h"
extern void *__kmalloc(size_t  , gfp_t  ) ;
#line 267 "include/linux/slub_def.h"
__inline static void *kmalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp___2 ;

  {
#line 282
  tmp___2 = __kmalloc(size, flags);
#line 282
  return (tmp___2);
}
}
#line 375 "include/linux/slab.h"
__inline static void *kzalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
#line 377
  tmp = kmalloc(size, flags | 32768U);
#line 377
  return (tmp);
}
}
#line 66 "include/linux/highmem.h"
__inline static void *kmap_atomic(struct page *page ) 
{ 
  void *tmp ;

  {
#line 68
  __rcu_read_lock();
#line 69
  tmp = lowmem_page_address((struct page  const  *)page);
#line 69
  return (tmp);
}
}
#line 73 "include/linux/highmem.h"
__inline static void __kunmap_atomic(void *addr ) 
{ 


  {
#line 75
  __rcu_read_unlock();
#line 76
  return;
}
}
#line 244 "include/linux/highmem.h"
__inline static void copy_highpage(struct page *to , struct page *from ) 
{ 
  char *vfrom ;
  char *vto ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 248
  tmp = kmap_atomic(from);
#line 248
  vfrom = (char *)tmp;
#line 249
  tmp___0 = kmap_atomic(to);
#line 249
  vto = (char *)tmp___0;
#line 250
  copy_page((void *)vto, (void *)vfrom);
#line 251
  __kunmap_atomic((void *)vto);
#line 252
  __kunmap_atomic((void *)vfrom);
#line 253
  return;
}
}
#line 34 "include/linux/mempool.h"
extern void *mempool_alloc(mempool_t * , gfp_t  ) ;
#line 35
extern void mempool_free(void * , mempool_t * ) ;
#line 216 "include/linux/bio.h"
extern void bio_put(struct bio * ) ;
#line 244
extern void bio_endio(struct bio * , int  ) ;
#line 251
extern int bio_add_page(struct bio * , struct page * , unsigned int  , unsigned int  ) ;
#line 1033 "include/linux/blkdev.h"
extern int blkdev_issue_flush(struct block_device * , gfp_t  , sector_t * ) ;
#line 120 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_state.h"
enum drbd_state_rv __drbd_set_state(struct drbd_conf *mdev , union drbd_state ns ,
                                    enum chg_state_flags flags , struct completion *done ) ;
#line 70 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
int enable_faults ;
#line 71
int fault_rate ;
#line 148
unsigned int _drbd_insert_fault(struct drbd_conf *mdev , unsigned int type ) ;
#line 151 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_insert_fault(struct drbd_conf *mdev , unsigned int type ) 
{ 
  unsigned int tmp ;
  int tmp___0 ;

  {
#line 153
  if (fault_rate != 0 && (enable_faults >> (int )type) & 1) {
#line 153
    tmp = _drbd_insert_fault(mdev, type);
#line 153
    if (tmp != 0U) {
#line 153
      tmp___0 = 1;
    } else {
#line 153
      tmp___0 = 0;
    }
  } else {
#line 153
    tmp___0 = 0;
  }
#line 153
  return (tmp___0);
}
}
#line 166
struct ratelimit_state drbd_ratelimit_state ;
#line 1066
char *drbd_task_to_thread_name(struct drbd_tconn *tconn , struct task_struct *task ) ;
#line 1151
void drbd_go_diskless(struct drbd_conf *mdev ) ;
#line 1152
void drbd_ldev_destroy(struct drbd_conf *mdev ) ;
#line 1317
int drbd_bm_init(struct drbd_conf *mdev ) ;
#line 1318
int drbd_bm_resize(struct drbd_conf *mdev , sector_t capacity , int set_new_bits ) ;
#line 1319
void drbd_bm_cleanup(struct drbd_conf *mdev ) ;
#line 1320
void drbd_bm_set_all(struct drbd_conf *mdev ) ;
#line 1321
void drbd_bm_clear_all(struct drbd_conf *mdev ) ;
#line 1323
int drbd_bm_set_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) ;
#line 1325
int drbd_bm_clear_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) ;
#line 1327
int drbd_bm_count_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) ;
#line 1331
void _drbd_bm_set_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) ;
#line 1333
int drbd_bm_test_bit(struct drbd_conf *mdev , unsigned long const   bitnr ) ;
#line 1334
int drbd_bm_e_weight(struct drbd_conf *mdev , unsigned long enr ) ;
#line 1335
int drbd_bm_write_page(struct drbd_conf *mdev , unsigned int idx ) ;
#line 1336
int drbd_bm_read(struct drbd_conf *mdev ) ;
#line 1337
void drbd_bm_mark_for_writeout(struct drbd_conf *mdev , int page_nr ) ;
#line 1338
int drbd_bm_write(struct drbd_conf *mdev ) ;
#line 1339
int drbd_bm_write_hinted(struct drbd_conf *mdev ) ;
#line 1340
int drbd_bm_write_all(struct drbd_conf *mdev ) ;
#line 1341
int drbd_bm_write_copy_pages(struct drbd_conf *mdev ) ;
#line 1342
size_t drbd_bm_words(struct drbd_conf *mdev ) ;
#line 1343
unsigned long drbd_bm_bits(struct drbd_conf *mdev ) ;
#line 1344
sector_t drbd_bm_capacity(struct drbd_conf *mdev ) ;
#line 1347
unsigned long drbd_bm_find_next(struct drbd_conf *mdev , unsigned long bm_fo ) ;
#line 1349
unsigned long _drbd_bm_find_next(struct drbd_conf *mdev , unsigned long bm_fo ) ;
#line 1350
unsigned long _drbd_bm_find_next_zero(struct drbd_conf *mdev , unsigned long bm_fo ) ;
#line 1351
unsigned long _drbd_bm_total_weight(struct drbd_conf *mdev ) ;
#line 1352
unsigned long drbd_bm_total_weight(struct drbd_conf *mdev ) ;
#line 1355
void drbd_bm_merge_lel(struct drbd_conf *mdev , size_t offset , size_t number , unsigned long *buffer ) ;
#line 1358
void drbd_bm_get_lel(struct drbd_conf *mdev , size_t offset , size_t number , unsigned long *buffer ) ;
#line 1361
void drbd_bm_lock(struct drbd_conf *mdev , char *why , enum bm_flag flags ) ;
#line 1362
void drbd_bm_unlock(struct drbd_conf *mdev ) ;
#line 1396
mempool_t *drbd_md_io_page_pool ;
#line 1402
struct bio *bio_alloc_drbd(gfp_t gfp_mask ) ;
#line 1404
rwlock_t global_state_lock ;
#line 1432
char *ppsize(char *buf , unsigned long long size ) ;
#line 1459
void wait_until_done_or_force_detached(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ,
                                       unsigned int *done ) ;
#line 1643 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static enum drbd_state_rv _drbd_set_state(struct drbd_conf *mdev , union drbd_state ns ,
                                                   enum chg_state_flags flags , struct completion *done ) 
{ 
  enum drbd_state_rv rv ;

  {
#line 1648
  _raw_read_lock(& global_state_lock);
#line 1649
  rv = __drbd_set_state(mdev, ns, flags, done);
#line 1650
  _raw_read_unlock(& global_state_lock);
#line 1652
  return (rv);
}
}
#line 1655 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static union drbd_state drbd_read_state(struct drbd_conf *mdev ) 
{ 
  union drbd_state rv ;

  {
#line 1659
  rv.i = mdev->state.i;
#line 1660
  rv.ldv_40024.susp = (mdev->tconn)->susp;
#line 1661
  rv.ldv_40024.susp_nod = (mdev->tconn)->susp_nod;
#line 1662
  rv.ldv_40024.susp_fen = (mdev->tconn)->susp_fen;
#line 1664
  return (rv);
}
}
#line 1675 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void __drbd_chk_io_error_(struct drbd_conf *mdev , enum drbd_force_detach_flags df ,
                                          char const   *where ) 
{ 
  enum drbd_io_error_p ep ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  union drbd_state __ns ;
  union drbd_state __ns___0 ;

  {
#line 1681
  rcu_read_lock();
#line 1682
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1682
  tmp = debug_lockdep_rcu_enabled();
#line 1682
  if (tmp != 0 && ! __warned) {
#line 1682
    tmp___0 = rcu_read_lock_held();
#line 1682
    if (tmp___0 == 0 && 1) {
#line 1682
      __warned = 1;
#line 1682
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1682, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1682
  ep = (enum drbd_io_error_p )_________p1->on_io_error;
#line 1683
  rcu_read_unlock();
#line 1684
  switch ((unsigned int )ep) {
  case 0U: ;
#line 1686
  if ((unsigned int )df == 0U || (unsigned int )df == 1U) {
#line 1687
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "__drbd_chk_io_error_");
#line 1687
    if (tmp___1 != 0) {
#line 1688
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s.\n",
              where);
    } else {

    }
#line 1689
    if ((int )mdev->state.ldv_49522.disk > 4) {
#line 1690
      __ns = drbd_read_state(mdev);
#line 1690
      __ns.ldv_40024.disk = 4U;
#line 1690
      _drbd_set_state(mdev, __ns, CS_HARD, 0);
    } else {

    }
#line 1691
    goto ldv_50794;
  } else {

  }
  case 2U: ;
  case 1U: 
#line 1716
  set_bit(12U, (unsigned long volatile   *)(& mdev->flags));
#line 1717
  if ((unsigned int )df == 0U) {
#line 1718
    set_bit(13U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1719
  if ((unsigned int )df == 3U) {
#line 1720
    set_bit(14U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1721
  if ((int )mdev->state.ldv_49522.disk > 2) {
#line 1722
    __ns___0 = drbd_read_state(mdev);
#line 1722
    __ns___0.ldv_40024.disk = 2U;
#line 1722
    _drbd_set_state(mdev, __ns___0, CS_HARD, 0);
#line 1723
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s. Detaching...\n",
            where);
  } else {

  }
#line 1726
  goto ldv_50794;
  }
  ldv_50794: ;
#line 1729
  return;
}
}
#line 1739 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_chk_io_error_(struct drbd_conf *mdev , int error , enum drbd_force_detach_flags forcedetach ,
                                        char const   *where ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 1742
  if (error != 0) {
#line 1744
    tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 1744
    flags = _raw_spin_lock_irqsave(tmp);
#line 1745
    __drbd_chk_io_error_(mdev, forcedetach, where);
#line 1746
    spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
  } else {

  }
#line 1748
  return;
}
}
#line 1785 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_md_last_sector(struct drbd_backing_dev *bdev ) 
{ 
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 1789
  rcu_read_lock();
#line 1790
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1790
  tmp = debug_lockdep_rcu_enabled();
#line 1790
  if (tmp != 0 && ! __warned) {
#line 1790
    tmp___0 = rcu_read_lock_held();
#line 1790
    if (tmp___0 == 0 && 1) {
#line 1790
      __warned = 1;
#line 1790
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1790, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1790
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1791
  rcu_read_unlock();
#line 1793
  switch (meta_dev_idx) {
  case -1: ;
  case -3: ;
#line 1796
  return ((sector_t )(bdev->md.md_offset + 7ULL));
  case -2: ;
  default: ;
#line 1799
  return ((sector_t )(bdev->md.md_offset + (u64 )bdev->md.md_size_sect));
  }
}
}
#line 2043 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void put_ldev(struct drbd_conf *mdev ) 
{ 
  int i ;
  int tmp ;

  {
#line 2045
  tmp = atomic_sub_return(1, & mdev->local_cnt);
#line 2045
  i = tmp;
#line 2051
  if (i < 0) {
#line 2051
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( i >= 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
            2051);
  } else {

  }
#line 2052
  if (i == 0) {
#line 2053
    if ((unsigned int )*((unsigned char *)mdev + 749UL) == 0U) {
#line 2055
      drbd_ldev_destroy(mdev);
    } else {

    }
#line 2056
    if ((unsigned int )*((unsigned char *)mdev + 749UL) == 4U) {
#line 2058
      drbd_go_diskless(mdev);
    } else {

    }
#line 2059
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 2061
  return;
}
}
#line 2064 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int _get_ldev_if_state(struct drbd_conf *mdev , enum drbd_disk_state mins ) 
{ 
  int io_allowed ;

  {
#line 2069
  if ((unsigned int )*((unsigned char *)mdev + 749UL) == 0U) {
#line 2070
    return (0);
  } else {

  }
#line 2072
  atomic_inc(& mdev->local_cnt);
#line 2073
  io_allowed = (unsigned int )mdev->state.ldv_49522.disk >= (unsigned int )mins;
#line 2074
  if (io_allowed == 0) {
#line 2075
    put_ldev(mdev);
  } else {

  }
#line 2076
  return (io_allowed);
}
}
#line 2317 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_md_flush(struct drbd_conf *mdev ) 
{ 
  int r ;
  int tmp ;

  {
#line 2321
  if ((unsigned long )mdev->ldev == (unsigned long )((struct drbd_backing_dev *)0)) {
#line 2322
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "mdev->ldev == NULL in drbd_md_flush\n");
#line 2323
    return;
  } else {

  }
#line 2326
  tmp = constant_test_bit(7U, (unsigned long const volatile   *)(& mdev->flags));
#line 2326
  if (tmp != 0) {
#line 2327
    return;
  } else {

  }
#line 2329
  r = blkdev_issue_flush((mdev->ldev)->md_bdev, 16U, 0);
#line 2330
  if (r != 0) {
#line 2331
    set_bit(7U, (unsigned long volatile   *)(& mdev->flags));
#line 2332
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "meta data flush failed with status %d, disabling md-flushes\n",
            r);
  } else {

  }
#line 2334
  return;
}
}
#line 203 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void __bm_print_lock_info(struct drbd_conf *mdev , char const   *func ) 
{ 
  struct drbd_bitmap *b ;
  int tmp ;
  char *tmp___0 ;
  struct task_struct *tmp___1 ;
  char *tmp___2 ;

  {
#line 205
  b = mdev->bitmap;
#line 206
  tmp = ___ratelimit(& drbd_ratelimit_state, "__bm_print_lock_info");
#line 206
  if (tmp == 0) {
#line 207
    return;
  } else {

  }
#line 208
  tmp___0 = drbd_task_to_thread_name(mdev->tconn, b->bm_task);
#line 208
  tmp___1 = get_current();
#line 208
  tmp___2 = drbd_task_to_thread_name(mdev->tconn, tmp___1);
#line 208
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "FIXME %s in %s, bitmap locked for \'%s\' by %s\n",
          tmp___2, func, (unsigned long )b->bm_why != (unsigned long )((char *)0) ? b->bm_why : (char *)"?",
          tmp___0);
#line 212
  return;
}
}
#line 214 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_lock(struct drbd_conf *mdev , char *why , enum bm_flag flags ) 
{ 
  struct drbd_bitmap *b ;
  int trylock_failed ;
  int tmp ;
  char *tmp___0 ;
  struct task_struct *tmp___1 ;
  char *tmp___2 ;

  {
#line 216
  b = mdev->bitmap;
#line 219
  if ((unsigned long )b == (unsigned long )((struct drbd_bitmap *)0)) {
#line 220
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "FIXME no bitmap in drbd_bm_lock!?\n");
#line 221
    return;
  } else {

  }
#line 224
  tmp = ldv_mutex_trylock_12(& b->bm_change);
#line 224
  trylock_failed = tmp == 0;
#line 226
  if (trylock_failed != 0) {
#line 227
    tmp___0 = drbd_task_to_thread_name(mdev->tconn, b->bm_task);
#line 227
    tmp___1 = get_current();
#line 227
    tmp___2 = drbd_task_to_thread_name(mdev->tconn, tmp___1);
#line 227
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s going to \'%s\' but bitmap already locked for \'%s\' by %s\n",
             tmp___2, why, (unsigned long )b->bm_why != (unsigned long )((char *)0) ? b->bm_why : (char *)"?",
             tmp___0);
#line 231
    ldv_mutex_lock_13(& b->bm_change);
  } else {

  }
#line 233
  if (((unsigned int )b->bm_flags & 15U) != 0U) {
#line 234
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "FIXME bitmap already locked in bm_lock\n");
  } else {

  }
#line 235
  b->bm_flags = (enum bm_flag )((unsigned int )b->bm_flags | ((unsigned int )flags & 15U));
#line 237
  b->bm_why = why;
#line 238
  b->bm_task = get_current();
#line 239
  return;
}
}
#line 241 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_unlock(struct drbd_conf *mdev ) 
{ 
  struct drbd_bitmap *b ;

  {
#line 243
  b = mdev->bitmap;
#line 244
  if ((unsigned long )b == (unsigned long )((struct drbd_bitmap *)0)) {
#line 245
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "FIXME no bitmap in drbd_bm_unlock!?\n");
#line 246
    return;
  } else {

  }
#line 249
  if (((unsigned int )(mdev->bitmap)->bm_flags & 15U) == 0U) {
#line 250
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "FIXME bitmap not locked in bm_unlock\n");
  } else {

  }
#line 252
  b->bm_flags = (enum bm_flag )((unsigned int )b->bm_flags & 4294967280U);
#line 253
  b->bm_why = 0;
#line 254
  b->bm_task = 0;
#line 255
  ldv_mutex_unlock_14(& b->bm_change);
#line 256
  return;
}
}
#line 287 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_store_page_idx(struct page *page , unsigned long idx ) 
{ 
  long tmp ;

  {
#line 289
  tmp = __builtin_expect((idx & 0xffffffffff000000UL) != 0UL, 0L);
#line 289
  if (tmp != 0L) {
#line 289
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"),
                         "i" (289), "i" (12UL));
    ldv_51111: ;
#line 289
    goto ldv_51111;
  } else {

  }
#line 290
  page->ldv_14746.private = idx;
#line 291
  return;
}
}
#line 293 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned long bm_page_to_idx(struct page *page ) 
{ 


  {
#line 295
  return (page->ldv_14746.private & 16777215UL);
}
}
#line 301 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_page_lock_io(struct drbd_conf *mdev , int page_nr ) 
{ 
  struct drbd_bitmap *b ;
  void *addr ;
  int tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;

  {
#line 303
  b = mdev->bitmap;
#line 304
  addr = (void *)(& (*(b->bm_pages + (unsigned long )page_nr))->ldv_14746.private);
#line 305
  tmp = test_and_set_bit(31, (unsigned long volatile   *)addr);
#line 305
  if (tmp == 0) {
#line 305
    goto ldv_51121;
  } else {

  }
#line 305
  tmp___0 = get_current();
#line 305
  __wait.flags = 0U;
#line 305
  __wait.private = (void *)tmp___0;
#line 305
  __wait.func = & autoremove_wake_function;
#line 305
  __wait.task_list.next = & __wait.task_list;
#line 305
  __wait.task_list.prev = & __wait.task_list;
  ldv_51124: 
#line 305
  prepare_to_wait(& b->bm_io_wait, & __wait, 2);
#line 305
  tmp___1 = test_and_set_bit(31, (unsigned long volatile   *)addr);
#line 305
  if (tmp___1 == 0) {
#line 305
    goto ldv_51123;
  } else {

  }
#line 305
  schedule();
#line 305
  goto ldv_51124;
  ldv_51123: 
#line 305
  finish_wait(& b->bm_io_wait, & __wait);
  ldv_51121: ;
#line 308
  return;
}
}
#line 308 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_page_unlock_io(struct drbd_conf *mdev , int page_nr ) 
{ 
  struct drbd_bitmap *b ;
  void *addr ;

  {
#line 310
  b = mdev->bitmap;
#line 311
  addr = (void *)(& (*(b->bm_pages + (unsigned long )page_nr))->ldv_14746.private);
#line 312
  clear_bit_unlock(31U, (unsigned long volatile   *)addr);
#line 313
  __wake_up(& (mdev->bitmap)->bm_io_wait, 3U, 1, 0);
#line 314
  return;
}
}
#line 318 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_set_page_unchanged(struct page *page ) 
{ 


  {
#line 321
  clear_bit(29, (unsigned long volatile   *)(& page->ldv_14746.private));
#line 322
  clear_bit(28, (unsigned long volatile   *)(& page->ldv_14746.private));
#line 323
  return;
}
}
#line 325 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_set_page_need_writeout(struct page *page ) 
{ 


  {
#line 327
  set_bit(29U, (unsigned long volatile   *)(& page->ldv_14746.private));
#line 328
  return;
}
}
#line 339 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_mark_for_writeout(struct drbd_conf *mdev , int page_nr ) 
{ 
  struct page *page ;

  {
#line 342
  if ((size_t )page_nr >= (mdev->bitmap)->bm_number_of_pages) {
#line 343
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "BAD: page_nr: %u, number_of_pages: %u\n",
             page_nr, (int )(mdev->bitmap)->bm_number_of_pages);
#line 345
    return;
  } else {

  }
#line 347
  page = *((mdev->bitmap)->bm_pages + (unsigned long )page_nr);
#line 348
  set_bit(27U, (unsigned long volatile   *)(& page->ldv_14746.private));
#line 349
  return;
}
}
#line 351 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static int bm_test_page_unchanged(struct page *page ) 
{ 
  unsigned long const volatile   *addr ;

  {
#line 353
  addr = (unsigned long const volatile   *)(& page->ldv_14746.private);
#line 354
  return (((unsigned long )*addr & 805306368UL) == 0UL);
}
}
#line 357 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_set_page_io_err(struct page *page ) 
{ 


  {
#line 359
  set_bit(30U, (unsigned long volatile   *)(& page->ldv_14746.private));
#line 360
  return;
}
}
#line 362 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_clear_page_io_err(struct page *page ) 
{ 


  {
#line 364
  clear_bit(30, (unsigned long volatile   *)(& page->ldv_14746.private));
#line 365
  return;
}
}
#line 367 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_set_page_lazy_writeout(struct page *page ) 
{ 


  {
#line 369
  set_bit(28U, (unsigned long volatile   *)(& page->ldv_14746.private));
#line 370
  return;
}
}
#line 372 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static int bm_test_page_lazy_writeout(struct page *page ) 
{ 
  int tmp ;

  {
#line 374
  tmp = constant_test_bit(28U, (unsigned long const volatile   *)(& page->ldv_14746.private));
#line 374
  return (tmp);
}
}
#line 378 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned int bm_word_to_page_idx(struct drbd_bitmap *b , unsigned long long_nr ) 
{ 
  unsigned int page_nr ;
  long tmp ;

  {
#line 381
  page_nr = (unsigned int )(long_nr >> 9);
#line 382
  tmp = __builtin_expect((size_t )page_nr >= b->bm_number_of_pages, 0L);
#line 382
  if (tmp != 0L) {
#line 382
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"),
                         "i" (382), "i" (12UL));
    ldv_51163: ;
#line 382
    goto ldv_51163;
  } else {

  }
#line 383
  return (page_nr);
}
}
#line 386 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned int bm_bit_to_page_idx(struct drbd_bitmap *b , u64 bitnr ) 
{ 
  unsigned int page_nr ;
  long tmp ;

  {
#line 389
  page_nr = (unsigned int )(bitnr >> 15);
#line 390
  tmp = __builtin_expect((size_t )page_nr >= b->bm_number_of_pages, 0L);
#line 390
  if (tmp != 0L) {
#line 390
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"),
                         "i" (390), "i" (12UL));
    ldv_51169: ;
#line 390
    goto ldv_51169;
  } else {

  }
#line 391
  return (page_nr);
}
}
#line 394 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned long *__bm_map_pidx(struct drbd_bitmap *b , unsigned int idx ) 
{ 
  struct page *page ;
  void *tmp ;

  {
#line 396
  page = *(b->bm_pages + (unsigned long )idx);
#line 397
  tmp = kmap_atomic(page);
#line 397
  return ((unsigned long *)tmp);
}
}
#line 400 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned long *bm_map_pidx(struct drbd_bitmap *b , unsigned int idx ) 
{ 
  unsigned long *tmp ;

  {
#line 402
  tmp = __bm_map_pidx(b, idx);
#line 402
  return (tmp);
}
}
#line 405 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void __bm_unmap(unsigned long *p_addr ) 
{ 


  {
#line 407
  __kunmap_atomic((void *)p_addr);
#line 408
  return;
}
}
#line 410 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_unmap(unsigned long *p_addr ) 
{ 


  {
#line 412
  return;
}
}
#line 435 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_free_pages(struct page **pages , unsigned long number ) 
{ 
  unsigned long i ;

  {
#line 438
  if ((unsigned long )pages == (unsigned long )((struct page **)0)) {
#line 439
    return;
  } else {

  }
#line 441
  i = 0UL;
#line 441
  goto ldv_51192;
  ldv_51191: ;
#line 442
  if ((unsigned long )*(pages + i) == (unsigned long )((struct page *)0)) {
#line 443
    printk("\tdrbd: bm_free_pages tried to free a NULL pointer; i=%lu n=%lu\n", i,
           number);
#line 446
    goto ldv_51190;
  } else {

  }
#line 448
  __free_pages(*(pages + i), 0U);
#line 449
  *(pages + i) = 0;
  ldv_51190: 
#line 441
  i = i + 1UL;
  ldv_51192: ;
#line 441
  if (i < number) {
#line 442
    goto ldv_51191;
  } else {

  }

#line 446
  return;
}
}
#line 453 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_vk_free(void *ptr , int v ) 
{ 


  {
#line 455
  if (v != 0) {
#line 456
    vfree((void const   *)ptr);
  } else {
#line 458
    kfree((void const   *)ptr);
  }
#line 459
  return;
}
}
#line 464 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static struct page **bm_realloc_pages(struct drbd_bitmap *b , unsigned long want ) 
{ 
  struct page **old_pages ;
  struct page **new_pages ;
  struct page *page ;
  unsigned int i ;
  unsigned int bytes ;
  unsigned int vmalloced ;
  unsigned long have ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  void *tmp___3 ;
  pgprot_t __constr_expr_0 ;
  void *tmp___4 ;

  {
#line 466
  old_pages = b->bm_pages;
#line 468
  vmalloced = 0U;
#line 469
  have = b->bm_number_of_pages;
#line 471
  tmp = __builtin_expect(have == 0UL, 0L);
#line 471
  if (tmp != 0L) {
#line 471
    tmp___0 = __builtin_expect((unsigned long )old_pages != (unsigned long )((struct page **)0),
                               0L);
#line 471
    if (tmp___0 != 0L) {
#line 471
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"),
                           "i" (471), "i" (12UL));
      ldv_51209: ;
#line 471
      goto ldv_51209;
    } else {

    }
  } else {

  }
#line 472
  tmp___1 = __builtin_expect(have != 0UL, 0L);
#line 472
  if (tmp___1 != 0L) {
#line 472
    tmp___2 = __builtin_expect((unsigned long )old_pages == (unsigned long )((struct page **)0),
                               0L);
#line 472
    if (tmp___2 != 0L) {
#line 472
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"),
                           "i" (472), "i" (12UL));
      ldv_51210: ;
#line 472
      goto ldv_51210;
    } else {

    }
  } else {

  }
#line 474
  if (have == want) {
#line 475
    return (old_pages);
  } else {

  }
#line 482
  bytes = (unsigned int )want * 8U;
#line 483
  tmp___3 = kzalloc((size_t )bytes, 16U);
#line 483
  new_pages = (struct page **)tmp___3;
#line 484
  if ((unsigned long )new_pages == (unsigned long )((struct page **)0)) {
#line 485
    __constr_expr_0.pgprot = 0x8000000000000163UL;
#line 485
    tmp___4 = __vmalloc((unsigned long )bytes, 32786U, __constr_expr_0);
#line 485
    new_pages = (struct page **)tmp___4;
#line 488
    if ((unsigned long )new_pages == (unsigned long )((struct page **)0)) {
#line 489
      return (0);
    } else {

    }
#line 490
    vmalloced = 1U;
  } else {

  }
#line 493
  if (want >= have) {
#line 494
    i = 0U;
#line 494
    goto ldv_51213;
    ldv_51212: 
#line 495
    *(new_pages + (unsigned long )i) = *(old_pages + (unsigned long )i);
#line 494
    i = i + 1U;
    ldv_51213: ;
#line 494
    if ((unsigned long )i < have) {
#line 495
      goto ldv_51212;
    } else {

    }

#line 496
    goto ldv_51216;
    ldv_51215: 
#line 497
    page = alloc_pages(18U, 0U);
#line 498
    if ((unsigned long )page == (unsigned long )((struct page *)0)) {
#line 499
      bm_free_pages(new_pages + have, (unsigned long )i - have);
#line 500
      bm_vk_free((void *)new_pages, (int )vmalloced);
#line 501
      return (0);
    } else {

    }
#line 505
    bm_store_page_idx(page, (unsigned long )i);
#line 506
    *(new_pages + (unsigned long )i) = page;
#line 496
    i = i + 1U;
    ldv_51216: ;
#line 496
    if ((unsigned long )i < want) {
#line 497
      goto ldv_51215;
    } else {

    }

  } else {
#line 509
    i = 0U;
#line 509
    goto ldv_51219;
    ldv_51218: 
#line 510
    *(new_pages + (unsigned long )i) = *(old_pages + (unsigned long )i);
#line 509
    i = i + 1U;
    ldv_51219: ;
#line 509
    if ((unsigned long )i < want) {
#line 510
      goto ldv_51218;
    } else {

    }

  }
#line 516
  if (vmalloced != 0U) {
#line 517
    b->bm_flags = (enum bm_flag )((unsigned int )b->bm_flags | 65536U);
  } else {
#line 519
    b->bm_flags = (enum bm_flag )((unsigned int )b->bm_flags & 4294901759U);
  }
#line 521
  return (new_pages);
}
}
#line 528 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_init(struct drbd_conf *mdev ) 
{ 
  struct drbd_bitmap *b ;
  int __ret_warn_on ;
  long tmp ;
  void *tmp___0 ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;

  {
#line 530
  b = mdev->bitmap;
#line 531
  __ret_warn_on = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 531
  tmp = __builtin_expect(__ret_warn_on != 0, 0L);
#line 531
  if (tmp != 0L) {
#line 531
    warn_slowpath_null("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
                       531);
  } else {

  }
#line 531
  __builtin_expect(__ret_warn_on != 0, 0L);
#line 532
  tmp___0 = kzalloc(400UL, 208U);
#line 532
  b = (struct drbd_bitmap *)tmp___0;
#line 533
  if ((unsigned long )b == (unsigned long )((struct drbd_bitmap *)0)) {
#line 534
    return (-12);
  } else {

  }
#line 535
  spinlock_check(& b->bm_lock);
#line 535
  __raw_spin_lock_init(& b->bm_lock.ldv_5957.rlock, "&(&b->bm_lock)->rlock", & __key);
#line 536
  __mutex_init(& b->bm_change, "&b->bm_change", & __key___0);
#line 537
  __init_waitqueue_head(& b->bm_io_wait, "&b->bm_io_wait", & __key___1);
#line 539
  mdev->bitmap = b;
#line 541
  return (0);
}
}
#line 544 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
sector_t drbd_bm_capacity(struct drbd_conf *mdev ) 
{ 
  bool _bool ;
  int tmp ;

  {
#line 546
  _bool = (unsigned long )mdev->bitmap != (unsigned long )((struct drbd_bitmap *)0);
#line 546
  if (! _bool) {
#line 546
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"mdev->bitmap", "drbd_bm_capacity");
  } else {

  }
#line 546
  if (_bool) {
#line 546
    tmp = 0;
  } else {
#line 546
    tmp = 1;
  }
#line 546
  if (tmp) {
#line 547
    return (0UL);
  } else {

  }
#line 548
  return ((mdev->bitmap)->bm_dev_capacity);
}
}
#line 553 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_cleanup(struct drbd_conf *mdev ) 
{ 
  bool _bool ;
  int tmp ;

  {
#line 555
  _bool = (unsigned long )mdev->bitmap != (unsigned long )((struct drbd_bitmap *)0);
#line 555
  if (! _bool) {
#line 555
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"mdev->bitmap", "drbd_bm_cleanup");
  } else {

  }
#line 555
  if (_bool) {
#line 555
    tmp = 0;
  } else {
#line 555
    tmp = 1;
  }
#line 555
  if (tmp) {
#line 556
    return;
  } else {

  }
#line 557
  bm_free_pages((mdev->bitmap)->bm_pages, (mdev->bitmap)->bm_number_of_pages);
#line 558
  bm_vk_free((void *)(mdev->bitmap)->bm_pages, (int )(mdev->bitmap)->bm_flags & 65536);
#line 559
  kfree((void const   *)mdev->bitmap);
#line 560
  mdev->bitmap = 0;
#line 561
  return;
}
}
#line 571 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static int bm_clear_surplus(struct drbd_bitmap *b ) 
{ 
  unsigned long mask ;
  unsigned long *p_addr ;
  unsigned long *bm ;
  int tmp ;
  int cleared ;
  unsigned long tmp___0 ;

  {
#line 576
  cleared = 0;
#line 579
  tmp = (int )b->bm_bits & 32767;
#line 581
  mask = (1UL << (tmp & 63)) - 1UL;
#line 584
  mask = mask;
#line 586
  p_addr = bm_map_pidx(b, (unsigned int )b->bm_number_of_pages - 1U);
#line 587
  bm = p_addr + (unsigned long )(tmp / 64);
#line 588
  if (mask != 0UL) {
#line 593
    tmp___0 = hweight_long(*bm & ~ mask);
#line 593
    cleared = (int )tmp___0;
#line 594
    *bm = *bm & mask;
#line 595
    bm = bm + 1;
  } else {

  }
#line 604
  bm_unmap(p_addr);
#line 605
  return (cleared);
}
}
#line 608 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_set_surplus(struct drbd_bitmap *b ) 
{ 
  unsigned long mask ;
  unsigned long *p_addr ;
  unsigned long *bm ;
  int tmp ;

  {
#line 615
  tmp = (int )b->bm_bits & 32767;
#line 617
  mask = (1UL << (tmp & 63)) - 1UL;
#line 620
  mask = mask;
#line 622
  p_addr = bm_map_pidx(b, (unsigned int )b->bm_number_of_pages - 1U);
#line 623
  bm = p_addr + (unsigned long )(tmp / 64);
#line 624
  if (mask != 0UL) {
#line 629
    *bm = *bm | ~ mask;
#line 630
    bm = bm + 1;
  } else {

  }
#line 638
  bm_unmap(p_addr);
#line 639
  return;
}
}
#line 643 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned long bm_count_bits(struct drbd_bitmap *b ) 
{ 
  unsigned long *p_addr ;
  unsigned long bits ;
  unsigned long mask ;
  int idx ;
  int i ;
  int last_word ;
  unsigned long tmp ;
  unsigned long tmp___0 ;
  unsigned long tmp___1 ;

  {
#line 646
  bits = 0UL;
#line 647
  mask = (1UL << ((int )b->bm_bits & 63)) - 1UL;
#line 651
  idx = 0;
#line 651
  goto ldv_51271;
  ldv_51270: 
#line 652
  p_addr = __bm_map_pidx(b, (unsigned int )idx);
#line 653
  i = 0;
#line 653
  goto ldv_51267;
  ldv_51266: 
#line 654
  tmp = hweight_long(*(p_addr + (unsigned long )i));
#line 654
  bits = tmp + bits;
#line 653
  i = i + 1;
  ldv_51267: ;
#line 653
  if ((unsigned int )i <= 511U) {
#line 654
    goto ldv_51266;
  } else {

  }
#line 655
  __bm_unmap(p_addr);
#line 656
  __might_sleep("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
                656, 0);
#line 656
  _cond_resched();
#line 651
  idx = idx + 1;
  ldv_51271: ;
#line 651
  if ((size_t )idx < b->bm_number_of_pages - 1UL) {
#line 652
    goto ldv_51270;
  } else {

  }
#line 659
  last_word = (int )(((b->bm_bits - 1UL) & 32767UL) >> 6);
#line 660
  p_addr = __bm_map_pidx(b, (unsigned int )idx);
#line 661
  i = 0;
#line 661
  goto ldv_51274;
  ldv_51273: 
#line 662
  tmp___0 = hweight_long(*(p_addr + (unsigned long )i));
#line 662
  bits = tmp___0 + bits;
#line 661
  i = i + 1;
  ldv_51274: ;
#line 661
  if (i < last_word) {
#line 662
    goto ldv_51273;
  } else {

  }
#line 663
  *(p_addr + (unsigned long )last_word) = (unsigned long )((unsigned long long )*(p_addr + (unsigned long )last_word) & (unsigned long long )mask);
#line 664
  tmp___1 = hweight_long(*(p_addr + (unsigned long )last_word));
#line 664
  bits = tmp___1 + bits;
#line 668
  __bm_unmap(p_addr);
#line 669
  return (bits);
}
}
#line 673 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_memset(struct drbd_bitmap *b , size_t offset , int c , size_t len ) 
{ 
  unsigned long *p_addr ;
  unsigned long *bm ;
  unsigned int idx ;
  size_t do_now ;
  size_t end ;
  size_t __min1 ;
  size_t __min2 ;

  {
#line 679
  end = offset + len;
#line 681
  if (b->bm_words < end) {
#line 682
    printk("\tdrbd: bm_memset end > bm_words\n");
#line 683
    return;
  } else {

  }
#line 686
  goto ldv_51291;
  ldv_51290: 
#line 687
  __min1 = (offset + 512UL) & 0xfffffffffffffe00UL;
#line 687
  __min2 = end;
#line 687
  do_now = (__min1 < __min2 ? __min1 : __min2) - offset;
#line 688
  idx = bm_word_to_page_idx(b, offset);
#line 689
  p_addr = bm_map_pidx(b, idx);
#line 690
  bm = p_addr + (offset & 511UL);
#line 691
  if ((unsigned long )(bm + do_now) > (unsigned long )(p_addr + 512UL)) {
#line 692
    printk("\tdrbd: BUG BUG BUG! p_addr:%p bm:%p do_now:%d\n", p_addr, bm, (int )do_now);
  } else {
#line 695
    memset((void *)bm, c, do_now * 8UL);
  }
#line 696
  bm_unmap(p_addr);
#line 697
  bm_set_page_need_writeout(*(b->bm_pages + (unsigned long )idx));
#line 698
  offset = offset + do_now;
  ldv_51291: ;
#line 686
  if (offset < end) {
#line 687
    goto ldv_51290;
  } else {

  }

#line 691
  return;
}
}
#line 710 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_resize(struct drbd_conf *mdev , sector_t capacity , int set_new_bits ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long bits ;
  unsigned long words ;
  unsigned long owords ;
  unsigned long obits ;
  unsigned long want ;
  unsigned long have ;
  unsigned long onpages ;
  struct page **npages ;
  struct page **opages ;
  int err ;
  int growing ;
  int opages_vmalloced ;
  bool _bool ;
  int tmp ;
  unsigned long tmp___0 ;
  unsigned long tmp___1 ;
  size_t tmp___2 ;
  sector_t tmp___3 ;
  u64 bits_on_disk ;
  int tmp___4 ;
  int tmp___5 ;

  {
#line 712
  b = mdev->bitmap;
#line 715
  opages = 0;
#line 716
  err = 0;
#line 719
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 719
  if (! _bool) {
#line 719
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_resize");
  } else {

  }
#line 719
  if (_bool) {
#line 719
    tmp = 0;
  } else {
#line 719
    tmp = 1;
  }
#line 719
  if (tmp) {
#line 720
    return (-12);
  } else {

  }
#line 722
  drbd_bm_lock(mdev, (char *)"resize", BM_LOCKED_MASK);
#line 724
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_bm_resize called with capacity == %llu\n",
            (unsigned long long )capacity);
#line 727
  if (b->bm_dev_capacity == capacity) {
#line 728
    goto out;
  } else {

  }
#line 730
  opages_vmalloced = (int )b->bm_flags & 65536;
#line 732
  if (capacity == 0UL) {
#line 733
    spin_lock_irq(& b->bm_lock);
#line 734
    opages = b->bm_pages;
#line 735
    onpages = b->bm_number_of_pages;
#line 736
    owords = b->bm_words;
#line 737
    b->bm_pages = 0;
#line 738
    tmp___3 = 0UL;
#line 738
    b->bm_dev_capacity = tmp___3;
#line 738
    tmp___2 = tmp___3;
#line 738
    b->bm_words = tmp___2;
#line 738
    tmp___1 = tmp___2;
#line 738
    b->bm_bits = tmp___1;
#line 738
    tmp___0 = tmp___1;
#line 738
    b->bm_set = tmp___0;
#line 738
    b->bm_number_of_pages = tmp___0;
#line 743
    spin_unlock_irq(& b->bm_lock);
#line 744
    bm_free_pages(opages, onpages);
#line 745
    bm_vk_free((void *)opages, opages_vmalloced);
#line 746
    goto out;
  } else {

  }
#line 748
  bits = (capacity + 7UL) >> 3;
#line 755
  words = (bits + 63UL) >> 6;
#line 757
  tmp___4 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 757
  if (tmp___4 != 0) {
#line 758
    bits_on_disk = ((unsigned long long )(mdev->ldev)->md.md_size_sect - 72ULL) << 12;
#line 759
    put_ldev(mdev);
#line 760
    if ((unsigned long long )bits > bits_on_disk) {
#line 761
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bits = %lu\n",
                bits);
#line 762
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bits_on_disk = %llu\n",
                bits_on_disk);
#line 763
      err = -28;
#line 764
      goto out;
    } else {

    }
  } else {

  }
#line 768
  want = (words * 8UL + 4095UL) >> 12;
#line 769
  have = b->bm_number_of_pages;
#line 770
  if (want == have) {
#line 771
    if ((unsigned long )b->bm_pages == (unsigned long )((struct page **)0)) {
#line 771
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( b->bm_pages != NULL ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
              771);
    } else {

    }
#line 772
    npages = b->bm_pages;
  } else {
#line 774
    tmp___5 = drbd_insert_fault(mdev, 7U);
#line 774
    if (tmp___5 != 0) {
#line 775
      npages = 0;
    } else {
#line 777
      npages = bm_realloc_pages(b, want);
    }
  }
#line 780
  if ((unsigned long )npages == (unsigned long )((struct page **)0)) {
#line 781
    err = -12;
#line 782
    goto out;
  } else {

  }
#line 785
  spin_lock_irq(& b->bm_lock);
#line 786
  opages = b->bm_pages;
#line 787
  owords = b->bm_words;
#line 788
  obits = b->bm_bits;
#line 790
  growing = bits > obits;
#line 791
  if (((unsigned long )opages != (unsigned long )((struct page **)0) && growing != 0) && set_new_bits != 0) {
#line 792
    bm_set_surplus(b);
  } else {

  }
#line 794
  b->bm_pages = npages;
#line 795
  b->bm_number_of_pages = want;
#line 796
  b->bm_bits = bits;
#line 797
  b->bm_words = words;
#line 798
  b->bm_dev_capacity = capacity;
#line 800
  if (growing != 0) {
#line 801
    if (set_new_bits != 0) {
#line 802
      bm_memset(b, owords, 255, words - owords);
#line 803
      b->bm_set = b->bm_set + (bits - obits);
    } else {
#line 805
      bm_memset(b, owords, 0, words - owords);
    }
  } else {

  }
#line 809
  if (want < have) {
#line 811
    bm_free_pages(opages + want, have - want);
  } else {

  }
#line 814
  bm_clear_surplus(b);
#line 816
  spin_unlock_irq(& b->bm_lock);
#line 817
  if ((unsigned long )opages != (unsigned long )npages) {
#line 818
    bm_vk_free((void *)opages, opages_vmalloced);
  } else {

  }
#line 819
  if (growing == 0) {
#line 820
    b->bm_set = bm_count_bits(b);
  } else {

  }
#line 821
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "resync bitmap: bits=%lu words=%lu pages=%lu\n",
            bits, words, want);
  out: 
#line 824
  drbd_bm_unlock(mdev);
#line 825
  return (err);
}
}
#line 836 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
unsigned long _drbd_bm_total_weight(struct drbd_conf *mdev ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long s ;
  unsigned long flags ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  raw_spinlock_t *tmp___1 ;

  {
#line 838
  b = mdev->bitmap;
#line 842
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 842
  if (! _bool) {
#line 842
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "_drbd_bm_total_weight");
  } else {

  }
#line 842
  if (_bool) {
#line 842
    tmp = 0;
  } else {
#line 842
    tmp = 1;
  }
#line 842
  if (tmp) {
#line 843
    return (0UL);
  } else {

  }
#line 844
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 844
  if (! _bool___0) {
#line 844
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "_drbd_bm_total_weight");
  } else {

  }
#line 844
  if (_bool___0) {
#line 844
    tmp___0 = 0;
  } else {
#line 844
    tmp___0 = 1;
  }
#line 844
  if (tmp___0) {
#line 845
    return (0UL);
  } else {

  }
#line 847
  tmp___1 = spinlock_check(& b->bm_lock);
#line 847
  flags = _raw_spin_lock_irqsave(tmp___1);
#line 848
  s = b->bm_set;
#line 849
  spin_unlock_irqrestore(& b->bm_lock, flags);
#line 851
  return (s);
}
}
#line 854 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
unsigned long drbd_bm_total_weight(struct drbd_conf *mdev ) 
{ 
  unsigned long s ;
  int tmp ;

  {
#line 858
  tmp = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 858
  if (tmp == 0) {
#line 859
    return (0UL);
  } else {

  }
#line 860
  s = _drbd_bm_total_weight(mdev);
#line 861
  put_ldev(mdev);
#line 862
  return (s);
}
}
#line 865 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
size_t drbd_bm_words(struct drbd_conf *mdev ) 
{ 
  struct drbd_bitmap *b ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;

  {
#line 867
  b = mdev->bitmap;
#line 868
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 868
  if (! _bool) {
#line 868
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_words");
  } else {

  }
#line 868
  if (_bool) {
#line 868
    tmp = 0;
  } else {
#line 868
    tmp = 1;
  }
#line 868
  if (tmp) {
#line 869
    return (0UL);
  } else {

  }
#line 870
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 870
  if (! _bool___0) {
#line 870
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_words");
  } else {

  }
#line 870
  if (_bool___0) {
#line 870
    tmp___0 = 0;
  } else {
#line 870
    tmp___0 = 1;
  }
#line 870
  if (tmp___0) {
#line 871
    return (0UL);
  } else {

  }
#line 873
  return (b->bm_words);
}
}
#line 876 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
unsigned long drbd_bm_bits(struct drbd_conf *mdev ) 
{ 
  struct drbd_bitmap *b ;
  bool _bool ;
  int tmp ;

  {
#line 878
  b = mdev->bitmap;
#line 879
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 879
  if (! _bool) {
#line 879
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_bits");
  } else {

  }
#line 879
  if (_bool) {
#line 879
    tmp = 0;
  } else {
#line 879
    tmp = 1;
  }
#line 879
  if (tmp) {
#line 880
    return (0UL);
  } else {

  }
#line 882
  return (b->bm_bits);
}
}
#line 890 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_merge_lel(struct drbd_conf *mdev , size_t offset , size_t number , unsigned long *buffer ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long *p_addr ;
  unsigned long *bm ;
  unsigned long word ;
  unsigned long bits ;
  unsigned int idx ;
  size_t end ;
  size_t do_now ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  int __ret_warn_on ;
  long tmp___1 ;
  int __ret_warn_on___0 ;
  long tmp___2 ;
  size_t __min1 ;
  size_t __min2 ;
  unsigned long *tmp___3 ;
  unsigned long *tmp___4 ;
  unsigned long tmp___5 ;
  size_t tmp___6 ;
  int tmp___7 ;

  {
#line 893
  b = mdev->bitmap;
#line 899
  end = offset + number;
#line 901
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 901
  if (! _bool) {
#line 901
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_merge_lel");
  } else {

  }
#line 901
  if (_bool) {
#line 901
    tmp = 0;
  } else {
#line 901
    tmp = 1;
  }
#line 901
  if (tmp) {
#line 902
    return;
  } else {

  }
#line 903
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 903
  if (! _bool___0) {
#line 903
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_merge_lel");
  } else {

  }
#line 903
  if (_bool___0) {
#line 903
    tmp___0 = 0;
  } else {
#line 903
    tmp___0 = 1;
  }
#line 903
  if (tmp___0) {
#line 904
    return;
  } else {

  }
#line 905
  if (number == 0UL) {
#line 906
    return;
  } else {

  }
#line 907
  __ret_warn_on = b->bm_words <= offset;
#line 907
  tmp___1 = __builtin_expect(__ret_warn_on != 0, 0L);
#line 907
  if (tmp___1 != 0L) {
#line 907
    warn_slowpath_null("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
                       907);
  } else {

  }
#line 907
  __builtin_expect(__ret_warn_on != 0, 0L);
#line 908
  __ret_warn_on___0 = b->bm_words < end;
#line 908
  tmp___2 = __builtin_expect(__ret_warn_on___0 != 0, 0L);
#line 908
  if (tmp___2 != 0L) {
#line 908
    warn_slowpath_null("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
                       908);
  } else {

  }
#line 908
  __builtin_expect(__ret_warn_on___0 != 0, 0L);
#line 910
  spin_lock_irq(& b->bm_lock);
#line 911
  goto ldv_51380;
  ldv_51379: 
#line 912
  __min1 = (offset + 512UL) & 0xfffffffffffffe00UL;
#line 912
  __min2 = end;
#line 912
  do_now = (__min1 < __min2 ? __min1 : __min2) - offset;
#line 913
  idx = bm_word_to_page_idx(b, offset);
#line 914
  p_addr = bm_map_pidx(b, idx);
#line 915
  bm = p_addr + (offset & 511UL);
#line 916
  offset = offset + do_now;
#line 917
  goto ldv_51377;
  ldv_51376: 
#line 918
  bits = hweight_long(*bm);
#line 919
  tmp___3 = buffer;
#line 919
  buffer = buffer + 1;
#line 919
  word = *bm | *tmp___3;
#line 920
  tmp___4 = bm;
#line 920
  bm = bm + 1;
#line 920
  *tmp___4 = word;
#line 921
  tmp___5 = hweight_long(word);
#line 921
  b->bm_set = b->bm_set + (tmp___5 - bits);
  ldv_51377: 
#line 917
  tmp___6 = do_now;
#line 917
  do_now = do_now - (size_t )1;
#line 917
  if (tmp___6 != 0UL) {
#line 918
    goto ldv_51376;
  } else {

  }
#line 923
  bm_unmap(p_addr);
#line 924
  bm_set_page_need_writeout(*(b->bm_pages + (unsigned long )idx));
  ldv_51380: ;
#line 911
  if (offset < end) {
#line 912
    goto ldv_51379;
  } else {

  }

#line 931
  if (b->bm_words == end) {
#line 932
    tmp___7 = bm_clear_surplus(b);
#line 932
    b->bm_set = b->bm_set - (unsigned long )tmp___7;
  } else {

  }
#line 933
  spin_unlock_irq(& b->bm_lock);
#line 934
  return;
}
}
#line 939 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_get_lel(struct drbd_conf *mdev , size_t offset , size_t number , unsigned long *buffer ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long *p_addr ;
  unsigned long *bm ;
  size_t end ;
  size_t do_now ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  size_t __min1 ;
  size_t __min2 ;
  unsigned int tmp___1 ;
  unsigned long *tmp___2 ;
  unsigned long *tmp___3 ;
  size_t tmp___4 ;

  {
#line 942
  b = mdev->bitmap;
#line 946
  end = offset + number;
#line 948
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 948
  if (! _bool) {
#line 948
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_get_lel");
  } else {

  }
#line 948
  if (_bool) {
#line 948
    tmp = 0;
  } else {
#line 948
    tmp = 1;
  }
#line 948
  if (tmp) {
#line 949
    return;
  } else {

  }
#line 950
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 950
  if (! _bool___0) {
#line 950
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_get_lel");
  } else {

  }
#line 950
  if (_bool___0) {
#line 950
    tmp___0 = 0;
  } else {
#line 950
    tmp___0 = 1;
  }
#line 950
  if (tmp___0) {
#line 951
    return;
  } else {

  }
#line 953
  spin_lock_irq(& b->bm_lock);
#line 954
  if ((b->bm_words <= offset || b->bm_words < end) || number == 0UL) {
#line 957
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "offset=%lu number=%lu bm_words=%lu\n",
            offset, number, b->bm_words);
  } else {
#line 962
    goto ldv_51405;
    ldv_51404: 
#line 963
    __min1 = (offset + 512UL) & 0xfffffffffffffe00UL;
#line 963
    __min2 = end;
#line 963
    do_now = (__min1 < __min2 ? __min1 : __min2) - offset;
#line 964
    tmp___1 = bm_word_to_page_idx(b, offset);
#line 964
    p_addr = bm_map_pidx(b, tmp___1);
#line 965
    bm = p_addr + (offset & 511UL);
#line 966
    offset = offset + do_now;
#line 967
    goto ldv_51402;
    ldv_51401: 
#line 968
    tmp___2 = buffer;
#line 968
    buffer = buffer + 1;
#line 968
    tmp___3 = bm;
#line 968
    bm = bm + 1;
#line 968
    *tmp___2 = *tmp___3;
    ldv_51402: 
#line 967
    tmp___4 = do_now;
#line 967
    do_now = do_now - (size_t )1;
#line 967
    if (tmp___4 != 0UL) {
#line 968
      goto ldv_51401;
    } else {

    }
#line 969
    bm_unmap(p_addr);
    ldv_51405: ;
#line 962
    if (offset < end) {
#line 963
      goto ldv_51404;
    } else {

    }

  }
#line 972
  spin_unlock_irq(& b->bm_lock);
#line 973
  return;
}
}
#line 976 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_set_all(struct drbd_conf *mdev ) 
{ 
  struct drbd_bitmap *b ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;

  {
#line 978
  b = mdev->bitmap;
#line 979
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 979
  if (! _bool) {
#line 979
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_set_all");
  } else {

  }
#line 979
  if (_bool) {
#line 979
    tmp = 0;
  } else {
#line 979
    tmp = 1;
  }
#line 979
  if (tmp) {
#line 980
    return;
  } else {

  }
#line 981
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 981
  if (! _bool___0) {
#line 981
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_set_all");
  } else {

  }
#line 981
  if (_bool___0) {
#line 981
    tmp___0 = 0;
  } else {
#line 981
    tmp___0 = 1;
  }
#line 981
  if (tmp___0) {
#line 982
    return;
  } else {

  }
#line 984
  spin_lock_irq(& b->bm_lock);
#line 985
  bm_memset(b, 0UL, 255, b->bm_words);
#line 986
  bm_clear_surplus(b);
#line 987
  b->bm_set = b->bm_bits;
#line 988
  spin_unlock_irq(& b->bm_lock);
#line 989
  return;
}
}
#line 992 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void drbd_bm_clear_all(struct drbd_conf *mdev ) 
{ 
  struct drbd_bitmap *b ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;

  {
#line 994
  b = mdev->bitmap;
#line 995
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 995
  if (! _bool) {
#line 995
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_clear_all");
  } else {

  }
#line 995
  if (_bool) {
#line 995
    tmp = 0;
  } else {
#line 995
    tmp = 1;
  }
#line 995
  if (tmp) {
#line 996
    return;
  } else {

  }
#line 997
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 997
  if (! _bool___0) {
#line 997
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_clear_all");
  } else {

  }
#line 997
  if (_bool___0) {
#line 997
    tmp___0 = 0;
  } else {
#line 997
    tmp___0 = 1;
  }
#line 997
  if (tmp___0) {
#line 998
    return;
  } else {

  }
#line 1000
  spin_lock_irq(& b->bm_lock);
#line 1001
  bm_memset(b, 0UL, 0, b->bm_words);
#line 1002
  b->bm_set = 0UL;
#line 1003
  spin_unlock_irq(& b->bm_lock);
#line 1004
  return;
}
}
#line 1018 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_aio_ctx_destroy(struct kref *kref ) 
{ 
  struct bm_aio_ctx *ctx ;
  struct kref  const  *__mptr ;

  {
#line 1020
  __mptr = (struct kref  const  *)kref;
#line 1020
  ctx = (struct bm_aio_ctx *)__mptr + 0xffffffffffffffe8UL;
#line 1022
  put_ldev(ctx->mdev);
#line 1023
  kfree((void const   *)ctx);
#line 1024
  return;
}
}
#line 1027 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_async_io_complete(struct bio *bio , int error ) 
{ 
  struct bm_aio_ctx *ctx ;
  struct drbd_conf *mdev ;
  struct drbd_bitmap *b ;
  unsigned int idx ;
  unsigned long tmp ;
  int uptodate ;
  int tmp___0 ;
  int tmp___1 ;
  struct _ddebug descriptor ;
  long tmp___2 ;
  int tmp___3 ;

  {
#line 1029
  ctx = (struct bm_aio_ctx *)bio->bi_private;
#line 1030
  mdev = ctx->mdev;
#line 1031
  b = mdev->bitmap;
#line 1032
  tmp = bm_page_to_idx((bio->bi_io_vec)->bv_page);
#line 1032
  idx = (unsigned int )tmp;
#line 1033
  uptodate = (int )bio->bi_flags & 1;
#line 1040
  if (error == 0 && uptodate == 0) {
#line 1041
    error = -5;
  } else {

  }
#line 1043
  if ((ctx->flags & 1U) == 0U) {
#line 1043
    tmp___0 = bm_test_page_unchanged(*(b->bm_pages + (unsigned long )idx));
#line 1043
    if (tmp___0 == 0) {
#line 1045
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bitmap page idx %u changed during IO!\n",
               idx);
    } else {

    }
  } else {

  }
#line 1047
  if (error != 0) {
#line 1050
    ctx->error = error;
#line 1051
    bm_set_page_io_err(*(b->bm_pages + (unsigned long )idx));
#line 1054
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "bm_async_io_complete");
#line 1054
    if (tmp___1 != 0) {
#line 1055
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "IO ERROR %d on bitmap page idx %u\n",
              error, idx);
    } else {

    }
  } else {
#line 1058
    bm_clear_page_io_err(*(b->bm_pages + (unsigned long )idx));
#line 1059
    descriptor.modname = "drbd";
#line 1059
    descriptor.function = "bm_async_io_complete";
#line 1059
    descriptor.filename = "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared";
#line 1059
    descriptor.format = "bitmap page idx %u completed\n";
#line 1059
    descriptor.lineno = 1059U;
#line 1059
    descriptor.flags = 0U;
#line 1059
    tmp___2 = __builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1059
    if (tmp___2 != 0L) {
#line 1059
      __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (mdev->vdisk)->part0.__dev),
                        "bitmap page idx %u completed\n", idx);
    } else {

    }
  }
#line 1062
  bm_page_unlock_io(mdev, (int )idx);
#line 1064
  if ((int )ctx->flags & 1) {
#line 1065
    mempool_free((void *)(bio->bi_io_vec)->bv_page, drbd_md_io_page_pool);
  } else {

  }
#line 1067
  bio_put(bio);
#line 1069
  tmp___3 = atomic_dec_and_test(& ctx->in_flight);
#line 1069
  if (tmp___3 != 0) {
#line 1070
    ctx->done = 1U;
#line 1071
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
#line 1072
    kref_put(& ctx->kref, & bm_aio_ctx_destroy);
  } else {

  }
#line 1074
  return;
}
}
#line 1076 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static void bm_page_io_async(struct bm_aio_ctx *ctx , int page_nr , int rw ) 
{ 
  struct bio *bio ;
  struct bio *tmp ;
  struct drbd_conf *mdev ;
  struct drbd_bitmap *b ;
  struct page *page ;
  unsigned int len ;
  sector_t on_disk_sector ;
  unsigned int __min1 ;
  unsigned int __min2 ;
  sector_t tmp___0 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
#line 1078
  tmp = bio_alloc_drbd(16U);
#line 1078
  bio = tmp;
#line 1079
  mdev = ctx->mdev;
#line 1080
  b = mdev->bitmap;
#line 1084
  on_disk_sector = (sector_t )((mdev->ldev)->md.md_offset + (u64 )(mdev->ldev)->md.bm_offset);
#line 1086
  on_disk_sector = ((unsigned long )page_nr << 3) + on_disk_sector;
#line 1091
  __min1 = 4096U;
#line 1091
  tmp___0 = drbd_md_last_sector(mdev->ldev);
#line 1091
  __min2 = (((unsigned int )tmp___0 - (unsigned int )on_disk_sector) + 1U) << 9U;
#line 1091
  len = __min1 < __min2 ? __min1 : __min2;
#line 1095
  bm_page_lock_io(mdev, page_nr);
#line 1098
  bm_set_page_unchanged(*(b->bm_pages + (unsigned long )page_nr));
#line 1100
  if ((int )ctx->flags & 1) {
#line 1101
    tmp___1 = mempool_alloc(drbd_md_io_page_pool, 18U);
#line 1101
    page = (struct page *)tmp___1;
#line 1102
    copy_highpage(page, *(b->bm_pages + (unsigned long )page_nr));
#line 1103
    bm_store_page_idx(page, (unsigned long )page_nr);
  } else {
#line 1105
    page = *(b->bm_pages + (unsigned long )page_nr);
  }
#line 1106
  bio->bi_bdev = (mdev->ldev)->md_bdev;
#line 1107
  bio->bi_sector = on_disk_sector;
#line 1110
  bio_add_page(bio, page, len, 0U);
#line 1111
  bio->bi_private = (void *)ctx;
#line 1112
  bio->bi_end_io = & bm_async_io_complete;
#line 1114
  tmp___2 = drbd_insert_fault(mdev, rw & 1 ? 0U : 1U);
#line 1114
  if (tmp___2 != 0) {
#line 1115
    bio->bi_rw = bio->bi_rw | (unsigned long )rw;
#line 1116
    bio_endio(bio, -5);
  } else {
#line 1118
    submit_bio(rw, bio);
#line 1121
    atomic_add((int )(len >> 9), & mdev->rs_sect_ev);
  }
#line 1123
  return;
}
}
#line 1128 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static int bm_rw(struct drbd_conf *mdev , int rw , unsigned int flags , unsigned int lazy_writeout_upper_idx ) 
{ 
  struct bm_aio_ctx *ctx ;
  struct drbd_bitmap *b ;
  int num_pages ;
  int i ;
  int count ;
  unsigned long now ;
  char ppb[10U] ;
  int err ;
  void *tmp ;
  struct bm_aio_ctx __constr_expr_0 ;
  int tmp___0 ;
  int __ret_warn_on ;
  long tmp___1 ;
  int tmp___2 ;
  struct _ddebug descriptor ;
  long tmp___3 ;
  int tmp___4 ;
  struct _ddebug descriptor___0 ;
  long tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  char *tmp___9 ;

  {
#line 1131
  b = mdev->bitmap;
#line 1132
  count = 0;
#line 1135
  err = 0;
#line 1146
  tmp = kmalloc(32UL, 16U);
#line 1146
  ctx = (struct bm_aio_ctx *)tmp;
#line 1147
  if ((unsigned long )ctx == (unsigned long )((struct bm_aio_ctx *)0)) {
#line 1148
    return (-12);
  } else {

  }
#line 1150
  __constr_expr_0.mdev = mdev;
#line 1150
  __constr_expr_0.in_flight.counter = 1;
#line 1150
  __constr_expr_0.done = 0U;
#line 1150
  __constr_expr_0.flags = flags;
#line 1150
  __constr_expr_0.error = 0;
#line 1150
  __constr_expr_0.kref.refcount.counter = 2;
#line 1150
  *ctx = __constr_expr_0;
#line 1159
  tmp___0 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 1159
  if (tmp___0 == 0) {
#line 1160
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED: get_ldev_if_state() == 1 in bm_rw()\n");
#line 1161
    kfree((void const   *)ctx);
#line 1162
    return (-19);
  } else {

  }
#line 1165
  if (ctx->flags == 0U) {
#line 1166
    __ret_warn_on = ((unsigned int )b->bm_flags & 15U) == 0U;
#line 1166
    tmp___1 = __builtin_expect(__ret_warn_on != 0, 0L);
#line 1166
    if (tmp___1 != 0L) {
#line 1166
      warn_slowpath_null("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
                         1166);
    } else {

    }
#line 1166
    __builtin_expect(__ret_warn_on != 0, 0L);
  } else {

  }
#line 1168
  num_pages = (int )b->bm_number_of_pages;
#line 1170
  now = jiffies;
#line 1173
  i = 0;
#line 1173
  goto ldv_51487;
  ldv_51486: ;
#line 1175
  if (lazy_writeout_upper_idx != 0U && (unsigned int )i == lazy_writeout_upper_idx) {
#line 1176
    goto ldv_51480;
  } else {

  }
#line 1177
  if (rw & 1) {
#line 1178
    if ((flags & 2U) != 0U) {
#line 1178
      tmp___2 = test_and_clear_bit(27, (unsigned long volatile   *)(& (*(b->bm_pages + (unsigned long )i))->ldv_14746.private));
#line 1178
      if (tmp___2 == 0) {
#line 1181
        goto ldv_51481;
      } else {

      }
    } else {

    }
#line 1183
    if ((flags & 4U) == 0U) {
#line 1183
      tmp___4 = bm_test_page_unchanged(*(b->bm_pages + (unsigned long )i));
#line 1183
      if (tmp___4 != 0) {
#line 1185
        descriptor.modname = "drbd";
#line 1185
        descriptor.function = "bm_rw";
#line 1185
        descriptor.filename = "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared";
#line 1185
        descriptor.format = "skipped bm write for idx %u\n";
#line 1185
        descriptor.lineno = 1185U;
#line 1185
        descriptor.flags = 0U;
#line 1185
        tmp___3 = __builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1185
        if (tmp___3 != 0L) {
#line 1185
          __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (mdev->vdisk)->part0.__dev),
                            "skipped bm write for idx %u\n", i);
        } else {

        }
#line 1186
        goto ldv_51481;
      } else {

      }
    } else {

    }
#line 1190
    if (lazy_writeout_upper_idx != 0U) {
#line 1190
      tmp___6 = bm_test_page_lazy_writeout(*(b->bm_pages + (unsigned long )i));
#line 1190
      if (tmp___6 == 0) {
#line 1192
        descriptor___0.modname = "drbd";
#line 1192
        descriptor___0.function = "bm_rw";
#line 1192
        descriptor___0.filename = "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared";
#line 1192
        descriptor___0.format = "skipped bm lazy write for idx %u\n";
#line 1192
        descriptor___0.lineno = 1192U;
#line 1192
        descriptor___0.flags = 0U;
#line 1192
        tmp___5 = __builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 1192
        if (tmp___5 != 0L) {
#line 1192
          __dynamic_dev_dbg(& descriptor___0, (struct device  const  *)(& (mdev->vdisk)->part0.__dev),
                            "skipped bm lazy write for idx %u\n", i);
        } else {

        }
#line 1193
        goto ldv_51481;
      } else {

      }
    } else {

    }
  } else {

  }
#line 1196
  atomic_inc(& ctx->in_flight);
#line 1197
  bm_page_io_async(ctx, i, rw);
#line 1198
  count = count + 1;
#line 1199
  __might_sleep("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
                1199, 0);
#line 1199
  _cond_resched();
  ldv_51481: 
#line 1173
  i = i + 1;
  ldv_51487: ;
#line 1173
  if (i < num_pages) {
#line 1174
    goto ldv_51486;
  } else {

  }
  ldv_51480: 
#line 1210
  tmp___7 = atomic_dec_and_test(& ctx->in_flight);
#line 1210
  if (tmp___7 == 0) {
#line 1211
    wait_until_done_or_force_detached(mdev, mdev->ldev, & ctx->done);
  } else {
#line 1213
    kref_put(& ctx->kref, & bm_aio_ctx_destroy);
  }
#line 1216
  if (flags == 0U) {
#line 1217
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bitmap %s of %u pages took %lu jiffies\n",
              rw == 1 ? (char *)"WRITE" : (char *)"READ", count, (unsigned long )jiffies - now);
  } else {

  }
#line 1221
  if (ctx->error != 0) {
#line 1222
    dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "we had at least one MD IO ERROR during bitmap IO\n");
#line 1223
    drbd_chk_io_error_(mdev, 1, DRBD_META_IO_ERROR, "bm_rw");
#line 1224
    err = -5;
  } else {

  }
#line 1227
  tmp___8 = atomic_read((atomic_t const   *)(& ctx->in_flight));
#line 1227
  if (tmp___8 != 0) {
#line 1228
    err = -5;
  } else {

  }
#line 1230
  now = jiffies;
#line 1231
  if (rw == 1) {
#line 1232
    drbd_md_flush(mdev);
  } else {
#line 1234
    b->bm_set = bm_count_bits(b);
#line 1235
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "recounting of set bits took additional %lu jiffies\n",
              (unsigned long )jiffies - now);
  }
#line 1238
  now = b->bm_set;
#line 1240
  if (flags == 0U) {
#line 1241
    tmp___9 = ppsize((char *)(& ppb), (unsigned long long )(now << 2));
#line 1241
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s (%lu bits) marked out-of-sync by on disk bit-map.\n",
              tmp___9, now);
  } else {

  }
#line 1244
  kref_put(& ctx->kref, & bm_aio_ctx_destroy);
#line 1245
  return (err);
}
}
#line 1252 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_read(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 1254
  tmp = bm_rw(mdev, 0, 0U, 0U);
#line 1254
  return (tmp);
}
}
#line 1263 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_write(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 1265
  tmp = bm_rw(mdev, 1, 0U, 0U);
#line 1265
  return (tmp);
}
}
#line 1274 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_write_all(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 1276
  tmp = bm_rw(mdev, 1, 4U, 0U);
#line 1276
  return (tmp);
}
}
#line 1284 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_write_lazy(struct drbd_conf *mdev , unsigned int upper_idx ) 
{ 
  int tmp ;

  {
#line 1286
  tmp = bm_rw(mdev, 1, 1U, upper_idx);
#line 1286
  return (tmp);
}
}
#line 1300 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_write_copy_pages(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 1302
  tmp = bm_rw(mdev, 1, 1U, 0U);
#line 1302
  return (tmp);
}
}
#line 1309 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_write_hinted(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 1311
  tmp = bm_rw(mdev, 1, 3U, 0U);
#line 1311
  return (tmp);
}
}
#line 1326 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_write_page(struct drbd_conf *mdev , unsigned int idx ) 
{ 
  struct bm_aio_ctx *ctx ;
  int err ;
  struct _ddebug descriptor ;
  long tmp ;
  int tmp___0 ;
  void *tmp___1 ;
  struct bm_aio_ctx __constr_expr_0 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 1331
  tmp___0 = bm_test_page_unchanged(*((mdev->bitmap)->bm_pages + (unsigned long )idx));
#line 1331
  if (tmp___0 != 0) {
#line 1332
    descriptor.modname = "drbd";
#line 1332
    descriptor.function = "drbd_bm_write_page";
#line 1332
    descriptor.filename = "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared";
#line 1332
    descriptor.format = "skipped bm page write for idx %u\n";
#line 1332
    descriptor.lineno = 1332U;
#line 1332
    descriptor.flags = 0U;
#line 1332
    tmp = __builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1332
    if (tmp != 0L) {
#line 1332
      __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (mdev->vdisk)->part0.__dev),
                        "skipped bm page write for idx %u\n", idx);
    } else {

    }
#line 1333
    return (0);
  } else {

  }
#line 1336
  tmp___1 = kmalloc(32UL, 16U);
#line 1336
  ctx = (struct bm_aio_ctx *)tmp___1;
#line 1337
  if ((unsigned long )ctx == (unsigned long )((struct bm_aio_ctx *)0)) {
#line 1338
    return (-12);
  } else {

  }
#line 1340
  __constr_expr_0.mdev = mdev;
#line 1340
  __constr_expr_0.in_flight.counter = 1;
#line 1340
  __constr_expr_0.done = 0U;
#line 1340
  __constr_expr_0.flags = 1U;
#line 1340
  __constr_expr_0.error = 0;
#line 1340
  __constr_expr_0.kref.refcount.counter = 2;
#line 1340
  *ctx = __constr_expr_0;
#line 1349
  tmp___2 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 1349
  if (tmp___2 == 0) {
#line 1350
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED: get_ldev_if_state() == 1 in drbd_bm_write_page()\n");
#line 1351
    kfree((void const   *)ctx);
#line 1352
    return (-19);
  } else {

  }
#line 1355
  bm_page_io_async(ctx, (int )idx, 1041);
#line 1356
  wait_until_done_or_force_detached(mdev, mdev->ldev, & ctx->done);
#line 1358
  if (ctx->error != 0) {
#line 1359
    drbd_chk_io_error_(mdev, 1, DRBD_META_IO_ERROR, "drbd_bm_write_page");
  } else {

  }
#line 1363
  mdev->bm_writ_cnt = mdev->bm_writ_cnt + 1U;
#line 1364
  tmp___3 = atomic_read((atomic_t const   *)(& ctx->in_flight));
#line 1364
  err = tmp___3 == 0 ? ctx->error : -5;
#line 1365
  kref_put(& ctx->kref, & bm_aio_ctx_destroy);
#line 1366
  return (err);
}
}
#line 1377 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned long __bm_find_next(struct drbd_conf *mdev , unsigned long bm_fo ,
                                    int const   find_zero_bit ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long *p_addr ;
  unsigned long bit_offset ;
  unsigned int i ;
  unsigned int tmp ;
  unsigned long tmp___0 ;
  unsigned long tmp___1 ;

  {
#line 1380
  b = mdev->bitmap;
#line 1386
  if (b->bm_bits < bm_fo) {
#line 1387
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bm_fo=%lu bm_bits=%lu\n",
            bm_fo, b->bm_bits);
#line 1388
    bm_fo = 0xffffffffffffffffUL;
  } else {
#line 1390
    goto ldv_51528;
    ldv_51527: 
#line 1392
    bit_offset = bm_fo & 0xffffffffffff8000UL;
#line 1393
    tmp = bm_bit_to_page_idx(b, (u64 )bm_fo);
#line 1393
    p_addr = __bm_map_pidx(b, tmp);
#line 1395
    if ((int )find_zero_bit != 0) {
#line 1396
      tmp___0 = find_next_zero_bit_le((void const   *)p_addr, 32768UL, bm_fo & 32767UL);
#line 1396
      i = (unsigned int )tmp___0;
    } else {
#line 1399
      tmp___1 = find_next_bit_le((void const   *)p_addr, 32768UL, bm_fo & 32767UL);
#line 1399
      i = (unsigned int )tmp___1;
    }
#line 1402
    __bm_unmap(p_addr);
#line 1403
    if (i <= 32767U) {
#line 1404
      bm_fo = (unsigned long )i + bit_offset;
#line 1405
      if (b->bm_bits <= bm_fo) {
#line 1406
        goto ldv_51525;
      } else {

      }
#line 1407
      goto found;
    } else {

    }
#line 1409
    bm_fo = bit_offset + 32768UL;
    ldv_51528: ;
#line 1390
    if (b->bm_bits > bm_fo) {
#line 1391
      goto ldv_51527;
    } else {

    }
    ldv_51525: 
#line 1411
    bm_fo = 0xffffffffffffffffUL;
  }
  found: ;
#line 1414
  return (bm_fo);
}
}
#line 1417 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static unsigned long bm_find_next(struct drbd_conf *mdev , unsigned long bm_fo , int const   find_zero_bit ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long i ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;

  {
#line 1420
  b = mdev->bitmap;
#line 1421
  i = 0xffffffffffffffffUL;
#line 1423
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 1423
  if (! _bool) {
#line 1423
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "bm_find_next");
  } else {

  }
#line 1423
  if (_bool) {
#line 1423
    tmp = 0;
  } else {
#line 1423
    tmp = 1;
  }
#line 1423
  if (tmp) {
#line 1424
    return (i);
  } else {

  }
#line 1425
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 1425
  if (! _bool___0) {
#line 1425
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "bm_find_next");
  } else {

  }
#line 1425
  if (_bool___0) {
#line 1425
    tmp___0 = 0;
  } else {
#line 1425
    tmp___0 = 1;
  }
#line 1425
  if (tmp___0) {
#line 1426
    return (i);
  } else {

  }
#line 1428
  spin_lock_irq(& b->bm_lock);
#line 1429
  if (((unsigned int )b->bm_flags & 4U) != 0U) {
#line 1430
    __bm_print_lock_info(mdev, "bm_find_next");
  } else {

  }
#line 1432
  i = __bm_find_next(mdev, bm_fo, find_zero_bit);
#line 1434
  spin_unlock_irq(& b->bm_lock);
#line 1435
  return (i);
}
}
#line 1438 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
unsigned long drbd_bm_find_next(struct drbd_conf *mdev , unsigned long bm_fo ) 
{ 
  unsigned long tmp ;

  {
#line 1440
  tmp = bm_find_next(mdev, bm_fo, 0);
#line 1440
  return (tmp);
}
}
#line 1453 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
unsigned long _drbd_bm_find_next(struct drbd_conf *mdev , unsigned long bm_fo ) 
{ 
  unsigned long tmp ;

  {
#line 1456
  tmp = __bm_find_next(mdev, bm_fo, 0);
#line 1456
  return (tmp);
}
}
#line 1459 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
unsigned long _drbd_bm_find_next_zero(struct drbd_conf *mdev , unsigned long bm_fo ) 
{ 
  unsigned long tmp ;

  {
#line 1462
  tmp = __bm_find_next(mdev, bm_fo, 1);
#line 1462
  return (tmp);
}
}
#line 1471 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static int __bm_change_bits_to(struct drbd_conf *mdev , unsigned long const   s ,
                               unsigned long e , int val ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long *p_addr ;
  unsigned long bitnr ;
  unsigned int last_page_nr ;
  int c ;
  int changed_total ;
  unsigned int page_nr ;
  unsigned int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 1474
  b = mdev->bitmap;
#line 1475
  p_addr = 0;
#line 1477
  last_page_nr = 4294967295U;
#line 1478
  c = 0;
#line 1479
  changed_total = 0;
#line 1481
  if (b->bm_bits <= e) {
#line 1482
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED: bit_s=%lu bit_e=%lu bm_bits=%lu\n",
            s, e, b->bm_bits);
#line 1484
    e = b->bm_bits != 0UL ? b->bm_bits - 1UL : 0UL;
  } else {

  }
#line 1486
  bitnr = s;
#line 1486
  goto ldv_51567;
  ldv_51566: 
#line 1487
  tmp = bm_bit_to_page_idx(b, (u64 )bitnr);
#line 1487
  page_nr = tmp;
#line 1488
  if (page_nr != last_page_nr) {
#line 1489
    if ((unsigned long )p_addr != (unsigned long )((unsigned long *)0)) {
#line 1490
      __bm_unmap(p_addr);
    } else {

    }
#line 1491
    if (c < 0) {
#line 1492
      bm_set_page_lazy_writeout(*(b->bm_pages + (unsigned long )last_page_nr));
    } else
#line 1493
    if (c > 0) {
#line 1494
      bm_set_page_need_writeout(*(b->bm_pages + (unsigned long )last_page_nr));
    } else {

    }
#line 1495
    changed_total = changed_total + c;
#line 1496
    c = 0;
#line 1497
    p_addr = __bm_map_pidx(b, page_nr);
#line 1498
    last_page_nr = page_nr;
  } else {

  }
#line 1500
  if (val != 0) {
#line 1501
    tmp___0 = __test_and_set_bit_le((int )bitnr & 32767, (void *)p_addr);
#line 1501
    c = (tmp___0 == 0) + c;
  } else {
#line 1503
    tmp___1 = __test_and_clear_bit_le((int )bitnr & 32767, (void *)p_addr);
#line 1503
    c = c - (tmp___1 != 0);
  }
#line 1486
  bitnr = bitnr + 1UL;
  ldv_51567: ;
#line 1486
  if (bitnr <= e) {
#line 1487
    goto ldv_51566;
  } else {

  }

#line 1505
  if ((unsigned long )p_addr != (unsigned long )((unsigned long *)0)) {
#line 1506
    __bm_unmap(p_addr);
  } else {

  }
#line 1507
  if (c < 0) {
#line 1508
    bm_set_page_lazy_writeout(*(b->bm_pages + (unsigned long )last_page_nr));
  } else
#line 1509
  if (c > 0) {
#line 1510
    bm_set_page_need_writeout(*(b->bm_pages + (unsigned long )last_page_nr));
  } else {

  }
#line 1511
  changed_total = changed_total + c;
#line 1512
  b->bm_set = b->bm_set + (unsigned long )changed_total;
#line 1513
  return (changed_total);
}
}
#line 1520 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
static int bm_change_bits_to(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ,
                             int val ) 
{ 
  unsigned long flags ;
  struct drbd_bitmap *b ;
  int c ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  raw_spinlock_t *tmp___1 ;

  {
#line 1524
  b = mdev->bitmap;
#line 1525
  c = 0;
#line 1527
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 1527
  if (! _bool) {
#line 1527
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "bm_change_bits_to");
  } else {

  }
#line 1527
  if (_bool) {
#line 1527
    tmp = 0;
  } else {
#line 1527
    tmp = 1;
  }
#line 1527
  if (tmp) {
#line 1528
    return (1);
  } else {

  }
#line 1529
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 1529
  if (! _bool___0) {
#line 1529
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "bm_change_bits_to");
  } else {

  }
#line 1529
  if (_bool___0) {
#line 1529
    tmp___0 = 0;
  } else {
#line 1529
    tmp___0 = 1;
  }
#line 1529
  if (tmp___0) {
#line 1530
    return (0);
  } else {

  }
#line 1532
  tmp___1 = spinlock_check(& b->bm_lock);
#line 1532
  flags = _raw_spin_lock_irqsave(tmp___1);
#line 1533
  if (((val != 0 ? 2U : 1U) & (unsigned int )b->bm_flags) != 0U) {
#line 1534
    __bm_print_lock_info(mdev, "bm_change_bits_to");
  } else {

  }
#line 1536
  c = __bm_change_bits_to(mdev, s, e, val);
#line 1538
  spin_unlock_irqrestore(& b->bm_lock, flags);
#line 1539
  return (c);
}
}
#line 1543 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_set_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) 
{ 
  int tmp ;

  {
#line 1545
  tmp = bm_change_bits_to(mdev, s, e, 1);
#line 1545
  return (tmp);
}
}
#line 1549 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_clear_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) 
{ 
  int tmp ;

  {
#line 1551
  tmp = bm_change_bits_to(mdev, s, e, 0);
#line 1551
  return (- tmp);
}
}
#line 1556 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
__inline static void bm_set_full_words_within_one_page(struct drbd_bitmap *b , int page_nr ,
                                                       int first_word , int last_word ) 
{ 
  int i ;
  int bits ;
  int changed ;
  unsigned long *paddr ;
  void *tmp ;
  unsigned long tmp___0 ;

  {
#line 1561
  changed = 0;
#line 1562
  tmp = kmap_atomic(*(b->bm_pages + (unsigned long )page_nr));
#line 1562
  paddr = (unsigned long *)tmp;
#line 1563
  i = first_word;
#line 1563
  goto ldv_51607;
  ldv_51606: 
#line 1564
  tmp___0 = hweight_long(*(paddr + (unsigned long )i));
#line 1564
  bits = (int )tmp___0;
#line 1565
  *(paddr + (unsigned long )i) = 0xffffffffffffffffUL;
#line 1566
  changed = (64 - bits) + changed;
#line 1563
  i = i + 1;
  ldv_51607: ;
#line 1563
  if (i < last_word) {
#line 1564
    goto ldv_51606;
  } else {

  }
#line 1568
  __kunmap_atomic((void *)paddr);
#line 1569
  if (changed != 0) {
#line 1573
    bm_set_page_lazy_writeout(*(b->bm_pages + (unsigned long )page_nr));
#line 1574
    b->bm_set = b->bm_set + (unsigned long )changed;
  } else {

  }
#line 1576
  return;
}
}
#line 1583 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void _drbd_bm_set_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) 
{ 
  struct drbd_bitmap *b ;
  unsigned long sl ;
  unsigned long el ;
  int first_page ;
  int last_page ;
  int page_nr ;
  int first_word ;
  int last_word ;

  {
#line 1593
  b = mdev->bitmap;
#line 1594
  sl = ((unsigned long )s + 63UL) & 0xffffffffffffffc0UL;
#line 1595
  el = ((unsigned long )e + 1UL) & 0xffffffffffffffc0UL;
#line 1602
  if ((unsigned long )e - (unsigned long )s <= 192UL) {
#line 1604
    spin_lock_irq(& b->bm_lock);
#line 1605
    __bm_change_bits_to(mdev, s, e, 1);
#line 1606
    spin_unlock_irq(& b->bm_lock);
#line 1607
    return;
  } else {

  }
#line 1612
  spin_lock_irq(& b->bm_lock);
#line 1615
  if (sl != 0UL) {
#line 1616
    __bm_change_bits_to(mdev, s, sl - 1UL, 1);
  } else {

  }
#line 1618
  first_page = (int )(sl >> 15);
#line 1619
  last_page = (int )(el >> 15);
#line 1623
  first_word = (int )(sl >> 6) & 511;
#line 1624
  last_word = 512;
#line 1627
  page_nr = first_page;
#line 1627
  goto ldv_51624;
  ldv_51623: 
#line 1628
  bm_set_full_words_within_one_page(mdev->bitmap, page_nr, first_word, last_word);
#line 1629
  spin_unlock_irq(& b->bm_lock);
#line 1630
  __might_sleep("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared",
                1630, 0);
#line 1630
  _cond_resched();
#line 1631
  first_word = 0;
#line 1632
  spin_lock_irq(& b->bm_lock);
#line 1627
  page_nr = page_nr + 1;
  ldv_51624: ;
#line 1627
  if (page_nr < last_page) {
#line 1628
    goto ldv_51623;
  } else {

  }
#line 1635
  last_word = (int )(el >> 6) & 511;
#line 1643
  if (last_word != 0) {
#line 1644
    bm_set_full_words_within_one_page(mdev->bitmap, last_page, first_word, last_word);
  } else {

  }
#line 1651
  if (el <= (unsigned long )e) {
#line 1652
    __bm_change_bits_to(mdev, el, e, 1);
  } else {

  }
#line 1653
  spin_unlock_irq(& b->bm_lock);
#line 1654
  return;
}
}
#line 1663 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_test_bit(struct drbd_conf *mdev , unsigned long const   bitnr ) 
{ 
  unsigned long flags ;
  struct drbd_bitmap *b ;
  unsigned long *p_addr ;
  int i ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  raw_spinlock_t *tmp___1 ;
  unsigned int tmp___2 ;
  int tmp___3 ;

  {
#line 1666
  b = mdev->bitmap;
#line 1670
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 1670
  if (! _bool) {
#line 1670
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_test_bit");
  } else {

  }
#line 1670
  if (_bool) {
#line 1670
    tmp = 0;
  } else {
#line 1670
    tmp = 1;
  }
#line 1670
  if (tmp) {
#line 1671
    return (0);
  } else {

  }
#line 1672
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 1672
  if (! _bool___0) {
#line 1672
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_test_bit");
  } else {

  }
#line 1672
  if (_bool___0) {
#line 1672
    tmp___0 = 0;
  } else {
#line 1672
    tmp___0 = 1;
  }
#line 1672
  if (tmp___0) {
#line 1673
    return (0);
  } else {

  }
#line 1675
  tmp___1 = spinlock_check(& b->bm_lock);
#line 1675
  flags = _raw_spin_lock_irqsave(tmp___1);
#line 1676
  if (((unsigned int )b->bm_flags & 4U) != 0U) {
#line 1677
    __bm_print_lock_info(mdev, "drbd_bm_test_bit");
  } else {

  }
#line 1678
  if (b->bm_bits > (unsigned long )bitnr) {
#line 1679
    tmp___2 = bm_bit_to_page_idx(b, (u64 )bitnr);
#line 1679
    p_addr = bm_map_pidx(b, tmp___2);
#line 1680
    tmp___3 = test_bit_le((int )bitnr & 32767, (void const   *)p_addr);
#line 1680
    i = tmp___3 != 0;
#line 1681
    bm_unmap(p_addr);
  } else
#line 1682
  if (b->bm_bits == (unsigned long )bitnr) {
#line 1683
    i = -1;
  } else {
#line 1685
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bitnr=%lu > bm_bits=%lu\n",
            bitnr, b->bm_bits);
#line 1686
    i = 0;
  }
#line 1689
  spin_unlock_irqrestore(& b->bm_lock, flags);
#line 1690
  return (i);
}
}
#line 1694 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_count_bits(struct drbd_conf *mdev , unsigned long const   s , unsigned long const   e ) 
{ 
  unsigned long flags ;
  struct drbd_bitmap *b ;
  unsigned long *p_addr ;
  unsigned long bitnr ;
  unsigned int page_nr ;
  int c ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  raw_spinlock_t *tmp___1 ;
  unsigned int idx ;
  unsigned int tmp___2 ;
  int tmp___3 ;
  bool _bool___1 ;

  {
#line 1697
  b = mdev->bitmap;
#line 1698
  p_addr = 0;
#line 1700
  page_nr = 4294967295U;
#line 1701
  c = 0;
#line 1707
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 1707
  if (! _bool) {
#line 1707
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_count_bits");
  } else {

  }
#line 1707
  if (_bool) {
#line 1707
    tmp = 0;
  } else {
#line 1707
    tmp = 1;
  }
#line 1707
  if (tmp) {
#line 1708
    return (1);
  } else {

  }
#line 1709
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 1709
  if (! _bool___0) {
#line 1709
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_count_bits");
  } else {

  }
#line 1709
  if (_bool___0) {
#line 1709
    tmp___0 = 0;
  } else {
#line 1709
    tmp___0 = 1;
  }
#line 1709
  if (tmp___0) {
#line 1710
    return (1);
  } else {

  }
#line 1712
  tmp___1 = spinlock_check(& b->bm_lock);
#line 1712
  flags = _raw_spin_lock_irqsave(tmp___1);
#line 1713
  if (((unsigned int )b->bm_flags & 4U) != 0U) {
#line 1714
    __bm_print_lock_info(mdev, "drbd_bm_count_bits");
  } else {

  }
#line 1715
  bitnr = s;
#line 1715
  goto ldv_51665;
  ldv_51664: 
#line 1716
  tmp___2 = bm_bit_to_page_idx(b, (u64 )bitnr);
#line 1716
  idx = tmp___2;
#line 1717
  if (page_nr != idx) {
#line 1718
    page_nr = idx;
#line 1719
    if ((unsigned long )p_addr != (unsigned long )((unsigned long *)0)) {
#line 1720
      bm_unmap(p_addr);
    } else {

    }
#line 1721
    p_addr = bm_map_pidx(b, idx);
  } else {

  }
#line 1723
  _bool___1 = b->bm_bits > bitnr;
#line 1723
  if (! _bool___1) {
#line 1723
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"bitnr < b->bm_bits", "drbd_bm_count_bits");
  } else {

  }
#line 1723
  if ((int )_bool___1) {
#line 1724
    tmp___3 = test_bit_le((int )((unsigned int )bitnr - (page_nr << 15)), (void const   *)p_addr);
#line 1724
    c = (tmp___3 != 0) + c;
  } else {
#line 1726
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bitnr=%lu bm_bits=%lu\n",
            bitnr, b->bm_bits);
  }
#line 1715
  bitnr = bitnr + 1UL;
  ldv_51665: ;
#line 1715
  if (bitnr <= (unsigned long )e) {
#line 1716
    goto ldv_51664;
  } else {

  }

#line 1728
  if ((unsigned long )p_addr != (unsigned long )((unsigned long *)0)) {
#line 1729
    bm_unmap(p_addr);
  } else {

  }
#line 1730
  spin_unlock_irqrestore(& b->bm_lock, flags);
#line 1731
  return (c);
}
}
#line 1749 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int drbd_bm_e_weight(struct drbd_conf *mdev , unsigned long enr ) 
{ 
  struct drbd_bitmap *b ;
  int count ;
  int s ;
  int e ;
  unsigned long flags ;
  unsigned long *p_addr ;
  unsigned long *bm ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  raw_spinlock_t *tmp___1 ;
  unsigned long _min1 ;
  size_t _min2 ;
  int n ;
  unsigned int tmp___2 ;
  unsigned long *tmp___3 ;
  unsigned long tmp___4 ;
  int tmp___5 ;

  {
#line 1751
  b = mdev->bitmap;
#line 1756
  _bool = (unsigned long )b != (unsigned long )((struct drbd_bitmap *)0);
#line 1756
  if (! _bool) {
#line 1756
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b", "drbd_bm_e_weight");
  } else {

  }
#line 1756
  if (_bool) {
#line 1756
    tmp = 0;
  } else {
#line 1756
    tmp = 1;
  }
#line 1756
  if (tmp) {
#line 1757
    return (0);
  } else {

  }
#line 1758
  _bool___0 = (unsigned long )b->bm_pages != (unsigned long )((struct page **)0);
#line 1758
  if (! _bool___0) {
#line 1758
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"b->bm_pages", "drbd_bm_e_weight");
  } else {

  }
#line 1758
  if (_bool___0) {
#line 1758
    tmp___0 = 0;
  } else {
#line 1758
    tmp___0 = 1;
  }
#line 1758
  if (tmp___0) {
#line 1759
    return (0);
  } else {

  }
#line 1761
  tmp___1 = spinlock_check(& b->bm_lock);
#line 1761
  flags = _raw_spin_lock_irqsave(tmp___1);
#line 1762
  if (((unsigned int )b->bm_flags & 4U) != 0U) {
#line 1763
    __bm_print_lock_info(mdev, "drbd_bm_e_weight");
  } else {

  }
#line 1765
  s = (int )(enr << 6);
#line 1766
  _min1 = (enr + 1UL) << 6;
#line 1766
  _min2 = b->bm_words;
#line 1766
  e = (int )(_min1 < _min2 ? _min1 : _min2);
#line 1767
  count = 0;
#line 1768
  if ((size_t )s < b->bm_words) {
#line 1769
    n = e - s;
#line 1770
    tmp___2 = bm_word_to_page_idx(b, (unsigned long )s);
#line 1770
    p_addr = bm_map_pidx(b, tmp___2);
#line 1771
    bm = p_addr + ((unsigned long )s & 511UL);
#line 1772
    goto ldv_51691;
    ldv_51690: 
#line 1773
    tmp___3 = bm;
#line 1773
    bm = bm + 1;
#line 1773
    tmp___4 = hweight_long(*tmp___3);
#line 1773
    count = (int )((unsigned int )tmp___4 + (unsigned int )count);
    ldv_51691: 
#line 1772
    tmp___5 = n;
#line 1772
    n = n - 1;
#line 1772
    if (tmp___5 != 0) {
#line 1773
      goto ldv_51690;
    } else {

    }
#line 1774
    bm_unmap(p_addr);
  } else {
#line 1776
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "start offset (%d) too large in drbd_bm_e_weight\n",
            s);
  }
#line 1778
  spin_unlock_irqrestore(& b->bm_lock, flags);
#line 1779
  return (count);
}
}
#line 1782 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_lock_1(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1787
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 1789
  mutex_lock(ldv_func_arg1);
#line 1790
  return;
}
}
#line 1792 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_unlock_2(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1797
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 1799
  mutex_unlock(ldv_func_arg1);
#line 1800
  return;
}
}
#line 1802 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_lock_3(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1807
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 1809
  mutex_lock(ldv_func_arg1);
#line 1810
  return;
}
}
#line 1812 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int ldv_mutex_trylock_4(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 1817
  tmp = mutex_trylock(ldv_func_arg1);
#line 1817
  ldv_func_res = tmp;
#line 1819
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 1819
  return (tmp___0);
#line 1821
  return (ldv_func_res);
}
}
#line 1824 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_unlock_5(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1829
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 1831
  mutex_unlock(ldv_func_arg1);
#line 1832
  return;
}
}
#line 1834 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_lock_6(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1839
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1841
  mutex_lock(ldv_func_arg1);
#line 1842
  return;
}
}
#line 1844 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_unlock_7(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1849
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1851
  mutex_unlock(ldv_func_arg1);
#line 1852
  return;
}
}
#line 1854 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_lock_8(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1859
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1861
  mutex_lock(ldv_func_arg1);
#line 1862
  return;
}
}
#line 1864 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_unlock_9(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1869
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1871
  mutex_unlock(ldv_func_arg1);
#line 1872
  return;
}
}
#line 1874 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_lock_10(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1879
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1881
  mutex_lock(ldv_func_arg1);
#line 1882
  return;
}
}
#line 1884 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_unlock_11(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1889
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1891
  mutex_unlock(ldv_func_arg1);
#line 1892
  return;
}
}
#line 1894 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
int ldv_mutex_trylock_12(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 1899
  tmp = mutex_trylock(ldv_func_arg1);
#line 1899
  ldv_func_res = tmp;
#line 1901
  tmp___0 = ldv_mutex_trylock_bm_change_of_drbd_bitmap(ldv_func_arg1);
#line 1901
  return (tmp___0);
#line 1903
  return (ldv_func_res);
}
}
#line 1906 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_lock_13(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1911
  ldv_mutex_lock_bm_change_of_drbd_bitmap(ldv_func_arg1);
#line 1913
  mutex_lock(ldv_func_arg1);
#line 1914
  return;
}
}
#line 1916 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_bitmap.c.prepared"
void ldv_mutex_unlock_14(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1921
  ldv_mutex_unlock_bm_change_of_drbd_bitmap(ldv_func_arg1);
#line 1923
  mutex_unlock(ldv_func_arg1);
#line 1924
  return;
}
}
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_36(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_30(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_32(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_34(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_37(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_39(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_lock_29(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_31(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_33(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_35(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_38(struct mutex *ldv_func_arg1 ) ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info___0(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6318;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6318;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6318;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6318;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6318: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock___0(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info___0();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock___0(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info___0();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock___0(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock___0();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock___0(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock___0();
#line 763
  return;
}
}
#line 26 "include/linux/export.h"
extern struct module __this_module ;
#line 465 "include/linux/module.h"
extern bool try_module_get(struct module * ) ;
#line 467
extern void module_put(struct module * ) ;
#line 278 "include/linux/proc_fs.h"
__inline static struct proc_inode *PROC_I(struct inode  const  *inode ) 
{ 
  struct inode  const  *__mptr ;

  {
#line 280
  __mptr = inode;
#line 280
  return ((struct proc_inode *)__mptr + 0xffffffffffffffc0UL);
}
}
#line 283 "include/linux/proc_fs.h"
__inline static struct proc_dir_entry *PDE(struct inode  const  *inode ) 
{ 
  struct proc_inode *tmp ;

  {
#line 285
  tmp = PROC_I(inode);
#line 285
  return (tmp->pde);
}
}
#line 84 "include/linux/seq_file.h"
extern ssize_t seq_read(struct file * , char * , size_t  , loff_t * ) ;
#line 85
extern loff_t seq_lseek(struct file * , loff_t  , int  ) ;
#line 92
extern int seq_printf(struct seq_file * , char const   *  , ...) ;
#line 125
extern int single_open(struct file * , int (*)(struct seq_file * , void * ) , void * ) ;
#line 126
extern int single_release(struct inode * , struct file * ) ;
#line 110 "include/linux/idr.h"
extern void *idr_get_next(struct idr * , int * ) ;
#line 54 "include/linux/drbd.h"
char const   *drbd_buildtag(void) ;
#line 326
char const   *drbd_conn_str(enum drbd_conns s ) ;
#line 327
char const   *drbd_role_str(enum drbd_role s ) ;
#line 328
char const   *drbd_disk_str(enum drbd_disk_state s ) ;
#line 275 "include/linux/backing-dev.h"
__inline static int bdi_congested(struct backing_dev_info *bdi , int bdi_bits ) 
{ 
  int tmp ;

  {
#line 277
  if ((unsigned long )bdi->congested_fn != (unsigned long )((congested_fn *)0)) {
#line 278
    tmp = (*(bdi->congested_fn))(bdi->congested_data, bdi_bits);
#line 278
    return (tmp);
  } else {

  }
#line 279
  return ((int )((unsigned int )bdi->state & (unsigned int )bdi_bits));
}
}
#line 292 "include/linux/backing-dev.h"
__inline static int bdi_rw_congested(struct backing_dev_info *bdi ) 
{ 
  int tmp ;

  {
#line 294
  tmp = bdi_congested(bdi, 12);
#line 294
  return (tmp);
}
}
#line 266 "include/linux/lru_cache.h"
extern size_t lc_seq_printf_stats(struct seq_file * , struct lru_cache * ) ;
#line 268
extern void lc_seq_dump_details(struct seq_file * , struct lru_cache * , char * ,
                                void (*)(struct seq_file * , struct lc_element * ) ) ;
#line 167 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct idr minors ;
#line 1418
int proc_details ;
#line 1573 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct proc_dir_entry *drbd_proc  ;
#line 1574
struct file_operations  const  drbd_proc_fops ;
#line 2083 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_get_syncer_progress(struct drbd_conf *mdev , unsigned long *bits_left ,
                                              unsigned int *per_mil_done ) 
{ 
  unsigned long tmp ;
  char const   *tmp___0 ;
  unsigned int shift ;
  unsigned long left ;
  unsigned long total ;
  unsigned long tmp___1 ;

  {
#line 2094
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 288U || (unsigned int )*((unsigned short *)mdev + 374UL) == 304U) {
#line 2095
    *bits_left = mdev->ov_left;
  } else {
#line 2097
    tmp = drbd_bm_total_weight(mdev);
#line 2097
    *bits_left = tmp - mdev->rs_failed;
  }
#line 2100
  if (*bits_left > mdev->rs_total) {
#line 2106
    __asm__  volatile   ("": : : "memory");
#line 2107
    tmp___0 = drbd_conn_str((enum drbd_conns )mdev->state.ldv_49522.conn);
#line 2107
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "cs:%s rs_left=%lu > rs_total=%lu (rs_failed %lu)\n",
             tmp___0, *bits_left, mdev->rs_total, mdev->rs_failed);
#line 2110
    *per_mil_done = 0U;
  } else {
#line 2121
    shift = mdev->rs_total > 4294967295UL ? 16U : 10U;
#line 2122
    left = *bits_left >> (int )shift;
#line 2123
    total = (mdev->rs_total >> (int )shift) + 1UL;
#line 2124
    tmp___1 = 1000UL - (left * 1000UL) / total;
#line 2125
    *per_mil_done = (unsigned int )tmp___1;
  }
#line 2127
  return;
}
}
#line 2216 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_suspended(struct drbd_conf *mdev ) 
{ 
  struct drbd_tconn *tconn ;

  {
#line 2218
  tconn = mdev->tconn;
#line 2220
  return (((unsigned int )*((unsigned char *)tconn + 132UL) != 0U || (unsigned int )*((unsigned char *)tconn + 132UL) != 0U) || (unsigned int )*((unsigned char *)tconn + 132UL) != 0U);
}
}
#line 2294 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static bool verify_can_do_stop_sector(struct drbd_conf *mdev ) 
{ 


  {
#line 2296
  return ((bool )((mdev->tconn)->agreed_pro_version > 96 && (mdev->tconn)->agreed_pro_version != 100));
}
}
#line 124 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
static int drbd_proc_open(struct inode *inode , struct file *file ) ;
#line 125
static int drbd_proc_release(struct inode *inode , struct file *file ) ;
#line 129 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
struct file_operations  const  drbd_proc_fops  = 
#line 129
     {& __this_module, & seq_lseek, & seq_read, 0, 0, 0, 0, 0, 0, 0, 0, & drbd_proc_open,
    0, & drbd_proc_release, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
#line 137 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void seq_printf_with_thousands_grouping(struct seq_file *seq , long v ) 
{ 
  long tmp ;
  long tmp___0 ;

  {
#line 140
  tmp___0 = __builtin_expect(v > 999999L, 0L);
#line 140
  if (tmp___0 != 0L) {
#line 142
    seq_printf(seq, "%ld,", v / 1000000L);
#line 143
    v = v % 1000000L;
#line 144
    seq_printf(seq, "%03ld,%03ld", v / 1000L, v % 1000L);
  } else {
#line 145
    tmp = __builtin_expect(v > 999L, 1L);
#line 145
    if (tmp != 0L) {
#line 146
      seq_printf(seq, "%ld,%03ld", v / 1000L, v % 1000L);
    } else {
#line 148
      seq_printf(seq, "%ld", v);
    }
  }
#line 149
  return;
}
}
#line 157 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
static void drbd_syncer_progress(struct drbd_conf *mdev , struct seq_file *seq ) 
{ 
  unsigned long db ;
  unsigned long dt ;
  unsigned long dbdt ;
  unsigned long rt ;
  unsigned long rs_left ;
  unsigned int res ;
  int i ;
  int x ;
  int y ;
  int stalled ;
  unsigned long bm_bits ;
  unsigned long tmp ;
  unsigned long bit_pos ;
  unsigned long long stop_sector ;
  bool tmp___0 ;

  {
#line 162
  stalled = 0;
#line 164
  drbd_get_syncer_progress(mdev, & rs_left, & res);
#line 166
  x = (int )(res / 50U);
#line 167
  y = 20 - x;
#line 168
  seq_printf(seq, "\t[");
#line 169
  i = 1;
#line 169
  goto ldv_51946;
  ldv_51945: 
#line 170
  seq_printf(seq, "=");
#line 169
  i = i + 1;
  ldv_51946: ;
#line 169
  if (i < x) {
#line 170
    goto ldv_51945;
  } else {

  }
#line 171
  seq_printf(seq, ">");
#line 172
  i = 0;
#line 172
  goto ldv_51949;
  ldv_51948: 
#line 173
  seq_printf(seq, ".");
#line 172
  i = i + 1;
  ldv_51949: ;
#line 172
  if (i < y) {
#line 173
    goto ldv_51948;
  } else {

  }
#line 174
  seq_printf(seq, "] ");
#line 176
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 288U || (unsigned int )*((unsigned short *)mdev + 374UL) == 304U) {
#line 177
    seq_printf(seq, "verified:");
  } else {
#line 179
    seq_printf(seq, "sync\'ed:");
  }
#line 180
  seq_printf(seq, "%3u.%u%% ", res / 10U, res % 10U);
#line 183
  if (mdev->rs_total > 1048576UL) {
#line 184
    seq_printf(seq, "(%lu/%lu)M", (rs_left >> 10) << 2, (mdev->rs_total >> 10) << 2);
  } else {
#line 188
    seq_printf(seq, "(%lu/%lu)K\n\t", rs_left << 2, mdev->rs_total << 2);
  }
#line 205
  i = (mdev->rs_last_mark + 2) % 8;
#line 206
  dt = ((unsigned long )jiffies - mdev->rs_mark_time[i]) / 250UL;
#line 207
  if (dt > 6000UL) {
#line 208
    stalled = 1;
  } else {

  }
#line 210
  if (dt == 0UL) {
#line 211
    dt = dt + 1UL;
  } else {

  }
#line 212
  db = mdev->rs_mark_left[i] - rs_left;
#line 213
  rt = ((rs_left / (db / 100UL + 1UL)) * dt) / 100UL;
#line 215
  seq_printf(seq, "finish: %lu:%02lu:%02lu", rt / 3600UL, (rt % 3600UL) / 60UL, rt % 60UL);
#line 218
  dbdt = db / dt << 2;
#line 219
  seq_printf(seq, " speed: ");
#line 220
  seq_printf_with_thousands_grouping(seq, (long )dbdt);
#line 221
  seq_printf(seq, " (");
#line 223
  if (proc_details > 0) {
#line 225
    i = (mdev->rs_last_mark + 7) % 8;
#line 226
    dt = ((unsigned long )jiffies - mdev->rs_mark_time[i]) / 250UL;
#line 227
    if (dt == 0UL) {
#line 228
      dt = dt + 1UL;
    } else {

    }
#line 229
    db = mdev->rs_mark_left[i] - rs_left;
#line 230
    dbdt = db / dt << 2;
#line 231
    seq_printf_with_thousands_grouping(seq, (long )dbdt);
#line 232
    seq_printf(seq, " -- ");
  } else {

  }
#line 238
  dt = (((unsigned long )jiffies - mdev->rs_start) - mdev->rs_paused) / 250UL;
#line 239
  if (dt == 0UL) {
#line 240
    dt = 1UL;
  } else {

  }
#line 241
  db = mdev->rs_total - rs_left;
#line 242
  dbdt = db / dt << 2;
#line 243
  seq_printf_with_thousands_grouping(seq, (long )dbdt);
#line 244
  seq_printf(seq, ")");
#line 246
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 272U || (unsigned int )*((unsigned short *)mdev + 374UL) == 288U) {
#line 248
    seq_printf(seq, " want: ");
#line 249
    seq_printf_with_thousands_grouping(seq, (long )mdev->c_sync_rate);
  } else {

  }
#line 251
  seq_printf(seq, " K/sec%s\n", stalled != 0 ? (char *)" (stalled)" : (char *)"");
#line 253
  if (proc_details > 0) {
#line 256
    tmp = drbd_bm_bits(mdev);
#line 256
    bm_bits = tmp;
#line 258
    stop_sector = 0ULL;
#line 259
    if ((unsigned int )*((unsigned short *)mdev + 374UL) == 288U || (unsigned int )*((unsigned short *)mdev + 374UL) == 304U) {
#line 261
      bit_pos = bm_bits - mdev->ov_left;
#line 262
      tmp___0 = verify_can_do_stop_sector(mdev);
#line 262
      if ((int )tmp___0) {
#line 263
        stop_sector = (unsigned long long )mdev->ov_stop_sector;
      } else {

      }
    } else {
#line 265
      bit_pos = mdev->bm_resync_fo;
    }
#line 268
    seq_printf(seq, "\t%3d%% sector pos: %llu/%llu", (int )(bit_pos / (bm_bits / 100UL + 1UL)),
               (unsigned long long )bit_pos * 8ULL, (unsigned long long )bm_bits * 8ULL);
#line 273
    if (stop_sector != 0ULL && stop_sector != 0xffffffffffffffffULL) {
#line 274
      seq_printf(seq, " stop sector: %llu", stop_sector);
    } else {

    }
#line 275
    seq_printf(seq, "\n");
  } else {

  }
#line 277
  return;
}
}
#line 279 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
static void resync_dump_detail(struct seq_file *seq , struct lc_element *e ) 
{ 
  struct bm_extent *bme ;
  struct lc_element  const  *__mptr ;

  {
#line 281
  __mptr = (struct lc_element  const  *)e;
#line 281
  bme = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
#line 283
  seq_printf(seq, "%5d %s %s\n", bme->rs_left, (char *)"---------", (int )bme->flags & 1 ? (char *)"LOCKED" : (char *)"------");
#line 286
  return;
}
}
#line 289 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
static int drbd_seq_show(struct seq_file *seq , void *v ) 
{ 
  int i ;
  int prev_i ;
  char const   *sn ;
  struct drbd_conf *mdev ;
  struct net_conf *nc ;
  char wp ;
  char write_ordering_chars[3U] ;
  char const   *tmp ;
  void *tmp___0 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  char const   *tmp___10 ;
  char const   *tmp___11 ;
  char const   *tmp___12 ;
  char const   *tmp___13 ;
  unsigned long tmp___14 ;
  int tmp___15 ;
  void *tmp___16 ;

  {
#line 291
  prev_i = -1;
#line 297
  write_ordering_chars[0] = 110;
#line 297
  write_ordering_chars[1] = 100;
#line 297
  write_ordering_chars[2] = 102;
#line 303
  tmp = drbd_buildtag();
#line 303
  seq_printf(seq, "version: 8.4.2 (api:%d/proto:%d-%d)\n%s\n", 1, 86, 101, tmp);
#line 326
  rcu_read_lock___0();
#line 327
  i = 0;
#line 327
  tmp___0 = idr_get_next(& minors, & i);
#line 327
  mdev = (struct drbd_conf *)tmp___0;
#line 327
  goto ldv_51976;
  ldv_51975: ;
#line 328
  if (i + -1 != prev_i) {
#line 329
    seq_printf(seq, "\n");
  } else {

  }
#line 330
  prev_i = i;
#line 332
  sn = drbd_conn_str((enum drbd_conns )mdev->state.ldv_49522.conn);
#line 334
  if (((unsigned int )*((unsigned short *)mdev + 374UL) == 0U && (unsigned int )*((unsigned char *)mdev + 749UL) == 0U) && (unsigned int )*((unsigned char *)mdev + 748UL) == 2U) {
#line 337
    seq_printf(seq, "%2d: cs:Unconfigured\n", i);
  } else {
#line 340
    bdi_rw_congested(& (mdev->rq_queue)->backing_dev_info);
#line 342
    _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 342
    tmp___1 = debug_lockdep_rcu_enabled();
#line 342
    if (tmp___1 != 0 && ! __warned) {
#line 342
      tmp___2 = rcu_read_lock_held();
#line 342
      if (tmp___2 == 0 && 1) {
#line 342
        __warned = 1;
#line 342
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared",
                               342, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 342
    nc = _________p1;
#line 343
    wp = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (char )((unsigned int )((unsigned char )nc->wire_protocol) + 64U) : 32;
#line 344
    tmp___3 = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 344
    tmp___4 = atomic_read((atomic_t const   *)(& mdev->unacked_cnt));
#line 344
    tmp___5 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 344
    tmp___6 = atomic_read((atomic_t const   *)(& mdev->rs_pending_cnt));
#line 344
    tmp___7 = atomic_read((atomic_t const   *)(& mdev->local_cnt));
#line 344
    tmp___8 = constant_test_bit(18U, (unsigned long const volatile   *)(& mdev->flags));
#line 344
    tmp___9 = drbd_suspended(mdev);
#line 344
    tmp___10 = drbd_disk_str((enum drbd_disk_state )mdev->state.ldv_49522.pdsk);
#line 344
    tmp___11 = drbd_disk_str((enum drbd_disk_state )mdev->state.ldv_49522.disk);
#line 344
    tmp___12 = drbd_role_str((enum drbd_role )mdev->state.ldv_49522.peer);
#line 344
    tmp___13 = drbd_role_str((enum drbd_role )mdev->state.ldv_49522.role);
#line 344
    seq_printf(seq, "%2d: cs:%s ro:%s/%s ds:%s/%s %c %c%c%c%c%c%c\n    ns:%u nr:%u dw:%u dr:%u al:%u bm:%u lo:%d pe:%d ua:%d ap:%d ep:%d wo:%c",
               i, sn, tmp___13, tmp___12, tmp___11, tmp___10, (int )wp, tmp___9 != 0 ? 115 : 114,
               (unsigned int )*((unsigned char *)mdev + 750UL) != 0U ? 97 : 45, (unsigned int )*((unsigned char *)mdev + 750UL) != 0U ? 112 : 45,
               (unsigned int )*((unsigned char *)mdev + 750UL) != 0U ? 117 : 45, (int )mdev->congestion_reason != 0 ? (int )mdev->congestion_reason : 45,
               tmp___8 != 0 ? 115 : 45, mdev->send_cnt / 2U, mdev->recv_cnt / 2U,
               mdev->writ_cnt / 2U, mdev->read_cnt / 2U, mdev->al_writ_cnt, mdev->bm_writ_cnt,
               tmp___7, tmp___5 + tmp___6, tmp___4, tmp___3, (mdev->tconn)->epochs,
               (int )write_ordering_chars[(unsigned int )(mdev->tconn)->write_ordering]);
#line 374
    tmp___14 = drbd_bm_total_weight(mdev);
#line 374
    seq_printf(seq, " oos:%llu\n", (unsigned long long )tmp___14 << 2);
  }
#line 378
  if ((((unsigned int )*((unsigned short *)mdev + 374UL) == 256U || (unsigned int )*((unsigned short *)mdev + 374UL) == 272U) || (unsigned int )*((unsigned short *)mdev + 374UL) == 288U) || (unsigned int )*((unsigned short *)mdev + 374UL) == 304U) {
#line 382
    drbd_syncer_progress(mdev, seq);
  } else {

  }
#line 384
  if (proc_details > 0) {
#line 384
    tmp___15 = _get_ldev_if_state(mdev, D_FAILED);
#line 384
    if (tmp___15 != 0) {
#line 385
      lc_seq_printf_stats(seq, mdev->resync);
#line 386
      lc_seq_printf_stats(seq, mdev->act_log);
#line 387
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 390
  if (proc_details > 1) {
#line 391
    if ((unsigned long )mdev->resync != (unsigned long )((struct lru_cache *)0)) {
#line 392
      lc_seq_dump_details(seq, mdev->resync, (char *)"rs_left", & resync_dump_detail);
    } else {

    }
  } else {

  }
#line 327
  i = i + 1;
#line 327
  tmp___16 = idr_get_next(& minors, & i);
#line 327
  mdev = (struct drbd_conf *)tmp___16;
  ldv_51976: ;
#line 327
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 328
    goto ldv_51975;
  } else {

  }
#line 397
  rcu_read_unlock___0();
#line 399
  return (0);
}
}
#line 402 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
static int drbd_proc_open(struct inode *inode , struct file *file ) 
{ 
  struct proc_dir_entry *tmp ;
  int tmp___0 ;
  bool tmp___1 ;

  {
#line 404
  tmp___1 = try_module_get(& __this_module);
#line 404
  if ((int )tmp___1) {
#line 405
    tmp = PDE((struct inode  const  *)inode);
#line 405
    tmp___0 = single_open(file, & drbd_seq_show, tmp->data);
#line 405
    return (tmp___0);
  } else {

  }
#line 406
  return (-19);
}
}
#line 409 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
static int drbd_proc_release(struct inode *inode , struct file *file ) 
{ 
  int tmp ;

  {
#line 411
  module_put(& __this_module);
#line 412
  tmp = single_release(inode, file);
#line 412
  return (tmp);
}
}
#line 433
void ldv_check_final_state(void) ;
#line 436
extern void ldv_check_return_value(int  ) ;
#line 442
void ldv_initialize(void) ;
#line 445
extern void ldv_handler_precall(void) ;
#line 448
extern int nondet_int(void) ;
#line 451 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
int LDV_IN_INTERRUPT  ;
#line 454 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void main(void) 
{ 
  struct inode *var_group1 ;
  struct file *var_group2 ;
  int res_drbd_proc_open_4 ;
  int ldv_s_drbd_proc_fops_file_operations ;
  int tmp ;
  int tmp___0 ;

  {
#line 488
  ldv_s_drbd_proc_fops_file_operations = 0;
#line 478
  LDV_IN_INTERRUPT = 1;
#line 487
  ldv_initialize();
#line 491
  goto ldv_52012;
  ldv_52011: 
#line 495
  tmp = nondet_int();
#line 495
  switch (tmp) {
  case 0: ;
#line 500
  if (ldv_s_drbd_proc_fops_file_operations == 0) {
#line 505
    ldv_handler_precall();
#line 506
    res_drbd_proc_open_4 = drbd_proc_open(var_group1, var_group2);
#line 507
    ldv_check_return_value(res_drbd_proc_open_4);
#line 508
    if (res_drbd_proc_open_4 != 0) {
#line 509
      goto ldv_module_exit;
    } else {

    }
#line 510
    ldv_s_drbd_proc_fops_file_operations = ldv_s_drbd_proc_fops_file_operations + 1;
  } else {

  }
#line 516
  goto ldv_52008;
  case 1: ;
#line 520
  if (ldv_s_drbd_proc_fops_file_operations == 1) {
#line 525
    ldv_handler_precall();
#line 526
    drbd_proc_release(var_group1, var_group2);
#line 527
    ldv_s_drbd_proc_fops_file_operations = 0;
  } else {

  }
#line 533
  goto ldv_52008;
  default: ;
#line 534
  goto ldv_52008;
  }
  ldv_52008: ;
  ldv_52012: 
#line 491
  tmp___0 = nondet_int();
#line 491
  if (tmp___0 != 0 || ldv_s_drbd_proc_fops_file_operations != 0) {
#line 493
    goto ldv_52011;
  } else {

  }

  ldv_module_exit: ;
#line 543
  ldv_check_final_state();
#line 546
  return;
}
}
#line 550 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_lock_29(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 555
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 557
  mutex_lock(ldv_func_arg1);
#line 558
  return;
}
}
#line 560 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_unlock_30(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 565
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 567
  mutex_unlock(ldv_func_arg1);
#line 568
  return;
}
}
#line 570 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_lock_31(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 575
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 577
  mutex_lock(ldv_func_arg1);
#line 578
  return;
}
}
#line 580 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_unlock_32(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 585
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 587
  mutex_unlock(ldv_func_arg1);
#line 588
  return;
}
}
#line 590 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_lock_33(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 595
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 597
  mutex_lock(ldv_func_arg1);
#line 598
  return;
}
}
#line 600 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_unlock_34(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 605
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 607
  mutex_unlock(ldv_func_arg1);
#line 608
  return;
}
}
#line 610 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_lock_35(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 615
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 617
  mutex_lock(ldv_func_arg1);
#line 618
  return;
}
}
#line 620 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
int ldv_mutex_trylock_36(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 625
  tmp = mutex_trylock(ldv_func_arg1);
#line 625
  ldv_func_res = tmp;
#line 627
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 627
  return (tmp___0);
#line 629
  return (ldv_func_res);
}
}
#line 632 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_unlock_37(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 637
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 639
  mutex_unlock(ldv_func_arg1);
#line 640
  return;
}
}
#line 642 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_lock_38(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 647
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 649
  mutex_lock(ldv_func_arg1);
#line 650
  return;
}
}
#line 652 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_proc.c.prepared"
void ldv_mutex_unlock_39(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 657
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 659
  mutex_unlock(ldv_func_arg1);
#line 660
  return;
}
}
#line 1 "<compiler builtins>"
void __builtin_prefetch(void const   *  , ...) ;
#line 206 "include/linux/kernel.h"
extern void panic(char const   *  , ...) ;
#line 24 "include/linux/list.h"
__inline static void INIT_LIST_HEAD(struct list_head *list ) 
{ 


  {
#line 26
  list->next = list;
#line 27
  list->prev = list;
#line 28
  return;
}
}
#line 47
extern void __list_add(struct list_head * , struct list_head * , struct list_head * ) ;
#line 60 "include/linux/list.h"
__inline static void list_add(struct list_head *new , struct list_head *head ) 
{ 


  {
#line 62
  __list_add(new, head, head->next);
#line 63
  return;
}
}
#line 74 "include/linux/list.h"
__inline static void list_add_tail(struct list_head *new , struct list_head *head ) 
{ 


  {
#line 76
  __list_add(new, head->prev, head);
#line 77
  return;
}
}
#line 111
extern void __list_del_entry(struct list_head * ) ;
#line 112
extern void list_del(struct list_head * ) ;
#line 142 "include/linux/list.h"
__inline static void list_del_init(struct list_head *entry ) 
{ 


  {
#line 144
  __list_del_entry(entry);
#line 145
  INIT_LIST_HEAD(entry);
#line 146
  return;
}
}
#line 153 "include/linux/list.h"
__inline static void list_move(struct list_head *list , struct list_head *head ) 
{ 


  {
#line 155
  __list_del_entry(list);
#line 156
  list_add(list, head);
#line 157
  return;
}
}
#line 164 "include/linux/list.h"
__inline static void list_move_tail(struct list_head *list , struct list_head *head ) 
{ 


  {
#line 167
  __list_del_entry(list);
#line 168
  list_add_tail(list, head);
#line 169
  return;
}
}
#line 186 "include/linux/list.h"
__inline static int list_empty(struct list_head  const  *head ) 
{ 


  {
#line 188
  return ((unsigned long )((struct list_head  const  *)head->next) == (unsigned long )head);
}
}
#line 273 "include/linux/list.h"
__inline static void __list_splice(struct list_head  const  *list , struct list_head *prev ,
                                   struct list_head *next ) 
{ 
  struct list_head *first ;
  struct list_head *last ;

  {
#line 277
  first = list->next;
#line 278
  last = list->prev;
#line 280
  first->prev = prev;
#line 281
  prev->next = first;
#line 283
  last->next = next;
#line 284
  next->prev = last;
#line 285
  return;
}
}
#line 318 "include/linux/list.h"
__inline static void list_splice_init(struct list_head *list , struct list_head *head ) 
{ 
  int tmp ;

  {
#line 321
  tmp = list_empty((struct list_head  const  *)list);
#line 321
  if (tmp == 0) {
#line 322
    __list_splice((struct list_head  const  *)list, head, head->next);
#line 323
    INIT_LIST_HEAD(list);
  } else {

  }
#line 325
  return;
}
}
#line 60 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/string_64.h"
extern int memcmp(void const   * , void const   * , size_t  ) ;
#line 22 "include/linux/err.h"
__inline static void *ERR_PTR(long error ) 
{ 


  {
#line 24
  return ((void *)error);
}
}
#line 11 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/cmpxchg.h"
extern void __xchg_wrong_size(void) ;
#line 35 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static void atomic_set(atomic_t *v , int i ) 
{ 


  {
#line 37
  v->counter = i;
#line 38
  return;
}
}
#line 61 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static void atomic_sub(int i , atomic_t *v ) 
{ 


  {
#line 63
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; subl %1,%0": "+m" (v->counter): "ir" (i));
#line 65
  return;
}
}
#line 105 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static void atomic_dec(atomic_t *v ) 
{ 


  {
#line 107
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0": "+m" (v->counter));
#line 109
  return;
}
}
#line 214 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static int atomic_xchg(atomic_t *v , int new ) 
{ 
  int __ret ;

  {
#line 216
  __ret = new;
#line 216
  switch (4UL) {
  case 1UL: 
#line 216
  __asm__  volatile   ("xchgb %b0, %1\n": "+q" (__ret), "+m" (v->counter): : "memory",
                       "cc");
#line 216
  goto ldv_5505;
  case 2UL: 
#line 216
  __asm__  volatile   ("xchgw %w0, %1\n": "+r" (__ret), "+m" (v->counter): : "memory",
                       "cc");
#line 216
  goto ldv_5505;
  case 4UL: 
#line 216
  __asm__  volatile   ("xchgl %0, %1\n": "+r" (__ret), "+m" (v->counter): : "memory",
                       "cc");
#line 216
  goto ldv_5505;
  case 8UL: 
#line 216
  __asm__  volatile   ("xchgq %q0, %1\n": "+r" (__ret), "+m" (v->counter): : "memory",
                       "cc");
#line 216
  goto ldv_5505;
  default: 
#line 216
  __xchg_wrong_size();
  }
  ldv_5505: ;
#line 216
  return (__ret);
}
}
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_54(struct mutex *ldv_func_arg1 ) ;
#line 175
int ldv_mutex_trylock_64(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_52(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_55(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_57(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_59(struct mutex *ldv_func_arg1 ) ;
#line 196
void ldv_mutex_unlock_61(struct mutex *ldv_func_arg1 ) ;
#line 200
void ldv_mutex_unlock_63(struct mutex *ldv_func_arg1 ) ;
#line 204
void ldv_mutex_unlock_66(struct mutex *ldv_func_arg1 ) ;
#line 208
void ldv_mutex_unlock_67(struct mutex *ldv_func_arg1 ) ;
#line 212
void ldv_mutex_unlock_69(struct mutex *ldv_func_arg1 ) ;
#line 216
void ldv_mutex_unlock_71(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_51(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_53(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_56(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_58(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_60(struct mutex *ldv_func_arg1 ) ;
#line 30
void ldv_mutex_lock_62(struct mutex *ldv_func_arg1 ) ;
#line 34
void ldv_mutex_lock_65(struct mutex *ldv_func_arg1 ) ;
#line 38
void ldv_mutex_lock_68(struct mutex *ldv_func_arg1 ) ;
#line 42
void ldv_mutex_lock_70(struct mutex *ldv_func_arg1 ) ;
#line 111
void ldv_mutex_lock_mutex_of_drbd_socket(struct mutex *lock ) ;
#line 115
void ldv_mutex_unlock_mutex_of_drbd_socket(struct mutex *lock ) ;
#line 119
void ldv_mutex_lock_state_mutex_of_drbd_conf(struct mutex *lock ) ;
#line 120
int ldv_mutex_trylock_state_mutex_of_drbd_conf(struct mutex *lock ) ;
#line 123
void ldv_mutex_unlock_state_mutex_of_drbd_conf(struct mutex *lock ) ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info___1(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6358;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6358;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6358;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6358;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6358: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 89 "include/linux/thread_info.h"
__inline static int test_ti_thread_flag(struct thread_info *ti , int flag ) 
{ 
  int tmp ;

  {
#line 91
  tmp = variable_test_bit(flag, (unsigned long const volatile   *)(& ti->flags));
#line 91
  return (tmp);
}
}
#line 22 "include/linux/spinlock_api_smp.h"
extern void _raw_spin_lock(raw_spinlock_t * ) ;
#line 39
extern void _raw_spin_unlock(raw_spinlock_t * ) ;
#line 23 "include/linux/rwlock_api_smp.h"
extern void _raw_write_lock_irq(rwlock_t * ) ;
#line 35
extern void _raw_write_unlock_irq(rwlock_t * ) ;
#line 283 "include/linux/spinlock.h"
__inline static void spin_lock(spinlock_t *lock ) 
{ 


  {
#line 285
  _raw_spin_lock(& lock->ldv_5957.rlock);
#line 286
  return;
}
}
#line 323 "include/linux/spinlock.h"
__inline static void spin_unlock(spinlock_t *lock ) 
{ 


  {
#line 325
  _raw_spin_unlock(& lock->ldv_5957.rlock);
#line 326
  return;
}
}
#line 91 "include/linux/completion.h"
extern void complete(struct completion * ) ;
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock___1(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info___1();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock___1(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info___1();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock___1(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock___1();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock___1(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock___1();
#line 763
  return;
}
}
#line 176 "include/linux/timer.h"
extern int mod_timer(struct timer_list * , unsigned long  ) ;
#line 240
extern void add_timer(struct timer_list * ) ;
#line 40 "include/linux/kref.h"
__inline static void kref_get(struct kref *kref ) 
{ 
  int __ret_warn_on ;
  int tmp ;
  long tmp___0 ;

  {
#line 42
  tmp = atomic_read((atomic_t const   *)(& kref->refcount));
#line 42
  __ret_warn_on = tmp == 0;
#line 42
  tmp___0 = __builtin_expect(__ret_warn_on != 0, 0L);
#line 42
  if (tmp___0 != 0L) {
#line 42
    warn_slowpath_null("include/linux/kref.h", 42);
  } else {

  }
#line 42
  __builtin_expect(__ret_warn_on != 0, 0L);
#line 43
  atomic_inc(& kref->refcount);
#line 44
  return;
}
}
#line 915 "include/linux/device.h"
extern int dev_emerg(struct device  const  * , char const   *  , ...) ;
#line 343 "include/linux/page-flags.h"
__inline static int PageTail(struct page  const  *page ) 
{ 
  int tmp ;

  {
#line 343
  tmp = constant_test_bit(15U, (unsigned long const volatile   *)(& page->flags));
#line 343
  return (tmp);
}
}
#line 357 "include/linux/mm.h"
__inline static struct page *compound_head(struct page *page ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
#line 359
  tmp = PageTail((struct page  const  *)page);
#line 359
  tmp___0 = __builtin_expect(tmp != 0, 0L);
#line 359
  if (tmp___0 != 0L) {
#line 360
    return (page->ldv_14746.first_page);
  } else {

  }
#line 361
  return (page);
}
}
#line 379 "include/linux/mm.h"
__inline static int page_count(struct page *page ) 
{ 
  struct page *tmp ;
  int tmp___0 ;

  {
#line 381
  tmp = compound_head(page);
#line 381
  tmp___0 = atomic_read((atomic_t const   *)(& tmp->ldv_14727.ldv_14726.ldv_14725._count));
#line 381
  return (tmp___0);
}
}
#line 57 "include/linux/scatterlist.h"
__inline static void sg_assign_page(struct scatterlist *sg , struct page *page ) 
{ 
  unsigned long page_link ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
#line 59
  page_link = sg->page_link & 3UL;
#line 65
  tmp = __builtin_expect(((unsigned long )page & 3UL) != 0UL, 0L);
#line 65
  if (tmp != 0L) {
#line 65
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (65), "i" (12UL));
    ldv_19226: ;
#line 65
    goto ldv_19226;
  } else {

  }
#line 67
  tmp___0 = __builtin_expect(sg->sg_magic != 2271560481UL, 0L);
#line 67
  if (tmp___0 != 0L) {
#line 67
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (67), "i" (12UL));
    ldv_19227: ;
#line 67
    goto ldv_19227;
  } else {

  }
#line 68
  tmp___1 = __builtin_expect((long )((int )sg->page_link) & 1L, 0L);
#line 68
  if (tmp___1 != 0L) {
#line 68
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (68), "i" (12UL));
    ldv_19228: ;
#line 68
    goto ldv_19228;
  } else {

  }
#line 70
  sg->page_link = page_link | (unsigned long )page;
#line 71
  return;
}
}
#line 87 "include/linux/scatterlist.h"
__inline static void sg_set_page(struct scatterlist *sg , struct page *page , unsigned int len ,
                                 unsigned int offset ) 
{ 


  {
#line 90
  sg_assign_page(sg, page);
#line 91
  sg->offset = offset;
#line 92
  sg->length = len;
#line 93
  return;
}
}
#line 207
extern void sg_init_table(struct scatterlist * , unsigned int  ) ;
#line 648 "include/linux/fs.h"
__inline static loff_t i_size_read(struct inode  const  *inode ) 
{ 


  {
#line 667
  return ((loff_t )inode->i_size);
}
}
#line 321 "include/linux/sched.h"
extern long schedule_timeout_interruptible(long  ) ;
#line 2158
extern void flush_signals(struct task_struct * ) ;
#line 2192
extern void force_sig(int  , struct task_struct * ) ;
#line 2533 "include/linux/sched.h"
__inline static int test_tsk_thread_flag(struct task_struct *tsk , int flag ) 
{ 
  int tmp ;

  {
#line 2535
  tmp = test_ti_thread_flag((struct thread_info *)tsk->stack, flag);
#line 2535
  return (tmp);
}
}
#line 2559 "include/linux/sched.h"
__inline static int signal_pending(struct task_struct *p ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
#line 2561
  tmp = test_tsk_thread_flag(p, 2);
#line 2561
  tmp___0 = __builtin_expect(tmp != 0, 0L);
#line 2561
  return ((int )tmp___0);
}
}
#line 104 "include/linux/idr.h"
extern void *idr_find(struct idr * , int  ) ;
#line 1475 "include/net/sock.h"
extern int sock_setsockopt(struct socket * , int  , int  , char * , unsigned int  ) ;
#line 1134 "include/linux/crypto.h"
__inline static struct crypto_tfm *crypto_hash_tfm(struct crypto_hash *tfm ) 
{ 


  {
#line 1136
  return (& tfm->base);
}
}
#line 1154 "include/linux/crypto.h"
__inline static struct hash_tfm *crypto_hash_crt(struct crypto_hash *tfm ) 
{ 
  struct crypto_tfm *tmp ;

  {
#line 1156
  tmp = crypto_hash_tfm(tfm);
#line 1156
  return (& tmp->crt_u.hash);
}
}
#line 1169 "include/linux/crypto.h"
__inline static unsigned int crypto_hash_digestsize(struct crypto_hash *tfm ) 
{ 
  struct hash_tfm *tmp ;

  {
#line 1171
  tmp = crypto_hash_crt(tfm);
#line 1171
  return (tmp->digestsize);
}
}
#line 1189 "include/linux/crypto.h"
__inline static int crypto_hash_init(struct hash_desc *desc ) 
{ 
  struct hash_tfm *tmp ;
  int tmp___0 ;

  {
#line 1191
  tmp = crypto_hash_crt(desc->tfm);
#line 1191
  tmp___0 = (*(tmp->init))(desc);
#line 1191
  return (tmp___0);
}
}
#line 1194 "include/linux/crypto.h"
__inline static int crypto_hash_update(struct hash_desc *desc , struct scatterlist *sg ,
                                       unsigned int nbytes ) 
{ 
  struct hash_tfm *tmp ;
  int tmp___0 ;

  {
#line 1198
  tmp = crypto_hash_crt(desc->tfm);
#line 1198
  tmp___0 = (*(tmp->update))(desc, sg, nbytes);
#line 1198
  return (tmp___0);
}
}
#line 1201 "include/linux/crypto.h"
__inline static int crypto_hash_final(struct hash_desc *desc , u8 *out ) 
{ 
  struct hash_tfm *tmp ;
  int tmp___0 ;

  {
#line 1203
  tmp = crypto_hash_crt(desc->tfm);
#line 1203
  tmp___0 = (*(tmp->final))(desc, out);
#line 1203
  return (tmp___0);
}
}
#line 219 "include/linux/bio.h"
extern struct bio *bio_clone_bioset(struct bio * , gfp_t  , struct bio_set * ) ;
#line 221
extern struct bio_set *fs_bio_set ;
#line 228 "include/linux/bio.h"
__inline static struct bio *bio_clone(struct bio *bio , gfp_t gfp_mask ) 
{ 
  struct bio *tmp ;

  {
#line 230
  tmp = bio_clone_bioset(bio, gfp_mask, fs_bio_set);
#line 230
  return (tmp);
}
}
#line 717 "include/linux/blkdev.h"
extern void generic_make_request(struct bio * ) ;
#line 1083 "include/linux/blkdev.h"
__inline static unsigned int queue_max_hw_sectors(struct request_queue *q ) 
{ 


  {
#line 1085
  return (q->limits.max_hw_sectors);
}
}
#line 131 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_state.h"
enum drbd_state_rv conn_request_state(struct drbd_tconn *tconn , union drbd_state mask ,
                                      union drbd_state val , enum chg_state_flags flags ) ;
#line 525 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static enum drbd_thread_state get_t_state(struct drbd_thread *thi ) 
{ 


  {
#line 531
  __asm__  volatile   ("": : : "memory");
#line 532
  return (thi->t_state);
}
}
#line 798
struct fifo_buffer *fifo_alloc(int fifo_size ) ;
#line 1037 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static struct drbd_conf *minor_to_mdev(unsigned int minor ) 
{ 
  void *tmp ;

  {
#line 1039
  tmp = idr_find(& minors, (int )minor);
#line 1039
  return ((struct drbd_conf *)tmp);
}
}
#line 1068
void drbd_thread_current_set_cpu(struct drbd_thread *thi ) ;
#line 1087
void drbd_gen_and_send_sync_uuid(struct drbd_conf *mdev ) ;
#line 1094
int drbd_send_ack(struct drbd_conf *mdev , enum drbd_packet cmd , struct drbd_peer_request *peer_req ) ;
#line 1100
int drbd_send_ack_ex(struct drbd_conf *mdev , enum drbd_packet cmd , sector_t sector ,
                     int blksize , u64 block_id ) ;
#line 1102
int drbd_send_out_of_sync(struct drbd_conf *mdev , struct drbd_request *req ) ;
#line 1103
int drbd_send_block(struct drbd_conf *mdev , enum drbd_packet cmd , struct drbd_peer_request *peer_req ) ;
#line 1105
int drbd_send_dblock(struct drbd_conf *mdev , struct drbd_request *req ) ;
#line 1106
int drbd_send_drequest(struct drbd_conf *mdev , int cmd , sector_t sector , int size ,
                       u64 block_id ) ;
#line 1108
int drbd_send_drequest_csum(struct drbd_conf *mdev , sector_t sector , int size ,
                            void *digest , int digest_size , enum drbd_packet cmd ) ;
#line 1111
int drbd_send_ov_request(struct drbd_conf *mdev , sector_t sector , int size ) ;
#line 1117
void drbd_mdev_cleanup(struct drbd_conf *mdev ) ;
#line 1118
void drbd_print_uuids(struct drbd_conf *mdev , char const   *text ) ;
#line 1121
void drbd_md_sync(struct drbd_conf *mdev ) ;
#line 1123
void drbd_uuid_set(struct drbd_conf *mdev , int idx , u64 val ) ;
#line 1124
void _drbd_uuid_set(struct drbd_conf *mdev , int idx , u64 val ) ;
#line 1126
void drbd_uuid_set_bm(struct drbd_conf *mdev , u64 val ) ;
#line 1388
wait_queue_head_t drbd_pp_wait ;
#line 1404 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
rwlock_t global_state_lock  ;
#line 1408
void drbd_minor_destroy(struct kref *kref ) ;
#line 1443
int drbd_khelper(struct drbd_conf *mdev , char *cmd ) ;
#line 1446
int drbd_worker(struct drbd_thread *thi ) ;
#line 1447
enum drbd_ret_code drbd_resync_after_valid(struct drbd_conf *mdev , int o_minor ) ;
#line 1448
void drbd_resync_after_changed(struct drbd_conf *mdev ) ;
#line 1449
void drbd_start_resync(struct drbd_conf *mdev , enum drbd_conns side ) ;
#line 1450
void resume_next_sg(struct drbd_conf *mdev ) ;
#line 1451
void suspend_other_sg(struct drbd_conf *mdev ) ;
#line 1452
int drbd_resync_finished(struct drbd_conf *mdev ) ;
#line 1455
void drbd_md_put_buffer(struct drbd_conf *mdev ) ;
#line 1458
void drbd_ov_out_of_sync_found(struct drbd_conf *mdev , sector_t sector , int size ) ;
#line 1461
void drbd_rs_controller_reset(struct drbd_conf *mdev ) ;
#line 1463 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void ov_out_of_sync_print(struct drbd_conf *mdev ) 
{ 


  {
#line 1465
  if (mdev->ov_last_oos_size != 0UL) {
#line 1466
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Out of sync: start=%llu, size=%lu (sectors)\n",
            (unsigned long long )mdev->ov_last_oos_start, mdev->ov_last_oos_size);
  } else {

  }
#line 1470
  mdev->ov_last_oos_size = 0UL;
#line 1471
  return;
}
}
#line 1474
void drbd_csum_bio(struct drbd_conf *mdev , struct crypto_hash *tfm , struct bio *bio ,
                   void *digest ) ;
#line 1475
void drbd_csum_ee(struct drbd_conf *mdev , struct crypto_hash *tfm , struct drbd_peer_request *peer_req ,
                  void *digest ) ;
#line 1478
int w_e_end_data_req(struct drbd_work *w , int cancel ) ;
#line 1479
int w_e_end_rsdata_req(struct drbd_work *w , int cancel ) ;
#line 1480
int w_e_end_csum_rs_req(struct drbd_work *w , int cancel ) ;
#line 1481
int w_e_end_ov_reply(struct drbd_work *w , int cancel ) ;
#line 1482
int w_e_end_ov_req(struct drbd_work *w , int cancel ) ;
#line 1483
int w_ov_finished(struct drbd_work *w , int cancel ) ;
#line 1484
int w_resync_timer(struct drbd_work *w , int cancel ) ;
#line 1485
int w_send_write_hint(struct drbd_work *w , int cancel ) ;
#line 1486
int w_make_resync_request(struct drbd_work *w , int cancel ) ;
#line 1487
int w_send_dblock(struct drbd_work *w , int cancel ) ;
#line 1488
int w_send_read_req(struct drbd_work *w , int cancel ) ;
#line 1489
int w_prev_work_done(struct drbd_work *w , int cancel ) ;
#line 1491
int w_restart_disk_io(struct drbd_work *w , int cancel ) ;
#line 1492
int w_send_out_of_sync(struct drbd_work *w , int cancel ) ;
#line 1493
int w_start_resync(struct drbd_work *w , int cancel ) ;
#line 1495
void resync_timer_fn(unsigned long data ) ;
#line 1496
void start_resync_timer_fn(unsigned long data ) ;
#line 1499
int drbd_rs_should_slow_down(struct drbd_conf *mdev , sector_t sector ) ;
#line 1500
int drbd_submit_peer_request(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ,
                             unsigned int const   rw , int const   fault_type ) ;
#line 1504
struct drbd_peer_request *drbd_alloc_peer_req(struct drbd_conf *mdev , u64 id , sector_t sector ,
                                              unsigned int data_size , gfp_t gfp_mask ) ;
#line 1507
void __drbd_free_peer_req(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ,
                          int is_net ) ;
#line 1523 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_setsockopt(struct socket *sock , int level , int optname ,
                                    char *optval , int optlen ) 
{ 
  mm_segment_t oldfs ;
  struct thread_info *tmp ;
  char *uoptval ;
  int err ;
  struct thread_info *tmp___0 ;
  mm_segment_t __constr_expr_0 ;
  struct thread_info *tmp___1 ;

  {
#line 1526
  tmp = current_thread_info___1();
#line 1526
  oldfs = tmp->addr_limit;
#line 1530
  uoptval = optval;
#line 1532
  tmp___0 = current_thread_info___1();
#line 1532
  __constr_expr_0.seg = 0xffffffffffffffffUL;
#line 1532
  tmp___0->addr_limit = __constr_expr_0;
#line 1533
  if (level == 1) {
#line 1534
    err = sock_setsockopt(sock, level, optname, uoptval, (unsigned int )optlen);
  } else {
#line 1536
    err = (*((sock->ops)->setsockopt))(sock, level, optname, uoptval, (unsigned int )optlen);
  }
#line 1538
  tmp___1 = current_thread_info___1();
#line 1538
  tmp___1->addr_limit = oldfs;
#line 1539
  return (err);
}
}
#line 1542 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_tcp_cork(struct socket *sock ) 
{ 
  int val ;

  {
#line 1544
  val = 1;
#line 1545
  drbd_setsockopt(sock, 6, 3, (char *)(& val), 4);
#line 1547
  return;
}
}
#line 1549 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_tcp_uncork(struct socket *sock ) 
{ 
  int val ;

  {
#line 1551
  val = 0;
#line 1552
  drbd_setsockopt(sock, 6, 3, (char *)(& val), 4);
#line 1554
  return;
}
}
#line 1579
void drbd_al_begin_io(struct drbd_conf *mdev , struct drbd_interval *i ) ;
#line 1580
void drbd_al_complete_io(struct drbd_conf *mdev , struct drbd_interval *i ) ;
#line 1581
void drbd_rs_complete_io(struct drbd_conf *mdev , sector_t sector ) ;
#line 1583
int drbd_try_rs_begin_io(struct drbd_conf *mdev , sector_t sector ) ;
#line 1585
int drbd_rs_del_all(struct drbd_conf *mdev ) ;
#line 1586
void drbd_rs_failed_io(struct drbd_conf *mdev , sector_t sector , int size ) ;
#line 1588
void drbd_advance_rs_marks(struct drbd_conf *mdev , unsigned long still_to_go ) ;
#line 1589
void __drbd_set_in_sync(struct drbd_conf *mdev , sector_t sector , int size , char const   *file ,
                        unsigned int const   line ) ;
#line 1593
int __drbd_set_out_of_sync(struct drbd_conf *mdev , sector_t sector , int size , char const   *file ,
                           unsigned int const   line ) ;
#line 1621 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static struct page *page_chain_next(struct page *page ) 
{ 


  {
#line 1623
  return ((struct page *)page->ldv_14746.private);
}
}
#line 1632 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_peer_req_has_active_page(struct drbd_peer_request *peer_req ) 
{ 
  struct page *page ;
  int tmp ;
  struct page *tmp___0 ;

  {
#line 1634
  page = peer_req->pages;
#line 1635
  goto ldv_51606;
  ldv_51605: 
#line 1636
  tmp = page_count(page);
#line 1636
  if (tmp > 1) {
#line 1637
    return (1);
  } else {

  }
#line 1635
  page = page_chain_next(page);
  ldv_51606: ;
#line 1635
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 1635
    tmp___0 = page_chain_next(page);
#line 1635
    __builtin_prefetch((void const   *)tmp___0);
#line 1635
    if (1 != 0) {
#line 1636
      goto ldv_51605;
    } else {
#line 1638
      goto ldv_51607;
    }
  } else {

  }
  ldv_51607: ;
#line 1639
  return (0);
}
}
#line 1675 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void __drbd_chk_io_error____0(struct drbd_conf *mdev , enum drbd_force_detach_flags df ,
                                              char const   *where ) 
{ 
  enum drbd_io_error_p ep ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  union drbd_state __ns ;
  union drbd_state __ns___0 ;

  {
#line 1681
  rcu_read_lock___1();
#line 1682
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1682
  tmp = debug_lockdep_rcu_enabled();
#line 1682
  if (tmp != 0 && ! __warned) {
#line 1682
    tmp___0 = rcu_read_lock_held();
#line 1682
    if (tmp___0 == 0 && 1) {
#line 1682
      __warned = 1;
#line 1682
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1682, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1682
  ep = (enum drbd_io_error_p )_________p1->on_io_error;
#line 1683
  rcu_read_unlock___1();
#line 1684
  switch ((unsigned int )ep) {
  case 0U: ;
#line 1686
  if ((unsigned int )df == 0U || (unsigned int )df == 1U) {
#line 1687
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "__drbd_chk_io_error_");
#line 1687
    if (tmp___1 != 0) {
#line 1688
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s.\n",
              where);
    } else {

    }
#line 1689
    if ((int )mdev->state.ldv_49522.disk > 4) {
#line 1690
      __ns = drbd_read_state(mdev);
#line 1690
      __ns.ldv_40024.disk = 4U;
#line 1690
      _drbd_set_state(mdev, __ns, CS_HARD, 0);
    } else {

    }
#line 1691
    goto ldv_51637;
  } else {

  }
  case 2U: ;
  case 1U: 
#line 1716
  set_bit(12U, (unsigned long volatile   *)(& mdev->flags));
#line 1717
  if ((unsigned int )df == 0U) {
#line 1718
    set_bit(13U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1719
  if ((unsigned int )df == 3U) {
#line 1720
    set_bit(14U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1721
  if ((int )mdev->state.ldv_49522.disk > 2) {
#line 1722
    __ns___0 = drbd_read_state(mdev);
#line 1722
    __ns___0.ldv_40024.disk = 2U;
#line 1722
    _drbd_set_state(mdev, __ns___0, CS_HARD, 0);
#line 1723
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s. Detaching...\n",
            where);
  } else {

  }
#line 1726
  goto ldv_51637;
  }
  ldv_51637: ;
#line 1729
  return;
}
}
#line 1804 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_get_capacity(struct block_device *bdev ) 
{ 
  loff_t tmp ;
  sector_t tmp___0 ;

  {
#line 1807
  if ((unsigned long )bdev != (unsigned long )((struct block_device *)0)) {
#line 1807
    tmp = i_size_read((struct inode  const  *)bdev->bd_inode);
#line 1807
    tmp___0 = (sector_t )(tmp >> 9);
  } else {
#line 1807
    tmp___0 = 0UL;
  }
#line 1807
  return (tmp___0);
}
}
#line 1897 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_queue_work(struct drbd_work_queue *q , struct drbd_work *w ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 1900
  tmp = spinlock_check(& q->q_lock);
#line 1900
  flags = _raw_spin_lock_irqsave(tmp);
#line 1901
  list_add_tail(& w->list, & q->q);
#line 1902
  spin_unlock_irqrestore(& q->q_lock, flags);
#line 1903
  __wake_up(& q->q_wait, 3U, 1, 0);
#line 1904
  return;
}
}
#line 1906 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void wake_asender(struct drbd_tconn *tconn ) 
{ 
  int tmp ;

  {
#line 1908
  tmp = constant_test_bit(3U, (unsigned long const volatile   *)(& tconn->flags));
#line 1908
  if (tmp != 0) {
#line 1909
    force_sig(24, tconn->asender.task);
  } else {

  }
#line 1910
  return;
}
}
#line 1912 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void request_ping(struct drbd_tconn *tconn ) 
{ 


  {
#line 1914
  set_bit(2U, (unsigned long volatile   *)(& tconn->flags));
#line 1915
  wake_asender(tconn);
#line 1916
  return;
}
}
#line 1918
void *conn_prepare_command(struct drbd_tconn *tconn , struct drbd_socket *sock ) ;
#line 1919
void *drbd_prepare_command(struct drbd_conf *mdev , struct drbd_socket *sock ) ;
#line 1920
int conn_send_command(struct drbd_tconn *tconn , struct drbd_socket *sock , enum drbd_packet cmd ,
                      unsigned int header_size , void *data , unsigned int size ) ;
#line 1923
int drbd_send_command(struct drbd_conf *mdev , struct drbd_socket *sock , enum drbd_packet cmd ,
                      unsigned int header_size , void *data , unsigned int size ) ;
#line 1994 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void inc_rs_pending(struct drbd_conf *mdev ) 
{ 


  {
#line 1996
  atomic_inc(& mdev->rs_pending_cnt);
#line 1997
  return;
}
}
#line 2000 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void _dec_rs_pending(struct drbd_conf *mdev , char const   *func ,
                                     int line ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
#line 2002
  atomic_dec(& mdev->rs_pending_cnt);
#line 2003
  tmp___0 = atomic_read((atomic_t const   *)(& mdev->rs_pending_cnt));
#line 2003
  if (tmp___0 < 0) {
#line 2003
    tmp = atomic_read((atomic_t const   *)(& mdev->rs_pending_cnt));
#line 2003
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "in %s:%d: rs_pending_cnt = %d < 0 !\n",
            func, line, tmp);
  } else {

  }
#line 2004
  return;
}
}
#line 2021 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void _dec_unacked(struct drbd_conf *mdev , char const   *func , int line ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
#line 2023
  atomic_dec(& mdev->unacked_cnt);
#line 2024
  tmp___0 = atomic_read((atomic_t const   *)(& mdev->unacked_cnt));
#line 2024
  if (tmp___0 < 0) {
#line 2024
    tmp = atomic_read((atomic_t const   *)(& mdev->unacked_cnt));
#line 2024
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "in %s:%d: unacked_cnt = %d < 0 !\n",
            func, line, tmp);
  } else {

  }
#line 2025
  return;
}
}
#line 23 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_wrappers.h"
void drbd_md_io_complete(struct bio *bio , int error ) ;
#line 24
void drbd_peer_request_endio(struct bio *bio , int error ) ;
#line 25
void drbd_request_endio(struct bio *bio , int error ) ;
#line 250 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
__inline static void drbd_req_make_private_bio(struct drbd_request *req , struct bio *bio_src ) 
{ 
  struct bio *bio ;

  {
#line 253
  bio = bio_clone(bio_src, 16U);
#line 255
  req->private_bio = bio;
#line 257
  bio->bi_private = (void *)req;
#line 258
  bio->bi_end_io = & drbd_request_endio;
#line 259
  bio->bi_next = 0;
#line 260
  return;
}
}
#line 273
int __req_mod(struct drbd_request *req , enum drbd_req_event what , struct bio_and_error *m ) ;
#line 275
void complete_master_bio(struct drbd_conf *mdev , struct bio_and_error *m ) ;
#line 304 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
__inline static int req_mod(struct drbd_request *req , enum drbd_req_event what ) 
{ 
  unsigned long flags ;
  struct drbd_conf *mdev ;
  struct bio_and_error m ;
  int rv ;
  raw_spinlock_t *tmp ;

  {
#line 308
  mdev = req->w.ldv_49807.mdev;
#line 312
  tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 312
  flags = _raw_spin_lock_irqsave(tmp);
#line 313
  rv = __req_mod(req, what, & m);
#line 314
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 316
  if ((unsigned long )m.bio != (unsigned long )((struct bio *)0)) {
#line 317
    complete_master_bio(mdev, & m);
  } else {

  }
#line 319
  return (rv);
}
}
#line 128 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int w_make_ov_request(struct drbd_work *w , int cancel ) ;
#line 154 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_md_io_complete(struct bio *bio , int error ) 
{ 
  struct drbd_md_io *md_io ;
  struct drbd_conf *mdev ;
  struct drbd_md_io  const  *__mptr ;

  {
#line 159
  md_io = (struct drbd_md_io *)bio->bi_private;
#line 160
  __mptr = (struct drbd_md_io  const  *)md_io;
#line 160
  mdev = (struct drbd_conf *)__mptr + 0xfffffffffffffa38UL;
#line 162
  md_io->error = error;
#line 175
  drbd_md_put_buffer(mdev);
#line 176
  md_io->done = 1U;
#line 177
  __wake_up(& mdev->misc_wait, 3U, 1, 0);
#line 178
  bio_put(bio);
#line 179
  put_ldev(mdev);
#line 180
  return;
}
}
#line 185 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_endio_read_sec_final(struct drbd_peer_request *peer_req ) 
{ 
  unsigned long flags ;
  struct drbd_conf *mdev ;
  raw_spinlock_t *tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 187
  flags = 0UL;
#line 188
  mdev = peer_req->w.ldv_49807.mdev;
#line 190
  tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 190
  flags = _raw_spin_lock_irqsave(tmp);
#line 191
  mdev->read_cnt = mdev->read_cnt + (peer_req->i.size >> 9);
#line 192
  list_del(& peer_req->w.list);
#line 193
  tmp___0 = list_empty((struct list_head  const  *)(& mdev->read_ee));
#line 193
  if (tmp___0 != 0) {
#line 194
    __wake_up(& mdev->ee_wait, 3U, 1, 0);
  } else {

  }
#line 195
  tmp___1 = constant_test_bit(3U, (unsigned long const volatile   *)(& peer_req->flags));
#line 195
  if (tmp___1 != 0) {
#line 196
    __drbd_chk_io_error____0(mdev, DRBD_READ_ERROR, "drbd_endio_read_sec_final");
  } else {

  }
#line 197
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 199
  drbd_queue_work(& (mdev->tconn)->sender_work, & peer_req->w);
#line 200
  put_ldev(mdev);
#line 201
  return;
}
}
#line 205 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static void drbd_endio_write_sec_final(struct drbd_peer_request *peer_req ) 
{ 
  unsigned long flags ;
  struct drbd_conf *mdev ;
  struct drbd_interval i ;
  int do_wake ;
  u64 block_id ;
  int do_al_complete_io ;
  raw_spinlock_t *tmp ;
  int tmp___0 ;

  {
#line 207
  flags = 0UL;
#line 208
  mdev = peer_req->w.ldv_49807.mdev;
#line 218
  i = peer_req->i;
#line 219
  do_al_complete_io = (int )peer_req->flags & 1;
#line 220
  block_id = peer_req->ldv_50726.block_id;
#line 222
  tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 222
  flags = _raw_spin_lock_irqsave(tmp);
#line 223
  mdev->writ_cnt = mdev->writ_cnt + (peer_req->i.size >> 9);
#line 224
  list_move_tail(& peer_req->w.list, & mdev->done_ee);
#line 234
  do_wake = list_empty((struct list_head  const  *)(block_id == 0xffffffffffffffffULL ? & mdev->sync_ee : & mdev->active_ee));
#line 236
  tmp___0 = constant_test_bit(3U, (unsigned long const volatile   *)(& peer_req->flags));
#line 236
  if (tmp___0 != 0) {
#line 237
    __drbd_chk_io_error____0(mdev, DRBD_WRITE_ERROR, "drbd_endio_write_sec_final");
  } else {

  }
#line 238
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 240
  if (block_id == 0xffffffffffffffffULL) {
#line 241
    drbd_rs_complete_io(mdev, i.sector);
  } else {

  }
#line 243
  if (do_wake != 0) {
#line 244
    __wake_up(& mdev->ee_wait, 3U, 1, 0);
  } else {

  }
#line 246
  if (do_al_complete_io != 0) {
#line 247
    drbd_al_complete_io(mdev, & i);
  } else {

  }
#line 249
  wake_asender(mdev->tconn);
#line 250
  put_ldev(mdev);
#line 251
  return;
}
}
#line 256 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_peer_request_endio(struct bio *bio , int error ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_conf *mdev ;
  int uptodate ;
  int is_write ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 258
  peer_req = (struct drbd_peer_request *)bio->bi_private;
#line 259
  mdev = peer_req->w.ldv_49807.mdev;
#line 260
  uptodate = (int )bio->bi_flags & 1;
#line 261
  is_write = (int )bio->bi_rw & 1;
#line 263
  if (error != 0) {
#line 263
    tmp = ___ratelimit(& drbd_ratelimit_state, "drbd_peer_request_endio");
#line 263
    if (tmp != 0) {
#line 264
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s: error=%d s=%llus\n",
               is_write != 0 ? (char *)"write" : (char *)"read", error, (unsigned long long )peer_req->i.sector);
    } else {

    }
  } else {

  }
#line 267
  if (error == 0 && uptodate == 0) {
#line 268
    tmp___0 = ___ratelimit(& drbd_ratelimit_state, "drbd_peer_request_endio");
#line 268
    if (tmp___0 != 0) {
#line 269
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s: setting error to -EIO s=%llus\n",
               is_write != 0 ? (char *)"write" : (char *)"read", (unsigned long long )peer_req->i.sector);
    } else {

    }
#line 275
    error = -5;
  } else {

  }
#line 278
  if (error != 0) {
#line 279
    set_bit(3U, (unsigned long volatile   *)(& peer_req->flags));
  } else {

  }
#line 281
  bio_put(bio);
#line 282
  tmp___1 = atomic_dec_and_test(& peer_req->pending_bios);
#line 282
  if (tmp___1 != 0) {
#line 283
    if (is_write != 0) {
#line 284
      drbd_endio_write_sec_final(peer_req);
    } else {
#line 286
      drbd_endio_read_sec_final(peer_req);
    }
  } else {

  }
#line 287
  return;
}
}
#line 292 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_request_endio(struct bio *bio , int error ) 
{ 
  unsigned long flags ;
  struct drbd_request *req ;
  struct drbd_conf *mdev ;
  struct bio_and_error m ;
  enum drbd_req_event what ;
  int uptodate ;
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  void *tmp___2 ;
  raw_spinlock_t *tmp___3 ;

  {
#line 295
  req = (struct drbd_request *)bio->bi_private;
#line 296
  mdev = req->w.ldv_49807.mdev;
#line 299
  uptodate = (int )bio->bi_flags & 1;
#line 301
  if (error == 0 && uptodate == 0) {
#line 302
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "p %s: setting error to -EIO\n",
             (int )bio->bi_rw & 1 ? (char *)"write" : (char *)"read");
#line 307
    error = -5;
  } else {

  }
#line 339
  tmp___0 = __builtin_expect(((unsigned long )req->rq_state & 8UL) != 0UL, 0L);
#line 339
  if (tmp___0 != 0L) {
#line 340
    tmp = ___ratelimit(& drbd_ratelimit_state, "drbd_request_endio");
#line 340
    if (tmp != 0) {
#line 341
      dev_emerg((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "delayed completion of aborted local request; disk-timeout may be too aggressive\n");
    } else {

    }
#line 343
    if (error == 0) {
#line 344
      panic("possible random memory corruption caused by delayed completion of aborted local request\n");
    } else {

    }
  } else {

  }
#line 348
  tmp___1 = __builtin_expect(error != 0, 0L);
#line 348
  if (tmp___1 != 0L) {
#line 349
    what = (int )bio->bi_rw & 1 ? WRITE_COMPLETED_WITH_ERROR : ((bio->bi_rw & 8193UL) == 0UL ? READ_COMPLETED_WITH_ERROR : READ_AHEAD_COMPLETED_WITH_ERROR);
  } else {
#line 355
    what = COMPLETED_OK;
  }
#line 357
  bio_put(req->private_bio);
#line 358
  tmp___2 = ERR_PTR((long )error);
#line 358
  req->private_bio = (struct bio *)tmp___2;
#line 361
  tmp___3 = spinlock_check(& (mdev->tconn)->req_lock);
#line 361
  flags = _raw_spin_lock_irqsave(tmp___3);
#line 362
  __req_mod(req, what, & m);
#line 363
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 364
  put_ldev(mdev);
#line 366
  if ((unsigned long )m.bio != (unsigned long )((struct bio *)0)) {
#line 367
    complete_master_bio(mdev, & m);
  } else {

  }
#line 368
  return;
}
}
#line 370 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_csum_ee(struct drbd_conf *mdev , struct crypto_hash *tfm , struct drbd_peer_request *peer_req ,
                  void *digest ) 
{ 
  struct hash_desc desc ;
  struct scatterlist sg ;
  struct page *page ;
  struct page *tmp ;
  unsigned int len ;

  {
#line 375
  page = peer_req->pages;
#line 379
  desc.tfm = tfm;
#line 380
  desc.flags = 0U;
#line 382
  sg_init_table(& sg, 1U);
#line 383
  crypto_hash_init(& desc);
#line 385
  goto ldv_52122;
  ldv_52121: 
#line 387
  sg_set_page(& sg, page, 4096U, 0U);
#line 388
  crypto_hash_update(& desc, & sg, sg.length);
#line 389
  page = tmp;
  ldv_52122: 
#line 385
  tmp = page_chain_next(page);
#line 385
  if ((unsigned long )tmp != (unsigned long )((struct page *)0)) {
#line 386
    goto ldv_52121;
  } else {

  }
#line 392
  len = peer_req->i.size & 4095U;
#line 393
  sg_set_page(& sg, page, len != 0U ? len : 4096U, 0U);
#line 394
  crypto_hash_update(& desc, & sg, sg.length);
#line 395
  crypto_hash_final(& desc, (u8 *)digest);
#line 396
  return;
}
}
#line 398 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_csum_bio(struct drbd_conf *mdev , struct crypto_hash *tfm , struct bio *bio ,
                   void *digest ) 
{ 
  struct hash_desc desc ;
  struct scatterlist sg ;
  struct bio_vec *bvec ;
  int i ;

  {
#line 405
  desc.tfm = tfm;
#line 406
  desc.flags = 0U;
#line 408
  sg_init_table(& sg, 1U);
#line 409
  crypto_hash_init(& desc);
#line 411
  bvec = bio->bi_io_vec + (unsigned long )bio->bi_idx;
#line 411
  i = (int )bio->bi_idx;
#line 411
  goto ldv_52135;
  ldv_52134: 
#line 412
  sg_set_page(& sg, bvec->bv_page, bvec->bv_len, bvec->bv_offset);
#line 413
  crypto_hash_update(& desc, & sg, sg.length);
#line 411
  bvec = bvec + 1;
#line 411
  i = i + 1;
  ldv_52135: ;
#line 411
  if ((int )bio->bi_vcnt > i) {
#line 412
    goto ldv_52134;
  } else {

  }
#line 415
  crypto_hash_final(& desc, (u8 *)digest);
#line 416
  return;
}
}
#line 419 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int w_e_send_csum(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  int digest_size ;
  void *digest ;
  int err ;
  long tmp ;
  long tmp___0 ;
  unsigned int tmp___1 ;
  sector_t sector ;
  unsigned int size ;
  long tmp___2 ;

  {
#line 421
  __mptr = (struct drbd_work  const  *)w;
#line 421
  peer_req = (struct drbd_peer_request *)__mptr;
#line 422
  mdev = w->ldv_49807.mdev;
#line 425
  err = 0;
#line 427
  tmp = __builtin_expect(cancel != 0, 0L);
#line 427
  if (tmp != 0L) {
#line 428
    goto out;
  } else {

  }
#line 430
  tmp___0 = __builtin_expect((peer_req->flags & 8UL) != 0UL, 0L);
#line 430
  if (tmp___0 != 0L) {
#line 431
    goto out;
  } else {

  }
#line 433
  tmp___1 = crypto_hash_digestsize((mdev->tconn)->csums_tfm);
#line 433
  digest_size = (int )tmp___1;
#line 434
  digest = kmalloc((size_t )digest_size, 16U);
#line 435
  if ((unsigned long )digest != (unsigned long )((void *)0)) {
#line 436
    sector = peer_req->i.sector;
#line 437
    size = peer_req->i.size;
#line 438
    drbd_csum_ee(mdev, (mdev->tconn)->csums_tfm, peer_req, digest);
#line 444
    __drbd_free_peer_req(mdev, peer_req, 0);
#line 445
    peer_req = 0;
#line 446
    inc_rs_pending(mdev);
#line 447
    err = drbd_send_drequest_csum(mdev, sector, (int )size, digest, digest_size, P_CSUM_RS_REQUEST);
#line 450
    kfree((void const   *)digest);
  } else {
#line 452
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "kmalloc() of digest failed.\n");
#line 453
    err = -12;
  }
  out: ;
#line 457
  if ((unsigned long )peer_req != (unsigned long )((struct drbd_peer_request *)0)) {
#line 458
    __drbd_free_peer_req(mdev, peer_req, 0);
  } else {

  }
#line 460
  tmp___2 = __builtin_expect(err != 0, 0L);
#line 460
  if (tmp___2 != 0L) {
#line 461
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_send_drequest(..., csum) failed\n");
  } else {

  }
#line 462
  return (err);
}
}
#line 467 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int read_for_csum(struct drbd_conf *mdev , sector_t sector , int size ) 
{ 
  struct drbd_peer_request *peer_req ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 471
  tmp = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 471
  if (tmp == 0) {
#line 472
    return (-5);
  } else {

  }
#line 474
  tmp___0 = drbd_rs_should_slow_down(mdev, sector);
#line 474
  if (tmp___0 != 0) {
#line 475
    goto defer;
  } else {

  }
#line 479
  peer_req = drbd_alloc_peer_req(mdev, 0xffffffffffffffffULL, sector, (unsigned int )size,
                                 514U);
#line 481
  if ((unsigned long )peer_req == (unsigned long )((struct drbd_peer_request *)0)) {
#line 482
    goto defer;
  } else {

  }
#line 484
  peer_req->w.cb = & w_e_send_csum;
#line 485
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 486
  list_add(& peer_req->w.list, & mdev->read_ee);
#line 487
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 489
  atomic_add(size >> 9, & mdev->rs_sect_ev);
#line 490
  tmp___1 = drbd_submit_peer_request(mdev, peer_req, 0U, 3);
#line 490
  if (tmp___1 == 0) {
#line 491
    return (0);
  } else {

  }
#line 497
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 498
  list_del(& peer_req->w.list);
#line 499
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 501
  __drbd_free_peer_req(mdev, peer_req, 0);
  defer: 
#line 503
  put_ldev(mdev);
#line 504
  return (-11);
}
}
#line 507 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_resync_timer(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_conf *mdev ;

  {
#line 509
  mdev = w->ldv_49807.mdev;
#line 510
  switch ((int )mdev->state.ldv_49522.conn) {
  case 18: 
#line 512
  w_make_ov_request(w, cancel);
#line 513
  goto ldv_52164;
  case 17: 
#line 515
  w_make_resync_request(w, cancel);
#line 516
  goto ldv_52164;
  }
  ldv_52164: ;
#line 519
  return (0);
}
}
#line 522 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void resync_timer_fn(unsigned long data ) 
{ 
  struct drbd_conf *mdev ;
  int tmp ;

  {
#line 524
  mdev = (struct drbd_conf *)data;
#line 526
  tmp = list_empty((struct list_head  const  *)(& mdev->resync_work.list));
#line 526
  if (tmp != 0) {
#line 527
    drbd_queue_work(& (mdev->tconn)->sender_work, & mdev->resync_work);
  } else {

  }
#line 528
  return;
}
}
#line 530 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static void fifo_set(struct fifo_buffer *fb , int value ) 
{ 
  int i ;

  {
#line 534
  i = 0;
#line 534
  goto ldv_52176;
  ldv_52175: 
#line 535
  fb->values[i] = value;
#line 534
  i = i + 1;
  ldv_52176: ;
#line 534
  if ((unsigned int )i < fb->size) {
#line 535
    goto ldv_52175;
  } else {

  }

#line 539
  return;
}
}
#line 538 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int fifo_push(struct fifo_buffer *fb , int value ) 
{ 
  int ov ;
  unsigned int tmp ;

  {
#line 542
  ov = fb->values[fb->head_index];
#line 543
  tmp = fb->head_index;
#line 543
  fb->head_index = fb->head_index + 1U;
#line 543
  fb->values[tmp] = value;
#line 545
  if (fb->head_index >= fb->size) {
#line 546
    fb->head_index = 0U;
  } else {

  }
#line 548
  return (ov);
}
}
#line 551 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static void fifo_add_val(struct fifo_buffer *fb , int value ) 
{ 
  int i ;

  {
#line 555
  i = 0;
#line 555
  goto ldv_52189;
  ldv_52188: 
#line 556
  fb->values[i] = fb->values[i] + value;
#line 555
  i = i + 1;
  ldv_52189: ;
#line 555
  if ((unsigned int )i < fb->size) {
#line 556
    goto ldv_52188;
  } else {

  }

#line 560
  return;
}
}
#line 559 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
struct fifo_buffer *fifo_alloc(int fifo_size ) 
{ 
  struct fifo_buffer *fb ;
  void *tmp ;

  {
#line 563
  tmp = kzalloc(((unsigned long )fifo_size + 3UL) * 4UL, 16U);
#line 563
  fb = (struct fifo_buffer *)tmp;
#line 564
  if ((unsigned long )fb == (unsigned long )((struct fifo_buffer *)0)) {
#line 565
    return (0);
  } else {

  }
#line 567
  fb->head_index = 0U;
#line 568
  fb->size = (unsigned int )fifo_size;
#line 569
  fb->total = 0;
#line 571
  return (fb);
}
}
#line 574 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int drbd_rs_controller(struct drbd_conf *mdev ) 
{ 
  struct disk_conf *dc ;
  unsigned int sect_in ;
  unsigned int want ;
  int req_sect ;
  int correction ;
  int cps ;
  int steps ;
  int curr_corr ;
  int max_sect ;
  struct fifo_buffer *plan ;
  int tmp ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  struct fifo_buffer *_________p1___0 ;
  bool __warned___0 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 587
  tmp = atomic_xchg(& mdev->rs_sect_in, 0);
#line 587
  sect_in = (unsigned int )tmp;
#line 588
  mdev->rs_in_flight = (int )((unsigned int )mdev->rs_in_flight - sect_in);
#line 590
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 590
  tmp___0 = debug_lockdep_rcu_enabled();
#line 590
  if (tmp___0 != 0 && ! __warned) {
#line 590
    tmp___1 = rcu_read_lock_held();
#line 590
    if (tmp___1 == 0 && 1) {
#line 590
      __warned = 1;
#line 590
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             590, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 590
  dc = _________p1;
#line 591
  _________p1___0 = *((struct fifo_buffer * volatile  *)(& mdev->rs_plan_s));
#line 591
  tmp___2 = debug_lockdep_rcu_enabled();
#line 591
  if (tmp___2 != 0 && ! __warned___0) {
#line 591
    tmp___3 = rcu_read_lock_held();
#line 591
    if (tmp___3 == 0 && 1) {
#line 591
      __warned___0 = 1;
#line 591
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             591, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 591
  plan = _________p1___0;
#line 593
  steps = (int )plan->size;
#line 595
  if ((unsigned int )mdev->rs_in_flight + sect_in == 0U) {
#line 596
    want = ((dc->resync_rate * 50U) / 250U) * (__u32 )steps;
  } else {
#line 598
    want = dc->c_fill_target != 0U ? dc->c_fill_target : ((dc->c_delay_target * sect_in) * 250U) / 250U;
  }
#line 602
  correction = (int )((want - (unsigned int )mdev->rs_in_flight) - (unsigned int )plan->total);
#line 605
  cps = correction / steps;
#line 606
  fifo_add_val(plan, cps);
#line 607
  plan->total = plan->total + cps * steps;
#line 610
  curr_corr = fifo_push(plan, 0);
#line 611
  plan->total = plan->total - curr_corr;
#line 613
  req_sect = (int )(sect_in + (unsigned int )curr_corr);
#line 614
  if (req_sect < 0) {
#line 615
    req_sect = 0;
  } else {

  }
#line 617
  max_sect = (int )((dc->c_max_rate * 50U) / 250U);
#line 618
  if (req_sect > max_sect) {
#line 619
    req_sect = max_sect;
  } else {

  }
#line 627
  return (req_sect);
}
}
#line 630 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int drbd_rs_number_requests(struct drbd_conf *mdev ) 
{ 
  int number ;
  int tmp ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  struct fifo_buffer *_________p1___0 ;
  bool __warned___0 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 634
  rcu_read_lock___1();
#line 635
  _________p1___0 = *((struct fifo_buffer * volatile  *)(& mdev->rs_plan_s));
#line 635
  tmp___2 = debug_lockdep_rcu_enabled();
#line 635
  if (tmp___2 != 0 && ! __warned___0) {
#line 635
    tmp___3 = rcu_read_lock_held();
#line 635
    if (tmp___3 == 0 && 1) {
#line 635
      __warned___0 = 1;
#line 635
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             635, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 635
  if (_________p1___0->size != 0U) {
#line 636
    tmp = drbd_rs_controller(mdev);
#line 636
    number = tmp >> 3;
#line 637
    mdev->c_sync_rate = (number * 1000) / 25;
  } else {
#line 639
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 639
    tmp___0 = debug_lockdep_rcu_enabled();
#line 639
    if (tmp___0 != 0 && ! __warned) {
#line 639
      tmp___1 = rcu_read_lock_held();
#line 639
      if (tmp___1 == 0 && 1) {
#line 639
        __warned = 1;
#line 639
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                               639, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 639
    mdev->c_sync_rate = (int )_________p1->resync_rate;
#line 640
    number = (mdev->c_sync_rate * 25) / 1000;
  }
#line 642
  rcu_read_unlock___1();
#line 646
  return (number);
}
}
#line 649 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_make_resync_request(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_conf *mdev ;
  unsigned long bit ;
  sector_t sector ;
  sector_t capacity ;
  sector_t tmp ;
  int max_bio_size ;
  int number ;
  int rollback_i ;
  int size ;
  int align ;
  int queued ;
  int sndbuf ;
  int i ;
  long tmp___0 ;
  int tmp___1 ;
  unsigned int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  long tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int err ;
  unsigned long tmp___9 ;

  {
#line 651
  mdev = w->ldv_49807.mdev;
#line 654
  tmp = drbd_get_capacity(mdev->this_bdev);
#line 654
  capacity = tmp;
#line 658
  i = 0;
#line 660
  tmp___0 = __builtin_expect(cancel != 0, 0L);
#line 660
  if (tmp___0 != 0L) {
#line 661
    return (0);
  } else {

  }
#line 663
  if (mdev->rs_total == 0UL) {
#line 665
    drbd_resync_finished(mdev);
#line 666
    return (0);
  } else {

  }
#line 669
  tmp___1 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 669
  if (tmp___1 == 0) {
#line 674
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Disk broke down during resync!\n");
#line 675
    return (0);
  } else {

  }
#line 678
  tmp___2 = queue_max_hw_sectors(mdev->rq_queue);
#line 678
  max_bio_size = (int )(tmp___2 << 9);
#line 679
  number = drbd_rs_number_requests(mdev);
#line 680
  if (number == 0) {
#line 681
    goto requeue;
  } else {

  }
#line 683
  i = 0;
#line 683
  goto ldv_52253;
  ldv_52252: 
#line 685
  ldv_mutex_lock_62(& (mdev->tconn)->data.mutex);
#line 686
  if ((unsigned long )(mdev->tconn)->data.socket != (unsigned long )((struct socket *)0)) {
#line 687
    queued = (((mdev->tconn)->data.socket)->sk)->sk_wmem_queued;
#line 688
    sndbuf = (((mdev->tconn)->data.socket)->sk)->sk_sndbuf;
  } else {
#line 690
    queued = 1;
#line 691
    sndbuf = 0;
  }
#line 693
  ldv_mutex_unlock_63(& (mdev->tconn)->data.mutex);
#line 694
  if (sndbuf / 2 < queued) {
#line 695
    goto requeue;
  } else {

  }
  next_sector: 
#line 698
  size = 4096;
#line 699
  bit = drbd_bm_find_next(mdev, mdev->bm_resync_fo);
#line 701
  if (bit == 0xffffffffffffffffUL) {
#line 702
    mdev->bm_resync_fo = drbd_bm_bits(mdev);
#line 703
    put_ldev(mdev);
#line 704
    return (0);
  } else {

  }
#line 707
  sector = bit << 3;
#line 709
  tmp___3 = drbd_rs_should_slow_down(mdev, sector);
#line 709
  if (tmp___3 != 0) {
#line 711
    mdev->bm_resync_fo = bit;
#line 712
    goto requeue;
  } else {
#line 709
    tmp___4 = drbd_try_rs_begin_io(mdev, sector);
#line 709
    if (tmp___4 != 0) {
#line 711
      mdev->bm_resync_fo = bit;
#line 712
      goto requeue;
    } else {

    }
  }
#line 714
  mdev->bm_resync_fo = bit + 1UL;
#line 716
  tmp___5 = drbd_bm_test_bit(mdev, bit);
#line 716
  tmp___6 = __builtin_expect(tmp___5 == 0, 0L);
#line 716
  if (tmp___6 != 0L) {
#line 717
    drbd_rs_complete_io(mdev, sector);
#line 718
    goto next_sector;
  } else {

  }
#line 728
  align = 1;
#line 729
  rollback_i = i;
  ldv_52243: ;
#line 731
  if (size + 4096 > max_bio_size) {
#line 732
    goto ldv_52242;
  } else {

  }
#line 735
  if (((sector_t )((1 << (align + 3)) + -1) & sector) != 0UL) {
#line 736
    goto ldv_52242;
  } else {

  }
#line 739
  if (((bit + 1UL) & 4095UL) == 0UL) {
#line 740
    goto ldv_52242;
  } else {

  }
#line 746
  tmp___7 = drbd_bm_test_bit(mdev, bit + 1UL);
#line 746
  if (tmp___7 != 1) {
#line 747
    goto ldv_52242;
  } else {

  }
#line 748
  bit = bit + 1UL;
#line 749
  size = size + 4096;
#line 750
  if (4096 << align <= size) {
#line 751
    align = align + 1;
  } else {

  }
#line 752
  i = i + 1;
#line 753
  goto ldv_52243;
  ldv_52242: ;
#line 756
  if (size > 4096) {
#line 757
    mdev->bm_resync_fo = bit + 1UL;
  } else {

  }
#line 761
  if ((sector_t )(size >> 9) + sector > capacity) {
#line 762
    size = (int )((capacity - sector) << 9);
  } else {

  }
#line 763
  if ((mdev->tconn)->agreed_pro_version > 88 && (unsigned long )(mdev->tconn)->csums_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 764
    tmp___8 = read_for_csum(mdev, sector, size);
#line 764
    switch (tmp___8) {
    case -5: 
#line 766
    put_ldev(mdev);
#line 767
    return (-5);
    case -11: 
#line 769
    drbd_rs_complete_io(mdev, sector);
#line 770
    mdev->bm_resync_fo = sector >> 3;
#line 771
    i = rollback_i;
#line 772
    goto requeue;
    case 0: ;
#line 775
    goto ldv_52247;
    default: 
#line 777
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"),
                         "i" (777), "i" (12UL));
    ldv_52249: ;
#line 777
    goto ldv_52249;
    }
    ldv_52247: ;
  } else {
#line 782
    inc_rs_pending(mdev);
#line 783
    err = drbd_send_drequest(mdev, 9, sector, size, 0xffffffffffffffffULL);
#line 785
    if (err != 0) {
#line 786
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_send_drequest() failed, aborting...\n");
#line 787
      _dec_rs_pending(mdev, "w_make_resync_request", 787);
#line 788
      put_ldev(mdev);
#line 789
      return (err);
    } else {

    }
  }
#line 683
  i = i + 1;
  ldv_52253: ;
#line 683
  if (i < number) {
#line 684
    goto ldv_52252;
  } else {

  }
#line 794
  tmp___9 = drbd_bm_bits(mdev);
#line 794
  if (mdev->bm_resync_fo >= tmp___9) {
#line 801
    put_ldev(mdev);
#line 802
    return (0);
  } else {

  }
  requeue: 
#line 806
  mdev->rs_in_flight = mdev->rs_in_flight + (i << 3);
#line 807
  mod_timer(& mdev->resync_timer, (unsigned long )jiffies + 25UL);
#line 808
  put_ldev(mdev);
#line 809
  return (0);
}
}
#line 812 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int w_make_ov_request(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_conf *mdev ;
  int number ;
  int i ;
  int size ;
  sector_t sector ;
  sector_t capacity ;
  sector_t tmp ;
  bool stop_sector_reached ;
  long tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
#line 814
  mdev = w->ldv_49807.mdev;
#line 817
  tmp = drbd_get_capacity(mdev->this_bdev);
#line 817
  capacity = tmp;
#line 818
  stop_sector_reached = 0;
#line 820
  tmp___0 = __builtin_expect(cancel != 0, 0L);
#line 820
  if (tmp___0 != 0L) {
#line 821
    return (1);
  } else {

  }
#line 823
  number = drbd_rs_number_requests(mdev);
#line 825
  sector = mdev->ov_position;
#line 826
  i = 0;
#line 826
  goto ldv_52270;
  ldv_52269: ;
#line 827
  if (sector >= capacity) {
#line 828
    return (1);
  } else {

  }
#line 833
  if (i > 0) {
#line 833
    tmp___1 = verify_can_do_stop_sector(mdev);
#line 833
    if ((int )tmp___1) {
#line 833
      if (mdev->ov_stop_sector <= sector) {
#line 833
        tmp___2 = 1;
      } else {
#line 833
        tmp___2 = 0;
      }
    } else {
#line 833
      tmp___2 = 0;
    }
  } else {
#line 833
    tmp___2 = 0;
  }
#line 833
  stop_sector_reached = (bool )tmp___2;
#line 836
  if ((int )stop_sector_reached) {
#line 837
    goto ldv_52266;
  } else {

  }
#line 839
  size = 4096;
#line 841
  tmp___3 = drbd_rs_should_slow_down(mdev, sector);
#line 841
  if (tmp___3 != 0) {
#line 843
    mdev->ov_position = sector;
#line 844
    goto requeue;
  } else {
#line 841
    tmp___4 = drbd_try_rs_begin_io(mdev, sector);
#line 841
    if (tmp___4 != 0) {
#line 843
      mdev->ov_position = sector;
#line 844
      goto requeue;
    } else {

    }
  }
#line 847
  if ((sector_t )(size >> 9) + sector > capacity) {
#line 848
    size = (int )((capacity - sector) << 9);
  } else {

  }
#line 850
  inc_rs_pending(mdev);
#line 851
  tmp___5 = drbd_send_ov_request(mdev, sector, size);
#line 851
  if (tmp___5 != 0) {
#line 852
    _dec_rs_pending(mdev, "w_make_ov_request", 852);
#line 853
    return (0);
  } else {

  }
#line 855
  sector = sector + 8UL;
#line 826
  i = i + 1;
  ldv_52270: ;
#line 826
  if (i < number) {
#line 827
    goto ldv_52269;
  } else {

  }
  ldv_52266: 
#line 857
  mdev->ov_position = sector;
  requeue: 
#line 860
  mdev->rs_in_flight = mdev->rs_in_flight + (i << 3);
#line 861
  if (i == 0 || ! stop_sector_reached) {
#line 862
    mod_timer(& mdev->resync_timer, (unsigned long )jiffies + 25UL);
  } else {

  }
#line 863
  return (1);
}
}
#line 866 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_ov_finished(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_conf *mdev ;

  {
#line 868
  mdev = w->ldv_49807.mdev;
#line 869
  kfree((void const   *)w);
#line 870
  ov_out_of_sync_print(mdev);
#line 871
  drbd_resync_finished(mdev);
#line 873
  return (0);
}
}
#line 876 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int w_resync_finished(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_conf *mdev ;

  {
#line 878
  mdev = w->ldv_49807.mdev;
#line 879
  kfree((void const   *)w);
#line 881
  drbd_resync_finished(mdev);
#line 883
  return (0);
}
}
#line 886 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static void ping_peer(struct drbd_conf *mdev ) 
{ 
  struct drbd_tconn *tconn ;
  int tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;

  {
#line 888
  tconn = mdev->tconn;
#line 890
  clear_bit(4, (unsigned long volatile   *)(& tconn->flags));
#line 891
  request_ping(tconn);
#line 892
  tmp = constant_test_bit(4U, (unsigned long const volatile   *)(& tconn->flags));
#line 892
  if (tmp != 0 || (int )mdev->state.ldv_49522.conn <= 9) {
#line 892
    goto ldv_52285;
  } else {

  }
#line 892
  tmp___0 = get_current();
#line 892
  __wait.flags = 0U;
#line 892
  __wait.private = (void *)tmp___0;
#line 892
  __wait.func = & autoremove_wake_function;
#line 892
  __wait.task_list.next = & __wait.task_list;
#line 892
  __wait.task_list.prev = & __wait.task_list;
  ldv_52288: 
#line 892
  prepare_to_wait(& tconn->ping_wait, & __wait, 2);
#line 892
  tmp___1 = constant_test_bit(4U, (unsigned long const volatile   *)(& tconn->flags));
#line 892
  if (tmp___1 != 0 || (int )mdev->state.ldv_49522.conn <= 9) {
#line 892
    goto ldv_52287;
  } else {

  }
#line 892
  schedule();
#line 892
  goto ldv_52288;
  ldv_52287: 
#line 892
  finish_wait(& tconn->ping_wait, & __wait);
  ldv_52285: ;
#line 895
  return;
}
}
#line 896 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int drbd_resync_finished(struct drbd_conf *mdev ) 
{ 
  unsigned long db ;
  unsigned long dt ;
  unsigned long dbdt ;
  unsigned long n_oos ;
  union drbd_state os ;
  union drbd_state ns ;
  struct drbd_work *w ;
  char *khelper_cmd ;
  int verify_done ;
  void *tmp ;
  int tmp___0 ;
  int tmp___1 ;
  unsigned long s ;
  unsigned long t ;
  int ratio ;
  int i ;
  int i___0 ;

  {
#line 902
  khelper_cmd = 0;
#line 903
  verify_done = 0;
#line 908
  tmp___0 = drbd_rs_del_all(mdev);
#line 908
  if (tmp___0 != 0) {
#line 914
    schedule_timeout_interruptible(25L);
#line 915
    tmp = kmalloc(32UL, 32U);
#line 915
    w = (struct drbd_work *)tmp;
#line 916
    if ((unsigned long )w != (unsigned long )((struct drbd_work *)0)) {
#line 917
      w->cb = & w_resync_finished;
#line 918
      w->ldv_49807.mdev = mdev;
#line 919
      drbd_queue_work(& (mdev->tconn)->sender_work, w);
#line 920
      return (1);
    } else {

    }
#line 922
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Warn failed to drbd_rs_del_all() and to kmalloc(w).\n");
  } else {

  }
#line 925
  dt = (((unsigned long )jiffies - mdev->rs_start) - mdev->rs_paused) / 250UL;
#line 926
  if (dt == 0UL) {
#line 927
    dt = 1UL;
  } else {

  }
#line 929
  db = mdev->rs_total;
#line 931
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 288U || (unsigned int )*((unsigned short *)mdev + 374UL) == 304U) {
#line 932
    db = db - mdev->ov_left;
  } else {

  }
#line 934
  dbdt = db / dt << 2;
#line 935
  mdev->rs_paused = mdev->rs_paused / 250UL;
#line 937
  tmp___1 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 937
  if (tmp___1 == 0) {
#line 938
    goto out;
  } else {

  }
#line 940
  ping_peer(mdev);
#line 942
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 943
  os = drbd_read_state(mdev);
#line 945
  verify_done = (unsigned int )*((unsigned short *)(& os) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 304U;
#line 949
  if ((int )os.ldv_40024.conn <= 10) {
#line 950
    goto out_unlock;
  } else {

  }
#line 952
  ns = os;
#line 953
  ns.ldv_40024.conn = 10U;
#line 955
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s done (total %lu sec; paused %lu sec; %lu K/sec)\n",
            verify_done != 0 ? (char *)"Online verify" : (char *)"Resync", mdev->rs_paused + dt,
            mdev->rs_paused, dbdt);
#line 959
  n_oos = drbd_bm_total_weight(mdev);
#line 961
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 304U) {
#line 962
    if (n_oos != 0UL) {
#line 963
      dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Online verify found %lu %dk block out of sync!\n",
                n_oos, 4);
#line 965
      khelper_cmd = (char *)"out-of-sync";
    } else {
#line 968
      if (mdev->rs_failed != n_oos) {
#line 968
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( (n_oos - mdev->rs_failed) == 0 ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                968);
      } else {

      }
#line 970
      if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 272U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 336U) {
#line 971
        khelper_cmd = (char *)"after-resync-target";
      } else {

      }
#line 973
      if ((unsigned long )(mdev->tconn)->csums_tfm != (unsigned long )((struct crypto_hash *)0) && mdev->rs_total != 0UL) {
#line 974
        s = mdev->rs_same_csum;
#line 975
        t = mdev->rs_total;
#line 976
        ratio = t != 0UL ? (t <= 99999UL ? (int const   )((s * 100UL) / t) : (int const   )(s / (t / 100UL))) : 0;
#line 979
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%u %% had equal checksums, eliminated: %luK; transferred %luK total %luK\n",
                  ratio, mdev->rs_same_csum << 2, (mdev->rs_total - mdev->rs_same_csum) << 2,
                  mdev->rs_total << 2);
      } else {

      }
    }
  } else {

  }
#line 988
  if (mdev->rs_failed != 0UL) {
#line 989
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "            %lu failed blocks\n",
              mdev->rs_failed);
#line 991
    if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 272U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 336U) {
#line 992
      ns.ldv_40024.disk = 4U;
#line 993
      ns.ldv_40024.pdsk = 8U;
    } else {
#line 995
      ns.ldv_40024.disk = 8U;
#line 996
      ns.ldv_40024.pdsk = 4U;
    }
  } else {
#line 999
    ns.ldv_40024.disk = 8U;
#line 1000
    ns.ldv_40024.pdsk = 8U;
#line 1002
    if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 272U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 336U) {
#line 1003
      if ((unsigned long )mdev->p_uuid != (unsigned long )((u64 *)0)) {
#line 1005
        i = 1;
#line 1005
        goto ldv_52308;
        ldv_52307: 
#line 1006
        _drbd_uuid_set(mdev, i, *(mdev->p_uuid + (unsigned long )i));
#line 1005
        i = i + 1;
        ldv_52308: ;
#line 1005
        if (i <= 3) {
#line 1006
          goto ldv_52307;
        } else {

        }
#line 1007
        drbd_uuid_set(mdev, 1, (mdev->ldev)->md.uuid[0]);
#line 1008
        _drbd_uuid_set(mdev, 0, *(mdev->p_uuid));
      } else {
#line 1010
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "mdev->p_uuid is NULL! BUG\n");
      }
    } else {

    }
#line 1014
    if ((unsigned int )*((unsigned short *)(& os) + 0UL) != 288U && (unsigned int )*((unsigned short *)(& os) + 0UL) != 304U) {
#line 1017
      drbd_uuid_set_bm(mdev, 0ULL);
#line 1018
      drbd_print_uuids(mdev, "updated UUIDs");
#line 1019
      if ((unsigned long )mdev->p_uuid != (unsigned long )((u64 *)0)) {
#line 1023
        i___0 = 0;
#line 1023
        goto ldv_52312;
        ldv_52311: 
#line 1024
        *(mdev->p_uuid + (unsigned long )i___0) = (mdev->ldev)->md.uuid[i___0];
#line 1023
        i___0 = i___0 + 1;
        ldv_52312: ;
#line 1023
        if (i___0 <= 3) {
#line 1024
          goto ldv_52311;
        } else {

        }

      } else {

      }
    } else {

    }
  }
#line 1029
  _drbd_set_state(mdev, ns, CS_VERBOSE, 0);
  out_unlock: 
#line 1031
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1032
  put_ldev(mdev);
  out: 
#line 1034
  mdev->rs_total = 0UL;
#line 1035
  mdev->rs_failed = 0UL;
#line 1036
  mdev->rs_paused = 0UL;
#line 1039
  if (verify_done != 0 && mdev->ov_left == 0UL) {
#line 1040
    mdev->ov_start_sector = 0UL;
  } else {

  }
#line 1042
  drbd_md_sync(mdev);
#line 1044
  if ((unsigned long )khelper_cmd != (unsigned long )((char *)0)) {
#line 1045
    drbd_khelper(mdev, khelper_cmd);
  } else {

  }
#line 1047
  return (1);
}
}
#line 1051 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static void move_to_net_ee_or_free(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ) 
{ 
  int i ;
  int tmp ;

  {
#line 1053
  tmp = drbd_peer_req_has_active_page(peer_req);
#line 1053
  if (tmp != 0) {
#line 1055
    i = (int )(((unsigned long )peer_req->i.size + 4095UL) >> 12);
#line 1056
    atomic_add(i, & mdev->pp_in_use_by_net);
#line 1057
    atomic_sub(i, & mdev->pp_in_use);
#line 1058
    spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1059
    list_add_tail(& peer_req->w.list, & mdev->net_ee);
#line 1060
    spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1061
    __wake_up(& drbd_pp_wait, 3U, 1, 0);
  } else {
#line 1063
    __drbd_free_peer_req(mdev, peer_req, 0);
  }
#line 1064
  return;
}
}
#line 1072 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_e_end_data_req(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  int err ;
  long tmp ;
  int tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;

  {
#line 1074
  __mptr = (struct drbd_work  const  *)w;
#line 1074
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1075
  mdev = w->ldv_49807.mdev;
#line 1078
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1078
  if (tmp != 0L) {
#line 1079
    __drbd_free_peer_req(mdev, peer_req, 0);
#line 1080
    _dec_unacked(mdev, "w_e_end_data_req", 1080);
#line 1081
    return (0);
  } else {

  }
#line 1084
  tmp___1 = __builtin_expect((peer_req->flags & 8UL) == 0UL, 1L);
#line 1084
  if (tmp___1 != 0L) {
#line 1085
    err = drbd_send_block(mdev, P_DATA_REPLY, peer_req);
  } else {
#line 1087
    tmp___0 = ___ratelimit(& drbd_ratelimit_state, "w_e_end_data_req");
#line 1087
    if (tmp___0 != 0) {
#line 1088
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Sending NegDReply. sector=%llus.\n",
              (unsigned long long )peer_req->i.sector);
    } else {

    }
#line 1091
    err = drbd_send_ack(mdev, P_NEG_DREPLY, peer_req);
  }
#line 1094
  _dec_unacked(mdev, "w_e_end_data_req", 1094);
#line 1096
  move_to_net_ee_or_free(mdev, peer_req);
#line 1098
  tmp___2 = __builtin_expect(err != 0, 0L);
#line 1098
  if (tmp___2 != 0L) {
#line 1099
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_send_block() failed\n");
  } else {

  }
#line 1100
  return (err);
}
}
#line 1109 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_e_end_rsdata_req(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  int err ;
  long tmp ;
  int tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;
  long tmp___5 ;

  {
#line 1111
  __mptr = (struct drbd_work  const  *)w;
#line 1111
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1112
  mdev = w->ldv_49807.mdev;
#line 1115
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1115
  if (tmp != 0L) {
#line 1116
    __drbd_free_peer_req(mdev, peer_req, 0);
#line 1117
    _dec_unacked(mdev, "w_e_end_rsdata_req", 1117);
#line 1118
    return (0);
  } else {

  }
#line 1121
  tmp___0 = _get_ldev_if_state(mdev, D_FAILED);
#line 1121
  if (tmp___0 != 0) {
#line 1122
    drbd_rs_complete_io(mdev, peer_req->i.sector);
#line 1123
    put_ldev(mdev);
  } else {

  }
#line 1126
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 352U) {
#line 1127
    err = drbd_send_ack(mdev, P_RS_CANCEL, peer_req);
  } else {
#line 1128
    tmp___4 = __builtin_expect((peer_req->flags & 8UL) == 0UL, 1L);
#line 1128
    if (tmp___4 != 0L) {
#line 1129
      tmp___2 = __builtin_expect((int )mdev->state.ldv_49522.pdsk > 3, 1L);
#line 1129
      if (tmp___2 != 0L) {
#line 1130
        inc_rs_pending(mdev);
#line 1131
        err = drbd_send_block(mdev, P_RS_DATA_REPLY, peer_req);
      } else {
#line 1133
        tmp___1 = ___ratelimit(& drbd_ratelimit_state, "w_e_end_rsdata_req");
#line 1133
        if (tmp___1 != 0) {
#line 1134
          dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Not sending RSDataReply, partner DISKLESS!\n");
        } else {

        }
#line 1136
        err = 0;
      }
    } else {
#line 1139
      tmp___3 = ___ratelimit(& drbd_ratelimit_state, "w_e_end_rsdata_req");
#line 1139
      if (tmp___3 != 0) {
#line 1140
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Sending NegRSDReply. sector %llus.\n",
                (unsigned long long )peer_req->i.sector);
      } else {

      }
#line 1143
      err = drbd_send_ack(mdev, P_NEG_RS_DREPLY, peer_req);
#line 1146
      drbd_rs_failed_io(mdev, peer_req->i.sector, (int )peer_req->i.size);
    }
  }
#line 1149
  _dec_unacked(mdev, "w_e_end_rsdata_req", 1149);
#line 1151
  move_to_net_ee_or_free(mdev, peer_req);
#line 1153
  tmp___5 = __builtin_expect(err != 0, 0L);
#line 1153
  if (tmp___5 != 0L) {
#line 1154
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_send_block() failed\n");
  } else {

  }
#line 1155
  return (err);
}
}
#line 1158 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_e_end_csum_rs_req(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  struct digest_info *di ;
  int digest_size ;
  void *digest ;
  int err ;
  int eq ;
  long tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;
  long tmp___5 ;

  {
#line 1160
  __mptr = (struct drbd_work  const  *)w;
#line 1160
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1161
  mdev = w->ldv_49807.mdev;
#line 1164
  digest = 0;
#line 1165
  eq = 0;
#line 1167
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1167
  if (tmp != 0L) {
#line 1168
    __drbd_free_peer_req(mdev, peer_req, 0);
#line 1169
    _dec_unacked(mdev, "w_e_end_csum_rs_req", 1169);
#line 1170
    return (0);
  } else {

  }
#line 1173
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1173
  if (tmp___0 != 0) {
#line 1174
    drbd_rs_complete_io(mdev, peer_req->i.sector);
#line 1175
    put_ldev(mdev);
  } else {

  }
#line 1178
  di = peer_req->ldv_50726.digest;
#line 1180
  tmp___4 = __builtin_expect((peer_req->flags & 8UL) == 0UL, 1L);
#line 1180
  if (tmp___4 != 0L) {
#line 1184
    if ((unsigned long )(mdev->tconn)->csums_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 1185
      tmp___1 = crypto_hash_digestsize((mdev->tconn)->csums_tfm);
#line 1185
      digest_size = (int )tmp___1;
#line 1186
      if (di->digest_size != digest_size) {
#line 1186
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( digest_size == di->digest_size ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                1186);
      } else {

      }
#line 1187
      digest = kmalloc((size_t )digest_size, 16U);
    } else {

    }
#line 1189
    if ((unsigned long )digest != (unsigned long )((void *)0)) {
#line 1190
      drbd_csum_ee(mdev, (mdev->tconn)->csums_tfm, peer_req, digest);
#line 1191
      tmp___2 = memcmp((void const   *)digest, (void const   *)di->digest, (size_t )digest_size);
#line 1191
      eq = tmp___2 == 0;
#line 1192
      kfree((void const   *)digest);
    } else {

    }
#line 1195
    if (eq != 0) {
#line 1196
      __drbd_set_in_sync(mdev, peer_req->i.sector, (int )peer_req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                         1196U);
#line 1198
      mdev->rs_same_csum = mdev->rs_same_csum + (unsigned long )(peer_req->i.size >> 12);
#line 1199
      err = drbd_send_ack(mdev, P_RS_IS_IN_SYNC, peer_req);
    } else {
#line 1201
      inc_rs_pending(mdev);
#line 1202
      peer_req->ldv_50726.block_id = 0xffffffffffffffffULL;
#line 1203
      peer_req->flags = peer_req->flags & 0xffffffffffffffefUL;
#line 1204
      kfree((void const   *)di);
#line 1205
      err = drbd_send_block(mdev, P_RS_DATA_REPLY, peer_req);
    }
  } else {
#line 1208
    err = drbd_send_ack(mdev, P_NEG_RS_DREPLY, peer_req);
#line 1209
    tmp___3 = ___ratelimit(& drbd_ratelimit_state, "w_e_end_csum_rs_req");
#line 1209
    if (tmp___3 != 0) {
#line 1210
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Sending NegDReply. I guess it gets messy.\n");
    } else {

    }
  }
#line 1213
  _dec_unacked(mdev, "w_e_end_csum_rs_req", 1213);
#line 1214
  move_to_net_ee_or_free(mdev, peer_req);
#line 1216
  tmp___5 = __builtin_expect(err != 0, 0L);
#line 1216
  if (tmp___5 != 0L) {
#line 1217
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_send_block/ack() failed\n");
  } else {

  }
#line 1218
  return (err);
}
}
#line 1221 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_e_end_ov_req(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  sector_t sector ;
  unsigned int size ;
  int digest_size ;
  void *digest ;
  int err ;
  long tmp ;
  unsigned int tmp___0 ;
  long tmp___1 ;

  {
#line 1223
  __mptr = (struct drbd_work  const  *)w;
#line 1223
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1224
  mdev = w->ldv_49807.mdev;
#line 1225
  sector = peer_req->i.sector;
#line 1226
  size = peer_req->i.size;
#line 1229
  err = 0;
#line 1231
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1231
  if (tmp != 0L) {
#line 1232
    goto out;
  } else {

  }
#line 1234
  tmp___0 = crypto_hash_digestsize((mdev->tconn)->verify_tfm);
#line 1234
  digest_size = (int )tmp___0;
#line 1235
  digest = kmalloc((size_t )digest_size, 16U);
#line 1236
  if ((unsigned long )digest == (unsigned long )((void *)0)) {
#line 1237
    err = 1;
#line 1238
    goto out;
  } else {

  }
#line 1241
  tmp___1 = __builtin_expect((peer_req->flags & 8UL) == 0UL, 1L);
#line 1241
  if (tmp___1 != 0L) {
#line 1242
    drbd_csum_ee(mdev, (mdev->tconn)->verify_tfm, peer_req, digest);
  } else {
#line 1244
    memset(digest, 0, (size_t )digest_size);
  }
#line 1251
  __drbd_free_peer_req(mdev, peer_req, 0);
#line 1252
  peer_req = 0;
#line 1253
  inc_rs_pending(mdev);
#line 1254
  err = drbd_send_drequest_csum(mdev, sector, (int )size, digest, digest_size, P_OV_REPLY);
#line 1255
  if (err != 0) {
#line 1256
    _dec_rs_pending(mdev, "w_e_end_ov_req", 1256);
  } else {

  }
#line 1257
  kfree((void const   *)digest);
  out: ;
#line 1260
  if ((unsigned long )peer_req != (unsigned long )((struct drbd_peer_request *)0)) {
#line 1261
    __drbd_free_peer_req(mdev, peer_req, 0);
  } else {

  }
#line 1262
  _dec_unacked(mdev, "w_e_end_ov_req", 1262);
#line 1263
  return (err);
}
}
#line 1266 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_ov_out_of_sync_found(struct drbd_conf *mdev , sector_t sector , int size ) 
{ 


  {
#line 1268
  if (mdev->ov_last_oos_start + mdev->ov_last_oos_size == sector) {
#line 1269
    mdev->ov_last_oos_size = mdev->ov_last_oos_size + (sector_t )(size >> 9);
  } else {
#line 1271
    mdev->ov_last_oos_start = sector;
#line 1272
    mdev->ov_last_oos_size = (sector_t )(size >> 9);
  }
#line 1274
  __drbd_set_out_of_sync(mdev, sector, size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                         1274U);
#line 1275
  return;
}
}
#line 1277 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_e_end_ov_reply(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  struct digest_info *di ;
  void *digest ;
  sector_t sector ;
  unsigned int size ;
  int digest_size ;
  int err ;
  int eq ;
  bool stop_sector_reached ;
  long tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  bool tmp___4 ;

  {
#line 1279
  __mptr = (struct drbd_work  const  *)w;
#line 1279
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1280
  mdev = w->ldv_49807.mdev;
#line 1283
  sector = peer_req->i.sector;
#line 1284
  size = peer_req->i.size;
#line 1286
  eq = 0;
#line 1287
  stop_sector_reached = 0;
#line 1289
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1289
  if (tmp != 0L) {
#line 1290
    __drbd_free_peer_req(mdev, peer_req, 0);
#line 1291
    _dec_unacked(mdev, "w_e_end_ov_reply", 1291);
#line 1292
    return (0);
  } else {

  }
#line 1297
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1297
  if (tmp___0 != 0) {
#line 1298
    drbd_rs_complete_io(mdev, peer_req->i.sector);
#line 1299
    put_ldev(mdev);
  } else {

  }
#line 1302
  di = peer_req->ldv_50726.digest;
#line 1304
  tmp___3 = __builtin_expect((peer_req->flags & 8UL) == 0UL, 1L);
#line 1304
  if (tmp___3 != 0L) {
#line 1305
    tmp___1 = crypto_hash_digestsize((mdev->tconn)->verify_tfm);
#line 1305
    digest_size = (int )tmp___1;
#line 1306
    digest = kmalloc((size_t )digest_size, 16U);
#line 1307
    if ((unsigned long )digest != (unsigned long )((void *)0)) {
#line 1308
      drbd_csum_ee(mdev, (mdev->tconn)->verify_tfm, peer_req, digest);
#line 1310
      if (di->digest_size != digest_size) {
#line 1310
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( digest_size == di->digest_size ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                1310);
      } else {

      }
#line 1311
      tmp___2 = memcmp((void const   *)digest, (void const   *)di->digest, (size_t )digest_size);
#line 1311
      eq = tmp___2 == 0;
#line 1312
      kfree((void const   *)digest);
    } else {

    }
  } else {

  }
#line 1321
  __drbd_free_peer_req(mdev, peer_req, 0);
#line 1322
  if (eq == 0) {
#line 1323
    drbd_ov_out_of_sync_found(mdev, sector, (int )size);
  } else {
#line 1325
    ov_out_of_sync_print(mdev);
  }
#line 1327
  err = drbd_send_ack_ex(mdev, P_OV_RESULT, sector, (int )size, eq != 0 ? 4711ULL : 4712ULL);
#line 1330
  _dec_unacked(mdev, "w_e_end_ov_reply", 1330);
#line 1332
  mdev->ov_left = mdev->ov_left - 1UL;
#line 1335
  if ((mdev->ov_left & 512UL) != 0UL) {
#line 1336
    drbd_advance_rs_marks(mdev, mdev->ov_left);
  } else {

  }
#line 1338
  tmp___4 = verify_can_do_stop_sector(mdev);
#line 1338
  stop_sector_reached = (bool )((int )tmp___4 && (sector_t )(size >> 9) + sector >= mdev->ov_stop_sector);
#line 1341
  if (mdev->ov_left == 0UL || (int )stop_sector_reached) {
#line 1342
    ov_out_of_sync_print(mdev);
#line 1343
    drbd_resync_finished(mdev);
  } else {

  }
#line 1346
  return (err);
}
}
#line 1349 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_prev_work_done(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_wq_barrier *b ;
  struct drbd_work  const  *__mptr ;

  {
#line 1351
  __mptr = (struct drbd_work  const  *)w;
#line 1351
  b = (struct drbd_wq_barrier *)__mptr;
#line 1353
  complete(& b->done);
#line 1354
  return (0);
}
}
#line 1362 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int drbd_send_barrier(struct drbd_tconn *tconn ) 
{ 
  struct p_barrier *p ;
  struct drbd_socket *sock ;
  void *tmp ;
  int tmp___0 ;

  {
#line 1367
  sock = & tconn->data;
#line 1368
  tmp = conn_prepare_command(tconn, sock);
#line 1368
  p = (struct p_barrier *)tmp;
#line 1369
  if ((unsigned long )p == (unsigned long )((struct p_barrier *)0)) {
#line 1370
    return (-5);
  } else {

  }
#line 1371
  p->barrier = (u32 )tconn->send.current_epoch_nr;
#line 1372
  p->pad = 0U;
#line 1373
  tconn->send.current_epoch_writes = 0U;
#line 1375
  tmp___0 = conn_send_command(tconn, sock, P_BARRIER, 8U, 0, 0U);
#line 1375
  return (tmp___0);
}
}
#line 1378 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_send_write_hint(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_conf *mdev ;
  struct drbd_socket *sock ;
  void *tmp ;
  int tmp___0 ;

  {
#line 1380
  mdev = w->ldv_49807.mdev;
#line 1383
  if (cancel != 0) {
#line 1384
    return (0);
  } else {

  }
#line 1385
  sock = & (mdev->tconn)->data;
#line 1386
  tmp = drbd_prepare_command(mdev, sock);
#line 1386
  if ((unsigned long )tmp == (unsigned long )((void *)0)) {
#line 1387
    return (-5);
  } else {

  }
#line 1388
  tmp___0 = drbd_send_command(mdev, sock, P_UNPLUG_REMOTE, 0U, 0, 0U);
#line 1388
  return (tmp___0);
}
}
#line 1391 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static void re_init_if_first_write(struct drbd_tconn *tconn , unsigned int epoch ) 
{ 


  {
#line 1393
  if (! tconn->send.seen_any_write_yet) {
#line 1394
    tconn->send.seen_any_write_yet = 1;
#line 1395
    tconn->send.current_epoch_nr = (int )epoch;
#line 1396
    tconn->send.current_epoch_writes = 0U;
  } else {

  }
#line 1398
  return;
}
}
#line 1400 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static void maybe_send_barrier(struct drbd_tconn *tconn , unsigned int epoch ) 
{ 


  {
#line 1403
  if (! tconn->send.seen_any_write_yet) {
#line 1404
    return;
  } else {

  }
#line 1405
  if ((unsigned int )tconn->send.current_epoch_nr != epoch) {
#line 1406
    if (tconn->send.current_epoch_writes != 0U) {
#line 1407
      drbd_send_barrier(tconn);
    } else {

    }
#line 1408
    tconn->send.current_epoch_nr = (int )epoch;
  } else {

  }
#line 1410
  return;
}
}
#line 1412 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_send_out_of_sync(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_request *req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  struct drbd_tconn *tconn ;
  int err ;
  long tmp ;

  {
#line 1414
  __mptr = (struct drbd_work  const  *)w;
#line 1414
  req = (struct drbd_request *)__mptr;
#line 1415
  mdev = w->ldv_49807.mdev;
#line 1416
  tconn = mdev->tconn;
#line 1419
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1419
  if (tmp != 0L) {
#line 1420
    req_mod(req, SEND_CANCELED);
#line 1421
    return (0);
  } else {

  }
#line 1428
  maybe_send_barrier(tconn, req->epoch);
#line 1430
  err = drbd_send_out_of_sync(mdev, req);
#line 1431
  req_mod(req, OOS_HANDED_TO_NETWORK);
#line 1433
  return (err);
}
}
#line 1442 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_send_dblock(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_request *req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  struct drbd_tconn *tconn ;
  int err ;
  long tmp ;

  {
#line 1444
  __mptr = (struct drbd_work  const  *)w;
#line 1444
  req = (struct drbd_request *)__mptr;
#line 1445
  mdev = w->ldv_49807.mdev;
#line 1446
  tconn = mdev->tconn;
#line 1449
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1449
  if (tmp != 0L) {
#line 1450
    req_mod(req, SEND_CANCELED);
#line 1451
    return (0);
  } else {

  }
#line 1454
  re_init_if_first_write(tconn, req->epoch);
#line 1455
  maybe_send_barrier(tconn, req->epoch);
#line 1456
  tconn->send.current_epoch_writes = tconn->send.current_epoch_writes + 1U;
#line 1458
  err = drbd_send_dblock(mdev, req);
#line 1459
  req_mod(req, err != 0 ? SEND_FAILED : HANDED_OVER_TO_NETWORK);
#line 1461
  return (err);
}
}
#line 1470 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_send_read_req(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_request *req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  struct drbd_tconn *tconn ;
  int err ;
  long tmp ;

  {
#line 1472
  __mptr = (struct drbd_work  const  *)w;
#line 1472
  req = (struct drbd_request *)__mptr;
#line 1473
  mdev = w->ldv_49807.mdev;
#line 1474
  tconn = mdev->tconn;
#line 1477
  tmp = __builtin_expect(cancel != 0, 0L);
#line 1477
  if (tmp != 0L) {
#line 1478
    req_mod(req, SEND_CANCELED);
#line 1479
    return (0);
  } else {

  }
#line 1484
  maybe_send_barrier(tconn, req->epoch);
#line 1486
  err = drbd_send_drequest(mdev, 8, req->i.sector, (int )req->i.size, (u64 )req);
#line 1489
  req_mod(req, err != 0 ? SEND_FAILED : HANDED_OVER_TO_NETWORK);
#line 1491
  return (err);
}
}
#line 1494 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_restart_disk_io(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_request *req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;

  {
#line 1496
  __mptr = (struct drbd_work  const  *)w;
#line 1496
  req = (struct drbd_request *)__mptr;
#line 1497
  mdev = w->ldv_49807.mdev;
#line 1499
  if ((int )(req->master_bio)->bi_rw & 1 && ((unsigned long )req->rq_state & 4096UL) != 0UL) {
#line 1500
    drbd_al_begin_io(mdev, & req->i);
  } else {

  }
#line 1502
  drbd_req_make_private_bio(req, req->master_bio);
#line 1503
  (req->private_bio)->bi_bdev = (mdev->ldev)->backing_bdev;
#line 1504
  generic_make_request(req->private_bio);
#line 1506
  return (0);
}
}
#line 1509 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int _drbd_may_sync_now(struct drbd_conf *mdev ) 
{ 
  struct drbd_conf *odev ;
  int resync_after ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  bool _bool ;
  int tmp___1 ;

  {
#line 1511
  odev = mdev;
  ldv_52465: ;
#line 1515
  if ((unsigned long )odev->ldev == (unsigned long )((struct drbd_backing_dev *)0)) {
#line 1516
    return (1);
  } else {

  }
#line 1517
  rcu_read_lock___1();
#line 1518
  _________p1 = *((struct disk_conf * volatile  *)(& (odev->ldev)->disk_conf));
#line 1518
  tmp = debug_lockdep_rcu_enabled();
#line 1518
  if (tmp != 0 && ! __warned) {
#line 1518
    tmp___0 = rcu_read_lock_held();
#line 1518
    if (tmp___0 == 0 && 1) {
#line 1518
      __warned = 1;
#line 1518
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             1518, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1518
  resync_after = _________p1->resync_after;
#line 1519
  rcu_read_unlock___1();
#line 1520
  if (resync_after == -1) {
#line 1521
    return (1);
  } else {

  }
#line 1522
  odev = minor_to_mdev((unsigned int )resync_after);
#line 1523
  _bool = (unsigned long )odev != (unsigned long )((struct drbd_conf *)0);
#line 1523
  if (! _bool) {
#line 1523
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"odev", "_drbd_may_sync_now");
  } else {

  }
#line 1523
  if (_bool) {
#line 1523
    tmp___1 = 0;
  } else {
#line 1523
    tmp___1 = 1;
  }
#line 1523
  if (tmp___1) {
#line 1524
    return (1);
  } else {

  }
#line 1525
  if (((((int )odev->state.ldv_49522.conn > 15 && (int )odev->state.ldv_49522.conn <= 21) || (unsigned int )*((unsigned char *)odev + 750UL) != 0U) || (unsigned int )*((unsigned char *)odev + 750UL) != 0U) || (unsigned int )*((unsigned char *)odev + 750UL) != 0U) {
#line 1529
    return (0);
  } else {

  }
#line 1530
  goto ldv_52465;
}
}
#line 1539 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int _drbd_pause_after(struct drbd_conf *mdev ) 
{ 
  struct drbd_conf *odev ;
  int i ;
  int rv ;
  void *tmp ;
  union drbd_state __ns ;
  enum drbd_state_rv tmp___0 ;
  int tmp___1 ;
  void *tmp___2 ;

  {
#line 1542
  rv = 0;
#line 1544
  rcu_read_lock___1();
#line 1545
  i = 0;
#line 1545
  tmp = idr_get_next(& minors, & i);
#line 1545
  odev = (struct drbd_conf *)tmp;
#line 1545
  goto ldv_52476;
  ldv_52475: ;
#line 1546
  if ((unsigned int )*((unsigned short *)odev + 374UL) == 0U && (unsigned int )*((unsigned char *)odev + 749UL) == 0U) {
#line 1547
    goto ldv_52472;
  } else {

  }
#line 1548
  tmp___1 = _drbd_may_sync_now(odev);
#line 1548
  if (tmp___1 == 0) {
#line 1549
    __ns = drbd_read_state(odev);
#line 1549
    __ns.ldv_40024.aftr_isp = 1U;
#line 1549
    tmp___0 = __drbd_set_state(odev, __ns, CS_HARD, 0);
#line 1549
    rv = ((int )tmp___0 != 2) | rv;
  } else {

  }
  ldv_52472: 
#line 1545
  i = i + 1;
#line 1545
  tmp___2 = idr_get_next(& minors, & i);
#line 1545
  odev = (struct drbd_conf *)tmp___2;
  ldv_52476: ;
#line 1545
  if ((unsigned long )odev != (unsigned long )((struct drbd_conf *)0)) {
#line 1546
    goto ldv_52475;
  } else {

  }
#line 1552
  rcu_read_unlock___1();
#line 1554
  return (rv);
}
}
#line 1563 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
static int _drbd_resume_next(struct drbd_conf *mdev ) 
{ 
  struct drbd_conf *odev ;
  int i ;
  int rv ;
  void *tmp ;
  union drbd_state __ns ;
  enum drbd_state_rv tmp___0 ;
  int tmp___1 ;
  void *tmp___2 ;

  {
#line 1566
  rv = 0;
#line 1568
  rcu_read_lock___1();
#line 1569
  i = 0;
#line 1569
  tmp = idr_get_next(& minors, & i);
#line 1569
  odev = (struct drbd_conf *)tmp;
#line 1569
  goto ldv_52488;
  ldv_52487: ;
#line 1570
  if ((unsigned int )*((unsigned short *)odev + 374UL) == 0U && (unsigned int )*((unsigned char *)odev + 749UL) == 0U) {
#line 1571
    goto ldv_52484;
  } else {

  }
#line 1572
  if ((unsigned int )*((unsigned char *)odev + 750UL) != 0U) {
#line 1573
    tmp___1 = _drbd_may_sync_now(odev);
#line 1573
    if (tmp___1 != 0) {
#line 1574
      __ns = drbd_read_state(odev);
#line 1574
      __ns.ldv_40024.aftr_isp = 0U;
#line 1574
      tmp___0 = __drbd_set_state(odev, __ns, CS_HARD, 0);
#line 1574
      rv = ((int )tmp___0 != 2) | rv;
    } else {

    }
  } else {

  }
  ldv_52484: 
#line 1569
  i = i + 1;
#line 1569
  tmp___2 = idr_get_next(& minors, & i);
#line 1569
  odev = (struct drbd_conf *)tmp___2;
  ldv_52488: ;
#line 1569
  if ((unsigned long )odev != (unsigned long )((struct drbd_conf *)0)) {
#line 1570
    goto ldv_52487;
  } else {

  }
#line 1579
  rcu_read_unlock___1();
#line 1580
  return (rv);
}
}
#line 1583 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void resume_next_sg(struct drbd_conf *mdev ) 
{ 


  {
#line 1585
  _raw_write_lock_irq(& global_state_lock);
#line 1586
  _drbd_resume_next(mdev);
#line 1587
  _raw_write_unlock_irq(& global_state_lock);
#line 1588
  return;
}
}
#line 1590 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void suspend_other_sg(struct drbd_conf *mdev ) 
{ 


  {
#line 1592
  _raw_write_lock_irq(& global_state_lock);
#line 1593
  _drbd_pause_after(mdev);
#line 1594
  _raw_write_unlock_irq(& global_state_lock);
#line 1595
  return;
}
}
#line 1598 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
enum drbd_ret_code drbd_resync_after_valid(struct drbd_conf *mdev , int o_minor ) 
{ 
  struct drbd_conf *odev ;
  int resync_after ;
  struct drbd_conf *tmp ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 1603
  if (o_minor == -1) {
#line 1604
    return (NO_ERROR);
  } else {

  }
#line 1605
  if (o_minor < -1) {
#line 1606
    return (ERR_RESYNC_AFTER);
  } else {
#line 1605
    tmp = minor_to_mdev((unsigned int )o_minor);
#line 1605
    if ((unsigned long )tmp == (unsigned long )((struct drbd_conf *)0)) {
#line 1606
      return (ERR_RESYNC_AFTER);
    } else {

    }
  }
#line 1609
  odev = minor_to_mdev((unsigned int )o_minor);
  ldv_52505: ;
#line 1611
  if ((unsigned long )odev == (unsigned long )mdev) {
#line 1612
    return (ERR_RESYNC_AFTER_CYCLE);
  } else {

  }
#line 1614
  rcu_read_lock___1();
#line 1615
  _________p1 = *((struct disk_conf * volatile  *)(& (odev->ldev)->disk_conf));
#line 1615
  tmp___0 = debug_lockdep_rcu_enabled();
#line 1615
  if (tmp___0 != 0 && ! __warned) {
#line 1615
    tmp___1 = rcu_read_lock_held();
#line 1615
    if (tmp___1 == 0 && 1) {
#line 1615
      __warned = 1;
#line 1615
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             1615, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1615
  resync_after = _________p1->resync_after;
#line 1616
  rcu_read_unlock___1();
#line 1618
  if (resync_after == -1) {
#line 1619
    return (NO_ERROR);
  } else {

  }
#line 1622
  odev = minor_to_mdev((unsigned int )resync_after);
#line 1623
  goto ldv_52505;
}
}
#line 1627 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_resync_after_changed(struct drbd_conf *mdev ) 
{ 
  int changes ;
  int tmp ;

  {
  ldv_52510: 
#line 1632
  changes = _drbd_pause_after(mdev);
#line 1633
  tmp = _drbd_resume_next(mdev);
#line 1633
  changes = tmp | changes;
#line 1634
  if (changes != 0) {
#line 1635
    goto ldv_52510;
  } else {

  }

#line 1639
  return;
}
}
#line 1637 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_rs_controller_reset(struct drbd_conf *mdev ) 
{ 
  struct fifo_buffer *plan ;
  struct fifo_buffer *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 1641
  atomic_set(& mdev->rs_sect_in, 0);
#line 1642
  atomic_set(& mdev->rs_sect_ev, 0);
#line 1643
  mdev->rs_in_flight = 0;
#line 1649
  rcu_read_lock___1();
#line 1650
  _________p1 = *((struct fifo_buffer * volatile  *)(& mdev->rs_plan_s));
#line 1650
  tmp = debug_lockdep_rcu_enabled();
#line 1650
  if (tmp != 0 && ! __warned) {
#line 1650
    tmp___0 = rcu_read_lock_held();
#line 1650
    if (tmp___0 == 0 && 1) {
#line 1650
      __warned = 1;
#line 1650
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             1650, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1650
  plan = _________p1;
#line 1651
  plan->total = 0;
#line 1652
  fifo_set(plan, 0);
#line 1653
  rcu_read_unlock___1();
#line 1654
  return;
}
}
#line 1656 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void start_resync_timer_fn(unsigned long data ) 
{ 
  struct drbd_conf *mdev ;

  {
#line 1658
  mdev = (struct drbd_conf *)data;
#line 1660
  drbd_queue_work(& (mdev->tconn)->sender_work, & mdev->start_resync_work);
#line 1661
  return;
}
}
#line 1663 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int w_start_resync(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_conf *mdev ;
  int tmp ;
  int tmp___0 ;

  {
#line 1665
  mdev = w->ldv_49807.mdev;
#line 1667
  tmp = atomic_read((atomic_t const   *)(& mdev->unacked_cnt));
#line 1667
  if (tmp != 0) {
#line 1668
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "w_start_resync later...\n");
#line 1669
    mdev->start_resync_timer.expires = (unsigned long )jiffies + 25UL;
#line 1670
    add_timer(& mdev->start_resync_timer);
#line 1671
    return (0);
  } else {
#line 1667
    tmp___0 = atomic_read((atomic_t const   *)(& mdev->rs_pending_cnt));
#line 1667
    if (tmp___0 != 0) {
#line 1668
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "w_start_resync later...\n");
#line 1669
      mdev->start_resync_timer.expires = (unsigned long )jiffies + 25UL;
#line 1670
      add_timer(& mdev->start_resync_timer);
#line 1671
      return (0);
    } else {

    }
  }
#line 1674
  drbd_start_resync(mdev, C_SYNC_SOURCE);
#line 1675
  clear_bit(19, (unsigned long volatile   *)(& mdev->flags));
#line 1676
  return (0);
}
}
#line 1687 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void drbd_start_resync(struct drbd_conf *mdev , enum drbd_conns side ) 
{ 
  union drbd_state ns ;
  int r ;
  union drbd_state val ;
  union drbd_state mask ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;
  int tmp ;
  int tmp___0 ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  enum drbd_state_rv tmp___4 ;
  unsigned long tw ;
  unsigned long tmp___5 ;
  unsigned long now ;
  int i ;
  char const   *tmp___6 ;
  struct net_conf *nc ;
  int timeo ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___7 ;
  int tmp___8 ;

  {
#line 1692
  if ((int )mdev->state.ldv_49522.conn > 15 && (int )mdev->state.ldv_49522.conn <= 21) {
#line 1693
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Resync already running!\n");
#line 1694
    return;
  } else {

  }
#line 1697
  tmp = constant_test_bit(20U, (unsigned long const volatile   *)(& mdev->flags));
#line 1697
  if (tmp == 0) {
#line 1698
    if ((unsigned int )side == 17U) {
#line 1702
      r = drbd_khelper(mdev, (char *)"before-resync-target");
#line 1703
      r = (r >> 8) & 255;
#line 1704
      if (r > 0) {
#line 1705
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "before-resync-target handler returned %d, dropping connection.\n",
                  r);
#line 1707
        val.i = 0U;
#line 1707
        val.ldv_40024.conn = 1U;
#line 1707
        mask.i = 0U;
#line 1707
        mask.ldv_40024.conn = 31U;
#line 1707
        conn_request_state(mdev->tconn, mask, val, CS_HARD);
#line 1708
        return;
      } else {

      }
    } else {
#line 1711
      r = drbd_khelper(mdev, (char *)"before-resync-source");
#line 1712
      r = (r >> 8) & 255;
#line 1713
      if (r > 0) {
#line 1714
        if (r == 3) {
#line 1715
          _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "before-resync-source handler returned %d, ignoring. Old userland tools?",
                    r);
        } else {
#line 1718
          _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "before-resync-source handler returned %d, dropping connection.\n",
                    r);
#line 1720
          val___0.i = 0U;
#line 1720
          val___0.ldv_40024.conn = 1U;
#line 1720
          mask___0.i = 0U;
#line 1720
          mask___0.ldv_40024.conn = 31U;
#line 1720
          conn_request_state(mdev->tconn, mask___0, val___0, CS_HARD);
#line 1721
          return;
        }
      } else {

      }
    }
  } else {

  }
#line 1727
  tmp___1 = get_current();
#line 1727
  if ((unsigned long )tmp___1 == (unsigned long )(mdev->tconn)->worker.task) {
#line 1730
    tmp___0 = ldv_mutex_trylock_64(mdev->state_mutex);
#line 1730
    if (tmp___0 == 0) {
#line 1731
      set_bit(20U, (unsigned long volatile   *)(& mdev->flags));
#line 1732
      mdev->start_resync_timer.expires = (unsigned long )jiffies + 50UL;
#line 1733
      add_timer(& mdev->start_resync_timer);
#line 1734
      return;
    } else {
#line 1737
      ldv_mutex_lock_65(mdev->state_mutex);
    }
  } else {

  }
#line 1739
  clear_bit(20, (unsigned long volatile   *)(& mdev->flags));
#line 1741
  _raw_write_lock_irq(& global_state_lock);
#line 1742
  tmp___2 = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 1742
  if (tmp___2 == 0) {
#line 1743
    _raw_write_unlock_irq(& global_state_lock);
#line 1744
    ldv_mutex_unlock_66(mdev->state_mutex);
#line 1745
    return;
  } else {

  }
#line 1748
  ns = drbd_read_state(mdev);
#line 1750
  tmp___3 = _drbd_may_sync_now(mdev);
#line 1750
  ns.ldv_40024.aftr_isp = tmp___3 == 0;
#line 1752
  ns.ldv_40024.conn = (unsigned char )side;
#line 1754
  if ((unsigned int )side == 17U) {
#line 1755
    ns.ldv_40024.disk = 4U;
  } else {
#line 1757
    ns.ldv_40024.pdsk = 4U;
  }
#line 1759
  tmp___4 = __drbd_set_state(mdev, ns, CS_VERBOSE, 0);
#line 1759
  r = (int )tmp___4;
#line 1760
  ns = drbd_read_state(mdev);
#line 1762
  if ((int )ns.ldv_40024.conn <= 9) {
#line 1763
    r = 0;
  } else {

  }
#line 1765
  if (r == 1) {
#line 1766
    tmp___5 = drbd_bm_total_weight(mdev);
#line 1766
    tw = tmp___5;
#line 1767
    now = jiffies;
#line 1770
    mdev->rs_failed = 0UL;
#line 1771
    mdev->rs_paused = 0UL;
#line 1772
    mdev->rs_same_csum = 0UL;
#line 1773
    mdev->rs_last_events = 0;
#line 1774
    mdev->rs_last_sect_ev = 0;
#line 1775
    mdev->rs_total = tw;
#line 1776
    mdev->rs_start = now;
#line 1777
    i = 0;
#line 1777
    goto ldv_52546;
    ldv_52545: 
#line 1778
    mdev->rs_mark_left[i] = tw;
#line 1779
    mdev->rs_mark_time[i] = now;
#line 1777
    i = i + 1;
    ldv_52546: ;
#line 1777
    if (i <= 7) {
#line 1778
      goto ldv_52545;
    } else {

    }
#line 1781
    _drbd_pause_after(mdev);
  } else {

  }
#line 1783
  _raw_write_unlock_irq(& global_state_lock);
#line 1785
  if (r == 1) {
#line 1788
    mdev->rs_last_bcast = (unsigned long )jiffies - 250UL;
#line 1790
    tmp___6 = drbd_conn_str((enum drbd_conns )ns.ldv_40024.conn);
#line 1790
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Began resync as %s (will sync %lu KB [%lu bits set]).\n",
              tmp___6, mdev->rs_total << 2, mdev->rs_total);
#line 1794
    if ((unsigned int )side == 17U) {
#line 1795
      mdev->bm_resync_fo = 0UL;
    } else {

    }
#line 1804
    if ((unsigned int )side == 16U && (mdev->tconn)->agreed_pro_version <= 95) {
#line 1805
      drbd_gen_and_send_sync_uuid(mdev);
    } else {

    }
#line 1807
    if ((mdev->tconn)->agreed_pro_version <= 94 && mdev->rs_total == 0UL) {
#line 1818
      if ((unsigned int )side == 16U) {
#line 1822
        rcu_read_lock___1();
#line 1823
        _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 1823
        tmp___7 = debug_lockdep_rcu_enabled();
#line 1823
        if (tmp___7 != 0 && ! __warned) {
#line 1823
          tmp___8 = rcu_read_lock_held();
#line 1823
          if (tmp___8 == 0 && 1) {
#line 1823
            __warned = 1;
#line 1823
            lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                                   1823, "suspicious rcu_dereference_check() usage");
          } else {

          }
        } else {

        }
#line 1823
        nc = _________p1;
#line 1824
        timeo = (int )(nc->ping_int * 250U + (nc->ping_timeo * 250U) / 9U);
#line 1825
        rcu_read_unlock___1();
#line 1826
        schedule_timeout_interruptible((long )timeo);
      } else {

      }
#line 1828
      drbd_resync_finished(mdev);
    } else {

    }
#line 1831
    drbd_rs_controller_reset(mdev);
#line 1836
    if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 272U) {
#line 1837
      mod_timer(& mdev->resync_timer, jiffies);
    } else {

    }
#line 1839
    drbd_md_sync(mdev);
  } else {

  }
#line 1841
  put_ldev(mdev);
#line 1842
  ldv_mutex_unlock_67(mdev->state_mutex);
#line 1843
  return;
}
}
#line 1849 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
bool need_to_send_barrier(struct drbd_tconn *connection ) 
{ 
  int tmp ;

  {
#line 1851
  if (! connection->send.seen_any_write_yet) {
#line 1852
    return (0);
  } else {

  }
#line 1856
  if (connection->send.current_epoch_writes == 0U) {
#line 1857
    return (0);
  } else {

  }
#line 1866
  tmp = atomic_read((atomic_t const   *)(& connection->current_tle_nr));
#line 1866
  if (tmp != connection->send.current_epoch_nr + 1) {
#line 1868
    return (0);
  } else {

  }
#line 1870
  return (1);
}
}
#line 1873 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
bool dequeue_work_batch(struct drbd_work_queue *queue , struct list_head *work_list ) 
{ 
  int tmp ;

  {
#line 1875
  spin_lock_irq(& queue->q_lock);
#line 1876
  list_splice_init(& queue->q, work_list);
#line 1877
  spin_unlock_irq(& queue->q_lock);
#line 1878
  tmp = list_empty((struct list_head  const  *)work_list);
#line 1878
  return (tmp == 0);
}
}
#line 1881 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
bool dequeue_work_item(struct drbd_work_queue *queue , struct list_head *work_list ) 
{ 
  int tmp ;
  int tmp___0 ;

  {
#line 1883
  spin_lock_irq(& queue->q_lock);
#line 1884
  tmp = list_empty((struct list_head  const  *)(& queue->q));
#line 1884
  if (tmp == 0) {
#line 1885
    list_move(queue->q.next, work_list);
  } else {

  }
#line 1886
  spin_unlock_irq(& queue->q_lock);
#line 1887
  tmp___0 = list_empty((struct list_head  const  *)work_list);
#line 1887
  return (tmp___0 == 0);
}
}
#line 1890 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void wait_for_work(struct drbd_tconn *connection , struct list_head *work_list ) 
{ 
  wait_queue_t wait ;
  struct task_struct *tmp ;
  struct net_conf *nc ;
  int uncork ;
  int cork ;
  int tmp___0 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___1 ;
  int tmp___2 ;
  int send_barrier ;
  int tmp___3 ;
  int tmp___4 ;
  struct task_struct *tmp___5 ;
  int tmp___6 ;
  bool tmp___7 ;
  struct net_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___8 ;
  int tmp___9 ;

  {
#line 1892
  tmp = get_current();
#line 1892
  wait.flags = 0U;
#line 1892
  wait.private = (void *)tmp;
#line 1892
  wait.func = & autoremove_wake_function;
#line 1892
  wait.task_list.next = & wait.task_list;
#line 1892
  wait.task_list.prev = & wait.task_list;
#line 1896
  dequeue_work_item(& connection->sender_work, work_list);
#line 1897
  tmp___0 = list_empty((struct list_head  const  *)work_list);
#line 1897
  if (tmp___0 == 0) {
#line 1898
    return;
  } else {

  }
#line 1906
  rcu_read_lock___1();
#line 1907
  _________p1 = *((struct net_conf * volatile  *)(& connection->net_conf));
#line 1907
  tmp___1 = debug_lockdep_rcu_enabled();
#line 1907
  if (tmp___1 != 0 && ! __warned) {
#line 1907
    tmp___2 = rcu_read_lock_held();
#line 1907
    if (tmp___2 == 0 && 1) {
#line 1907
      __warned = 1;
#line 1907
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             1907, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1907
  nc = _________p1;
#line 1908
  uncork = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (int )nc->tcp_cork : 0;
#line 1909
  rcu_read_unlock___1();
#line 1910
  if (uncork != 0) {
#line 1911
    ldv_mutex_lock_68(& connection->data.mutex);
#line 1912
    if ((unsigned long )connection->data.socket != (unsigned long )((struct socket *)0)) {
#line 1913
      drbd_tcp_uncork(connection->data.socket);
    } else {

    }
#line 1914
    ldv_mutex_unlock_69(& connection->data.mutex);
  } else {

  }
  ldv_52577: 
#line 1919
  prepare_to_wait(& connection->sender_work.q_wait, & wait, 1);
#line 1920
  spin_lock_irq(& connection->req_lock);
#line 1921
  spin_lock(& connection->sender_work.q_lock);
#line 1924
  tmp___3 = list_empty((struct list_head  const  *)(& connection->sender_work.q));
#line 1924
  if (tmp___3 == 0) {
#line 1925
    list_move(connection->sender_work.q.next, work_list);
  } else {

  }
#line 1926
  spin_unlock(& connection->sender_work.q_lock);
#line 1927
  tmp___4 = list_empty((struct list_head  const  *)work_list);
#line 1927
  if (tmp___4 == 0) {
#line 1928
    spin_unlock_irq(& connection->req_lock);
#line 1929
    goto ldv_52576;
  } else {
#line 1927
    tmp___5 = get_current();
#line 1927
    tmp___6 = signal_pending(tmp___5);
#line 1927
    if (tmp___6 != 0) {
#line 1928
      spin_unlock_irq(& connection->req_lock);
#line 1929
      goto ldv_52576;
    } else {

    }
  }
#line 1931
  tmp___7 = need_to_send_barrier(connection);
#line 1931
  send_barrier = (int )tmp___7;
#line 1932
  spin_unlock_irq(& connection->req_lock);
#line 1933
  if (send_barrier != 0) {
#line 1934
    drbd_send_barrier(connection);
#line 1935
    connection->send.current_epoch_nr = connection->send.current_epoch_nr + 1;
  } else {

  }
#line 1937
  schedule();
#line 1941
  goto ldv_52577;
  ldv_52576: 
#line 1942
  finish_wait(& connection->sender_work.q_wait, & wait);
#line 1945
  rcu_read_lock___1();
#line 1946
  _________p1___0 = *((struct net_conf * volatile  *)(& connection->net_conf));
#line 1946
  tmp___8 = debug_lockdep_rcu_enabled();
#line 1946
  if (tmp___8 != 0 && ! __warned___0) {
#line 1946
    tmp___9 = rcu_read_lock_held();
#line 1946
    if (tmp___9 == 0 && 1) {
#line 1946
      __warned___0 = 1;
#line 1946
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
                             1946, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1946
  nc = _________p1___0;
#line 1947
  cork = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (int )nc->tcp_cork : 0;
#line 1948
  rcu_read_unlock___1();
#line 1949
  ldv_mutex_lock_70(& connection->data.mutex);
#line 1950
  if ((unsigned long )connection->data.socket != (unsigned long )((struct socket *)0)) {
#line 1951
    if (cork != 0) {
#line 1952
      drbd_tcp_cork(connection->data.socket);
    } else
#line 1953
    if (uncork == 0) {
#line 1954
      drbd_tcp_uncork(connection->data.socket);
    } else {

    }
  } else {

  }
#line 1956
  ldv_mutex_unlock_71(& connection->data.mutex);
#line 1957
  return;
}
}
#line 1959 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int drbd_worker(struct drbd_thread *thi ) 
{ 
  struct drbd_tconn *tconn ;
  struct drbd_work *w ;
  struct drbd_conf *mdev ;
  struct list_head work_list ;
  int vnr ;
  int tmp ;
  struct task_struct *tmp___0 ;
  enum drbd_thread_state tmp___1 ;
  struct task_struct *tmp___2 ;
  int tmp___3 ;
  enum drbd_thread_state tmp___4 ;
  struct list_head  const  *__mptr ;
  int tmp___5 ;
  union drbd_state val ;
  union drbd_state mask ;
  int tmp___6 ;
  enum drbd_thread_state tmp___7 ;
  struct list_head  const  *__mptr___0 ;
  int tmp___8 ;
  int tmp___9 ;
  void *tmp___10 ;
  void *tmp___11 ;

  {
#line 1961
  tconn = thi->tconn;
#line 1962
  w = 0;
#line 1964
  work_list.next = & work_list;
#line 1964
  work_list.prev = & work_list;
#line 1967
  goto ldv_52589;
  ldv_52600: 
#line 1968
  drbd_thread_current_set_cpu(thi);
#line 1972
  tmp = list_empty((struct list_head  const  *)(& work_list));
#line 1972
  if (tmp != 0) {
#line 1973
    wait_for_work(tconn, & work_list);
  } else {

  }
#line 1975
  tmp___2 = get_current();
#line 1975
  tmp___3 = signal_pending(tmp___2);
#line 1975
  if (tmp___3 != 0) {
#line 1976
    tmp___0 = get_current();
#line 1976
    flush_signals(tmp___0);
#line 1977
    tmp___1 = get_t_state(thi);
#line 1977
    if ((unsigned int )tmp___1 == 1U) {
#line 1978
      printk("\fd-con %s: Worker got an unexpected signal\n", tconn->name);
#line 1979
      goto ldv_52589;
    } else {

    }
#line 1981
    goto ldv_52590;
  } else {

  }
#line 1984
  tmp___4 = get_t_state(thi);
#line 1984
  if ((unsigned int )tmp___4 != 1U) {
#line 1985
    goto ldv_52590;
  } else {

  }
#line 1987
  goto ldv_52593;
  ldv_52598: 
#line 1988
  __mptr = (struct list_head  const  *)work_list.next;
#line 1988
  w = (struct drbd_work *)__mptr;
#line 1989
  list_del_init(& w->list);
#line 1990
  tmp___5 = (*(w->cb))(w, (unsigned int )tconn->cstate <= 8U);
#line 1990
  if (tmp___5 == 0) {
#line 1991
    goto ldv_52593;
  } else {

  }
#line 1992
  if ((unsigned int )tconn->cstate > 8U) {
#line 1993
    val.i = 0U;
#line 1993
    val.ldv_40024.conn = 5U;
#line 1993
    mask.i = 0U;
#line 1993
    mask.ldv_40024.conn = 31U;
#line 1993
    conn_request_state(tconn, mask, val, CS_HARD);
  } else {

  }
  ldv_52593: 
#line 1987
  tmp___6 = list_empty((struct list_head  const  *)(& work_list));
#line 1987
  if (tmp___6 == 0) {
#line 1988
    goto ldv_52598;
  } else {

  }

  ldv_52589: 
#line 1967
  tmp___7 = get_t_state(thi);
#line 1967
  if ((unsigned int )tmp___7 == 1U) {
#line 1968
    goto ldv_52600;
  } else {

  }
  ldv_52590: ;
  ldv_52606: ;
#line 1998
  goto ldv_52604;
  ldv_52603: 
#line 1999
  __mptr___0 = (struct list_head  const  *)work_list.next;
#line 1999
  w = (struct drbd_work *)__mptr___0;
#line 2000
  list_del_init(& w->list);
#line 2001
  (*(w->cb))(w, 1);
  ldv_52604: 
#line 1998
  tmp___8 = list_empty((struct list_head  const  *)(& work_list));
#line 1998
  if (tmp___8 == 0) {
#line 1999
    goto ldv_52603;
  } else {

  }
#line 2003
  dequeue_work_batch(& tconn->sender_work, & work_list);
#line 2004
  tmp___9 = list_empty((struct list_head  const  *)(& work_list));
#line 2004
  if (tmp___9 == 0) {
#line 2005
    goto ldv_52606;
  } else {

  }
#line 2006
  rcu_read_lock___1();
#line 2007
  vnr = 0;
#line 2007
  tmp___10 = idr_get_next(& tconn->volumes, & vnr);
#line 2007
  mdev = (struct drbd_conf *)tmp___10;
#line 2007
  goto ldv_52609;
  ldv_52608: ;
#line 2008
  if ((unsigned int )*((unsigned char *)mdev + 749UL) != 0U || (unsigned int )*((unsigned short *)mdev + 374UL) != 0U) {
#line 2008
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->state.disk == D_DISKLESS && mdev->state.conn == C_STANDALONE ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared",
            2008);
  } else {

  }
#line 2009
  kref_get(& mdev->kref);
#line 2010
  rcu_read_unlock___1();
#line 2011
  drbd_mdev_cleanup(mdev);
#line 2012
  kref_put(& mdev->kref, & drbd_minor_destroy);
#line 2013
  rcu_read_lock___1();
#line 2007
  vnr = vnr + 1;
#line 2007
  tmp___11 = idr_get_next(& tconn->volumes, & vnr);
#line 2007
  mdev = (struct drbd_conf *)tmp___11;
  ldv_52609: ;
#line 2007
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 2008
    goto ldv_52608;
  } else {

  }
#line 2015
  rcu_read_unlock___1();
#line 2017
  return (0);
}
}
#line 2020 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_51(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2025
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 2027
  mutex_lock(ldv_func_arg1);
#line 2028
  return;
}
}
#line 2030 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_52(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2035
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 2037
  mutex_unlock(ldv_func_arg1);
#line 2038
  return;
}
}
#line 2040 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_53(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2045
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 2047
  mutex_lock(ldv_func_arg1);
#line 2048
  return;
}
}
#line 2050 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int ldv_mutex_trylock_54(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 2055
  tmp = mutex_trylock(ldv_func_arg1);
#line 2055
  ldv_func_res = tmp;
#line 2057
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 2057
  return (tmp___0);
#line 2059
  return (ldv_func_res);
}
}
#line 2062 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_55(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2067
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 2069
  mutex_unlock(ldv_func_arg1);
#line 2070
  return;
}
}
#line 2072 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_56(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2077
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2079
  mutex_lock(ldv_func_arg1);
#line 2080
  return;
}
}
#line 2082 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_57(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2087
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2089
  mutex_unlock(ldv_func_arg1);
#line 2090
  return;
}
}
#line 2092 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_58(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2097
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2099
  mutex_lock(ldv_func_arg1);
#line 2100
  return;
}
}
#line 2102 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_59(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2107
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2109
  mutex_unlock(ldv_func_arg1);
#line 2110
  return;
}
}
#line 2112 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_60(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2117
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 2119
  mutex_lock(ldv_func_arg1);
#line 2120
  return;
}
}
#line 2122 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_61(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2127
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 2129
  mutex_unlock(ldv_func_arg1);
#line 2130
  return;
}
}
#line 2132 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_62(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2137
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 2139
  mutex_lock(ldv_func_arg1);
#line 2140
  return;
}
}
#line 2142 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_63(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2147
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 2149
  mutex_unlock(ldv_func_arg1);
#line 2150
  return;
}
}
#line 2152 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
int ldv_mutex_trylock_64(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 2157
  tmp = mutex_trylock(ldv_func_arg1);
#line 2157
  ldv_func_res = tmp;
#line 2159
  tmp___0 = ldv_mutex_trylock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 2159
  return (tmp___0);
#line 2161
  return (ldv_func_res);
}
}
#line 2164 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_65(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2169
  ldv_mutex_lock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 2171
  mutex_lock(ldv_func_arg1);
#line 2172
  return;
}
}
#line 2174 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_66(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2179
  ldv_mutex_unlock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 2181
  mutex_unlock(ldv_func_arg1);
#line 2182
  return;
}
}
#line 2184 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_67(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2189
  ldv_mutex_unlock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 2191
  mutex_unlock(ldv_func_arg1);
#line 2192
  return;
}
}
#line 2194 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_68(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2199
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 2201
  mutex_lock(ldv_func_arg1);
#line 2202
  return;
}
}
#line 2204 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_69(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2209
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 2211
  mutex_unlock(ldv_func_arg1);
#line 2212
  return;
}
}
#line 2214 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_lock_70(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2219
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 2221
  mutex_lock(ldv_func_arg1);
#line 2222
  return;
}
}
#line 2224 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_worker.c.prepared"
void ldv_mutex_unlock_71(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2229
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 2231
  mutex_unlock(ldv_func_arg1);
#line 2232
  return;
}
}
#line 1 "<compiler builtins>"
void *__builtin_memcpy(void * , void const   * , unsigned long  ) ;
#line 7 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/swab.h"
__inline static __u32 __arch_swab32(__u32 val ) 
{ 


  {
#line 21
  __asm__  ("bswapl %0": "=r" (val): "0" (val));
#line 25
  return (val);
}
}
#line 29 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/swab.h"
__inline static __u64 __arch_swab64(__u64 val ) 
{ 


  {
#line 53
  __asm__  ("bswapq %0": "=r" (val): "0" (val));
#line 56
  return (val);
}
}
#line 46 "include/uapi/linux/swab.h"
__inline static __u16 __fswab16(__u16 val ) 
{ 


  {
#line 51
  return ((__u16 )((int )((short )((int )val << 8)) | (int )((short )((int )val >> 8))));
}
}
#line 55 "include/uapi/linux/swab.h"
__inline static __u32 __fswab32(__u32 val ) 
{ 
  __u32 tmp ;

  {
#line 58
  tmp = __arch_swab32(val);
#line 58
  return (tmp);
}
}
#line 64 "include/uapi/linux/swab.h"
__inline static __u64 __fswab64(__u64 val ) 
{ 
  __u64 tmp ;

  {
#line 67
  tmp = __arch_swab64(val);
#line 67
  return (tmp);
}
}
#line 177 "include/linux/printk.h"
extern void dump_stack(void) ;
#line 61 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page_64_types.h"
extern unsigned long __phys_addr(unsigned long  ) ;
#line 18 "include/asm-generic/percpu.h"
extern unsigned long __per_cpu_offset[4096U] ;
#line 61 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/string_64.h"
extern size_t strlen(char const   * ) ;
#line 62
extern char *strcpy(char * , char const   * ) ;
#line 64
extern int strcmp(char const   * , char const   * ) ;
#line 28 "include/linux/cpumask.h"
extern int nr_cpu_ids ;
#line 79
extern struct cpumask  const  * const  cpu_possible_mask ;
#line 105 "include/linux/cpumask.h"
__inline static unsigned int cpumask_check(unsigned int cpu ) 
{ 
  bool __warned ;
  int __ret_warn_once ;
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
#line 108
  __ret_warn_once = (unsigned int )nr_cpu_ids <= cpu;
#line 108
  tmp___1 = __builtin_expect(__ret_warn_once != 0, 0L);
#line 108
  if (tmp___1 != 0L) {
#line 108
    __ret_warn_on = ! __warned;
#line 108
    tmp = __builtin_expect(__ret_warn_on != 0, 0L);
#line 108
    if (tmp != 0L) {
#line 108
      warn_slowpath_null("include/linux/cpumask.h", 108);
    } else {

    }
#line 108
    tmp___0 = __builtin_expect(__ret_warn_on != 0, 0L);
#line 108
    if (tmp___0 != 0L) {
#line 108
      __warned = 1;
    } else {

    }
  } else {

  }
#line 108
  __builtin_expect(__ret_warn_once != 0, 0L);
#line 110
  return (cpu);
}
}
#line 170 "include/linux/cpumask.h"
__inline static unsigned int cpumask_next(int n , struct cpumask  const  *srcp ) 
{ 
  unsigned long tmp ;

  {
#line 173
  if (n != -1) {
#line 174
    cpumask_check((unsigned int )n);
  } else {

  }
#line 175
  tmp = find_next_bit((unsigned long const   *)(& srcp->bits), (unsigned long )nr_cpu_ids,
                      (unsigned long )(n + 1));
#line 175
  return ((unsigned int )tmp);
}
}
#line 27 "include/linux/err.h"
__inline static long PTR_ERR(void const   *ptr ) 
{ 


  {
#line 29
  return ((long )ptr);
}
}
#line 32 "include/linux/err.h"
__inline static long IS_ERR(void const   *ptr ) 
{ 
  long tmp ;

  {
#line 34
  tmp = __builtin_expect((unsigned long )ptr > 0xfffffffffffff000UL, 0L);
#line 34
  return (tmp);
}
}
#line 124 "include/linux/mutex.h"
__inline static int mutex_is_locked(struct mutex *lock ) 
{ 
  int tmp ;

  {
#line 126
  tmp = atomic_read((atomic_t const   *)(& lock->count));
#line 126
  return (tmp != 1);
}
}
#line 130
__inline static int ldv_mutex_is_locked_121(struct mutex *lock ) ;
#line 134
__inline static int ldv_mutex_is_locked_122(struct mutex *lock ) ;
#line 171
int ldv_mutex_trylock_96(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_94(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_97(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_99(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_101(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_103(struct mutex *ldv_func_arg1 ) ;
#line 196
void ldv_mutex_unlock_105(struct mutex *ldv_func_arg1 ) ;
#line 200
void ldv_mutex_unlock_107(struct mutex *ldv_func_arg1 ) ;
#line 204
void ldv_mutex_unlock_110(struct mutex *ldv_func_arg1 ) ;
#line 208
void ldv_mutex_unlock_111(struct mutex *ldv_func_arg1 ) ;
#line 212
void ldv_mutex_unlock_113(struct mutex *ldv_func_arg1 ) ;
#line 216
void ldv_mutex_unlock_114(struct mutex *ldv_func_arg1 ) ;
#line 220
void ldv_mutex_unlock_115(struct mutex *ldv_func_arg1 ) ;
#line 224
void ldv_mutex_unlock_116(struct mutex *ldv_func_arg1 ) ;
#line 228
void ldv_mutex_unlock_118(struct mutex *ldv_func_arg1 ) ;
#line 232
void ldv_mutex_unlock_120(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_93(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_95(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_98(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_100(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_102(struct mutex *ldv_func_arg1 ) ;
#line 30
void ldv_mutex_lock_104(struct mutex *ldv_func_arg1 ) ;
#line 34
void ldv_mutex_lock_106(struct mutex *ldv_func_arg1 ) ;
#line 38
void ldv_mutex_lock_108(struct mutex *ldv_func_arg1 ) ;
#line 42
void ldv_mutex_lock_109(struct mutex *ldv_func_arg1 ) ;
#line 46
void ldv_mutex_lock_112(struct mutex *ldv_func_arg1 ) ;
#line 50
void ldv_mutex_lock_117(struct mutex *ldv_func_arg1 ) ;
#line 54
void ldv_mutex_lock_119(struct mutex *ldv_func_arg1 ) ;
#line 67
void ldv_mutex_lock_conf_update_of_drbd_tconn(struct mutex *lock ) ;
#line 71
void ldv_mutex_unlock_conf_update_of_drbd_tconn(struct mutex *lock ) ;
#line 86
int ldv_mutex_is_locked_cstate_mutex_of_drbd_tconn(struct mutex *lock ) ;
#line 134
int ldv_mutex_is_locked_state_mutex_of_drbd_conf(struct mutex *lock ) ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info___2(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6396;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6396;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6396;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6396;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6396: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 21 "include/linux/rwlock_api_smp.h"
extern void _raw_write_lock_bh(rwlock_t * ) ;
#line 33
extern void _raw_write_unlock_bh(rwlock_t * ) ;
#line 73 "include/linux/completion.h"
__inline static void init_completion(struct completion *x ) 
{ 
  struct lock_class_key __key ;

  {
#line 75
  x->done = 0U;
#line 76
  __init_waitqueue_head(& x->wait, "&x->wait", & __key);
#line 78
  return;
}
}
#line 79
extern void wait_for_completion(struct completion * ) ;
#line 84
extern long wait_for_completion_interruptible_timeout(struct completion * , unsigned long  ) ;
#line 144 "include/linux/rcupdate.h"
extern void synchronize_sched(void) ;
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock___2(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info___2();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock___2(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info___2();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 173 "include/linux/rcupdate.h"
__inline static void synchronize_rcu(void) 
{ 


  {
#line 175
  synchronize_sched();
#line 176
  return;
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock___2(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock___2();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock___2(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock___2();
#line 763
  return;
}
}
#line 245 "include/linux/timer.h"
extern int del_timer_sync(struct timer_list * ) ;
#line 453 "include/linux/mm.h"
extern void put_page(struct page * ) ;
#line 57 "include/linux/scatterlist.h"
__inline static void sg_assign_page___0(struct scatterlist *sg , struct page *page ) 
{ 
  unsigned long page_link ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
#line 59
  page_link = sg->page_link & 3UL;
#line 65
  tmp = __builtin_expect(((unsigned long )page & 3UL) != 0UL, 0L);
#line 65
  if (tmp != 0L) {
#line 65
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (65), "i" (12UL));
    ldv_19264: ;
#line 65
    goto ldv_19264;
  } else {

  }
#line 67
  tmp___0 = __builtin_expect(sg->sg_magic != 2271560481UL, 0L);
#line 67
  if (tmp___0 != 0L) {
#line 67
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (67), "i" (12UL));
    ldv_19265: ;
#line 67
    goto ldv_19265;
  } else {

  }
#line 68
  tmp___1 = __builtin_expect((long )((int )sg->page_link) & 1L, 0L);
#line 68
  if (tmp___1 != 0L) {
#line 68
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/scatterlist.h"),
                         "i" (68), "i" (12UL));
    ldv_19266: ;
#line 68
    goto ldv_19266;
  } else {

  }
#line 70
  sg->page_link = page_link | (unsigned long )page;
#line 71
  return;
}
}
#line 87 "include/linux/scatterlist.h"
__inline static void sg_set_page___0(struct scatterlist *sg , struct page *page ,
                                     unsigned int len , unsigned int offset ) 
{ 


  {
#line 90
  sg_assign_page___0(sg, page);
#line 91
  sg->offset = offset;
#line 92
  sg->length = len;
#line 93
  return;
}
}
#line 111 "include/linux/scatterlist.h"
__inline static void sg_set_buf(struct scatterlist *sg , void const   *buf , unsigned int buflen ) 
{ 
  unsigned long tmp ;

  {
#line 114
  tmp = __phys_addr((unsigned long )buf);
#line 114
  sg_set_page___0(sg, 0xffffea0000000000UL + (tmp >> 12), buflen, (unsigned int )((long )buf) & 4095U);
#line 115
  return;
}
}
#line 263 "include/linux/sched.h"
extern void io_schedule(void) ;
#line 320
extern long schedule_timeout(long  ) ;
#line 323
extern long schedule_timeout_uninterruptible(long  ) ;
#line 17 "include/linux/random.h"
extern void get_random_bytes(void * , int  ) ;
#line 28
extern u32 random32(void) ;
#line 205 "include/linux/net.h"
extern int sock_create_kern(int  , int  , int  , struct socket ** ) ;
#line 209
extern void sock_release(struct socket * ) ;
#line 212
extern int sock_recvmsg(struct socket * , struct msghdr * , size_t  , int  ) ;
#line 255
extern int kernel_accept(struct socket * , struct socket ** , int  ) ;
#line 329 "include/linux/drbd.h"
char const   *drbd_set_st_err_str(enum drbd_state_rv err ) ;
#line 492 "include/linux/crypto.h"
extern struct crypto_tfm *crypto_alloc_base(char const   * , u32  , u32  ) ;
#line 495 "include/linux/crypto.h"
__inline static void crypto_free_tfm(struct crypto_tfm *tfm ) 
{ 


  {
#line 497
  return;
}
}
#line 1111 "include/linux/crypto.h"
__inline static struct crypto_hash *__crypto_hash_cast(struct crypto_tfm *tfm ) 
{ 


  {
#line 1113
  return ((struct crypto_hash *)tfm);
}
}
#line 1123 "include/linux/crypto.h"
__inline static struct crypto_hash *crypto_alloc_hash(char const   *alg_name , u32 type ,
                                                      u32 mask ) 
{ 
  struct crypto_tfm *tmp ;
  struct crypto_hash *tmp___0 ;

  {
#line 1126
  type = type & 4294967280U;
#line 1127
  mask = mask & 4294967280U;
#line 1128
  type = type | 8U;
#line 1129
  mask = mask | 14U;
#line 1131
  tmp = crypto_alloc_base(alg_name, type, mask);
#line 1131
  tmp___0 = __crypto_hash_cast(tmp);
#line 1131
  return (tmp___0);
}
}
#line 1139 "include/linux/crypto.h"
__inline static void crypto_free_hash(struct crypto_hash *tfm ) 
{ 
  struct crypto_tfm *tmp ;

  {
#line 1141
  tmp = crypto_hash_tfm(tfm);
#line 1141
  crypto_free_tfm(tmp);
#line 1142
  return;
}
}
#line 1206 "include/linux/crypto.h"
__inline static int crypto_hash_digest(struct hash_desc *desc , struct scatterlist *sg ,
                                       unsigned int nbytes , u8 *out ) 
{ 
  struct hash_tfm *tmp ;
  int tmp___0 ;

  {
#line 1210
  tmp = crypto_hash_crt(desc->tfm);
#line 1210
  tmp___0 = (*(tmp->digest))(desc, sg, nbytes, out);
#line 1210
  return (tmp___0);
}
}
#line 1213 "include/linux/crypto.h"
__inline static int crypto_hash_setkey(struct crypto_hash *hash , u8 const   *key ,
                                       unsigned int keylen ) 
{ 
  struct hash_tfm *tmp ;
  int tmp___0 ;

  {
#line 1216
  tmp = crypto_hash_crt(hash);
#line 1216
  tmp___0 = (*(tmp->setkey))(hash, key, keylen);
#line 1216
  return (tmp___0);
}
}
#line 443 "include/linux/genhd.h"
__inline static void set_capacity(struct gendisk *disk , sector_t size ) 
{ 


  {
#line 445
  disk->part0.nr_sects = size;
#line 446
  return;
}
}
#line 56 "include/linux/highmem.h"
__inline static void *kmap(struct page *page ) 
{ 
  void *tmp ;

  {
#line 58
  __might_sleep("include/linux/highmem.h", 58, 0);
#line 59
  tmp = lowmem_page_address((struct page  const  *)page);
#line 59
  return (tmp);
}
}
#line 62 "include/linux/highmem.h"
__inline static void kunmap(struct page *page ) 
{ 


  {
#line 64
  return;
}
}
#line 215 "include/linux/bio.h"
extern struct bio *bio_alloc_bioset(gfp_t  , int  , struct bio_set * ) ;
#line 223 "include/linux/bio.h"
__inline static struct bio *bio_alloc(gfp_t gfp_mask , unsigned int nr_iovecs ) 
{ 
  struct bio *tmp ;

  {
#line 225
  tmp = bio_alloc_bioset(gfp_mask, (int )nr_iovecs, fs_bio_set);
#line 225
  return (tmp);
}
}
#line 260 "include/linux/lru_cache.h"
extern struct lc_element *lc_find(struct lru_cache * , unsigned int  ) ;
#line 110 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_state.h"
enum drbd_state_rv drbd_change_state(struct drbd_conf *mdev , enum chg_state_flags f ,
                                     union drbd_state mask , union drbd_state val ) ;
#line 114
void drbd_force_state(struct drbd_conf *mdev , union drbd_state mask , union drbd_state val ) ;
#line 116
enum drbd_state_rv _drbd_request_state(struct drbd_conf *mdev , union drbd_state mask ,
                                       union drbd_state val , enum chg_state_flags f ) ;
#line 127
enum drbd_state_rv _conn_request_state(struct drbd_tconn *tconn , union drbd_state mask ,
                                       union drbd_state val , enum chg_state_flags flags ) ;
#line 154
enum drbd_role conn_highest_role(struct drbd_tconn *tconn ) ;
#line 158
enum drbd_disk_state conn_highest_pdsk(struct drbd_tconn *tconn ) ;
#line 65 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
unsigned int minor_count ;
#line 236
char const   *cmdname(enum drbd_packet cmd ) ;
#line 256
void INFO_bm_xfer_stats(struct drbd_conf *mdev , char const   *direction , struct bm_xfer_ctx *c ) ;
#line 259 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void bm_xfer_ctx_bit_to_word_offset(struct bm_xfer_ctx *c ) 
{ 


  {
#line 269
  c->word_offset = c->bit_offset >> 6;
#line 270
  return;
}
}
#line 313
unsigned int drbd_header_size(struct drbd_tconn *tconn ) ;
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_interval.h"
__inline static void drbd_clear_interval(struct drbd_interval *i ) 
{ 


  {
#line 18
  i->rb.__rb_parent_color = (unsigned long )(& i->rb);
#line 19
  return;
}
}
#line 21 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_interval.h"
__inline static bool drbd_interval_empty(struct drbd_interval *i ) 
{ 


  {
#line 23
  return (i->rb.__rb_parent_color == (unsigned long )(& i->rb));
}
}
#line 26
bool drbd_insert_interval(struct rb_root *root , struct drbd_interval *this ) ;
#line 27
bool drbd_contains_interval(struct rb_root *root , sector_t sector , struct drbd_interval *interval ) ;
#line 29
void drbd_remove_interval(struct rb_root *root , struct drbd_interval *this ) ;
#line 30
struct drbd_interval *drbd_find_overlap(struct rb_root *root , sector_t sector , unsigned int size ) ;
#line 32
struct drbd_interval *drbd_next_overlap(struct drbd_interval *i , sector_t sector ,
                                        unsigned int size ) ;
#line 546 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
int drbd_wait_misc(struct drbd_conf *mdev , struct drbd_interval *i ) ;
#line 1042 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static unsigned int mdev_to_minor(struct drbd_conf *mdev ) 
{ 


  {
#line 1044
  return (mdev->minor);
}
}
#line 1047 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static struct drbd_conf *vnr_to_mdev(struct drbd_tconn *tconn , int vnr ) 
{ 
  void *tmp ;

  {
#line 1049
  tmp = idr_find(& tconn->volumes, vnr);
#line 1049
  return ((struct drbd_conf *)tmp);
}
}
#line 1064
int drbd_thread_start(struct drbd_thread *thi ) ;
#line 1065
void _drbd_thread_stop(struct drbd_thread *thi , int restart , int wait ) ;
#line 1074
void tl_release(struct drbd_tconn *tconn , unsigned int barrier_nr , unsigned int set_size ) ;
#line 1076
void tl_clear(struct drbd_tconn *tconn ) ;
#line 1077
void drbd_free_sock(struct drbd_tconn *tconn ) ;
#line 1084
int drbd_send_protocol(struct drbd_tconn *tconn ) ;
#line 1085
int drbd_send_uuids(struct drbd_conf *mdev ) ;
#line 1088
int drbd_send_sizes(struct drbd_conf *mdev , int trigger_reply , enum dds_flags flags ) ;
#line 1090
int drbd_send_current_state(struct drbd_conf *mdev ) ;
#line 1091
int drbd_send_sync_param(struct drbd_conf *mdev ) ;
#line 1092
void drbd_send_b_ack(struct drbd_tconn *tconn , u32 barrier_nr , u32 set_size ) ;
#line 1096
void drbd_send_ack_rp(struct drbd_conf *mdev , enum drbd_packet cmd , struct p_block_req *rp ) ;
#line 1098
void drbd_send_ack_dp(struct drbd_conf *mdev , enum drbd_packet cmd , struct p_data *dp ,
                      int data_size ) ;
#line 1113
int drbd_send_bitmap(struct drbd_conf *mdev ) ;
#line 1114
void drbd_send_sr_reply(struct drbd_conf *mdev , enum drbd_state_rv retcode ) ;
#line 1115
void conn_send_sr_reply(struct drbd_tconn *tconn , enum drbd_state_rv retcode ) ;
#line 1120
void conn_md_sync(struct drbd_tconn *tconn ) ;
#line 1125
void drbd_uuid_new_current(struct drbd_conf *mdev ) ;
#line 1127
void drbd_uuid_move_history(struct drbd_conf *mdev ) ;
#line 1128
void __drbd_uuid_set(struct drbd_conf *mdev , int idx , u64 val ) ;
#line 1143
int drbd_bitmap_io(struct drbd_conf *mdev , int (*io_fn)(struct drbd_conf * ) , char *why ,
                   enum bm_flag flags ) ;
#line 1149
int drbd_bmio_set_n_write(struct drbd_conf *mdev ) ;
#line 1150
int drbd_bmio_clear_n_write(struct drbd_conf *mdev ) ;
#line 1370
mempool_t *drbd_ee_mempool ;
#line 1385
struct page *drbd_pp_pool ;
#line 1386
spinlock_t drbd_pp_lock ;
#line 1387
int drbd_pp_vacant ;
#line 1433
sector_t drbd_new_dev_size(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ,
                           sector_t u_size , int assume_peer_has_space ) ;
#line 1435
enum determine_dev_size drbd_determine_dev_size(struct drbd_conf *mdev , enum dds_flags flags ) ;
#line 1436
void resync_after_online_grow(struct drbd_conf *mdev ) ;
#line 1437
void drbd_reconsider_max_bio_size(struct drbd_conf *mdev ) ;
#line 1438
enum drbd_state_rv drbd_set_role(struct drbd_conf *mdev , enum drbd_role new_role ,
                                 int force ) ;
#line 1442
void conn_try_outdate_peer_async(struct drbd_tconn *tconn ) ;
#line 1503
int drbd_free_peer_reqs(struct drbd_conf *mdev , struct list_head *list ) ;
#line 1511
struct page *drbd_alloc_pages(struct drbd_conf *mdev , unsigned int number , bool retry___0 ) ;
#line 1514
void conn_flush_workqueue(struct drbd_tconn *tconn ) ;
#line 1515
int drbd_connected(struct drbd_conf *mdev ) ;
#line 1516 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_flush_workqueue(struct drbd_conf *mdev ) 
{ 


  {
#line 1518
  conn_flush_workqueue(mdev->tconn);
#line 1519
  return;
}
}
#line 1523 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_setsockopt___0(struct socket *sock , int level , int optname ,
                                        char *optval , int optlen ) 
{ 
  mm_segment_t oldfs ;
  struct thread_info *tmp ;
  char *uoptval ;
  int err ;
  struct thread_info *tmp___0 ;
  mm_segment_t __constr_expr_0 ;
  struct thread_info *tmp___1 ;

  {
#line 1526
  tmp = current_thread_info___2();
#line 1526
  oldfs = tmp->addr_limit;
#line 1530
  uoptval = optval;
#line 1532
  tmp___0 = current_thread_info___2();
#line 1532
  __constr_expr_0.seg = 0xffffffffffffffffUL;
#line 1532
  tmp___0->addr_limit = __constr_expr_0;
#line 1533
  if (level == 1) {
#line 1534
    err = sock_setsockopt(sock, level, optname, uoptval, (unsigned int )optlen);
  } else {
#line 1536
    err = (*((sock->ops)->setsockopt))(sock, level, optname, uoptval, (unsigned int )optlen);
  }
#line 1538
  tmp___1 = current_thread_info___2();
#line 1538
  tmp___1->addr_limit = oldfs;
#line 1539
  return (err);
}
}
#line 1542 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_tcp_cork___0(struct socket *sock ) 
{ 
  int val ;

  {
#line 1544
  val = 1;
#line 1545
  drbd_setsockopt___0(sock, 6, 3, (char *)(& val), 4);
#line 1547
  return;
}
}
#line 1549 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_tcp_uncork___0(struct socket *sock ) 
{ 
  int val ;

  {
#line 1551
  val = 0;
#line 1552
  drbd_setsockopt___0(sock, 6, 3, (char *)(& val), 4);
#line 1554
  return;
}
}
#line 1556 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_tcp_nodelay(struct socket *sock ) 
{ 
  int val ;

  {
#line 1558
  val = 1;
#line 1559
  drbd_setsockopt___0(sock, 6, 1, (char *)(& val), 4);
#line 1561
  return;
}
}
#line 1563 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_tcp_quickack(struct socket *sock ) 
{ 
  int val ;

  {
#line 1565
  val = 2;
#line 1566
  drbd_setsockopt___0(sock, 6, 12, (char *)(& val), 4);
#line 1568
  return;
}
}
#line 1570
void drbd_bump_write_ordering(struct drbd_tconn *tconn , enum write_ordering_e wo ) ;
#line 1582
int drbd_rs_begin_io(struct drbd_conf *mdev , sector_t sector ) ;
#line 1584
void drbd_rs_cancel_all(struct drbd_conf *mdev ) ;
#line 1632 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_peer_req_has_active_page___0(struct drbd_peer_request *peer_req ) 
{ 
  struct page *page ;
  int tmp ;
  struct page *tmp___0 ;

  {
#line 1634
  page = peer_req->pages;
#line 1635
  goto ldv_52106;
  ldv_52105: 
#line 1636
  tmp = page_count(page);
#line 1636
  if (tmp > 1) {
#line 1637
    return (1);
  } else {

  }
#line 1635
  page = page_chain_next(page);
  ldv_52106: ;
#line 1635
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 1635
    tmp___0 = page_chain_next(page);
#line 1635
    __builtin_prefetch((void const   *)tmp___0);
#line 1635
    if (1 != 0) {
#line 1636
      goto ldv_52105;
    } else {
#line 1638
      goto ldv_52107;
    }
  } else {

  }
  ldv_52107: ;
#line 1639
  return (0);
}
}
#line 1758 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t _drbd_md_first_sector(int meta_dev_idx , struct drbd_backing_dev *bdev ) 
{ 


  {
#line 1760
  switch (meta_dev_idx) {
  case -1: ;
  case -3: ;
#line 1763
  return ((sector_t )(bdev->md.md_offset + (u64 )bdev->md.bm_offset));
  case -2: ;
  default: ;
#line 1766
  return ((sector_t )bdev->md.md_offset);
  }
}
}
#line 1818 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_get_max_capacity(struct drbd_backing_dev *bdev ) 
{ 
  sector_t s ;
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  sector_t __min1 ;
  sector_t __min2 ;
  sector_t tmp___2 ;
  sector_t tmp___3 ;
  sector_t __min1___0 ;
  sector_t __min2___0 ;
  sector_t tmp___4 ;
  sector_t __min1___1 ;
  sector_t __min2___1 ;
  sector_t __min1___2 ;
  sector_t __min2___2 ;
  sector_t tmp___5 ;

  {
#line 1823
  rcu_read_lock___2();
#line 1824
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1824
  tmp = debug_lockdep_rcu_enabled();
#line 1824
  if (tmp != 0 && ! __warned) {
#line 1824
    tmp___0 = rcu_read_lock_held();
#line 1824
    if (tmp___0 == 0 && 1) {
#line 1824
      __warned = 1;
#line 1824
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1824, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1824
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1825
  rcu_read_unlock___2();
#line 1827
  switch (meta_dev_idx) {
  case -1: ;
  case -3: 
#line 1831
  tmp___3 = drbd_get_capacity(bdev->backing_bdev);
#line 1831
  if (tmp___3 != 0UL) {
#line 1831
    __min1 = 2251799813685248UL;
#line 1831
    tmp___2 = _drbd_md_first_sector(meta_dev_idx, bdev);
#line 1831
    __min2 = tmp___2;
#line 1831
    s = __min1 < __min2 ? __min1 : __min2;
  } else {
#line 1831
    s = 0UL;
  }
#line 1834
  goto ldv_52194;
  case -2: 
#line 1836
  __min1___0 = 2251799813685248UL;
#line 1836
  tmp___4 = drbd_get_capacity(bdev->backing_bdev);
#line 1836
  __min2___0 = tmp___4;
#line 1836
  s = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
#line 1839
  __min1___1 = s;
#line 1839
  __min2___1 = (unsigned long )(bdev->md.md_size_sect - (u32 )bdev->md.bm_offset) << 15;
#line 1839
  s = __min1___1 < __min2___1 ? __min1___1 : __min2___1;
#line 1842
  goto ldv_52194;
  default: 
#line 1844
  __min1___2 = 8587575296UL;
#line 1844
  tmp___5 = drbd_get_capacity(bdev->backing_bdev);
#line 1844
  __min2___2 = tmp___5;
#line 1844
  s = __min1___2 < __min2___2 ? __min1___2 : __min2___2;
  }
  ldv_52194: ;
#line 1847
  return (s);
}
}
#line 1927
int drbd_send_ping(struct drbd_tconn *tconn ) ;
#line 1928
int drbd_send_ping_ack(struct drbd_tconn *tconn ) ;
#line 1932 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_thread_stop(struct drbd_thread *thi ) 
{ 


  {
#line 1934
  _drbd_thread_stop(thi, 0, 1);
#line 1935
  return;
}
}
#line 2015 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void inc_unacked(struct drbd_conf *mdev ) 
{ 


  {
#line 2017
  atomic_inc(& mdev->unacked_cnt);
#line 2018
  return;
}
}
#line 2300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_set_ed_uuid(struct drbd_conf *mdev , u64 val ) 
{ 
  int changed ;

  {
#line 2302
  changed = mdev->ed_uuid != val;
#line 2303
  mdev->ed_uuid = val;
#line 2304
  return (changed);
}
}
#line 12 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_wrappers.h"
__inline static void drbd_set_my_capacity(struct drbd_conf *mdev , sector_t size ) 
{ 


  {
#line 16
  set_capacity(mdev->vdisk, size);
#line 17
  ((mdev->this_bdev)->bd_inode)->i_size = (long long )size << 9;
#line 18
  return;
}
}
#line 30 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_wrappers.h"
__inline static void drbd_generic_make_request(struct drbd_conf *mdev , int fault_type ,
                                               struct bio *bio ) 
{ 
  unsigned int tmp ;
  int tmp___0 ;

  {
#line 34
  if ((unsigned long )bio->bi_bdev == (unsigned long )((struct block_device *)0)) {
#line 35
    tmp = mdev_to_minor(mdev);
#line 35
    printk("\vdrbd%d: drbd_generic_make_request: bio->bi_bdev == NULL\n", tmp);
#line 38
    dump_stack();
#line 39
    bio_endio(bio, -19);
#line 40
    return;
  } else {

  }
#line 43
  tmp___0 = drbd_insert_fault(mdev, (unsigned int )fault_type);
#line 43
  if (tmp___0 != 0) {
#line 44
    bio_endio(bio, -5);
  } else {
#line 46
    generic_make_request(bio);
  }
#line 47
  return;
}
}
#line 146 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static int vli_decode_bits(u64 *out , u64 const   in ) 
{ 
  u64 adj ;

  {
#line 148
  adj = 1ULL;
#line 159
  if (((unsigned long long )in & 1ULL) == 0ULL) {
#line 159
    *out = (((unsigned long long )in & 3ULL) >> 1) + adj;
#line 159
    return (2);
  } else {

  }
#line 159
  adj = adj + 2ULL;
#line 159
  if (((unsigned long long )in & 3ULL) == 1ULL) {
#line 159
    *out = (((unsigned long long )in & 7ULL) >> 2) + adj;
#line 159
    return (3);
  } else {

  }
#line 159
  adj = adj + 2ULL;
#line 159
  if (((unsigned long long )in & 7ULL) == 3ULL) {
#line 159
    *out = (((unsigned long long )in & 31ULL) >> 3) + adj;
#line 159
    return (5);
  } else {

  }
#line 159
  adj = adj + 4ULL;
#line 159
  if (((unsigned long long )in & 15ULL) == 7ULL) {
#line 159
    *out = (((unsigned long long )in & 127ULL) >> 4) + adj;
#line 159
    return (7);
  } else {

  }
#line 159
  adj = adj + 8ULL;
#line 159
  if (((unsigned long long )in & 31ULL) == 15ULL) {
#line 159
    *out = (((unsigned long long )in & 1023ULL) >> 5) + adj;
#line 159
    return (10);
  } else {

  }
#line 159
  adj = adj + 32ULL;
#line 159
  if (((unsigned long long )in & 63ULL) == 31ULL) {
#line 159
    *out = (((unsigned long long )in & 16383ULL) >> 6) + adj;
#line 159
    return (14);
  } else {

  }
#line 159
  adj = adj + 256ULL;
#line 159
  if (((unsigned long long )in & 255ULL) == 63ULL) {
#line 159
    *out = (((unsigned long long )in & 2097151ULL) >> 8) + adj;
#line 159
    return (21);
  } else {

  }
#line 159
  adj = adj + 8192ULL;
#line 159
  if (((unsigned long long )in & 255ULL) == 127ULL) {
#line 159
    *out = (((unsigned long long )in & 536870911ULL) >> 8) + adj;
#line 159
    return (29);
  } else {

  }
#line 159
  adj = adj + 2097152ULL;
#line 159
  if (((unsigned long long )in & 255ULL) == 191ULL) {
#line 159
    *out = (((unsigned long long )in & 4398046511103ULL) >> 8) + adj;
#line 159
    return (42);
  } else {

  }
#line 159
  adj = adj + 17179869184ULL;
#line 159
  if (((unsigned long long )in & 255ULL) == 255ULL) {
#line 159
    *out = ((unsigned long long )in >> 8) + adj;
#line 159
    return (64);
  } else {

  }
#line 159
  adj = adj + 72057594037927936ULL;
#line 162
  __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"),
                       "i" (162), "i" (12UL));
  ldv_52558: ;
#line 162
  goto ldv_52558;
}
}
#line 211 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static void bitstream_cursor_reset(struct bitstream_cursor *cur , void *s ) 
{ 


  {
#line 213
  cur->b = (u8 *)s;
#line 214
  cur->bit = 0U;
#line 215
  return;
}
}
#line 219 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static void bitstream_cursor_advance(struct bitstream_cursor *cur , unsigned int bits ) 
{ 


  {
#line 221
  bits = cur->bit + bits;
#line 222
  cur->b = cur->b + (unsigned long )(bits >> 3);
#line 223
  cur->bit = bits & 7U;
#line 224
  return;
}
}
#line 238 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static void bitstream_init(struct bitstream *bs , void *s , size_t len ,
                                    unsigned int pad_bits ) 
{ 


  {
#line 240
  bs->buf = (unsigned char *)s;
#line 241
  bs->buf_len = len;
#line 242
  bs->pad_bits = pad_bits;
#line 243
  bitstream_cursor_reset(& bs->cur, (void *)bs->buf);
#line 244
  return;
}
}
#line 293 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static int bitstream_get_bits(struct bitstream *bs , u64 *out , int bits ) 
{ 
  u64 val ;
  unsigned int n ;
  size_t __len ;
  void *__ret ;

  {
#line 298
  if (bits > 64) {
#line 299
    return (-22);
  } else {

  }
#line 301
  if ((unsigned long )((long )(bs->cur.b + (unsigned long )((((bs->cur.bit + bs->pad_bits) + (unsigned int )bits) - 1U) >> 3)) - (long )bs->buf) >= bs->buf_len) {
#line 302
    bits = (int )(((((unsigned int )bs->buf_len + ((unsigned int )((long )bs->buf) - (unsigned int )((long )bs->cur.b))) << 3U) - bs->cur.bit) - bs->pad_bits);
  } else {

  }
#line 305
  if (bits == 0) {
#line 306
    *out = 0ULL;
#line 307
    return (0);
  } else {

  }
#line 311
  val = 0ULL;
#line 312
  n = ((bs->cur.bit + (unsigned int )bits) + 7U) >> 3;
#line 315
  if (n != 0U) {
#line 316
    __len = (size_t )(n - 1U);
#line 316
    __ret = __builtin_memcpy((void *)(& val), (void const   *)bs->cur.b + 1U, __len);
#line 317
    val = val << (int )(8U - bs->cur.bit);
  } else {

  }
#line 321
  val = (u64 )((int )*(bs->cur.b) >> (int )bs->cur.bit) | val;
#line 324
  val = (0xffffffffffffffffULL >> (64 - bits)) & val;
#line 326
  bitstream_cursor_advance(& bs->cur, (unsigned int )bits);
#line 327
  *out = val;
#line 329
  return (bits);
}
}
#line 152 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_do_features(struct drbd_tconn *tconn ) ;
#line 153
static int drbd_do_auth(struct drbd_tconn *tconn ) ;
#line 154
static int drbd_disconnected(struct drbd_conf *mdev ) ;
#line 156
static enum finish_epoch drbd_may_finish_epoch(struct drbd_tconn *tconn , struct drbd_epoch *epoch ,
                                               enum epoch_event ev ) ;
#line 157
static int e_end_block(struct drbd_work *w , int cancel ) ;
#line 171 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct page *page_chain_del(struct page **head , int n ) 
{ 
  struct page *page ;
  struct page *tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
#line 176
  tmp___0 = __builtin_expect(n == 0, 0L);
#line 176
  if (tmp___0 != 0L) {
#line 176
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"),
                         "i" (176), "i" (12UL));
    ldv_52644: ;
#line 176
    goto ldv_52644;
  } else {

  }
#line 177
  tmp___1 = __builtin_expect((unsigned long )head == (unsigned long )((struct page **)0),
                             0L);
#line 177
  if (tmp___1 != 0L) {
#line 177
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"),
                         "i" (177), "i" (12UL));
    ldv_52645: ;
#line 177
    goto ldv_52645;
  } else {

  }
#line 179
  page = *head;
#line 181
  if ((unsigned long )page == (unsigned long )((struct page *)0)) {
#line 182
    return (0);
  } else {

  }
#line 184
  goto ldv_52648;
  ldv_52647: 
#line 185
  tmp = page_chain_next(page);
#line 186
  n = n - 1;
#line 186
  if (n == 0) {
#line 187
    goto ldv_52646;
  } else {

  }
#line 188
  if ((unsigned long )tmp == (unsigned long )((struct page *)0)) {
#line 190
    return (0);
  } else {

  }
#line 191
  page = tmp;
  ldv_52648: ;
#line 184
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 185
    goto ldv_52647;
  } else {

  }
  ldv_52646: 
#line 195
  page->ldv_14746.private = 0UL;
#line 197
  page = *head;
#line 198
  *head = tmp;
#line 199
  return (page);
}
}
#line 205 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct page *page_chain_tail(struct page *page , int *len ) 
{ 
  struct page *tmp ;
  int i ;

  {
#line 208
  i = 1;
#line 209
  goto ldv_52656;
  ldv_52655: 
#line 210
  i = i + 1;
#line 210
  page = tmp;
  ldv_52656: 
#line 209
  tmp = page_chain_next(page);
#line 209
  if ((unsigned long )tmp != (unsigned long )((struct page *)0)) {
#line 210
    goto ldv_52655;
  } else {

  }

#line 211
  if ((unsigned long )len != (unsigned long )((int *)0)) {
#line 212
    *len = i;
  } else {

  }
#line 213
  return (page);
}
}
#line 216 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int page_chain_free(struct page *page ) 
{ 
  struct page *tmp ;
  int i ;

  {
#line 219
  i = 0;
#line 220
  goto ldv_52665;
  ldv_52664: 
#line 221
  put_page(page);
#line 222
  i = i + 1;
#line 220
  page = tmp;
  ldv_52665: ;
#line 220
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 220
    tmp = page_chain_next(page);
#line 220
    if (1 != 0) {
#line 221
      goto ldv_52664;
    } else {
#line 223
      goto ldv_52666;
    }
  } else {

  }
  ldv_52666: ;
#line 224
  return (i);
}
}
#line 227 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void page_chain_add(struct page **head , struct page *chain_first , struct page *chain_last ) 
{ 
  struct page *tmp ;
  long tmp___0 ;

  {
#line 232
  tmp = page_chain_tail(chain_first, 0);
#line 233
  tmp___0 = __builtin_expect((unsigned long )tmp != (unsigned long )chain_last, 0L);
#line 233
  if (tmp___0 != 0L) {
#line 233
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"),
                         "i" (233), "i" (12UL));
    ldv_52673: ;
#line 233
    goto ldv_52673;
  } else {

  }
#line 237
  chain_last->ldv_14746.private = (unsigned long )*head;
#line 238
  *head = chain_first;
#line 239
  return;
}
}
#line 241 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct page *__drbd_alloc_pages(struct drbd_conf *mdev , unsigned int number ) 
{ 
  struct page *page ;
  struct page *tmp ;
  unsigned int i ;

  {
#line 244
  page = 0;
#line 245
  tmp = 0;
#line 246
  i = 0U;
#line 250
  if ((unsigned int )drbd_pp_vacant >= number) {
#line 251
    spin_lock(& drbd_pp_lock);
#line 252
    page = page_chain_del(& drbd_pp_pool, (int )number);
#line 253
    if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 254
      drbd_pp_vacant = (int )((unsigned int )drbd_pp_vacant - number);
    } else {

    }
#line 255
    spin_unlock(& drbd_pp_lock);
#line 256
    if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 257
      return (page);
    } else {

    }
  } else {

  }
#line 263
  i = 0U;
#line 263
  goto ldv_52683;
  ldv_52682: 
#line 264
  tmp = alloc_pages(514U, 0U);
#line 265
  if ((unsigned long )tmp == (unsigned long )((struct page *)0)) {
#line 266
    goto ldv_52681;
  } else {

  }
#line 267
  tmp->ldv_14746.private = (unsigned long )page;
#line 268
  page = tmp;
#line 263
  i = i + 1U;
  ldv_52683: ;
#line 263
  if (i < number) {
#line 264
    goto ldv_52682;
  } else {

  }
  ldv_52681: ;
#line 271
  if (i == number) {
#line 272
    return (page);
  } else {

  }
#line 277
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 278
    tmp = page_chain_tail(page, 0);
#line 279
    spin_lock(& drbd_pp_lock);
#line 280
    page_chain_add(& drbd_pp_pool, page, tmp);
#line 281
    drbd_pp_vacant = (int )((unsigned int )drbd_pp_vacant + i);
#line 282
    spin_unlock(& drbd_pp_lock);
  } else {

  }
#line 284
  return (0);
}
}
#line 287 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void reclaim_finished_net_peer_reqs(struct drbd_conf *mdev , struct list_head *to_be_freed ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct list_head *le ;
  struct list_head *tle ;
  struct list_head  const  *__mptr ;
  int tmp ;

  {
#line 298
  le = mdev->net_ee.next;
#line 298
  tle = le->next;
#line 298
  goto ldv_52695;
  ldv_52694: 
#line 299
  __mptr = (struct list_head  const  *)le;
#line 299
  peer_req = (struct drbd_peer_request *)__mptr;
#line 300
  tmp = drbd_peer_req_has_active_page___0(peer_req);
#line 300
  if (tmp != 0) {
#line 301
    goto ldv_52693;
  } else {

  }
#line 302
  list_move(le, to_be_freed);
#line 298
  le = tle;
#line 298
  tle = le->next;
  ldv_52695: ;
#line 298
  if ((unsigned long )(& mdev->net_ee) != (unsigned long )le) {
#line 299
    goto ldv_52694;
  } else {

  }
  ldv_52693: ;
#line 303
  return;
}
}
#line 306 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_kick_lo_and_reclaim_net(struct drbd_conf *mdev ) 
{ 
  struct list_head reclaimed ;
  struct drbd_peer_request *peer_req ;
  struct drbd_peer_request *t ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
#line 308
  reclaimed.next = & reclaimed;
#line 308
  reclaimed.prev = & reclaimed;
#line 311
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 312
  reclaim_finished_net_peer_reqs(mdev, & reclaimed);
#line 313
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 315
  __mptr = (struct list_head  const  *)reclaimed.next;
#line 315
  peer_req = (struct drbd_peer_request *)__mptr;
#line 315
  __mptr___0 = (struct list_head  const  *)peer_req->w.list.next;
#line 315
  t = (struct drbd_peer_request *)__mptr___0;
#line 315
  goto ldv_52709;
  ldv_52708: 
#line 316
  __drbd_free_peer_req(mdev, peer_req, 1);
#line 315
  peer_req = t;
#line 315
  __mptr___1 = (struct list_head  const  *)t->w.list.next;
#line 315
  t = (struct drbd_peer_request *)__mptr___1;
  ldv_52709: ;
#line 315
  if ((unsigned long )(& peer_req->w.list) != (unsigned long )(& reclaimed)) {
#line 316
    goto ldv_52708;
  } else {

  }

#line 320
  return;
}
}
#line 331 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
struct page *drbd_alloc_pages(struct drbd_conf *mdev , unsigned int number , bool retry___0 ) 
{ 
  struct page *page ;
  struct net_conf *nc ;
  wait_queue_t wait ;
  struct task_struct *tmp ;
  int mxb ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  struct task_struct *tmp___4 ;
  int tmp___5 ;

  {
#line 334
  page = 0;
#line 336
  tmp = get_current();
#line 336
  wait.flags = 0U;
#line 336
  wait.private = (void *)tmp;
#line 336
  wait.func = & autoremove_wake_function;
#line 336
  wait.task_list.next = & wait.task_list;
#line 336
  wait.task_list.prev = & wait.task_list;
#line 341
  rcu_read_lock___2();
#line 342
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 342
  tmp___0 = debug_lockdep_rcu_enabled();
#line 342
  if (tmp___0 != 0 && ! __warned) {
#line 342
    tmp___1 = rcu_read_lock_held();
#line 342
    if (tmp___1 == 0 && 1) {
#line 342
      __warned = 1;
#line 342
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             342, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 342
  nc = _________p1;
#line 343
  mxb = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (int )nc->max_buffers : 1000000;
#line 344
  rcu_read_unlock___2();
#line 346
  tmp___2 = atomic_read((atomic_t const   *)(& mdev->pp_in_use));
#line 346
  if (tmp___2 < mxb) {
#line 347
    page = __drbd_alloc_pages(mdev, number);
  } else {

  }
#line 349
  goto ldv_52725;
  ldv_52724: 
#line 350
  prepare_to_wait(& drbd_pp_wait, & wait, 1);
#line 352
  drbd_kick_lo_and_reclaim_net(mdev);
#line 354
  tmp___3 = atomic_read((atomic_t const   *)(& mdev->pp_in_use));
#line 354
  if (tmp___3 < mxb) {
#line 355
    page = __drbd_alloc_pages(mdev, number);
#line 356
    if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 357
      goto ldv_52723;
    } else {

    }
  } else {

  }
#line 360
  if (! retry___0) {
#line 361
    goto ldv_52723;
  } else {

  }
#line 363
  tmp___4 = get_current();
#line 363
  tmp___5 = signal_pending(tmp___4);
#line 363
  if (tmp___5 != 0) {
#line 364
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_alloc_pages interrupted!\n");
#line 365
    goto ldv_52723;
  } else {

  }
#line 368
  schedule();
  ldv_52725: ;
#line 349
  if ((unsigned long )page == (unsigned long )((struct page *)0)) {
#line 350
    goto ldv_52724;
  } else {

  }
  ldv_52723: 
#line 370
  finish_wait(& drbd_pp_wait, & wait);
#line 372
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 373
    atomic_add((int )number, & mdev->pp_in_use);
  } else {

  }
#line 374
  return (page);
}
}
#line 381 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_free_pages(struct drbd_conf *mdev , struct page *page , int is_net ) 
{ 
  atomic_t *a ;
  int i ;
  struct page *tmp ;

  {
#line 383
  a = is_net != 0 ? & mdev->pp_in_use_by_net : & mdev->pp_in_use;
#line 386
  if ((unsigned long )page == (unsigned long )((struct page *)0)) {
#line 387
    return;
  } else {

  }
#line 389
  if ((unsigned long )drbd_pp_vacant > (unsigned long )minor_count * 256UL) {
#line 390
    i = page_chain_free(page);
  } else {
#line 393
    tmp = page_chain_tail(page, & i);
#line 394
    spin_lock(& drbd_pp_lock);
#line 395
    page_chain_add(& drbd_pp_pool, page, tmp);
#line 396
    drbd_pp_vacant = drbd_pp_vacant + i;
#line 397
    spin_unlock(& drbd_pp_lock);
  }
#line 399
  i = atomic_sub_return(i, a);
#line 400
  if (i < 0) {
#line 401
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION FAILED: %s: %d < 0\n",
             is_net != 0 ? (char *)"pp_in_use_by_net" : (char *)"pp_in_use", i);
  } else {

  }
#line 403
  __wake_up(& drbd_pp_wait, 3U, 1, 0);
#line 404
  return;
}
}
#line 421 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
struct drbd_peer_request *drbd_alloc_peer_req(struct drbd_conf *mdev , u64 id , sector_t sector ,
                                              unsigned int data_size , gfp_t gfp_mask ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct page *page ;
  unsigned int nr_pages ;
  int tmp ;
  void *tmp___0 ;

  {
#line 425
  page = 0;
#line 426
  nr_pages = (unsigned int )(((unsigned long )data_size + 4095UL) >> 12);
#line 428
  tmp = drbd_insert_fault(mdev, 8U);
#line 428
  if (tmp != 0) {
#line 429
    return (0);
  } else {

  }
#line 431
  tmp___0 = mempool_alloc(drbd_ee_mempool, gfp_mask & 4294967293U);
#line 431
  peer_req = (struct drbd_peer_request *)tmp___0;
#line 432
  if ((unsigned long )peer_req == (unsigned long )((struct drbd_peer_request *)0)) {
#line 433
    if ((gfp_mask & 512U) == 0U) {
#line 434
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s: allocation failed\n",
              "drbd_alloc_peer_req");
    } else {

    }
#line 435
    return (0);
  } else {

  }
#line 438
  if (data_size != 0U) {
#line 439
    page = drbd_alloc_pages(mdev, nr_pages, (gfp_mask & 16U) != 0U);
#line 440
    if ((unsigned long )page == (unsigned long )((struct page *)0)) {
#line 441
      goto fail;
    } else {

    }
  } else {

  }
#line 444
  drbd_clear_interval(& peer_req->i);
#line 445
  peer_req->i.size = data_size;
#line 446
  peer_req->i.sector = sector;
#line 447
  peer_req->i.local = 0;
#line 448
  peer_req->i.waiting = 0;
#line 450
  peer_req->epoch = 0;
#line 451
  peer_req->w.ldv_49807.mdev = mdev;
#line 452
  peer_req->pages = page;
#line 453
  atomic_set(& peer_req->pending_bios, 0);
#line 454
  peer_req->flags = 0UL;
#line 459
  peer_req->ldv_50726.block_id = id;
#line 461
  return (peer_req);
  fail: 
#line 464
  mempool_free((void *)peer_req, drbd_ee_mempool);
#line 465
  return (0);
}
}
#line 468 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void __drbd_free_peer_req(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ,
                          int is_net ) 
{ 
  int tmp ;
  bool tmp___0 ;
  int tmp___1 ;

  {
#line 471
  if ((peer_req->flags & 16UL) != 0UL) {
#line 472
    kfree((void const   *)peer_req->ldv_50726.digest);
  } else {

  }
#line 473
  drbd_free_pages(mdev, peer_req->pages, is_net);
#line 474
  tmp = atomic_read((atomic_t const   *)(& peer_req->pending_bios));
#line 474
  if (tmp != 0) {
#line 474
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( atomic_read(&peer_req->pending_bios) == 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            474);
  } else {

  }
#line 475
  tmp___0 = drbd_interval_empty(& peer_req->i);
#line 475
  if (tmp___0) {
#line 475
    tmp___1 = 0;
  } else {
#line 475
    tmp___1 = 1;
  }
#line 475
  if (tmp___1) {
#line 475
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( drbd_interval_empty(&peer_req->i) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            475);
  } else {

  }
#line 476
  mempool_free((void *)peer_req, drbd_ee_mempool);
#line 477
  return;
}
}
#line 479 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
int drbd_free_peer_reqs(struct drbd_conf *mdev , struct list_head *list ) 
{ 
  struct list_head work_list ;
  struct drbd_peer_request *peer_req ;
  struct drbd_peer_request *t ;
  int count ;
  int is_net ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
#line 481
  work_list.next = & work_list;
#line 481
  work_list.prev = & work_list;
#line 483
  count = 0;
#line 484
  is_net = (unsigned long )(& mdev->net_ee) == (unsigned long )list;
#line 486
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 487
  list_splice_init(list, & work_list);
#line 488
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 490
  __mptr = (struct list_head  const  *)work_list.next;
#line 490
  peer_req = (struct drbd_peer_request *)__mptr;
#line 490
  __mptr___0 = (struct list_head  const  *)peer_req->w.list.next;
#line 490
  t = (struct drbd_peer_request *)__mptr___0;
#line 490
  goto ldv_52767;
  ldv_52766: 
#line 491
  __drbd_free_peer_req(mdev, peer_req, is_net);
#line 492
  count = count + 1;
#line 490
  peer_req = t;
#line 490
  __mptr___1 = (struct list_head  const  *)t->w.list.next;
#line 490
  t = (struct drbd_peer_request *)__mptr___1;
  ldv_52767: ;
#line 490
  if ((unsigned long )(& peer_req->w.list) != (unsigned long )(& work_list)) {
#line 491
    goto ldv_52766;
  } else {

  }

#line 494
  return (count);
}
}
#line 500 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_finish_peer_reqs(struct drbd_conf *mdev ) 
{ 
  struct list_head work_list ;
  struct list_head reclaimed ;
  struct drbd_peer_request *peer_req ;
  struct drbd_peer_request *t ;
  int err ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head  const  *__mptr___2 ;
  struct list_head  const  *__mptr___3 ;
  int err2 ;
  struct list_head  const  *__mptr___4 ;

  {
#line 502
  work_list.next = & work_list;
#line 502
  work_list.prev = & work_list;
#line 503
  reclaimed.next = & reclaimed;
#line 503
  reclaimed.prev = & reclaimed;
#line 505
  err = 0;
#line 507
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 508
  reclaim_finished_net_peer_reqs(mdev, & reclaimed);
#line 509
  list_splice_init(& mdev->done_ee, & work_list);
#line 510
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 512
  __mptr = (struct list_head  const  *)reclaimed.next;
#line 512
  peer_req = (struct drbd_peer_request *)__mptr;
#line 512
  __mptr___0 = (struct list_head  const  *)peer_req->w.list.next;
#line 512
  t = (struct drbd_peer_request *)__mptr___0;
#line 512
  goto ldv_52784;
  ldv_52783: 
#line 513
  __drbd_free_peer_req(mdev, peer_req, 1);
#line 512
  peer_req = t;
#line 512
  __mptr___1 = (struct list_head  const  *)t->w.list.next;
#line 512
  t = (struct drbd_peer_request *)__mptr___1;
  ldv_52784: ;
#line 512
  if ((unsigned long )(& peer_req->w.list) != (unsigned long )(& reclaimed)) {
#line 513
    goto ldv_52783;
  } else {

  }
#line 519
  __mptr___2 = (struct list_head  const  *)work_list.next;
#line 519
  peer_req = (struct drbd_peer_request *)__mptr___2;
#line 519
  __mptr___3 = (struct list_head  const  *)peer_req->w.list.next;
#line 519
  t = (struct drbd_peer_request *)__mptr___3;
#line 519
  goto ldv_52794;
  ldv_52793: 
#line 523
  err2 = (*(peer_req->w.cb))(& peer_req->w, err != 0);
#line 524
  if (err == 0) {
#line 525
    err = err2;
  } else {

  }
#line 526
  __drbd_free_peer_req(mdev, peer_req, 0);
#line 519
  peer_req = t;
#line 519
  __mptr___4 = (struct list_head  const  *)t->w.list.next;
#line 519
  t = (struct drbd_peer_request *)__mptr___4;
  ldv_52794: ;
#line 519
  if ((unsigned long )(& peer_req->w.list) != (unsigned long )(& work_list)) {
#line 520
    goto ldv_52793;
  } else {

  }
#line 528
  __wake_up(& mdev->ee_wait, 3U, 1, 0);
#line 530
  return (err);
}
}
#line 533 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void _drbd_wait_ee_list_empty(struct drbd_conf *mdev , struct list_head *head ) 
{ 
  wait_queue_t wait ;
  struct task_struct *tmp ;
  int tmp___0 ;

  {
#line 536
  tmp = get_current();
#line 536
  wait.flags = 0U;
#line 536
  wait.private = (void *)tmp;
#line 536
  wait.func = & autoremove_wake_function;
#line 536
  wait.task_list.next = & wait.task_list;
#line 536
  wait.task_list.prev = & wait.task_list;
#line 540
  goto ldv_52802;
  ldv_52801: 
#line 541
  prepare_to_wait(& mdev->ee_wait, & wait, 2);
#line 542
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 543
  io_schedule();
#line 544
  finish_wait(& mdev->ee_wait, & wait);
#line 545
  spin_lock_irq(& (mdev->tconn)->req_lock);
  ldv_52802: 
#line 540
  tmp___0 = list_empty((struct list_head  const  *)head);
#line 540
  if (tmp___0 == 0) {
#line 541
    goto ldv_52801;
  } else {

  }

#line 545
  return;
}
}
#line 549 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_wait_ee_list_empty(struct drbd_conf *mdev , struct list_head *head ) 
{ 


  {
#line 552
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 553
  _drbd_wait_ee_list_empty(mdev, head);
#line 554
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 555
  return;
}
}
#line 557 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_recv_short(struct socket *sock , void *buf , size_t size , int flags ) 
{ 
  mm_segment_t oldfs ;
  struct kvec iov ;
  struct msghdr msg ;
  int rv ;
  struct thread_info *tmp ;
  struct thread_info *tmp___0 ;
  mm_segment_t __constr_expr_0 ;
  struct thread_info *tmp___1 ;

  {
#line 560
  iov.iov_base = buf;
#line 560
  iov.iov_len = size;
#line 564
  msg.msg_name = 0;
#line 564
  msg.msg_namelen = 0;
#line 564
  msg.msg_iov = (struct iovec *)(& iov);
#line 564
  msg.msg_iovlen = 1UL;
#line 564
  msg.msg_control = 0;
#line 564
  msg.msg_controllen = 0UL;
#line 564
  msg.msg_flags = flags != 0 ? (unsigned int )flags : 16640U;
#line 571
  tmp = current_thread_info___2();
#line 571
  oldfs = tmp->addr_limit;
#line 572
  tmp___0 = current_thread_info___2();
#line 572
  __constr_expr_0.seg = 0xffffffffffffffffUL;
#line 572
  tmp___0->addr_limit = __constr_expr_0;
#line 573
  rv = sock_recvmsg(sock, & msg, size, (int )msg.msg_flags);
#line 574
  tmp___1 = current_thread_info___2();
#line 574
  tmp___1->addr_limit = oldfs;
#line 576
  return (rv);
}
}
#line 579 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_recv(struct drbd_tconn *tconn , void *buf , size_t size ) 
{ 
  int rv ;
  long t ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  long __ret ;
  wait_queue_t __wait ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 583
  rv = drbd_recv_short(tconn->data.socket, buf, size, 0);
#line 585
  if (rv < 0) {
#line 586
    if (rv == -104) {
#line 587
      printk("\016d-con %s: sock was reset by peer\n", tconn->name);
    } else
#line 588
    if (rv != -512) {
#line 589
      printk("\vd-con %s: sock_recvmsg returned %d\n", tconn->name, rv);
    } else
#line 590
    if (rv == 0) {
#line 591
      tmp___2 = constant_test_bit(12U, (unsigned long const volatile   *)(& tconn->flags));
#line 591
      if (tmp___2 != 0) {
#line 593
        rcu_read_lock___2();
#line 594
        _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 594
        tmp = debug_lockdep_rcu_enabled();
#line 594
        if (tmp != 0 && ! __warned) {
#line 594
          tmp___0 = rcu_read_lock_held();
#line 594
          if (tmp___0 == 0 && 1) {
#line 594
            __warned = 1;
#line 594
            lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                                   594, "suspicious rcu_dereference_check() usage");
          } else {

          }
        } else {

        }
#line 594
        t = (long )((_________p1->ping_timeo * 250U) / 10U);
#line 595
        rcu_read_unlock___2();
#line 597
        __ret = t;
#line 597
        if ((unsigned int )tconn->cstate > 8U) {
#line 597
          tmp___1 = get_current();
#line 597
          __wait.flags = 0U;
#line 597
          __wait.private = (void *)tmp___1;
#line 597
          __wait.func = & autoremove_wake_function;
#line 597
          __wait.task_list.next = & __wait.task_list;
#line 597
          __wait.task_list.prev = & __wait.task_list;
          ldv_52832: 
#line 597
          prepare_to_wait(& tconn->ping_wait, & __wait, 2);
#line 597
          if ((unsigned int )tconn->cstate <= 8U) {
#line 597
            goto ldv_52831;
          } else {

          }
#line 597
          __ret = schedule_timeout(__ret);
#line 597
          if (__ret == 0L) {
#line 597
            goto ldv_52831;
          } else {

          }
#line 597
          goto ldv_52832;
          ldv_52831: 
#line 597
          finish_wait(& tconn->ping_wait, & __wait);
        } else {

        }
#line 597
        t = __ret;
#line 599
        if (t != 0L) {
#line 600
          goto out;
        } else {

        }
      } else {

      }
#line 602
      printk("\016d-con %s: sock was shut down by peer\n", tconn->name);
    } else {

    }
  } else {

  }
#line 605
  if ((size_t )rv != size) {
#line 606
    val.i = 0U;
#line 606
    val.ldv_40024.conn = 4U;
#line 606
    mask.i = 0U;
#line 606
    mask.ldv_40024.conn = 31U;
#line 606
    conn_request_state(tconn, mask, val, CS_HARD);
  } else {

  }
  out: ;
#line 609
  return (rv);
}
}
#line 612 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_recv_all(struct drbd_tconn *tconn , void *buf , size_t size ) 
{ 
  int err ;

  {
#line 616
  err = drbd_recv(tconn, buf, size);
#line 617
  if ((size_t )err != size) {
#line 618
    if (err >= 0) {
#line 619
      err = -5;
    } else {
#line 621
      err = 0;
    }
  } else {

  }
#line 622
  return (err);
}
}
#line 625 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_recv_all_warn(struct drbd_tconn *tconn , void *buf , size_t size ) 
{ 
  int err ;
  struct task_struct *tmp ;
  int tmp___0 ;

  {
#line 629
  err = drbd_recv_all(tconn, buf, size);
#line 630
  if (err != 0) {
#line 630
    tmp = get_current();
#line 630
    tmp___0 = signal_pending(tmp);
#line 630
    if (tmp___0 == 0) {
#line 631
      printk("\fd-con %s: short read (expected size %d)\n", tconn->name, (int )size);
    } else {

    }
  } else {

  }
#line 632
  return (err);
}
}
#line 640 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_setbufsize(struct socket *sock , unsigned int snd , unsigned int rcv ) 
{ 


  {
#line 644
  if (snd != 0U) {
#line 645
    (sock->sk)->sk_sndbuf = (int )snd;
#line 646
    (sock->sk)->sk_userlocks = (unsigned char )((unsigned int )(sock->sk)->sk_userlocks | 1U);
  } else {

  }
#line 648
  if (rcv != 0U) {
#line 649
    (sock->sk)->sk_rcvbuf = (int )rcv;
#line 650
    (sock->sk)->sk_userlocks = (unsigned char )((unsigned int )(sock->sk)->sk_userlocks | 2U);
  } else {

  }
#line 652
  return;
}
}
#line 654 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct socket *drbd_try_connect(struct drbd_tconn *tconn ) 
{ 
  char const   *what ;
  struct socket *sock ;
  struct sockaddr_in6 src_in6 ;
  struct sockaddr_in6 peer_in6 ;
  struct net_conf *nc ;
  int err ;
  int peer_addr_len ;
  int my_addr_len ;
  int sndbuf_size ;
  int rcvbuf_size ;
  int connect_int ;
  int disconnect_on_error ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int __min1 ;
  int __min2 ;
  size_t __len ;
  void *__ret ;
  int __min1___0 ;
  int __min2___0 ;
  size_t __len___0 ;
  void *__ret___0 ;
  long tmp___1 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 663
  disconnect_on_error = 1;
#line 665
  rcu_read_lock___2();
#line 666
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 666
  tmp = debug_lockdep_rcu_enabled();
#line 666
  if (tmp != 0 && ! __warned) {
#line 666
    tmp___0 = rcu_read_lock_held();
#line 666
    if (tmp___0 == 0 && 1) {
#line 666
      __warned = 1;
#line 666
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             666, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 666
  nc = _________p1;
#line 667
  if ((unsigned long )nc == (unsigned long )((struct net_conf *)0)) {
#line 668
    rcu_read_unlock___2();
#line 669
    return (0);
  } else {

  }
#line 671
  sndbuf_size = (int )nc->sndbuf_size;
#line 672
  rcvbuf_size = (int )nc->rcvbuf_size;
#line 673
  connect_int = (int )nc->connect_int;
#line 674
  rcu_read_unlock___2();
#line 676
  __min1 = tconn->my_addr_len;
#line 676
  __min2 = 28;
#line 676
  my_addr_len = __min1 < __min2 ? __min1 : __min2;
#line 677
  __len = (size_t )my_addr_len;
#line 677
  __ret = __builtin_memcpy((void *)(& src_in6), (void const   *)(& tconn->my_addr),
                           __len);
#line 679
  if ((unsigned int )((struct sockaddr *)(& tconn->my_addr))->sa_family == 10U) {
#line 680
    src_in6.sin6_port = 0U;
  } else {
#line 682
    ((struct sockaddr_in *)(& src_in6))->sin_port = 0U;
  }
#line 684
  __min1___0 = tconn->peer_addr_len;
#line 684
  __min2___0 = 28;
#line 684
  peer_addr_len = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
#line 685
  __len___0 = (size_t )peer_addr_len;
#line 685
  __ret___0 = __builtin_memcpy((void *)(& peer_in6), (void const   *)(& tconn->peer_addr),
                               __len___0);
#line 687
  what = "sock_create_kern";
#line 688
  err = sock_create_kern((int )((struct sockaddr *)(& src_in6))->sa_family, 1, 6,
                         & sock);
#line 690
  if (err < 0) {
#line 691
    sock = 0;
#line 692
    goto out;
  } else {

  }
#line 695
  tmp___1 = (long )(connect_int * 250);
#line 695
  (sock->sk)->sk_sndtimeo = tmp___1;
#line 695
  (sock->sk)->sk_rcvtimeo = tmp___1;
#line 697
  drbd_setbufsize(sock, (unsigned int )sndbuf_size, (unsigned int )rcvbuf_size);
#line 706
  what = "bind before connect";
#line 707
  err = (*((sock->ops)->bind))(sock, (struct sockaddr *)(& src_in6), my_addr_len);
#line 708
  if (err < 0) {
#line 709
    goto out;
  } else {

  }
#line 713
  disconnect_on_error = 0;
#line 714
  what = "connect";
#line 715
  err = (*((sock->ops)->connect))(sock, (struct sockaddr *)(& peer_in6), peer_addr_len,
                                  0);
  out: ;
#line 718
  if (err < 0) {
#line 719
    if ((unsigned long )sock != (unsigned long )((struct socket *)0)) {
#line 720
      sock_release(sock);
#line 721
      sock = 0;
    } else {

    }
#line 723
    switch (- err) {
    case 110: ;
    case 11: ;
    case 115: ;
    case 4: ;
    case 512: ;
    case 111: ;
    case 101: ;
    case 112: ;
    case 113: 
#line 730
    disconnect_on_error = 0;
#line 731
    goto ldv_52896;
    default: 
#line 733
    printk("\vd-con %s: %s failed, err = %d\n", tconn->name, what, err);
    }
    ldv_52896: ;
#line 735
    if (disconnect_on_error != 0) {
#line 736
      val.i = 0U;
#line 736
      val.ldv_40024.conn = 1U;
#line 736
      mask.i = 0U;
#line 736
      mask.ldv_40024.conn = 31U;
#line 736
      conn_request_state(tconn, mask, val, CS_HARD);
    } else {

    }
  } else {

  }
#line 739
  return (sock);
}
}
#line 750 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_incoming_connection(struct sock *sk ) 
{ 
  struct accept_wait_data *ad ;
  void (*state_change)(struct sock * ) ;

  {
#line 752
  ad = (struct accept_wait_data *)sk->sk_user_data;
#line 755
  state_change = ad->original_sk_state_change;
#line 756
  if ((unsigned int )((unsigned char )sk->__sk_common.skc_state) == 1U) {
#line 757
    complete(& ad->door_bell);
  } else {

  }
#line 758
  (*state_change)(sk);
#line 759
  return;
}
}
#line 761 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int prepare_listen_socket(struct drbd_tconn *tconn , struct accept_wait_data *ad ) 
{ 
  int err ;
  int sndbuf_size ;
  int rcvbuf_size ;
  int my_addr_len ;
  struct sockaddr_in6 my_addr ;
  struct socket *s_listen ;
  struct net_conf *nc ;
  char const   *what ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int __min1 ;
  int __min2 ;
  size_t __len ;
  void *__ret ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 769
  rcu_read_lock___2();
#line 770
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 770
  tmp = debug_lockdep_rcu_enabled();
#line 770
  if (tmp != 0 && ! __warned) {
#line 770
    tmp___0 = rcu_read_lock_held();
#line 770
    if (tmp___0 == 0 && 1) {
#line 770
      __warned = 1;
#line 770
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             770, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 770
  nc = _________p1;
#line 771
  if ((unsigned long )nc == (unsigned long )((struct net_conf *)0)) {
#line 772
    rcu_read_unlock___2();
#line 773
    return (-5);
  } else {

  }
#line 775
  sndbuf_size = (int )nc->sndbuf_size;
#line 776
  rcvbuf_size = (int )nc->rcvbuf_size;
#line 777
  rcu_read_unlock___2();
#line 779
  __min1 = tconn->my_addr_len;
#line 779
  __min2 = 28;
#line 779
  my_addr_len = __min1 < __min2 ? __min1 : __min2;
#line 780
  __len = (size_t )my_addr_len;
#line 780
  __ret = __builtin_memcpy((void *)(& my_addr), (void const   *)(& tconn->my_addr),
                           __len);
#line 782
  what = "sock_create_kern";
#line 783
  err = sock_create_kern((int )((struct sockaddr *)(& my_addr))->sa_family, 1, 6,
                         & s_listen);
#line 785
  if (err != 0) {
#line 786
    s_listen = 0;
#line 787
    goto out;
  } else {

  }
#line 790
  (s_listen->sk)->__sk_common.skc_reuse = 1U;
#line 791
  drbd_setbufsize(s_listen, (unsigned int )sndbuf_size, (unsigned int )rcvbuf_size);
#line 793
  what = "bind before listen";
#line 794
  err = (*((s_listen->ops)->bind))(s_listen, (struct sockaddr *)(& my_addr), my_addr_len);
#line 795
  if (err < 0) {
#line 796
    goto out;
  } else {

  }
#line 798
  ad->s_listen = s_listen;
#line 799
  _raw_write_lock_bh(& (s_listen->sk)->sk_callback_lock);
#line 800
  ad->original_sk_state_change = (s_listen->sk)->sk_state_change;
#line 801
  (s_listen->sk)->sk_state_change = & drbd_incoming_connection;
#line 802
  (s_listen->sk)->sk_user_data = (void *)ad;
#line 803
  _raw_write_unlock_bh(& (s_listen->sk)->sk_callback_lock);
#line 805
  what = "listen";
#line 806
  err = (*((s_listen->ops)->listen))(s_listen, 5);
#line 807
  if (err < 0) {
#line 808
    goto out;
  } else {

  }
#line 810
  return (0);
  out: ;
#line 812
  if ((unsigned long )s_listen != (unsigned long )((struct socket *)0)) {
#line 813
    sock_release(s_listen);
  } else {

  }
#line 814
  if (err < 0) {
#line 815
    if ((err != -11 && err != -4) && err != -512) {
#line 816
      printk("\vd-con %s: %s failed, err = %d\n", tconn->name, what, err);
#line 817
      val.i = 0U;
#line 817
      val.ldv_40024.conn = 1U;
#line 817
      mask.i = 0U;
#line 817
      mask.ldv_40024.conn = 31U;
#line 817
      conn_request_state(tconn, mask, val, CS_HARD);
    } else {

    }
  } else {

  }
#line 821
  return (-5);
}
}
#line 824 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void unregister_state_change(struct sock *sk , struct accept_wait_data *ad ) 
{ 


  {
#line 826
  _raw_write_lock_bh(& sk->sk_callback_lock);
#line 827
  sk->sk_state_change = ad->original_sk_state_change;
#line 828
  sk->sk_user_data = 0;
#line 829
  _raw_write_unlock_bh(& sk->sk_callback_lock);
#line 830
  return;
}
}
#line 832 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct socket *drbd_wait_for_connect(struct drbd_tconn *tconn , struct accept_wait_data *ad ) 
{ 
  int timeo ;
  int connect_int ;
  int err ;
  struct socket *s_estab ;
  struct net_conf *nc ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  u32 tmp___1 ;
  long tmp___2 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 834
  err = 0;
#line 835
  s_estab = 0;
#line 838
  rcu_read_lock___2();
#line 839
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 839
  tmp = debug_lockdep_rcu_enabled();
#line 839
  if (tmp != 0 && ! __warned) {
#line 839
    tmp___0 = rcu_read_lock_held();
#line 839
    if (tmp___0 == 0 && 1) {
#line 839
      __warned = 1;
#line 839
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             839, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 839
  nc = _________p1;
#line 840
  if ((unsigned long )nc == (unsigned long )((struct net_conf *)0)) {
#line 841
    rcu_read_unlock___2();
#line 842
    return (0);
  } else {

  }
#line 844
  connect_int = (int )nc->connect_int;
#line 845
  rcu_read_unlock___2();
#line 847
  timeo = connect_int * 250;
#line 848
  tmp___1 = random32();
#line 848
  timeo = ((int )tmp___1 & 1 ? timeo / 7 : - timeo / 7) + timeo;
#line 850
  tmp___2 = wait_for_completion_interruptible_timeout(& ad->door_bell, (unsigned long )timeo);
#line 850
  err = (int )tmp___2;
#line 851
  if (err <= 0) {
#line 852
    return (0);
  } else {

  }
#line 854
  err = kernel_accept(ad->s_listen, & s_estab, 0);
#line 855
  if (err < 0) {
#line 856
    if ((err != -11 && err != -4) && err != -512) {
#line 857
      printk("\vd-con %s: accept failed, err = %d\n", tconn->name, err);
#line 858
      val.i = 0U;
#line 858
      val.ldv_40024.conn = 1U;
#line 858
      mask.i = 0U;
#line 858
      mask.ldv_40024.conn = 31U;
#line 858
      conn_request_state(tconn, mask, val, CS_HARD);
    } else {

    }
  } else {

  }
#line 862
  if ((unsigned long )s_estab != (unsigned long )((struct socket *)0)) {
#line 863
    unregister_state_change(s_estab->sk, ad);
  } else {

  }
#line 865
  return (s_estab);
}
}
#line 868
static int decode_header(struct drbd_tconn *tconn , void *header , struct packet_info *pi ) ;
#line 870 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int send_first_packet(struct drbd_tconn *tconn , struct drbd_socket *sock ,
                             enum drbd_packet cmd ) 
{ 
  void *tmp ;
  int tmp___0 ;

  {
#line 873
  tmp = conn_prepare_command(tconn, sock);
#line 873
  if ((unsigned long )tmp == (unsigned long )((void *)0)) {
#line 874
    return (-5);
  } else {

  }
#line 875
  tmp___0 = conn_send_command(tconn, sock, cmd, 0U, 0, 0U);
#line 875
  return (tmp___0);
}
}
#line 878 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_first_packet(struct drbd_tconn *tconn , struct socket *sock ) 
{ 
  unsigned int header_size ;
  unsigned int tmp ;
  struct packet_info pi ;
  int err ;

  {
#line 880
  tmp = drbd_header_size(tconn);
#line 880
  header_size = tmp;
#line 884
  err = drbd_recv_short(sock, tconn->data.rbuf, (size_t )header_size, 0);
#line 885
  if ((unsigned int )err != header_size) {
#line 886
    if (err >= 0) {
#line 887
      err = -5;
    } else {

    }
#line 888
    return (err);
  } else {

  }
#line 890
  err = decode_header(tconn, tconn->data.rbuf, & pi);
#line 891
  if (err != 0) {
#line 892
    return (err);
  } else {

  }
#line 893
  return ((int )pi.cmd);
}
}
#line 900 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_socket_okay(struct socket **sock ) 
{ 
  int rr ;
  char tb[4U] ;

  {
#line 905
  if ((unsigned long )*sock == (unsigned long )((struct socket *)0)) {
#line 906
    return (0);
  } else {

  }
#line 908
  rr = drbd_recv_short(*sock, (void *)(& tb), 4UL, 66);
#line 910
  if (rr > 0 || rr == -11) {
#line 911
    return (1);
  } else {
#line 913
    sock_release(*sock);
#line 914
    *sock = 0;
#line 915
    return (0);
  }
}
}
#line 920 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
int drbd_connected(struct drbd_conf *mdev ) 
{ 
  int err ;

  {
#line 924
  atomic_set(& mdev->packet_seq, 0);
#line 925
  mdev->peer_seq = 0U;
#line 927
  mdev->state_mutex = (mdev->tconn)->agreed_pro_version <= 99 ? & (mdev->tconn)->cstate_mutex : & mdev->own_state_mutex;
#line 931
  err = drbd_send_sync_param(mdev);
#line 932
  if (err == 0) {
#line 933
    err = drbd_send_sizes(mdev, 0, 0);
  } else {

  }
#line 934
  if (err == 0) {
#line 935
    err = drbd_send_uuids(mdev);
  } else {

  }
#line 936
  if (err == 0) {
#line 937
    err = drbd_send_current_state(mdev);
  } else {

  }
#line 938
  clear_bit(2, (unsigned long volatile   *)(& mdev->flags));
#line 939
  clear_bit(16, (unsigned long volatile   *)(& mdev->flags));
#line 940
  mod_timer(& mdev->request_timer, (unsigned long )jiffies + 250UL);
#line 941
  return (err);
}
}
#line 952 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int conn_connect(struct drbd_tconn *tconn ) 
{ 
  struct drbd_socket sock ;
  struct drbd_socket msock ;
  struct drbd_conf *mdev ;
  struct net_conf *nc ;
  int vnr ;
  int timeout ;
  int h ;
  int ok ;
  bool discard_my_data ;
  enum drbd_state_rv rv ;
  struct accept_wait_data ad ;
  union drbd_state val ;
  union drbd_state mask ;
  enum drbd_state_rv tmp ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  int tmp___0 ;
  struct socket *s ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int fp ;
  int tmp___4 ;
  u32 tmp___5 ;
  struct task_struct *tmp___6 ;
  enum drbd_thread_state tmp___7 ;
  struct task_struct *tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  struct net_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___11 ;
  int tmp___12 ;
  long tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;
  void *tmp___16 ;
  void *tmp___17 ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;

  {
#line 962
  init_completion(& ad.door_bell);
#line 962
  ad.tconn = tconn;
#line 962
  ad.s_listen = 0;
#line 962
  ad.door_bell = ad.door_bell;
#line 962
  ad.original_sk_state_change = 0;
#line 965
  clear_bit(12, (unsigned long volatile   *)(& tconn->flags));
#line 966
  val.i = 0U;
#line 966
  val.ldv_40024.conn = 8U;
#line 966
  mask.i = 0U;
#line 966
  mask.ldv_40024.conn = 31U;
#line 966
  tmp = conn_request_state(tconn, mask, val, CS_VERBOSE);
#line 966
  if ((int )tmp <= 0) {
#line 967
    return (-2);
  } else {

  }
#line 969
  __mutex_init(& sock.mutex, "&sock.mutex", & __key);
#line 970
  sock.sbuf = tconn->data.sbuf;
#line 971
  sock.rbuf = tconn->data.rbuf;
#line 972
  sock.socket = 0;
#line 973
  __mutex_init(& msock.mutex, "&msock.mutex", & __key___0);
#line 974
  msock.sbuf = tconn->meta.sbuf;
#line 975
  msock.rbuf = tconn->meta.rbuf;
#line 976
  msock.socket = 0;
#line 979
  tconn->agreed_pro_version = 80;
#line 981
  tmp___0 = prepare_listen_socket(tconn, & ad);
#line 981
  if (tmp___0 != 0) {
#line 982
    return (0);
  } else {

  }
  ldv_53019: 
#line 987
  s = drbd_try_connect(tconn);
#line 988
  if ((unsigned long )s != (unsigned long )((struct socket *)0)) {
#line 989
    if ((unsigned long )sock.socket == (unsigned long )((struct socket *)0)) {
#line 990
      sock.socket = s;
#line 991
      send_first_packet(tconn, & sock, P_INITIAL_DATA);
    } else
#line 992
    if ((unsigned long )msock.socket == (unsigned long )((struct socket *)0)) {
#line 993
      clear_bit(1, (unsigned long volatile   *)(& tconn->flags));
#line 994
      msock.socket = s;
#line 995
      send_first_packet(tconn, & msock, P_INITIAL_META);
    } else {
#line 997
      printk("\vd-con %s: Logic error in conn_connect()\n", tconn->name);
#line 998
      goto out_release_sockets;
    }
  } else {

  }
#line 1002
  if ((unsigned long )sock.socket != (unsigned long )((struct socket *)0) && (unsigned long )msock.socket != (unsigned long )((struct socket *)0)) {
#line 1003
    rcu_read_lock___2();
#line 1004
    _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 1004
    tmp___1 = debug_lockdep_rcu_enabled();
#line 1004
    if (tmp___1 != 0 && ! __warned) {
#line 1004
      tmp___2 = rcu_read_lock_held();
#line 1004
      if (tmp___2 == 0 && 1) {
#line 1004
        __warned = 1;
#line 1004
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                               1004, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 1004
    nc = _________p1;
#line 1005
    timeout = (int )((nc->ping_timeo * 250U) / 10U);
#line 1006
    rcu_read_unlock___2();
#line 1007
    schedule_timeout_interruptible((long )timeout);
#line 1008
    ok = drbd_socket_okay(& sock.socket);
#line 1009
    tmp___3 = drbd_socket_okay(& msock.socket);
#line 1009
    ok = tmp___3 != 0 && ok != 0;
#line 1010
    if (ok != 0) {
#line 1011
      goto ldv_53011;
    } else {

    }
  } else {

  }
  retry: 
#line 1015
  s = drbd_wait_for_connect(tconn, & ad);
#line 1016
  if ((unsigned long )s != (unsigned long )((struct socket *)0)) {
#line 1017
    tmp___4 = receive_first_packet(tconn, s);
#line 1017
    fp = tmp___4;
#line 1018
    drbd_socket_okay(& sock.socket);
#line 1019
    drbd_socket_okay(& msock.socket);
#line 1020
    switch (fp) {
    case 65522: ;
#line 1022
    if ((unsigned long )sock.socket != (unsigned long )((struct socket *)0)) {
#line 1023
      printk("\fd-con %s: initial packet S crossed\n", tconn->name);
#line 1024
      sock_release(sock.socket);
#line 1025
      sock.socket = s;
#line 1026
      goto randomize;
    } else {

    }
#line 1028
    sock.socket = s;
#line 1029
    goto ldv_53016;
    case 65521: 
#line 1031
    set_bit(1U, (unsigned long volatile   *)(& tconn->flags));
#line 1032
    if ((unsigned long )msock.socket != (unsigned long )((struct socket *)0)) {
#line 1033
      printk("\fd-con %s: initial packet M crossed\n", tconn->name);
#line 1034
      sock_release(msock.socket);
#line 1035
      msock.socket = s;
#line 1036
      goto randomize;
    } else {

    }
#line 1038
    msock.socket = s;
#line 1039
    goto ldv_53016;
    default: 
#line 1041
    printk("\fd-con %s: Error receiving initial packet\n", tconn->name);
#line 1042
    sock_release(s);
    randomize: 
#line 1044
    tmp___5 = random32();
#line 1044
    if ((int )tmp___5 & 1) {
#line 1045
      goto retry;
    } else {

    }
    }
    ldv_53016: ;
  } else {

  }
#line 1049
  if ((unsigned int )tconn->cstate <= 1U) {
#line 1050
    goto out_release_sockets;
  } else {

  }
#line 1051
  tmp___8 = get_current();
#line 1051
  tmp___9 = signal_pending(tmp___8);
#line 1051
  if (tmp___9 != 0) {
#line 1052
    tmp___6 = get_current();
#line 1052
    flush_signals(tmp___6);
#line 1053
    __asm__  volatile   ("": : : "memory");
#line 1054
    tmp___7 = get_t_state(& tconn->receiver);
#line 1054
    if ((unsigned int )tmp___7 == 2U) {
#line 1055
      goto out_release_sockets;
    } else {

    }
  } else {

  }
#line 1058
  ok = drbd_socket_okay(& sock.socket);
#line 1059
  tmp___10 = drbd_socket_okay(& msock.socket);
#line 1059
  ok = tmp___10 != 0 && ok != 0;
#line 1060
  if (ok == 0) {
#line 1061
    goto ldv_53019;
  } else {

  }
  ldv_53011: ;
#line 1062
  if ((unsigned long )ad.s_listen != (unsigned long )((struct socket *)0)) {
#line 1063
    sock_release(ad.s_listen);
  } else {

  }
#line 1065
  ((sock.socket)->sk)->__sk_common.skc_reuse = 1U;
#line 1066
  ((msock.socket)->sk)->__sk_common.skc_reuse = 1U;
#line 1068
  ((sock.socket)->sk)->sk_allocation = 16U;
#line 1069
  ((msock.socket)->sk)->sk_allocation = 16U;
#line 1071
  ((sock.socket)->sk)->sk_priority = 4U;
#line 1072
  ((msock.socket)->sk)->sk_priority = 6U;
#line 1079
  rcu_read_lock___2();
#line 1080
  _________p1___0 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 1080
  tmp___11 = debug_lockdep_rcu_enabled();
#line 1080
  if (tmp___11 != 0 && ! __warned___0) {
#line 1080
    tmp___12 = rcu_read_lock_held();
#line 1080
    if (tmp___12 == 0 && 1) {
#line 1080
      __warned___0 = 1;
#line 1080
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             1080, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1080
  nc = _________p1___0;
#line 1082
  tmp___13 = (long )((nc->ping_timeo * 1000U) / 10U);
#line 1082
  ((sock.socket)->sk)->sk_rcvtimeo = tmp___13;
#line 1082
  ((sock.socket)->sk)->sk_sndtimeo = tmp___13;
#line 1085
  ((msock.socket)->sk)->sk_rcvtimeo = (long )(nc->ping_int * 250U);
#line 1086
  timeout = (int )((nc->timeout * 250U) / 10U);
#line 1087
  discard_my_data = (int )((signed char )nc->discard_my_data) != 0;
#line 1088
  rcu_read_unlock___2();
#line 1090
  ((msock.socket)->sk)->sk_sndtimeo = (long )timeout;
#line 1094
  drbd_tcp_nodelay(sock.socket);
#line 1095
  drbd_tcp_nodelay(msock.socket);
#line 1097
  tconn->data.socket = sock.socket;
#line 1098
  tconn->meta.socket = msock.socket;
#line 1099
  tconn->last_received = jiffies;
#line 1101
  h = drbd_do_features(tconn);
#line 1102
  if (h <= 0) {
#line 1103
    return (h);
  } else {

  }
#line 1105
  if ((unsigned long )tconn->cram_hmac_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 1107
    tmp___14 = drbd_do_auth(tconn);
#line 1107
    switch (tmp___14) {
    case -1: 
#line 1109
    printk("\vd-con %s: Authentication of peer failed\n", tconn->name);
#line 1110
    return (-1);
    case 0: 
#line 1112
    printk("\vd-con %s: Authentication of peer failed, trying again.\n", tconn->name);
#line 1113
    return (0);
    }
  } else {

  }
#line 1117
  ((tconn->data.socket)->sk)->sk_sndtimeo = (long )timeout;
#line 1118
  ((tconn->data.socket)->sk)->sk_rcvtimeo = 9223372036854775807L;
#line 1120
  tmp___15 = drbd_send_protocol(tconn);
#line 1120
  if (tmp___15 == -95) {
#line 1121
    return (-1);
  } else {

  }
#line 1123
  set_bit(10U, (unsigned long volatile   *)(& tconn->flags));
#line 1125
  rcu_read_lock___2();
#line 1126
  vnr = 0;
#line 1126
  tmp___16 = idr_get_next(& tconn->volumes, & vnr);
#line 1126
  mdev = (struct drbd_conf *)tmp___16;
#line 1126
  goto ldv_53026;
  ldv_53025: 
#line 1127
  kref_get(& mdev->kref);
#line 1135
  ldv_mutex_lock_104(mdev->state_mutex);
#line 1136
  ldv_mutex_unlock_105(mdev->state_mutex);
#line 1138
  rcu_read_unlock___2();
#line 1140
  if ((int )discard_my_data) {
#line 1141
    set_bit(21U, (unsigned long volatile   *)(& mdev->flags));
  } else {
#line 1143
    clear_bit(21, (unsigned long volatile   *)(& mdev->flags));
  }
#line 1145
  drbd_connected(mdev);
#line 1146
  kref_put(& mdev->kref, & drbd_minor_destroy);
#line 1147
  rcu_read_lock___2();
#line 1126
  vnr = vnr + 1;
#line 1126
  tmp___17 = idr_get_next(& tconn->volumes, & vnr);
#line 1126
  mdev = (struct drbd_conf *)tmp___17;
  ldv_53026: ;
#line 1126
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1127
    goto ldv_53025;
  } else {

  }
#line 1149
  rcu_read_unlock___2();
#line 1151
  val___0.i = 0U;
#line 1151
  val___0.ldv_40024.conn = 9U;
#line 1151
  mask___0.i = 0U;
#line 1151
  mask___0.ldv_40024.conn = 31U;
#line 1151
  rv = conn_request_state(tconn, mask___0, val___0, CS_VERBOSE);
#line 1152
  if ((int )rv <= 0 || (unsigned int )tconn->cstate != 9U) {
#line 1153
    clear_bit(10, (unsigned long volatile   *)(& tconn->flags));
#line 1154
    return (0);
  } else {

  }
#line 1157
  drbd_thread_start(& tconn->asender);
#line 1159
  ldv_mutex_lock_106(& tconn->conf_update);
#line 1164
  (tconn->net_conf)->discard_my_data = 0;
#line 1165
  ldv_mutex_unlock_107(& tconn->conf_update);
#line 1167
  return (h);
  out_release_sockets: ;
#line 1170
  if ((unsigned long )ad.s_listen != (unsigned long )((struct socket *)0)) {
#line 1171
    sock_release(ad.s_listen);
  } else {

  }
#line 1172
  if ((unsigned long )sock.socket != (unsigned long )((struct socket *)0)) {
#line 1173
    sock_release(sock.socket);
  } else {

  }
#line 1174
  if ((unsigned long )msock.socket != (unsigned long )((struct socket *)0)) {
#line 1175
    sock_release(msock.socket);
  } else {

  }
#line 1176
  return (-1);
}
}
#line 1179 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int decode_header(struct drbd_tconn *tconn , void *header , struct packet_info *pi ) 
{ 
  unsigned int header_size ;
  unsigned int tmp ;
  struct p_header100 *h ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  __u32 tmp___2 ;
  struct p_header95 *h___0 ;
  __u16 tmp___3 ;
  __u32 tmp___4 ;
  struct p_header80 *h___1 ;
  __u16 tmp___5 ;
  __u16 tmp___6 ;
  __u32 tmp___7 ;

  {
#line 1181
  tmp = drbd_header_size(tconn);
#line 1181
  header_size = tmp;
#line 1183
  if (header_size == 16U && *((__be32 *)header) == 552345734U) {
#line 1185
    h = (struct p_header100 *)header;
#line 1186
    if (h->pad != 0U) {
#line 1187
      printk("\vd-con %s: Header padding is not zero\n", tconn->name);
#line 1188
      return (-22);
    } else {

    }
#line 1190
    tmp___0 = __fswab16((int )h->volume);
#line 1190
    pi->vnr = (unsigned int )tmp___0;
#line 1191
    tmp___1 = __fswab16((int )h->command);
#line 1191
    pi->cmd = (enum drbd_packet )tmp___1;
#line 1192
    tmp___2 = __fswab32(h->length);
#line 1192
    pi->size = tmp___2;
  } else
#line 1193
  if (header_size == 8U && (unsigned int )*((__be16 *)header) == 23171U) {
#line 1195
    h___0 = (struct p_header95 *)header;
#line 1196
    tmp___3 = __fswab16((int )h___0->command);
#line 1196
    pi->cmd = (enum drbd_packet )tmp___3;
#line 1197
    tmp___4 = __fswab32(h___0->length);
#line 1197
    pi->size = tmp___4;
#line 1198
    pi->vnr = 0U;
  } else
#line 1199
  if (header_size == 8U && *((__be32 *)header) == 1728214147U) {
#line 1201
    h___1 = (struct p_header80 *)header;
#line 1202
    tmp___5 = __fswab16((int )h___1->command);
#line 1202
    pi->cmd = (enum drbd_packet )tmp___5;
#line 1203
    tmp___6 = __fswab16((int )h___1->length);
#line 1203
    pi->size = (unsigned int )tmp___6;
#line 1204
    pi->vnr = 0U;
  } else {
#line 1206
    tmp___7 = __fswab32(*((__be32 *)header));
#line 1206
    printk("\vd-con %s: Wrong magic value 0x%08x in protocol version %d\n", tconn->name,
           tmp___7, tconn->agreed_pro_version);
#line 1209
    return (-22);
  }
#line 1211
  pi->data = header + (unsigned long )header_size;
#line 1212
  return (0);
}
}
#line 1215 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_recv_header(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  void *buffer ;
  int err ;
  unsigned int tmp ;

  {
#line 1217
  buffer = tconn->data.rbuf;
#line 1220
  tmp = drbd_header_size(tconn);
#line 1220
  err = drbd_recv_all_warn(tconn, buffer, (size_t )tmp);
#line 1221
  if (err != 0) {
#line 1222
    return (err);
  } else {

  }
#line 1224
  err = decode_header(tconn, buffer, pi);
#line 1225
  tconn->last_received = jiffies;
#line 1227
  return (err);
}
}
#line 1230 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_flush(struct drbd_tconn *tconn ) 
{ 
  int rv ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  int tmp___0 ;
  void *tmp___1 ;

  {
#line 1236
  if ((unsigned int )tconn->write_ordering > 1U) {
#line 1237
    rcu_read_lock___2();
#line 1238
    vnr = 0;
#line 1238
    tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1238
    mdev = (struct drbd_conf *)tmp;
#line 1238
    goto ldv_53056;
    ldv_53055: 
#line 1239
    tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1239
    if (tmp___0 == 0) {
#line 1240
      goto ldv_53053;
    } else {

    }
#line 1241
    kref_get(& mdev->kref);
#line 1242
    rcu_read_unlock___2();
#line 1244
    rv = blkdev_issue_flush((mdev->ldev)->backing_bdev, 16U, 0);
#line 1246
    if (rv != 0) {
#line 1247
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "local disk flush failed with status %d\n",
                rv);
#line 1251
      drbd_bump_write_ordering(tconn, WO_drain_io);
    } else {

    }
#line 1253
    put_ldev(mdev);
#line 1254
    kref_put(& mdev->kref, & drbd_minor_destroy);
#line 1256
    rcu_read_lock___2();
#line 1257
    if (rv != 0) {
#line 1258
      goto ldv_53054;
    } else {

    }
    ldv_53053: 
#line 1238
    vnr = vnr + 1;
#line 1238
    tmp___1 = idr_get_next(& tconn->volumes, & vnr);
#line 1238
    mdev = (struct drbd_conf *)tmp___1;
    ldv_53056: ;
#line 1238
    if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1239
      goto ldv_53055;
    } else {

    }
    ldv_53054: 
#line 1260
    rcu_read_unlock___2();
  } else {

  }
#line 1262
  return;
}
}
#line 1270 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static enum finish_epoch drbd_may_finish_epoch(struct drbd_tconn *tconn , struct drbd_epoch *epoch ,
                                               enum epoch_event ev ) 
{ 
  int epoch_size ;
  struct drbd_epoch *next_epoch ;
  enum finish_epoch rv ;
  struct list_head  const  *__mptr ;
  int tmp ;
  int tmp___0 ;

  {
#line 1276
  rv = FE_STILL_LIVE;
#line 1278
  spin_lock(& tconn->epoch_lock);
  ldv_53072: 
#line 1280
  next_epoch = 0;
#line 1282
  epoch_size = atomic_read((atomic_t const   *)(& epoch->epoch_size));
#line 1284
  switch ((unsigned int )ev & 4294967263U) {
  case 0U: 
#line 1286
  atomic_dec(& epoch->active);
#line 1287
  goto ldv_53066;
  case 1U: 
#line 1289
  set_bit(0U, (unsigned long volatile   *)(& epoch->flags));
#line 1290
  goto ldv_53066;
  case 2U: ;
#line 1293
  goto ldv_53066;
  }
  ldv_53066: ;
#line 1296
  if (epoch_size != 0) {
#line 1296
    tmp = atomic_read((atomic_t const   *)(& epoch->active));
#line 1296
    if (tmp == 0) {
#line 1296
      tmp___0 = constant_test_bit(0U, (unsigned long const volatile   *)(& epoch->flags));
#line 1296
      if (tmp___0 != 0 || ((unsigned int )ev & 32U) != 0U) {
#line 1299
        if (((unsigned int )ev & 32U) == 0U) {
#line 1300
          spin_unlock(& tconn->epoch_lock);
#line 1301
          drbd_send_b_ack(epoch->tconn, epoch->barrier_nr, (u32 )epoch_size);
#line 1302
          spin_lock(& tconn->epoch_lock);
        } else {

        }
#line 1311
        if ((unsigned long )tconn->current_epoch != (unsigned long )epoch) {
#line 1312
          __mptr = (struct list_head  const  *)epoch->list.next;
#line 1312
          next_epoch = (struct drbd_epoch *)__mptr + 0xfffffffffffffff8UL;
#line 1313
          list_del(& epoch->list);
#line 1314
          ev = (enum epoch_event )(((unsigned int )ev & 32U) | 2U);
#line 1315
          tconn->epochs = tconn->epochs - 1U;
#line 1316
          kfree((void const   *)epoch);
#line 1318
          if ((unsigned int )rv == 0U) {
#line 1319
            rv = FE_DESTROYED;
          } else {

          }
        } else {
#line 1321
          epoch->flags = 0UL;
#line 1322
          atomic_set(& epoch->epoch_size, 0);
#line 1324
          if ((unsigned int )rv == 0U) {
#line 1325
            rv = FE_RECYCLED;
          } else {

          }
        }
      } else {

      }
    } else {

    }
  } else {

  }
#line 1329
  if ((unsigned long )next_epoch == (unsigned long )((struct drbd_epoch *)0)) {
#line 1330
    goto ldv_53071;
  } else {

  }
#line 1332
  epoch = next_epoch;
#line 1333
  goto ldv_53072;
  ldv_53071: 
#line 1335
  spin_unlock(& tconn->epoch_lock);
#line 1337
  return (rv);
}
}
#line 1345 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void drbd_bump_write_ordering(struct drbd_tconn *tconn , enum write_ordering_e wo ) 
{ 
  struct disk_conf *dc ;
  struct drbd_conf *mdev ;
  enum write_ordering_e pwo ;
  int vnr ;
  char *write_ordering_str[3U] ;
  enum write_ordering_e _min1 ;
  enum write_ordering_e _min2 ;
  void *tmp ;
  int tmp___0 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___1 ;
  int tmp___2 ;
  void *tmp___3 ;

  {
#line 1351
  write_ordering_str[0] = (char *)"none";
#line 1351
  write_ordering_str[1] = (char *)"drain";
#line 1351
  write_ordering_str[2] = (char *)"flush";
#line 1357
  pwo = tconn->write_ordering;
#line 1358
  _min1 = pwo;
#line 1358
  _min2 = wo;
#line 1358
  wo = (enum write_ordering_e )((unsigned int )_min1 < (unsigned int )_min2 ? (unsigned int )_min1 : (unsigned int )_min2);
#line 1359
  rcu_read_lock___2();
#line 1360
  vnr = 0;
#line 1360
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1360
  mdev = (struct drbd_conf *)tmp;
#line 1360
  goto ldv_53090;
  ldv_53089: 
#line 1361
  tmp___0 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 1361
  if (tmp___0 == 0) {
#line 1362
    goto ldv_53085;
  } else {

  }
#line 1363
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1363
  tmp___1 = debug_lockdep_rcu_enabled();
#line 1363
  if (tmp___1 != 0 && ! __warned) {
#line 1363
    tmp___2 = rcu_read_lock_held();
#line 1363
    if (tmp___2 == 0 && 1) {
#line 1363
      __warned = 1;
#line 1363
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             1363, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1363
  dc = _________p1;
#line 1365
  if ((unsigned int )wo == 2U && (int )((signed char )dc->disk_flushes) == 0) {
#line 1366
    wo = WO_drain_io;
  } else {

  }
#line 1367
  if ((unsigned int )wo == 1U && (int )((signed char )dc->disk_drain) == 0) {
#line 1368
    wo = WO_none;
  } else {

  }
#line 1369
  put_ldev(mdev);
  ldv_53085: 
#line 1360
  vnr = vnr + 1;
#line 1360
  tmp___3 = idr_get_next(& tconn->volumes, & vnr);
#line 1360
  mdev = (struct drbd_conf *)tmp___3;
  ldv_53090: ;
#line 1360
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1361
    goto ldv_53089;
  } else {

  }
#line 1371
  rcu_read_unlock___2();
#line 1372
  tconn->write_ordering = wo;
#line 1373
  if ((unsigned int )tconn->write_ordering != (unsigned int )pwo || (unsigned int )wo == 2U) {
#line 1374
    printk("\016d-con %s: Method to ensure write ordering: %s\n", tconn->name, write_ordering_str[(unsigned int )tconn->write_ordering]);
  } else {

  }
#line 1375
  return;
}
}
#line 1394 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
int drbd_submit_peer_request(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ,
                             unsigned int const   rw , int const   fault_type ) 
{ 
  struct bio *bios ;
  struct bio *bio ;
  struct page *page ;
  sector_t sector ;
  unsigned int ds ;
  unsigned int n_bios ;
  unsigned int nr_pages ;
  int err ;
  unsigned int len ;
  unsigned int __min1 ;
  unsigned int __min2 ;
  int tmp ;
  struct page *tmp___0 ;

  {
#line 1398
  bios = 0;
#line 1400
  page = peer_req->pages;
#line 1401
  sector = peer_req->i.sector;
#line 1402
  ds = peer_req->i.size;
#line 1403
  n_bios = 0U;
#line 1404
  nr_pages = (unsigned int )(((unsigned long )ds + 4095UL) >> 12);
#line 1405
  err = -12;
  next_bio: 
#line 1416
  bio = bio_alloc(16U, nr_pages);
#line 1417
  if ((unsigned long )bio == (unsigned long )((struct bio *)0)) {
#line 1418
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "submit_ee: Allocation of a bio failed\n");
#line 1419
    goto fail;
  } else {

  }
#line 1422
  bio->bi_sector = sector;
#line 1423
  bio->bi_bdev = (mdev->ldev)->backing_bdev;
#line 1424
  bio->bi_rw = (unsigned long )rw;
#line 1425
  bio->bi_private = (void *)peer_req;
#line 1426
  bio->bi_end_io = & drbd_peer_request_endio;
#line 1428
  bio->bi_next = bios;
#line 1429
  bios = bio;
#line 1430
  n_bios = n_bios + 1U;
#line 1432
  goto ldv_53114;
  ldv_53113: 
#line 1433
  __min1 = ds;
#line 1433
  __min2 = 4096U;
#line 1433
  len = __min1 < __min2 ? __min1 : __min2;
#line 1434
  tmp = bio_add_page(bio, page, len, 0U);
#line 1434
  if (tmp == 0) {
#line 1438
    if ((unsigned int )bio->bi_vcnt == 0U) {
#line 1439
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bio_add_page failed for len=%u, bi_vcnt=0 (bi_sector=%llu)\n",
              len, (unsigned long long )bio->bi_sector);
#line 1443
      err = -28;
#line 1444
      goto fail;
    } else {

    }
#line 1446
    goto next_bio;
  } else {

  }
#line 1448
  ds = ds - len;
#line 1449
  sector = (sector_t )(len >> 9) + sector;
#line 1450
  nr_pages = nr_pages - 1U;
#line 1432
  page = page_chain_next(page);
  ldv_53114: ;
#line 1432
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 1432
    tmp___0 = page_chain_next(page);
#line 1432
    __builtin_prefetch((void const   *)tmp___0);
#line 1432
    if (1 != 0) {
#line 1433
      goto ldv_53113;
    } else {
#line 1435
      goto ldv_53115;
    }
  } else {

  }
  ldv_53115: ;
#line 1452
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 1452
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( page == NULL ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            1452);
  } else {

  }
#line 1453
  if (ds != 0U) {
#line 1453
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( ds == 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            1453);
  } else {

  }
#line 1455
  atomic_set(& peer_req->pending_bios, (int )n_bios);
  ldv_53116: 
#line 1457
  bio = bios;
#line 1458
  bios = bios->bi_next;
#line 1459
  bio->bi_next = 0;
#line 1461
  drbd_generic_make_request(mdev, fault_type, bio);
#line 1462
  if ((unsigned long )bios != (unsigned long )((struct bio *)0)) {
#line 1463
    goto ldv_53116;
  } else {

  }

#line 1463
  return (0);
  fail: ;
#line 1466
  goto ldv_53119;
  ldv_53118: 
#line 1467
  bio = bios;
#line 1468
  bios = bios->bi_next;
#line 1469
  bio_put(bio);
  ldv_53119: ;
#line 1466
  if ((unsigned long )bios != (unsigned long )((struct bio *)0)) {
#line 1467
    goto ldv_53118;
  } else {

  }

#line 1471
  return (err);
}
}
#line 1474 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_remove_epoch_entry_interval(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ) 
{ 
  struct drbd_interval *i ;

  {
#line 1477
  i = & peer_req->i;
#line 1479
  drbd_remove_interval(& mdev->write_requests, i);
#line 1480
  drbd_clear_interval(i);
#line 1483
  if ((unsigned int )*((unsigned char *)i + 48UL) != 0U) {
#line 1484
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 1485
  return;
}
}
#line 1487 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void conn_wait_active_ee_empty(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 1492
  rcu_read_lock___2();
#line 1493
  vnr = 0;
#line 1493
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1493
  mdev = (struct drbd_conf *)tmp;
#line 1493
  goto ldv_53132;
  ldv_53131: 
#line 1494
  kref_get(& mdev->kref);
#line 1495
  rcu_read_unlock___2();
#line 1496
  drbd_wait_ee_list_empty(mdev, & mdev->active_ee);
#line 1497
  kref_put(& mdev->kref, & drbd_minor_destroy);
#line 1498
  rcu_read_lock___2();
#line 1493
  vnr = vnr + 1;
#line 1493
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 1493
  mdev = (struct drbd_conf *)tmp___0;
  ldv_53132: ;
#line 1493
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1494
    goto ldv_53131;
  } else {

  }
#line 1500
  rcu_read_unlock___2();
#line 1501
  return;
}
}
#line 1503 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_Barrier(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  int rv ;
  struct p_barrier *p ;
  struct drbd_epoch *epoch ;
  enum finish_epoch tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 1506
  p = (struct p_barrier *)pi->data;
#line 1512
  (tconn->current_epoch)->barrier_nr = p->barrier;
#line 1513
  (tconn->current_epoch)->tconn = tconn;
#line 1514
  tmp = drbd_may_finish_epoch(tconn, tconn->current_epoch, EV_GOT_BARRIER_NR);
#line 1514
  rv = (int )tmp;
#line 1521
  switch ((unsigned int )tconn->write_ordering) {
  case 0U: ;
#line 1523
  if (rv == 2) {
#line 1524
    return (0);
  } else {

  }
#line 1528
  tmp___0 = kmalloc(48UL, 16U);
#line 1528
  epoch = (struct drbd_epoch *)tmp___0;
#line 1529
  if ((unsigned long )epoch != (unsigned long )((struct drbd_epoch *)0)) {
#line 1530
    goto ldv_53142;
  } else {
#line 1532
    printk("\fd-con %s: Allocation of an epoch failed, slowing down\n", tconn->name);
  }
  case 2U: ;
  case 1U: 
#line 1537
  conn_wait_active_ee_empty(tconn);
#line 1538
  drbd_flush(tconn);
#line 1540
  tmp___2 = atomic_read((atomic_t const   *)(& (tconn->current_epoch)->epoch_size));
#line 1540
  if (tmp___2 != 0) {
#line 1541
    tmp___1 = kmalloc(48UL, 16U);
#line 1541
    epoch = (struct drbd_epoch *)tmp___1;
#line 1542
    if ((unsigned long )epoch != (unsigned long )((struct drbd_epoch *)0)) {
#line 1543
      goto ldv_53142;
    } else {

    }
  } else {

  }
#line 1546
  return (0);
  default: 
#line 1548
  printk("\vd-con %s: Strangeness in tconn->write_ordering %d\n", tconn->name, (unsigned int )tconn->write_ordering);
#line 1549
  return (-5);
  }
  ldv_53142: 
#line 1552
  epoch->flags = 0UL;
#line 1553
  atomic_set(& epoch->epoch_size, 0);
#line 1554
  atomic_set(& epoch->active, 0);
#line 1556
  spin_lock(& tconn->epoch_lock);
#line 1557
  tmp___3 = atomic_read((atomic_t const   *)(& (tconn->current_epoch)->epoch_size));
#line 1557
  if (tmp___3 != 0) {
#line 1558
    list_add(& epoch->list, & (tconn->current_epoch)->list);
#line 1559
    tconn->current_epoch = epoch;
#line 1560
    tconn->epochs = tconn->epochs + 1U;
  } else {
#line 1563
    kfree((void const   *)epoch);
  }
#line 1565
  spin_unlock(& tconn->epoch_lock);
#line 1567
  return (0);
}
}
#line 1573 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct drbd_peer_request *read_in_block(struct drbd_conf *mdev , u64 id , sector_t sector ,
                                               int data_size ) 
{ 
  sector_t capacity ;
  sector_t tmp ;
  struct drbd_peer_request *peer_req ;
  struct page *page ;
  int dgs ;
  int ds ;
  int err ;
  void *dig_in ;
  void *dig_vv ;
  unsigned long *data ;
  unsigned int tmp___0 ;
  bool _bool ;
  int tmp___1 ;
  bool _bool___0 ;
  int tmp___2 ;
  unsigned int len ;
  int __min1 ;
  int __min2 ;
  void *tmp___3 ;
  int tmp___4 ;
  struct page *tmp___5 ;
  int tmp___6 ;

  {
#line 1576
  tmp = drbd_get_capacity(mdev->this_bdev);
#line 1576
  capacity = tmp;
#line 1580
  dig_in = (mdev->tconn)->int_dig_in;
#line 1581
  dig_vv = (mdev->tconn)->int_dig_vv;
#line 1584
  dgs = 0;
#line 1585
  if ((unsigned long )(mdev->tconn)->peer_integrity_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 1586
    tmp___0 = crypto_hash_digestsize((mdev->tconn)->peer_integrity_tfm);
#line 1586
    dgs = (int )tmp___0;
#line 1591
    err = drbd_recv_all_warn(mdev->tconn, dig_in, (size_t )dgs);
#line 1592
    if (err != 0) {
#line 1593
      return (0);
    } else {

    }
#line 1594
    data_size = data_size - dgs;
  } else {

  }
#line 1597
  _bool = (data_size & 511) == 0;
#line 1597
  if (! _bool) {
#line 1597
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"IS_ALIGNED(data_size, 512)", "read_in_block");
  } else {

  }
#line 1597
  if (_bool) {
#line 1597
    tmp___1 = 0;
  } else {
#line 1597
    tmp___1 = 1;
  }
#line 1597
  if (tmp___1) {
#line 1598
    return (0);
  } else {

  }
#line 1599
  _bool___0 = (unsigned int )data_size <= 1048576U;
#line 1599
  if (! _bool___0) {
#line 1599
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"data_size <= DRBD_MAX_BIO_SIZE", "read_in_block");
  } else {

  }
#line 1599
  if (_bool___0) {
#line 1599
    tmp___2 = 0;
  } else {
#line 1599
    tmp___2 = 1;
  }
#line 1599
  if (tmp___2) {
#line 1600
    return (0);
  } else {

  }
#line 1604
  if ((sector_t )(data_size >> 9) + sector > capacity) {
#line 1605
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "request from peer beyond end of local disk: capacity: %llus < sector: %llus + size: %u\n",
            (unsigned long long )capacity, (unsigned long long )sector, data_size);
#line 1609
    return (0);
  } else {

  }
#line 1615
  peer_req = drbd_alloc_peer_req(mdev, id, sector, (unsigned int )data_size, 16U);
#line 1616
  if ((unsigned long )peer_req == (unsigned long )((struct drbd_peer_request *)0)) {
#line 1617
    return (0);
  } else {

  }
#line 1619
  if (data_size == 0) {
#line 1620
    return (peer_req);
  } else {

  }
#line 1622
  ds = data_size;
#line 1623
  page = peer_req->pages;
#line 1624
  goto ldv_53172;
  ldv_53171: 
#line 1625
  __min1 = ds;
#line 1625
  __min2 = 4096;
#line 1625
  len = (unsigned int )(__min1 < __min2 ? __min1 : __min2);
#line 1626
  tmp___3 = kmap(page);
#line 1626
  data = (unsigned long *)tmp___3;
#line 1627
  err = drbd_recv_all_warn(mdev->tconn, (void *)data, (size_t )len);
#line 1628
  tmp___4 = drbd_insert_fault(mdev, 9U);
#line 1628
  if (tmp___4 != 0) {
#line 1629
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Fault injection: Corrupting data on receive\n");
#line 1630
    *data = ~ *data;
  } else {

  }
#line 1632
  kunmap(page);
#line 1633
  if (err != 0) {
#line 1634
    __drbd_free_peer_req(mdev, peer_req, 0);
#line 1635
    return (0);
  } else {

  }
#line 1637
  ds = (int )((unsigned int )ds - len);
#line 1624
  page = page_chain_next(page);
  ldv_53172: ;
#line 1624
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 1624
    tmp___5 = page_chain_next(page);
#line 1624
    __builtin_prefetch((void const   *)tmp___5);
#line 1624
    if (1 != 0) {
#line 1625
      goto ldv_53171;
    } else {
#line 1627
      goto ldv_53173;
    }
  } else {

  }
  ldv_53173: ;
#line 1640
  if (dgs != 0) {
#line 1641
    drbd_csum_ee(mdev, (mdev->tconn)->peer_integrity_tfm, peer_req, dig_vv);
#line 1642
    tmp___6 = memcmp((void const   *)dig_in, (void const   *)dig_vv, (size_t )dgs);
#line 1642
    if (tmp___6 != 0) {
#line 1643
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Digest integrity check FAILED: %llus +%u\n",
              (unsigned long long )sector, data_size);
#line 1645
      __drbd_free_peer_req(mdev, peer_req, 0);
#line 1646
      return (0);
    } else {

    }
  } else {

  }
#line 1649
  mdev->recv_cnt = mdev->recv_cnt + (unsigned int )(data_size >> 9);
#line 1650
  return (peer_req);
}
}
#line 1656 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_drain_block(struct drbd_conf *mdev , int data_size ) 
{ 
  struct page *page ;
  int err ;
  void *data ;
  unsigned int len ;
  int __min1 ;
  int __min2 ;

  {
#line 1659
  err = 0;
#line 1662
  if (data_size == 0) {
#line 1663
    return (0);
  } else {

  }
#line 1665
  page = drbd_alloc_pages(mdev, 1U, 1);
#line 1667
  data = kmap(page);
#line 1668
  goto ldv_53187;
  ldv_53186: 
#line 1669
  __min1 = data_size;
#line 1669
  __min2 = 4096;
#line 1669
  len = (unsigned int )(__min1 < __min2 ? __min1 : __min2);
#line 1671
  err = drbd_recv_all_warn(mdev->tconn, data, (size_t )len);
#line 1672
  if (err != 0) {
#line 1673
    goto ldv_53185;
  } else {

  }
#line 1674
  data_size = (int )((unsigned int )data_size - len);
  ldv_53187: ;
#line 1668
  if (data_size != 0) {
#line 1669
    goto ldv_53186;
  } else {

  }
  ldv_53185: 
#line 1676
  kunmap(page);
#line 1677
  drbd_free_pages(mdev, page, 0);
#line 1678
  return (err);
}
}
#line 1681 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int recv_dless_read(struct drbd_conf *mdev , struct drbd_request *req , sector_t sector ,
                           int data_size ) 
{ 
  struct bio_vec *bvec ;
  struct bio *bio ;
  int dgs ;
  int err ;
  int i ;
  int expect ;
  void *dig_in ;
  void *dig_vv ;
  unsigned int tmp ;
  void *mapped ;
  void *tmp___0 ;
  int __min1 ;
  int __min2 ;
  int tmp___1 ;

  {
#line 1687
  dig_in = (mdev->tconn)->int_dig_in;
#line 1688
  dig_vv = (mdev->tconn)->int_dig_vv;
#line 1690
  dgs = 0;
#line 1691
  if ((unsigned long )(mdev->tconn)->peer_integrity_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 1692
    tmp = crypto_hash_digestsize((mdev->tconn)->peer_integrity_tfm);
#line 1692
    dgs = (int )tmp;
#line 1693
    err = drbd_recv_all_warn(mdev->tconn, dig_in, (size_t )dgs);
#line 1694
    if (err != 0) {
#line 1695
      return (err);
    } else {

    }
#line 1696
    data_size = data_size - dgs;
  } else {

  }
#line 1701
  mdev->recv_cnt = mdev->recv_cnt + (unsigned int )(data_size >> 9);
#line 1703
  bio = req->master_bio;
#line 1704
  if (bio->bi_sector != sector) {
#line 1704
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( sector == bio->bi_sector ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            1704);
  } else {

  }
#line 1706
  bvec = bio->bi_io_vec + (unsigned long )bio->bi_idx;
#line 1706
  i = (int )bio->bi_idx;
#line 1706
  goto ldv_53207;
  ldv_53206: 
#line 1707
  tmp___0 = kmap(bvec->bv_page);
#line 1707
  mapped = tmp___0 + (unsigned long )bvec->bv_offset;
#line 1708
  __min1 = data_size;
#line 1708
  __min2 = (int )bvec->bv_len;
#line 1708
  expect = __min1 < __min2 ? __min1 : __min2;
#line 1709
  err = drbd_recv_all_warn(mdev->tconn, mapped, (size_t )expect);
#line 1710
  kunmap(bvec->bv_page);
#line 1711
  if (err != 0) {
#line 1712
    return (err);
  } else {

  }
#line 1713
  data_size = data_size - expect;
#line 1706
  bvec = bvec + 1;
#line 1706
  i = i + 1;
  ldv_53207: ;
#line 1706
  if ((int )bio->bi_vcnt > i) {
#line 1707
    goto ldv_53206;
  } else {

  }

#line 1716
  if (dgs != 0) {
#line 1717
    drbd_csum_bio(mdev, (mdev->tconn)->peer_integrity_tfm, bio, dig_vv);
#line 1718
    tmp___1 = memcmp((void const   *)dig_in, (void const   *)dig_vv, (size_t )dgs);
#line 1718
    if (tmp___1 != 0) {
#line 1719
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Digest integrity check FAILED. Broken NICs?\n");
#line 1720
      return (-22);
    } else {

    }
  } else {

  }
#line 1724
  if (data_size != 0) {
#line 1724
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( data_size == 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            1724);
  } else {

  }
#line 1725
  return (0);
}
}
#line 1732 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int e_end_resync_block(struct drbd_work *w , int unused ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  sector_t sector ;
  int err ;
  bool tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
#line 1735
  __mptr = (struct drbd_work  const  *)w;
#line 1735
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1736
  mdev = w->ldv_49807.mdev;
#line 1737
  sector = peer_req->i.sector;
#line 1740
  tmp = drbd_interval_empty(& peer_req->i);
#line 1740
  if (tmp) {
#line 1740
    tmp___0 = 0;
  } else {
#line 1740
    tmp___0 = 1;
  }
#line 1740
  if (tmp___0) {
#line 1740
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( drbd_interval_empty(&peer_req->i) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            1740);
  } else {

  }
#line 1742
  tmp___1 = __builtin_expect((peer_req->flags & 8UL) == 0UL, 1L);
#line 1742
  if (tmp___1 != 0L) {
#line 1743
    __drbd_set_in_sync(mdev, sector, (int )peer_req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                       1743U);
#line 1744
    err = drbd_send_ack(mdev, P_RS_WRITE_ACK, peer_req);
  } else {
#line 1747
    drbd_rs_failed_io(mdev, sector, (int )peer_req->i.size);
#line 1749
    err = drbd_send_ack(mdev, P_NEG_ACK, peer_req);
  }
#line 1751
  _dec_unacked(mdev, "e_end_resync_block", 1751);
#line 1753
  return (err);
}
}
#line 1756 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int recv_resync_read(struct drbd_conf *mdev , sector_t sector , int data_size ) 
{ 
  struct drbd_peer_request *peer_req ;
  int tmp ;

  {
#line 1760
  peer_req = read_in_block(mdev, 0xffffffffffffffffULL, sector, data_size);
#line 1761
  if ((unsigned long )peer_req == (unsigned long )((struct drbd_peer_request *)0)) {
#line 1762
    goto fail;
  } else {

  }
#line 1764
  _dec_rs_pending(mdev, "recv_resync_read", 1764);
#line 1766
  inc_unacked(mdev);
#line 1770
  peer_req->w.cb = & e_end_resync_block;
#line 1772
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1773
  list_add(& peer_req->w.list, & mdev->sync_ee);
#line 1774
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1776
  atomic_add(data_size >> 9, & mdev->rs_sect_ev);
#line 1777
  tmp = drbd_submit_peer_request(mdev, peer_req, 1U, 2);
#line 1777
  if (tmp == 0) {
#line 1778
    return (0);
  } else {

  }
#line 1781
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "submit failed, triggering re-connect\n");
#line 1782
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1783
  list_del(& peer_req->w.list);
#line 1784
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1786
  __drbd_free_peer_req(mdev, peer_req, 0);
  fail: 
#line 1788
  put_ldev(mdev);
#line 1789
  return (-5);
}
}
#line 1793 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct drbd_request *find_request(struct drbd_conf *mdev , struct rb_root *root ,
                                         u64 id , sector_t sector , bool missing_ok ,
                                         char const   *func ) 
{ 
  struct drbd_request *req ;
  bool tmp ;

  {
#line 1799
  req = (struct drbd_request *)id;
#line 1800
  tmp = drbd_contains_interval(root, sector, & req->i);
#line 1800
  if ((int )tmp && (unsigned int )*((unsigned char *)req + 88UL) != 0U) {
#line 1801
    return (req);
  } else {

  }
#line 1802
  if (! missing_ok) {
#line 1803
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s: failed to find request 0x%lx, sector %llus\n",
            func, (unsigned long )id, (unsigned long long )sector);
  } else {

  }
#line 1806
  return (0);
}
}
#line 1809 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_DataReply(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct drbd_request *req ;
  sector_t sector ;
  int err ;
  struct p_data *p ;
  __u64 tmp ;
  long tmp___0 ;

  {
#line 1815
  p = (struct p_data *)pi->data;
#line 1817
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 1818
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 1819
    return (-5);
  } else {

  }
#line 1821
  tmp = __fswab64(p->sector);
#line 1821
  sector = (sector_t )tmp;
#line 1823
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1824
  req = find_request(mdev, & mdev->read_requests, p->block_id, sector, 0, "receive_DataReply");
#line 1825
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1826
  tmp___0 = __builtin_expect((unsigned long )req == (unsigned long )((struct drbd_request *)0),
                             0L);
#line 1826
  if (tmp___0 != 0L) {
#line 1827
    return (-5);
  } else {

  }
#line 1832
  err = recv_dless_read(mdev, req, sector, (int )pi->size);
#line 1833
  if (err == 0) {
#line 1834
    req_mod(req, DATA_RECEIVED);
  } else {

  }
#line 1839
  return (err);
}
}
#line 1842 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_RSDataReply(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  sector_t sector ;
  int err ;
  struct p_data *p ;
  __u64 tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 1847
  p = (struct p_data *)pi->data;
#line 1849
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 1850
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 1851
    return (-5);
  } else {

  }
#line 1853
  tmp = __fswab64(p->sector);
#line 1853
  sector = (sector_t )tmp;
#line 1854
  if (p->block_id != 0xffffffffffffffffULL) {
#line 1854
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( p->block_id == ID_SYNCER ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            1854);
  } else {

  }
#line 1856
  tmp___1 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1856
  if (tmp___1 != 0) {
#line 1860
    err = recv_resync_read(mdev, sector, (int )pi->size);
  } else {
#line 1862
    tmp___0 = ___ratelimit(& drbd_ratelimit_state, "receive_RSDataReply");
#line 1862
    if (tmp___0 != 0) {
#line 1863
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Can not write resync data to local disk.\n");
    } else {

    }
#line 1865
    err = drbd_drain_block(mdev, (int )pi->size);
#line 1867
    drbd_send_ack_dp(mdev, P_NEG_ACK, p, (int )pi->size);
  }
#line 1870
  atomic_add((int )(pi->size >> 9), & mdev->rs_sect_in);
#line 1872
  return (err);
}
}
#line 1875 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void restart_conflicting_writes(struct drbd_conf *mdev , sector_t sector ,
                                       int size ) 
{ 
  struct drbd_interval *i ;
  struct drbd_request *req ;
  struct drbd_interval  const  *__mptr ;

  {
#line 1881
  i = drbd_find_overlap(& mdev->write_requests, sector, (unsigned int )size);
#line 1881
  goto ldv_53267;
  ldv_53266: ;
#line 1882
  if ((unsigned int )*((unsigned char *)i + 48UL) == 0U) {
#line 1883
    goto ldv_53263;
  } else {

  }
#line 1884
  __mptr = (struct drbd_interval  const  *)i;
#line 1884
  req = (struct drbd_request *)__mptr + 0xffffffffffffffd8UL;
#line 1885
  if ((int )req->rq_state & 1 || ((unsigned long )req->rq_state & 8192UL) == 0UL) {
#line 1887
    goto ldv_53263;
  } else {

  }
#line 1890
  __req_mod(req, CONFLICT_RESOLVED, 0);
  ldv_53263: 
#line 1881
  i = drbd_next_overlap(i, sector, (unsigned int )size);
  ldv_53267: ;
#line 1881
  if ((unsigned long )i != (unsigned long )((struct drbd_interval *)0)) {
#line 1882
    goto ldv_53266;
  } else {

  }

#line 1886
  return;
}
}
#line 1897 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int e_end_block(struct drbd_work *w , int cancel ) 
{ 
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  sector_t sector ;
  int err ;
  int pcmd ;
  long tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
#line 1900
  __mptr = (struct drbd_work  const  *)w;
#line 1900
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1901
  mdev = w->ldv_49807.mdev;
#line 1902
  sector = peer_req->i.sector;
#line 1903
  err = 0;
#line 1905
  if ((peer_req->flags & 64UL) != 0UL) {
#line 1906
    tmp = __builtin_expect((peer_req->flags & 8UL) == 0UL, 1L);
#line 1906
    if (tmp != 0L) {
#line 1907
      pcmd = ((int )mdev->state.ldv_49522.conn > 15 && (int )mdev->state.ldv_49522.conn <= 21) && (peer_req->flags & 2UL) != 0UL ? 23 : 22;
#line 1911
      err = drbd_send_ack(mdev, (enum drbd_packet )pcmd, peer_req);
#line 1912
      if (pcmd == 23) {
#line 1913
        __drbd_set_in_sync(mdev, sector, (int )peer_req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                           1913U);
      } else {

      }
    } else {
#line 1915
      err = drbd_send_ack(mdev, P_NEG_ACK, peer_req);
    }
#line 1919
    _dec_unacked(mdev, "e_end_block", 1919);
  } else {

  }
#line 1923
  if ((peer_req->flags & 128UL) != 0UL) {
#line 1924
    spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1925
    tmp___0 = drbd_interval_empty(& peer_req->i);
#line 1925
    if ((int )tmp___0) {
#line 1925
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !drbd_interval_empty(&peer_req->i) ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              1925);
    } else {

    }
#line 1926
    drbd_remove_epoch_entry_interval(mdev, peer_req);
#line 1927
    if ((peer_req->flags & 32UL) != 0UL) {
#line 1928
      restart_conflicting_writes(mdev, sector, (int )peer_req->i.size);
    } else {

    }
#line 1929
    spin_unlock_irq(& (mdev->tconn)->req_lock);
  } else {
#line 1931
    tmp___1 = drbd_interval_empty(& peer_req->i);
#line 1931
    if (tmp___1) {
#line 1931
      tmp___2 = 0;
    } else {
#line 1931
      tmp___2 = 1;
    }
#line 1931
    if (tmp___2) {
#line 1931
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( drbd_interval_empty(&peer_req->i) ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              1931);
    } else {

    }
  }
#line 1933
  drbd_may_finish_epoch(mdev->tconn, peer_req->epoch, cancel != 0 ? EV_CLEANUP : EV_PUT);
#line 1935
  return (err);
}
}
#line 1938 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int e_send_ack(struct drbd_work *w , enum drbd_packet ack ) 
{ 
  struct drbd_conf *mdev ;
  struct drbd_peer_request *peer_req ;
  struct drbd_work  const  *__mptr ;
  int err ;

  {
#line 1940
  mdev = w->ldv_49807.mdev;
#line 1942
  __mptr = (struct drbd_work  const  *)w;
#line 1942
  peer_req = (struct drbd_peer_request *)__mptr;
#line 1945
  err = drbd_send_ack(mdev, ack, peer_req);
#line 1946
  _dec_unacked(mdev, "e_send_ack", 1946);
#line 1948
  return (err);
}
}
#line 1951 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int e_send_superseded(struct drbd_work *w , int unused ) 
{ 
  int tmp ;

  {
#line 1953
  tmp = e_send_ack(w, P_SUPERSEDED);
#line 1953
  return (tmp);
}
}
#line 1956 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int e_send_retry_write(struct drbd_work *w , int unused ) 
{ 
  struct drbd_tconn *tconn ;
  int tmp ;

  {
#line 1958
  tconn = (w->ldv_49807.mdev)->tconn;
#line 1960
  tmp = e_send_ack(w, tconn->agreed_pro_version > 99 ? P_RETRY_WRITE : P_SUPERSEDED);
#line 1960
  return (tmp);
}
}
#line 1964 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static bool seq_greater(u32 a , u32 b ) 
{ 


  {
#line 1971
  return ((int )a - (int )b > 0);
}
}
#line 1974 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static u32 seq_max(u32 a , u32 b ) 
{ 
  bool tmp ;

  {
#line 1976
  tmp = seq_greater(a, b);
#line 1976
  return ((int )tmp ? a : b);
}
}
#line 1979 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static bool need_peer_seq(struct drbd_conf *mdev ) 
{ 
  struct drbd_tconn *tconn ;
  int tp ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 1981
  tconn = mdev->tconn;
#line 1990
  rcu_read_lock___2();
#line 1991
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 1991
  tmp = debug_lockdep_rcu_enabled();
#line 1991
  if (tmp != 0 && ! __warned) {
#line 1991
    tmp___0 = rcu_read_lock_held();
#line 1991
    if (tmp___0 == 0 && 1) {
#line 1991
      __warned = 1;
#line 1991
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             1991, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1991
  tp = (int )_________p1->two_primaries;
#line 1992
  rcu_read_unlock___2();
#line 1994
  if (tp != 0) {
#line 1994
    tmp___1 = constant_test_bit(1U, (unsigned long const volatile   *)(& tconn->flags));
#line 1994
    if (tmp___1 != 0) {
#line 1994
      tmp___2 = 1;
    } else {
#line 1994
      tmp___2 = 0;
    }
  } else {
#line 1994
    tmp___2 = 0;
  }
#line 1994
  return ((bool )tmp___2);
}
}
#line 1997 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void update_peer_seq(struct drbd_conf *mdev , unsigned int peer_seq ) 
{ 
  unsigned int newest_peer_seq ;
  bool tmp ;

  {
#line 2001
  tmp = need_peer_seq(mdev);
#line 2001
  if ((int )tmp) {
#line 2002
    spin_lock(& mdev->peer_seq_lock);
#line 2003
    newest_peer_seq = seq_max(mdev->peer_seq, peer_seq);
#line 2004
    mdev->peer_seq = newest_peer_seq;
#line 2005
    spin_unlock(& mdev->peer_seq_lock);
#line 2007
    if (peer_seq == newest_peer_seq) {
#line 2008
      __wake_up(& mdev->seq_wait, 3U, 1, 0);
    } else {

    }
  } else {

  }
#line 2010
  return;
}
}
#line 2012 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
__inline static int overlaps(sector_t s1 , int l1 , sector_t s2 , int l2 ) 
{ 


  {
#line 2014
  return ((sector_t )(l1 >> 9) + s1 > s2 && (sector_t )(l2 >> 9) + s2 > s1);
}
}
#line 2018 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static bool overlapping_resync_write(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ) 
{ 
  struct drbd_peer_request *rs_req ;
  bool rv ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;

  {
#line 2021
  rv = 0;
#line 2023
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2024
  __mptr = (struct list_head  const  *)mdev->sync_ee.next;
#line 2024
  rs_req = (struct drbd_peer_request *)__mptr;
#line 2024
  goto ldv_53339;
  ldv_53338: 
#line 2025
  tmp = overlaps(peer_req->i.sector, (int )peer_req->i.size, rs_req->i.sector, (int )rs_req->i.size);
#line 2025
  if (tmp != 0) {
#line 2027
    rv = 1;
#line 2028
    goto ldv_53337;
  } else {

  }
#line 2024
  __mptr___0 = (struct list_head  const  *)rs_req->w.list.next;
#line 2024
  rs_req = (struct drbd_peer_request *)__mptr___0;
  ldv_53339: ;
#line 2024
  if ((unsigned long )(& rs_req->w.list) != (unsigned long )(& mdev->sync_ee)) {
#line 2025
    goto ldv_53338;
  } else {

  }
  ldv_53337: 
#line 2031
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2033
  return (rv);
}
}
#line 2057 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int wait_for_and_update_peer_seq(struct drbd_conf *mdev , u32 const   peer_seq ) 
{ 
  wait_queue_t wait ;
  struct task_struct *tmp ;
  long timeout ;
  int ret ;
  bool tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  struct task_struct *tmp___4 ;
  int tmp___5 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___6 ;
  int tmp___7 ;

  {
#line 2059
  tmp = get_current();
#line 2059
  wait.flags = 0U;
#line 2059
  wait.private = (void *)tmp;
#line 2059
  wait.func = & autoremove_wake_function;
#line 2059
  wait.task_list.next = & wait.task_list;
#line 2059
  wait.task_list.prev = & wait.task_list;
#line 2063
  tmp___0 = need_peer_seq(mdev);
#line 2063
  if (tmp___0) {
#line 2063
    tmp___1 = 0;
  } else {
#line 2063
    tmp___1 = 1;
  }
#line 2063
  if (tmp___1) {
#line 2064
    return (0);
  } else {

  }
#line 2066
  spin_lock(& mdev->peer_seq_lock);
  ldv_53351: 
#line 2068
  tmp___2 = seq_greater((unsigned int )peer_seq - 1U, mdev->peer_seq);
#line 2068
  if (tmp___2) {
#line 2068
    tmp___3 = 0;
  } else {
#line 2068
    tmp___3 = 1;
  }
#line 2068
  if (tmp___3) {
#line 2069
    mdev->peer_seq = seq_max(mdev->peer_seq, peer_seq);
#line 2070
    ret = 0;
#line 2071
    goto ldv_53347;
  } else {

  }
#line 2073
  tmp___4 = get_current();
#line 2073
  tmp___5 = signal_pending(tmp___4);
#line 2073
  if (tmp___5 != 0) {
#line 2074
    ret = -512;
#line 2075
    goto ldv_53347;
  } else {

  }
#line 2077
  prepare_to_wait(& mdev->seq_wait, & wait, 1);
#line 2078
  spin_unlock(& mdev->peer_seq_lock);
#line 2079
  rcu_read_lock___2();
#line 2080
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2080
  tmp___6 = debug_lockdep_rcu_enabled();
#line 2080
  if (tmp___6 != 0 && ! __warned) {
#line 2080
    tmp___7 = rcu_read_lock_held();
#line 2080
    if (tmp___7 == 0 && 1) {
#line 2080
      __warned = 1;
#line 2080
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             2080, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2080
  timeout = (long )((_________p1->ping_timeo * 250U) / 10U);
#line 2081
  rcu_read_unlock___2();
#line 2082
  timeout = schedule_timeout(timeout);
#line 2083
  spin_lock(& mdev->peer_seq_lock);
#line 2084
  if (timeout == 0L) {
#line 2085
    ret = -110;
#line 2086
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Timed out waiting for missing ack packets; disconnecting\n");
#line 2087
    goto ldv_53347;
  } else {

  }
#line 2089
  goto ldv_53351;
  ldv_53347: 
#line 2090
  spin_unlock(& mdev->peer_seq_lock);
#line 2091
  finish_wait(& mdev->seq_wait, & wait);
#line 2092
  return (ret);
}
}
#line 2098 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static unsigned long wire_flags_to_bio(struct drbd_conf *mdev , u32 dpf ) 
{ 


  {
#line 2100
  return ((unsigned long )(((((dpf & 2U) != 0U ? 16 : 0) | ((dpf & 16U) != 0U ? 2048 : 0)) | ((dpf & 32U) != 0U ? 4096 : 0)) | ((dpf & 64U) != 0U ? 128 : 0)));
}
}
#line 2106 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void fail_postponed_requests(struct drbd_conf *mdev , sector_t sector , unsigned int size ) 
{ 
  struct drbd_interval *i ;
  struct drbd_request *req ;
  struct bio_and_error m ;
  struct drbd_interval  const  *__mptr ;

  {
  repeat: 
#line 2112
  i = drbd_find_overlap(& mdev->write_requests, sector, size);
#line 2112
  goto ldv_53369;
  ldv_53368: ;
#line 2116
  if ((unsigned int )*((unsigned char *)i + 48UL) == 0U) {
#line 2117
    goto ldv_53365;
  } else {

  }
#line 2118
  __mptr = (struct drbd_interval  const  *)i;
#line 2118
  req = (struct drbd_request *)__mptr + 0xffffffffffffffd8UL;
#line 2119
  if (((unsigned long )req->rq_state & 8192UL) == 0UL) {
#line 2120
    goto ldv_53365;
  } else {

  }
#line 2121
  req->rq_state = req->rq_state & 4294959103U;
#line 2122
  __req_mod(req, NEG_ACKED, & m);
#line 2123
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2124
  if ((unsigned long )m.bio != (unsigned long )((struct bio *)0)) {
#line 2125
    complete_master_bio(mdev, & m);
  } else {

  }
#line 2126
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2127
  goto repeat;
  ldv_53365: 
#line 2112
  i = drbd_next_overlap(i, sector, size);
  ldv_53369: ;
#line 2112
  if ((unsigned long )i != (unsigned long )((struct drbd_interval *)0)) {
#line 2113
    goto ldv_53368;
  } else {

  }

#line 2117
  return;
}
}
#line 2131 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int handle_write_conflicts(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ) 
{ 
  struct drbd_tconn *tconn ;
  bool resolve_conflicts ;
  int tmp ;
  sector_t sector ;
  unsigned int size ;
  struct drbd_interval *i ;
  bool equal ;
  int err ;
  bool superseded ;
  struct drbd_request *req ;
  struct drbd_interval  const  *__mptr ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 2134
  tconn = mdev->tconn;
#line 2135
  tmp = constant_test_bit(1U, (unsigned long const volatile   *)(& tconn->flags));
#line 2135
  resolve_conflicts = tmp != 0;
#line 2136
  sector = peer_req->i.sector;
#line 2137
  size = peer_req->i.size;
#line 2146
  drbd_insert_interval(& mdev->write_requests, & peer_req->i);
  repeat: 
#line 2149
  i = drbd_find_overlap(& mdev->write_requests, sector, size);
#line 2149
  goto ldv_53394;
  ldv_53393: ;
#line 2150
  if ((unsigned long )(& peer_req->i) == (unsigned long )i) {
#line 2151
    goto ldv_53383;
  } else {

  }
#line 2153
  if ((unsigned int )*((unsigned char *)i + 48UL) == 0U) {
#line 2159
    err = drbd_wait_misc(mdev, i);
#line 2160
    if (err != 0) {
#line 2161
      goto out;
    } else {

    }
#line 2162
    goto repeat;
  } else {

  }
#line 2165
  equal = (bool )(i->sector == sector && i->size == size);
#line 2166
  if ((int )resolve_conflicts) {
#line 2173
    superseded = (bool )(i->sector <= sector && i->sector + (sector_t )(i->size >> 9) >= (sector_t )(size >> 9) + sector);
#line 2176
    if (! equal) {
#line 2177
      dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Concurrent writes detected: local=%llus +%u, remote=%llus +%u, assuming %s came first\n",
                (unsigned long long )i->sector, i->size, (unsigned long long )sector,
                size, (int )superseded ? (char *)"local" : (char *)"remote");
    } else {

    }
#line 2184
    inc_unacked(mdev);
#line 2185
    peer_req->w.cb = (int )superseded ? & e_send_superseded : & e_send_retry_write;
#line 2187
    list_add_tail(& peer_req->w.list, & mdev->done_ee);
#line 2188
    wake_asender(mdev->tconn);
#line 2190
    err = -2;
#line 2191
    goto out;
  } else {
#line 2194
    __mptr = (struct drbd_interval  const  *)i;
#line 2194
    req = (struct drbd_request *)__mptr + 0xffffffffffffffd8UL;
#line 2196
    if (! equal) {
#line 2197
      dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Concurrent writes detected: local=%llus +%u, remote=%llus +%u\n",
                (unsigned long long )i->sector, i->size, (unsigned long long )sector,
                size);
    } else {

    }
#line 2202
    if ((int )req->rq_state & 1 || ((unsigned long )req->rq_state & 8192UL) == 0UL) {
#line 2215
      err = drbd_wait_misc(mdev, & req->i);
#line 2216
      if (err != 0) {
#line 2218
        val.i = 0U;
#line 2218
        val.ldv_40024.conn = 3U;
#line 2218
        mask.i = 0U;
#line 2218
        mask.ldv_40024.conn = 31U;
#line 2218
        _conn_request_state(mdev->tconn, mask, val, CS_HARD);
#line 2220
        fail_postponed_requests(mdev, sector, size);
#line 2221
        goto out;
      } else {

      }
#line 2223
      goto repeat;
    } else {

    }
#line 2229
    peer_req->flags = peer_req->flags | 32UL;
  }
  ldv_53383: 
#line 2149
  i = drbd_next_overlap(i, sector, size);
  ldv_53394: ;
#line 2149
  if ((unsigned long )i != (unsigned long )((struct drbd_interval *)0)) {
#line 2150
    goto ldv_53393;
  } else {

  }
#line 2232
  err = 0;
  out: ;
#line 2235
  if (err != 0) {
#line 2236
    drbd_remove_epoch_entry_interval(mdev, peer_req);
  } else {

  }
#line 2237
  return (err);
}
}
#line 2241 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_Data(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  sector_t sector ;
  struct drbd_peer_request *peer_req ;
  struct p_data *p ;
  u32 peer_seq ;
  __u32 tmp ;
  int rw ;
  u32 dp_flags ;
  int err ;
  int tp ;
  int err2 ;
  int tmp___0 ;
  __u64 tmp___1 ;
  __u32 tmp___2 ;
  unsigned long tmp___3 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___4 ;
  int tmp___5 ;
  bool tmp___6 ;
  int tmp___7 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___8 ;
  bool tmp___9 ;
  int tmp___10 ;
  struct net_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___11 ;
  int tmp___12 ;

  {
#line 2246
  p = (struct p_data *)pi->data;
#line 2247
  tmp = __fswab32(p->seq_num);
#line 2247
  peer_seq = tmp;
#line 2248
  rw = 1;
#line 2252
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 2253
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 2254
    return (-5);
  } else {

  }
#line 2256
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 2256
  if (tmp___0 == 0) {
#line 2259
    err = wait_for_and_update_peer_seq(mdev, peer_seq);
#line 2260
    drbd_send_ack_dp(mdev, P_NEG_ACK, p, (int )pi->size);
#line 2261
    atomic_inc(& (tconn->current_epoch)->epoch_size);
#line 2262
    err2 = drbd_drain_block(mdev, (int )pi->size);
#line 2263
    if (err == 0) {
#line 2264
      err = err2;
    } else {

    }
#line 2265
    return (err);
  } else {

  }
#line 2274
  tmp___1 = __fswab64(p->sector);
#line 2274
  sector = (sector_t )tmp___1;
#line 2275
  peer_req = read_in_block(mdev, p->block_id, sector, (int )pi->size);
#line 2276
  if ((unsigned long )peer_req == (unsigned long )((struct drbd_peer_request *)0)) {
#line 2277
    put_ldev(mdev);
#line 2278
    return (-5);
  } else {

  }
#line 2281
  peer_req->w.cb = & e_end_block;
#line 2283
  tmp___2 = __fswab32(p->dp_flags);
#line 2283
  dp_flags = tmp___2;
#line 2284
  tmp___3 = wire_flags_to_bio(mdev, dp_flags);
#line 2284
  rw = (int )((unsigned int )tmp___3 | (unsigned int )rw);
#line 2285
  if ((unsigned long )peer_req->pages == (unsigned long )((struct page *)0)) {
#line 2286
    if (peer_req->i.size != 0U) {
#line 2286
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( peer_req->i.size == 0 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              2286);
    } else {

    }
#line 2287
    if ((dp_flags & 32U) == 0U) {
#line 2287
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( dp_flags & DP_FLUSH ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              2287);
    } else {

    }
  } else {

  }
#line 2290
  if ((dp_flags & 4U) != 0U) {
#line 2291
    peer_req->flags = peer_req->flags | 2UL;
  } else {

  }
#line 2293
  spin_lock(& tconn->epoch_lock);
#line 2294
  peer_req->epoch = tconn->current_epoch;
#line 2295
  atomic_inc(& (peer_req->epoch)->epoch_size);
#line 2296
  atomic_inc(& (peer_req->epoch)->active);
#line 2297
  spin_unlock(& tconn->epoch_lock);
#line 2299
  rcu_read_lock___2();
#line 2300
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2300
  tmp___4 = debug_lockdep_rcu_enabled();
#line 2300
  if (tmp___4 != 0 && ! __warned) {
#line 2300
    tmp___5 = rcu_read_lock_held();
#line 2300
    if (tmp___5 == 0 && 1) {
#line 2300
      __warned = 1;
#line 2300
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             2300, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2300
  tp = (int )_________p1->two_primaries;
#line 2301
  rcu_read_unlock___2();
#line 2302
  if (tp != 0) {
#line 2303
    peer_req->flags = peer_req->flags | 128UL;
#line 2304
    err = wait_for_and_update_peer_seq(mdev, peer_seq);
#line 2305
    if (err != 0) {
#line 2306
      goto out_interrupted;
    } else {

    }
#line 2307
    spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2308
    err = handle_write_conflicts(mdev, peer_req);
#line 2309
    if (err != 0) {
#line 2310
      spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2311
      if (err == -2) {
#line 2312
        put_ldev(mdev);
#line 2313
        return (0);
      } else {

      }
#line 2315
      goto out_interrupted;
    } else {

    }
  } else {
#line 2318
    spin_lock_irq(& (mdev->tconn)->req_lock);
  }
#line 2319
  list_add(& peer_req->w.list, & mdev->active_ee);
#line 2320
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2322
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 272U) {
#line 2323
    tmp___6 = overlapping_resync_write(mdev, peer_req);
#line 2323
    if (tmp___6) {
#line 2323
      tmp___7 = 0;
    } else {
#line 2323
      tmp___7 = 1;
    }
#line 2323
    if (tmp___7) {
#line 2323
      goto ldv_53414;
    } else {

    }
#line 2323
    tmp___8 = get_current();
#line 2323
    __wait.flags = 0U;
#line 2323
    __wait.private = (void *)tmp___8;
#line 2323
    __wait.func = & autoremove_wake_function;
#line 2323
    __wait.task_list.next = & __wait.task_list;
#line 2323
    __wait.task_list.prev = & __wait.task_list;
    ldv_53417: 
#line 2323
    prepare_to_wait(& mdev->ee_wait, & __wait, 2);
#line 2323
    tmp___9 = overlapping_resync_write(mdev, peer_req);
#line 2323
    if (tmp___9) {
#line 2323
      tmp___10 = 0;
    } else {
#line 2323
      tmp___10 = 1;
    }
#line 2323
    if (tmp___10) {
#line 2323
      goto ldv_53416;
    } else {

    }
#line 2323
    schedule();
#line 2323
    goto ldv_53417;
    ldv_53416: 
#line 2323
    finish_wait(& mdev->ee_wait, & __wait);
    ldv_53414: ;
  } else {

  }
#line 2325
  if ((mdev->tconn)->agreed_pro_version <= 99) {
#line 2326
    rcu_read_lock___2();
#line 2327
    _________p1___0 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2327
    tmp___11 = debug_lockdep_rcu_enabled();
#line 2327
    if (tmp___11 != 0 && ! __warned___0) {
#line 2327
      tmp___12 = rcu_read_lock_held();
#line 2327
      if (tmp___12 == 0 && 1) {
#line 2327
        __warned___0 = 1;
#line 2327
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                               2327, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 2327
    switch (_________p1___0->wire_protocol) {
    case (__u32 )3: 
#line 2329
    dp_flags = dp_flags | 256U;
#line 2330
    goto ldv_53422;
    case (__u32 )2: 
#line 2332
    dp_flags = dp_flags | 128U;
#line 2333
    goto ldv_53422;
    }
    ldv_53422: 
#line 2335
    rcu_read_unlock___2();
  } else {

  }
#line 2338
  if ((dp_flags & 256U) != 0U) {
#line 2339
    peer_req->flags = peer_req->flags | 64UL;
#line 2340
    inc_unacked(mdev);
  } else {

  }
#line 2345
  if ((dp_flags & 128U) != 0U) {
#line 2348
    drbd_send_ack(mdev, P_RECV_ACK, peer_req);
  } else {

  }
#line 2351
  if ((int )mdev->state.ldv_49522.pdsk <= 3) {
#line 2353
    __drbd_set_out_of_sync(mdev, peer_req->i.sector, (int )peer_req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                           2353U);
#line 2354
    peer_req->flags = peer_req->flags | 1UL;
#line 2355
    peer_req->flags = peer_req->flags & 0xfffffffffffffffdUL;
#line 2356
    drbd_al_begin_io(mdev, & peer_req->i);
  } else {

  }
#line 2359
  err = drbd_submit_peer_request(mdev, peer_req, (unsigned int const   )rw, 4);
#line 2360
  if (err == 0) {
#line 2361
    return (0);
  } else {

  }
#line 2364
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "submit failed, triggering re-connect\n");
#line 2365
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2366
  list_del(& peer_req->w.list);
#line 2367
  drbd_remove_epoch_entry_interval(mdev, peer_req);
#line 2368
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2369
  if ((int )peer_req->flags & 1) {
#line 2370
    drbd_al_complete_io(mdev, & peer_req->i);
  } else {

  }
  out_interrupted: 
#line 2373
  drbd_may_finish_epoch(tconn, peer_req->epoch, EV_CLEANUP);
#line 2374
  put_ldev(mdev);
#line 2375
  __drbd_free_peer_req(mdev, peer_req, 0);
#line 2376
  return (err);
}
}
#line 2390 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
int drbd_rs_should_slow_down(struct drbd_conf *mdev , sector_t sector ) 
{ 
  struct gendisk *disk ;
  unsigned long db ;
  unsigned long dt ;
  unsigned long dbdt ;
  struct lc_element *tmp ;
  int curr_events ;
  int throttle ;
  unsigned int c_min_rate ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  struct bm_extent *bm_ext ;
  struct lc_element  const  *__mptr ;
  int tmp___2 ;
  unsigned long res ;
  unsigned int _cpu ;
  void const   *__vpp_verify ;
  unsigned long __ptr ;
  unsigned long res___0 ;
  unsigned int _cpu___0 ;
  void const   *__vpp_verify___0 ;
  unsigned long __ptr___0 ;
  int tmp___3 ;
  unsigned long rs_left ;
  int i ;
  unsigned long tmp___4 ;

  {
#line 2392
  disk = (((mdev->ldev)->backing_bdev)->bd_contains)->bd_disk;
#line 2396
  throttle = 0;
#line 2399
  rcu_read_lock___2();
#line 2400
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 2400
  tmp___0 = debug_lockdep_rcu_enabled();
#line 2400
  if (tmp___0 != 0 && ! __warned) {
#line 2400
    tmp___1 = rcu_read_lock_held();
#line 2400
    if (tmp___1 == 0 && 1) {
#line 2400
      __warned = 1;
#line 2400
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             2400, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2400
  c_min_rate = _________p1->c_min_rate;
#line 2401
  rcu_read_unlock___2();
#line 2404
  if (c_min_rate == 0U) {
#line 2405
    return (0);
  } else {

  }
#line 2407
  spin_lock_irq(& mdev->al_lock);
#line 2408
  tmp = lc_find(mdev->resync, (unsigned int )(sector >> 15));
#line 2409
  if ((unsigned long )tmp != (unsigned long )((struct lc_element *)0)) {
#line 2410
    __mptr = (struct lc_element  const  *)tmp;
#line 2410
    bm_ext = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
#line 2411
    tmp___2 = constant_test_bit(2U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 2411
    if (tmp___2 != 0) {
#line 2412
      spin_unlock_irq(& mdev->al_lock);
#line 2413
      return (0);
    } else {

    }
  } else {

  }
#line 2417
  spin_unlock_irq(& mdev->al_lock);
#line 2419
  res = 0UL;
#line 2419
  _cpu = 4294967295U;
#line 2419
  goto ldv_53449;
  ldv_53448: 
#line 2419
  __vpp_verify = 0;
#line 2419
  __asm__  ("": "=r" (__ptr): "0" (disk->part0.dkstats));
#line 2419
  res = ((struct disk_stats *)(__per_cpu_offset[_cpu] + __ptr))->sectors[0] + res;
  ldv_53449: 
#line 2419
  _cpu = cpumask_next((int )_cpu, cpu_possible_mask);
#line 2419
  if ((unsigned int )nr_cpu_ids > _cpu) {
#line 2420
    goto ldv_53448;
  } else {

  }
#line 2420
  res___0 = 0UL;
#line 2420
  _cpu___0 = 4294967295U;
#line 2420
  goto ldv_53459;
  ldv_53458: 
#line 2420
  __vpp_verify___0 = 0;
#line 2420
  __asm__  ("": "=r" (__ptr___0): "0" (disk->part0.dkstats));
#line 2420
  res___0 = ((struct disk_stats *)(__per_cpu_offset[_cpu___0] + __ptr___0))->sectors[1] + res___0;
  ldv_53459: 
#line 2420
  _cpu___0 = cpumask_next((int )_cpu___0, cpu_possible_mask);
#line 2420
  if ((unsigned int )nr_cpu_ids > _cpu___0) {
#line 2421
    goto ldv_53458;
  } else {

  }
#line 2420
  tmp___3 = atomic_read((atomic_t const   *)(& mdev->rs_sect_ev));
#line 2420
  curr_events = ((int )res + (int )res___0) - tmp___3;
#line 2423
  if (mdev->rs_last_events == 0 || curr_events - mdev->rs_last_events > 64) {
#line 2427
    mdev->rs_last_events = curr_events;
#line 2431
    i = (mdev->rs_last_mark + 7) % 8;
#line 2433
    if ((unsigned int )*((unsigned short *)mdev + 374UL) == 288U || (unsigned int )*((unsigned short *)mdev + 374UL) == 304U) {
#line 2434
      rs_left = mdev->ov_left;
    } else {
#line 2436
      tmp___4 = drbd_bm_total_weight(mdev);
#line 2436
      rs_left = tmp___4 - mdev->rs_failed;
    }
#line 2438
    dt = (unsigned long )(((long )jiffies - (long )mdev->rs_mark_time[i]) / 250L);
#line 2439
    if (dt == 0UL) {
#line 2440
      dt = dt + 1UL;
    } else {

    }
#line 2441
    db = mdev->rs_mark_left[i] - rs_left;
#line 2442
    dbdt = db / dt << 2;
#line 2444
    if ((unsigned long )c_min_rate < dbdt) {
#line 2445
      throttle = 1;
    } else {

    }
  } else {

  }
#line 2447
  return (throttle);
}
}
#line 2451 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_DataRequest(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  sector_t sector ;
  sector_t capacity ;
  struct drbd_peer_request *peer_req ;
  struct digest_info *di ;
  int size ;
  int verb ;
  unsigned int fault_type ;
  struct p_block_req *p ;
  __u64 tmp ;
  __u32 tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  void *tmp___4 ;
  int tmp___5 ;
  unsigned long now ;
  int i ;
  unsigned long tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;

  {
#line 2457
  di = 0;
#line 2460
  p = (struct p_block_req *)pi->data;
#line 2462
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 2463
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 2464
    return (-5);
  } else {

  }
#line 2465
  capacity = drbd_get_capacity(mdev->this_bdev);
#line 2467
  tmp = __fswab64(p->sector);
#line 2467
  sector = (sector_t )tmp;
#line 2468
  tmp___0 = __fswab32(p->blksize);
#line 2468
  size = (int )tmp___0;
#line 2470
  if ((size <= 0 || (size & 511) != 0) || (unsigned int )size > 1048576U) {
#line 2471
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s:%d: sector: %llus, size: %u\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            2471, (unsigned long long )sector, size);
#line 2473
    return (-22);
  } else {

  }
#line 2475
  if ((sector_t )(size >> 9) + sector > capacity) {
#line 2476
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s:%d: sector: %llus, size: %u\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            2476, (unsigned long long )sector, size);
#line 2478
    return (-22);
  } else {

  }
#line 2481
  tmp___3 = _get_ldev_if_state(mdev, D_UP_TO_DATE);
#line 2481
  if (tmp___3 == 0) {
#line 2482
    verb = 1;
#line 2483
    switch ((unsigned int )pi->cmd) {
    case 8U: 
#line 2485
    drbd_send_ack_rp(mdev, P_NEG_DREPLY, p);
#line 2486
    goto ldv_53478;
    case 9U: ;
    case 33U: ;
    case 30U: 
#line 2490
    drbd_send_ack_rp(mdev, P_NEG_RS_DREPLY, p);
#line 2491
    goto ldv_53478;
    case 31U: 
#line 2493
    verb = 0;
#line 2494
    _dec_rs_pending(mdev, "receive_DataRequest", 2494);
#line 2495
    drbd_send_ack_ex(mdev, P_OV_RESULT, sector, size, 4711ULL);
#line 2496
    goto ldv_53478;
    default: 
#line 2498
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"),
                         "i" (2498), "i" (12UL));
    ldv_53485: ;
#line 2498
    goto ldv_53485;
    }
    ldv_53478: ;
#line 2500
    if (verb != 0) {
#line 2500
      tmp___1 = ___ratelimit(& drbd_ratelimit_state, "receive_DataRequest");
#line 2500
      if (tmp___1 != 0) {
#line 2501
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Can not satisfy peer\'s read request, no local data.\n");
      } else {

      }
    } else {

    }
#line 2505
    tmp___2 = drbd_drain_block(mdev, (int )pi->size);
#line 2505
    return (tmp___2);
  } else {

  }
#line 2511
  peer_req = drbd_alloc_peer_req(mdev, p->block_id, sector, (unsigned int )size, 16U);
#line 2512
  if ((unsigned long )peer_req == (unsigned long )((struct drbd_peer_request *)0)) {
#line 2513
    put_ldev(mdev);
#line 2514
    return (-12);
  } else {

  }
#line 2517
  switch ((unsigned int )pi->cmd) {
  case 8U: 
#line 2519
  peer_req->w.cb = & w_e_end_data_req;
#line 2520
  fault_type = 5U;
#line 2522
  goto submit;
  case 9U: 
#line 2525
  peer_req->w.cb = & w_e_end_rsdata_req;
#line 2526
  fault_type = 3U;
#line 2528
  mdev->bm_resync_fo = sector >> 3;
#line 2529
  goto ldv_53489;
  case 31U: ;
  case 33U: 
#line 2533
  fault_type = 3U;
#line 2534
  tmp___4 = kmalloc((unsigned long )pi->size + 16UL, 16U);
#line 2534
  di = (struct digest_info *)tmp___4;
#line 2535
  if ((unsigned long )di == (unsigned long )((struct digest_info *)0)) {
#line 2536
    goto out_free_e;
  } else {

  }
#line 2538
  di->digest_size = (int )pi->size;
#line 2539
  di->digest = (void *)di + 16U;
#line 2541
  peer_req->ldv_50726.digest = di;
#line 2542
  peer_req->flags = peer_req->flags | 16UL;
#line 2544
  tmp___5 = drbd_recv_all(mdev->tconn, di->digest, (size_t )pi->size);
#line 2544
  if (tmp___5 != 0) {
#line 2545
    goto out_free_e;
  } else {

  }
#line 2547
  if ((unsigned int )pi->cmd == 33U) {
#line 2548
    if ((mdev->tconn)->agreed_pro_version <= 88) {
#line 2548
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->tconn->agreed_pro_version >= 89 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              2548);
    } else {

    }
#line 2549
    peer_req->w.cb = & w_e_end_csum_rs_req;
#line 2551
    mdev->bm_resync_fo = sector >> 3;
  } else
#line 2552
  if ((unsigned int )pi->cmd == 31U) {
#line 2554
    atomic_add(size >> 9, & mdev->rs_sect_in);
#line 2555
    peer_req->w.cb = & w_e_end_ov_reply;
#line 2556
    _dec_rs_pending(mdev, "receive_DataRequest", 2556);
#line 2559
    goto submit_for_resync;
  } else {

  }
#line 2561
  goto ldv_53489;
  case 30U: ;
#line 2564
  if (mdev->ov_start_sector == 0xffffffffffffffffUL && (mdev->tconn)->agreed_pro_version > 89) {
#line 2566
    now = jiffies;
#line 2568
    mdev->ov_start_sector = sector;
#line 2569
    mdev->ov_position = sector;
#line 2570
    tmp___6 = drbd_bm_bits(mdev);
#line 2570
    mdev->ov_left = tmp___6 - (sector >> 3);
#line 2571
    mdev->rs_total = mdev->ov_left;
#line 2572
    i = 0;
#line 2572
    goto ldv_53498;
    ldv_53497: 
#line 2573
    mdev->rs_mark_left[i] = mdev->ov_left;
#line 2574
    mdev->rs_mark_time[i] = now;
#line 2572
    i = i + 1;
    ldv_53498: ;
#line 2572
    if (i <= 7) {
#line 2573
      goto ldv_53497;
    } else {

    }
#line 2576
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Online Verify start sector: %llu\n",
              (unsigned long long )sector);
  } else {

  }
#line 2579
  peer_req->w.cb = & w_e_end_ov_req;
#line 2580
  fault_type = 3U;
#line 2581
  goto ldv_53489;
  default: 
#line 2584
  __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"),
                       "i" (2584), "i" (12UL));
  ldv_53501: ;
#line 2584
  goto ldv_53501;
  }
  ldv_53489: ;
#line 2609
  if ((unsigned int )*((unsigned char *)mdev + 748UL) != 4U) {
#line 2609
    tmp___7 = drbd_rs_should_slow_down(mdev, sector);
#line 2609
    if (tmp___7 != 0) {
#line 2610
      schedule_timeout_uninterruptible(25L);
    } else {

    }
  } else {

  }
#line 2611
  tmp___8 = drbd_rs_begin_io(mdev, sector);
#line 2611
  if (tmp___8 != 0) {
#line 2612
    goto out_free_e;
  } else {

  }
  submit_for_resync: 
#line 2615
  atomic_add(size >> 9, & mdev->rs_sect_ev);
  submit: 
#line 2618
  inc_unacked(mdev);
#line 2619
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2620
  list_add_tail(& peer_req->w.list, & mdev->read_ee);
#line 2621
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2623
  tmp___9 = drbd_submit_peer_request(mdev, peer_req, 0U, (int const   )fault_type);
#line 2623
  if (tmp___9 == 0) {
#line 2624
    return (0);
  } else {

  }
#line 2627
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "submit failed, triggering re-connect\n");
#line 2628
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2629
  list_del(& peer_req->w.list);
#line 2630
  spin_unlock_irq(& (mdev->tconn)->req_lock);
  out_free_e: 
#line 2634
  put_ldev(mdev);
#line 2635
  __drbd_free_peer_req(mdev, peer_req, 0);
#line 2636
  return (-5);
}
}
#line 2639 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_asb_recover_0p(struct drbd_conf *mdev ) 
{ 
  int self ;
  int peer ;
  int rv ;
  unsigned long ch_self ;
  unsigned long ch_peer ;
  enum drbd_after_sb_p after_sb_0p ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 2641
  rv = -100;
#line 2645
  self = (int )(mdev->ldev)->md.uuid[1] & 1;
#line 2646
  peer = (int )*(mdev->p_uuid + 1UL) & 1;
#line 2648
  ch_peer = (unsigned long )*(mdev->p_uuid + 4UL);
#line 2649
  ch_self = mdev->comm_bm_set;
#line 2651
  rcu_read_lock___2();
#line 2652
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2652
  tmp = debug_lockdep_rcu_enabled();
#line 2652
  if (tmp != 0 && ! __warned) {
#line 2652
    tmp___0 = rcu_read_lock_held();
#line 2652
    if (tmp___0 == 0 && 1) {
#line 2652
      __warned = 1;
#line 2652
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             2652, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2652
  after_sb_0p = (enum drbd_after_sb_p )_________p1->after_sb_0p;
#line 2653
  rcu_read_unlock___2();
#line 2654
  switch ((unsigned int )after_sb_0p) {
  case 7U: ;
  case 8U: ;
  case 9U: ;
  case 10U: 
#line 2659
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Configuration error.\n");
#line 2660
  goto ldv_53518;
  case 0U: ;
#line 2662
  goto ldv_53518;
  case 1U: ;
#line 2664
  if (self == 0 && peer == 1) {
#line 2665
    rv = -1;
#line 2666
    goto ldv_53518;
  } else {

  }
#line 2668
  if (self == 1 && peer == 0) {
#line 2669
    rv = 1;
#line 2670
    goto ldv_53518;
  } else {

  }
  case 2U: ;
#line 2674
  if (self == 0 && peer == 1) {
#line 2675
    rv = 1;
#line 2676
    goto ldv_53518;
  } else {

  }
#line 2678
  if (self == 1 && peer == 0) {
#line 2679
    rv = -1;
#line 2680
    goto ldv_53518;
  } else {

  }
#line 2683
  dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Discard younger/older primary did not find a decision\nUsing discard-least-changes instead\n");
  case 3U: ;
#line 2686
  if (ch_peer == 0UL && ch_self == 0UL) {
#line 2687
    tmp___1 = constant_test_bit(1U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
#line 2687
    rv = tmp___1 != 0 ? -1 : 1;
#line 2689
    goto ldv_53518;
  } else {
#line 2691
    if (ch_peer == 0UL) {
#line 2691
      rv = 1;
#line 2691
      goto ldv_53518;
    } else {

    }
#line 2692
    if (ch_self == 0UL) {
#line 2692
      rv = -1;
#line 2692
      goto ldv_53518;
    } else {

    }
  }
#line 2694
  if ((unsigned int )after_sb_0p == 3U) {
#line 2695
    goto ldv_53518;
  } else {

  }
  case 4U: ;
#line 2697
  if (ch_self < ch_peer) {
#line 2698
    rv = -1;
  } else
#line 2699
  if (ch_self > ch_peer) {
#line 2700
    rv = 1;
  } else {
#line 2703
    tmp___2 = constant_test_bit(1U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
#line 2703
    rv = tmp___2 != 0 ? -1 : 1;
  }
#line 2705
  goto ldv_53518;
  case 5U: 
#line 2707
  rv = -1;
#line 2708
  goto ldv_53518;
  case 6U: 
#line 2710
  rv = 1;
  }
  ldv_53518: ;
#line 2713
  return (rv);
}
}
#line 2716 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_asb_recover_1p(struct drbd_conf *mdev ) 
{ 
  int hg ;
  int rv ;
  enum drbd_after_sb_p after_sb_1p ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  enum drbd_state_rv rv2 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 2718
  rv = -100;
#line 2721
  rcu_read_lock___2();
#line 2722
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2722
  tmp = debug_lockdep_rcu_enabled();
#line 2722
  if (tmp != 0 && ! __warned) {
#line 2722
    tmp___0 = rcu_read_lock_held();
#line 2722
    if (tmp___0 == 0 && 1) {
#line 2722
      __warned = 1;
#line 2722
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             2722, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2722
  after_sb_1p = (enum drbd_after_sb_p )_________p1->after_sb_1p;
#line 2723
  rcu_read_unlock___2();
#line 2724
  switch ((unsigned int )after_sb_1p) {
  case 1U: ;
  case 2U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 3U: 
#line 2731
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Configuration error.\n");
#line 2732
  goto ldv_53541;
  case 0U: ;
#line 2734
  goto ldv_53541;
  case 7U: 
#line 2736
  hg = drbd_asb_recover_0p(mdev);
#line 2737
  if (hg == -1 && (unsigned int )*((unsigned char *)mdev + 748UL) == 2U) {
#line 2738
    rv = hg;
  } else {

  }
#line 2739
  if (hg == 1 && (unsigned int )*((unsigned char *)mdev + 748UL) == 1U) {
#line 2740
    rv = hg;
  } else {

  }
#line 2741
  goto ldv_53541;
  case 10U: 
#line 2743
  rv = drbd_asb_recover_0p(mdev);
#line 2744
  goto ldv_53541;
  case 8U: ;
#line 2746
  return ((unsigned int )*((unsigned char *)mdev + 748UL) == 1U ? 1 : -1);
  case 9U: 
#line 2748
  hg = drbd_asb_recover_0p(mdev);
#line 2749
  if (hg == -1 && (unsigned int )*((unsigned char *)mdev + 748UL) == 1U) {
#line 2752
    drbd_set_role(mdev, R_SECONDARY, 0);
#line 2756
    val.i = 0U;
#line 2756
    val.ldv_40024.role = 2U;
#line 2756
    mask.i = 0U;
#line 2756
    mask.ldv_40024.role = 3U;
#line 2756
    rv2 = drbd_change_state(mdev, CS_VERBOSE, mask, val);
#line 2757
    if ((int )rv2 != 1) {
#line 2758
      drbd_khelper(mdev, (char *)"pri-lost-after-sb");
    } else {
#line 2760
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Successfully gave up primary role.\n");
#line 2761
      rv = hg;
    }
  } else {
#line 2764
    rv = hg;
  }
  }
  ldv_53541: ;
#line 2767
  return (rv);
}
}
#line 2770 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_asb_recover_2p(struct drbd_conf *mdev ) 
{ 
  int hg ;
  int rv ;
  enum drbd_after_sb_p after_sb_2p ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  enum drbd_state_rv rv2 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 2772
  rv = -100;
#line 2775
  rcu_read_lock___2();
#line 2776
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2776
  tmp = debug_lockdep_rcu_enabled();
#line 2776
  if (tmp != 0 && ! __warned) {
#line 2776
    tmp___0 = rcu_read_lock_held();
#line 2776
    if (tmp___0 == 0 && 1) {
#line 2776
      __warned = 1;
#line 2776
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             2776, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2776
  after_sb_2p = (enum drbd_after_sb_p )_________p1->after_sb_2p;
#line 2777
  rcu_read_unlock___2();
#line 2778
  switch ((unsigned int )after_sb_2p) {
  case 1U: ;
  case 2U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 8U: ;
  case 3U: 
#line 2787
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Configuration error.\n");
#line 2788
  goto ldv_53569;
  case 10U: 
#line 2790
  rv = drbd_asb_recover_0p(mdev);
#line 2791
  goto ldv_53569;
  case 0U: ;
#line 2793
  goto ldv_53569;
  case 9U: 
#line 2795
  hg = drbd_asb_recover_0p(mdev);
#line 2796
  if (hg == -1) {
#line 2802
    val.i = 0U;
#line 2802
    val.ldv_40024.role = 2U;
#line 2802
    mask.i = 0U;
#line 2802
    mask.ldv_40024.role = 3U;
#line 2802
    rv2 = drbd_change_state(mdev, CS_VERBOSE, mask, val);
#line 2803
    if ((int )rv2 != 1) {
#line 2804
      drbd_khelper(mdev, (char *)"pri-lost-after-sb");
    } else {
#line 2806
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Successfully gave up primary role.\n");
#line 2807
      rv = hg;
    }
  } else {
#line 2810
    rv = hg;
  }
  }
  ldv_53569: ;
#line 2813
  return (rv);
}
}
#line 2816 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbd_uuid_dump(struct drbd_conf *mdev , char *text , u64 *uuid , u64 bits ,
                           u64 flags ) 
{ 


  {
#line 2819
  if ((unsigned long )uuid == (unsigned long )((u64 *)0)) {
#line 2820
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s uuid info vanished while I was looking!\n",
              text);
#line 2821
    return;
  } else {

  }
#line 2823
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s %016llX:%016llX:%016llX:%016llX bits:%llu flags:%llX\n",
            text, *uuid, *(uuid + 1UL), *(uuid + 2UL), *(uuid + 3UL), bits, flags);
#line 2824
  return;
}
}
#line 2845 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_uuid_compare(struct drbd_conf *mdev , int *rule_nr ) 
{ 
  u64 self ;
  u64 peer ;
  int i ;
  int j ;
  int rct ;
  int dc ;
  unsigned long tmp ;
  u64 tmp___0 ;
  int tmp___1 ;
  unsigned long tmp___2 ;
  u64 tmp___3 ;

  {
#line 2850
  self = (mdev->ldev)->md.uuid[0] & 0xfffffffffffffffeULL;
#line 2851
  peer = *(mdev->p_uuid) & 0xfffffffffffffffeULL;
#line 2853
  *rule_nr = 10;
#line 2854
  if (self == 4ULL && peer == 4ULL) {
#line 2855
    return (0);
  } else {

  }
#line 2857
  *rule_nr = 20;
#line 2858
  if ((self == 4ULL || self == 0ULL) && peer != 4ULL) {
#line 2860
    return (-2);
  } else {

  }
#line 2862
  *rule_nr = 30;
#line 2863
  if (self != 4ULL && (peer == 4ULL || peer == 0ULL)) {
#line 2865
    return (2);
  } else {

  }
#line 2867
  if (self == peer) {
#line 2870
    if (*(mdev->p_uuid + 1UL) == 0ULL && (mdev->ldev)->md.uuid[1] != 0ULL) {
#line 2872
      if ((mdev->tconn)->agreed_pro_version <= 90) {
#line 2873
        return (-1091);
      } else {

      }
#line 2875
      if ((((mdev->ldev)->md.uuid[1] ^ *(mdev->p_uuid + 2UL)) & 0xfffffffffffffffeULL) == 0ULL && (((mdev->ldev)->md.uuid[2] ^ *(mdev->p_uuid + 3UL)) & 0xfffffffffffffffeULL) == 0ULL) {
#line 2877
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "was SyncSource, missed the resync finished event, corrected myself:\n");
#line 2878
        drbd_uuid_move_history(mdev);
#line 2879
        (mdev->ldev)->md.uuid[2] = (mdev->ldev)->md.uuid[1];
#line 2880
        (mdev->ldev)->md.uuid[1] = 0ULL;
#line 2882
        if ((int )mdev->state.ldv_49522.disk > 2) {
#line 2882
          tmp = drbd_bm_total_weight(mdev);
#line 2882
          tmp___0 = (u64 )tmp;
        } else {
#line 2882
          tmp___0 = 0ULL;
        }
#line 2882
        drbd_uuid_dump(mdev, (char *)"self", (u64 *)(& (mdev->ldev)->md.uuid), tmp___0,
                       0ULL);
#line 2884
        *rule_nr = 34;
      } else {
#line 2886
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "was SyncSource (peer failed to write sync_uuid)\n");
#line 2887
        *rule_nr = 36;
      }
#line 2890
      return (1);
    } else {

    }
#line 2893
    if ((mdev->ldev)->md.uuid[1] == 0ULL && *(mdev->p_uuid + 1UL) != 0ULL) {
#line 2895
      if ((mdev->tconn)->agreed_pro_version <= 90) {
#line 2896
        return (-1091);
      } else {

      }
#line 2898
      if ((((mdev->ldev)->md.uuid[2] ^ *(mdev->p_uuid + 1UL)) & 0xfffffffffffffffeULL) == 0ULL && (((mdev->ldev)->md.uuid[3] ^ *(mdev->p_uuid + 2UL)) & 0xfffffffffffffffeULL) == 0ULL) {
#line 2900
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "was SyncTarget, peer missed the resync finished event, corrected peer:\n");
#line 2902
        *(mdev->p_uuid + 3UL) = *(mdev->p_uuid + 2UL);
#line 2903
        *(mdev->p_uuid + 2UL) = *(mdev->p_uuid + 1UL);
#line 2904
        *(mdev->p_uuid + 1UL) = 0ULL;
#line 2906
        drbd_uuid_dump(mdev, (char *)"peer", mdev->p_uuid, *(mdev->p_uuid + 4UL),
                       *(mdev->p_uuid + 5UL));
#line 2907
        *rule_nr = 35;
      } else {
#line 2909
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "was SyncTarget (failed to write sync_uuid)\n");
#line 2910
        *rule_nr = 37;
      }
#line 2913
      return (-1);
    } else {

    }
#line 2917
    tmp___1 = constant_test_bit(5U, (unsigned long const volatile   *)(& mdev->flags));
#line 2917
    rct = (int )((tmp___1 != 0 ? 1U : 0U) + ((unsigned int )*(mdev->p_uuid + 5UL) & 2U));
#line 2921
    *rule_nr = 40;
#line 2923
    switch (rct) {
    case 0: ;
#line 2924
    return (0);
    case 1: ;
#line 2925
    return (1);
    case 2: ;
#line 2926
    return (-1);
    case 3: 
#line 2928
    dc = constant_test_bit(1U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
#line 2929
    return (dc != 0 ? -1 : 1);
    }
  } else {

  }
#line 2933
  *rule_nr = 50;
#line 2934
  peer = *(mdev->p_uuid + 1UL) & 0xfffffffffffffffeULL;
#line 2935
  if (self == peer) {
#line 2936
    return (-1);
  } else {

  }
#line 2938
  *rule_nr = 51;
#line 2939
  peer = *(mdev->p_uuid + 2UL) & 0xfffffffffffffffeULL;
#line 2940
  if (self == peer) {
#line 2941
    if ((mdev->tconn)->agreed_pro_version <= 95 ? (((mdev->ldev)->md.uuid[2] ^ *(mdev->p_uuid + 3UL)) & 0xfffffffffffffffeULL) == 0ULL : peer + 281474976710656ULL == (*(mdev->p_uuid + 1UL) & 0xfffffffffffffffeULL)) {
#line 2948
      if ((mdev->tconn)->agreed_pro_version <= 90) {
#line 2949
        return (-1091);
      } else {

      }
#line 2951
      *(mdev->p_uuid + 1UL) = *(mdev->p_uuid + 2UL);
#line 2952
      *(mdev->p_uuid + 2UL) = *(mdev->p_uuid + 3UL);
#line 2954
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Lost last syncUUID packet, corrected:\n");
#line 2955
      drbd_uuid_dump(mdev, (char *)"peer", mdev->p_uuid, *(mdev->p_uuid + 4UL), *(mdev->p_uuid + 5UL));
#line 2957
      return (-1);
    } else {

    }
  } else {

  }
#line 2961
  *rule_nr = 60;
#line 2962
  self = (mdev->ldev)->md.uuid[0] & 0xfffffffffffffffeULL;
#line 2963
  i = 2;
#line 2963
  goto ldv_53600;
  ldv_53599: 
#line 2964
  peer = *(mdev->p_uuid + (unsigned long )i) & 0xfffffffffffffffeULL;
#line 2965
  if (self == peer) {
#line 2966
    return (-2);
  } else {

  }
#line 2963
  i = i + 1;
  ldv_53600: ;
#line 2963
  if (i <= 3) {
#line 2964
    goto ldv_53599;
  } else {

  }
#line 2969
  *rule_nr = 70;
#line 2970
  self = (mdev->ldev)->md.uuid[1] & 0xfffffffffffffffeULL;
#line 2971
  peer = *(mdev->p_uuid) & 0xfffffffffffffffeULL;
#line 2972
  if (self == peer) {
#line 2973
    return (1);
  } else {

  }
#line 2975
  *rule_nr = 71;
#line 2976
  self = (mdev->ldev)->md.uuid[2] & 0xfffffffffffffffeULL;
#line 2977
  if (self == peer) {
#line 2978
    if ((mdev->tconn)->agreed_pro_version <= 95 ? (((mdev->ldev)->md.uuid[3] ^ *(mdev->p_uuid + 2UL)) & 0xfffffffffffffffeULL) == 0ULL : self + 281474976710656ULL == ((mdev->ldev)->md.uuid[1] & 0xfffffffffffffffeULL)) {
#line 2985
      if ((mdev->tconn)->agreed_pro_version <= 90) {
#line 2986
        return (-1091);
      } else {

      }
#line 2988
      __drbd_uuid_set(mdev, 1, (mdev->ldev)->md.uuid[2]);
#line 2989
      __drbd_uuid_set(mdev, 2, (mdev->ldev)->md.uuid[3]);
#line 2991
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Last syncUUID did not get through, corrected:\n");
#line 2992
      if ((int )mdev->state.ldv_49522.disk > 2) {
#line 2992
        tmp___2 = drbd_bm_total_weight(mdev);
#line 2992
        tmp___3 = (u64 )tmp___2;
      } else {
#line 2992
        tmp___3 = 0ULL;
      }
#line 2992
      drbd_uuid_dump(mdev, (char *)"self", (u64 *)(& (mdev->ldev)->md.uuid), tmp___3,
                     0ULL);
#line 2995
      return (1);
    } else {

    }
  } else {

  }
#line 3000
  *rule_nr = 80;
#line 3001
  peer = *(mdev->p_uuid) & 0xfffffffffffffffeULL;
#line 3002
  i = 2;
#line 3002
  goto ldv_53603;
  ldv_53602: 
#line 3003
  self = (mdev->ldev)->md.uuid[i] & 0xfffffffffffffffeULL;
#line 3004
  if (self == peer) {
#line 3005
    return (2);
  } else {

  }
#line 3002
  i = i + 1;
  ldv_53603: ;
#line 3002
  if (i <= 3) {
#line 3003
    goto ldv_53602;
  } else {

  }
#line 3008
  *rule_nr = 90;
#line 3009
  self = (mdev->ldev)->md.uuid[1] & 0xfffffffffffffffeULL;
#line 3010
  peer = *(mdev->p_uuid + 1UL) & 0xfffffffffffffffeULL;
#line 3011
  if (self == peer && self != 0ULL) {
#line 3012
    return (100);
  } else {

  }
#line 3014
  *rule_nr = 100;
#line 3015
  i = 2;
#line 3015
  goto ldv_53609;
  ldv_53608: 
#line 3016
  self = (mdev->ldev)->md.uuid[i] & 0xfffffffffffffffeULL;
#line 3017
  j = 2;
#line 3017
  goto ldv_53606;
  ldv_53605: 
#line 3018
  peer = *(mdev->p_uuid + (unsigned long )j) & 0xfffffffffffffffeULL;
#line 3019
  if (self == peer) {
#line 3020
    return (-100);
  } else {

  }
#line 3017
  j = j + 1;
  ldv_53606: ;
#line 3017
  if (j <= 3) {
#line 3018
    goto ldv_53605;
  } else {

  }
#line 3015
  i = i + 1;
  ldv_53609: ;
#line 3015
  if (i <= 3) {
#line 3016
    goto ldv_53608;
  } else {

  }

#line 3024
  return (-1000);
}
}
#line 3030 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static enum drbd_conns drbd_sync_handshake(struct drbd_conf *mdev , enum drbd_role peer_role ,
                                           enum drbd_disk_state peer_disk ) 
{ 
  enum drbd_conns rv ;
  enum drbd_disk_state mydisk ;
  struct net_conf *nc ;
  int hg ;
  int rule_nr ;
  int rr_conflict ;
  int tentative ;
  int f ;
  long ret ;
  int __x___0 ;
  int tmp ;
  long ret___0 ;
  int __x___2 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  int pcount ;
  int forced ;
  long ret___1 ;
  int __x___4 ;
  int tmp___2 ;
  int tmp___3 ;
  long ret___2 ;
  int __x___6 ;
  long ret___3 ;
  int __x___8 ;
  char const   *tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  long ret___4 ;
  int __x___10 ;
  unsigned long tmp___7 ;
  unsigned long tmp___8 ;

  {
#line 3033
  rv = C_MASK;
#line 3038
  mydisk = (enum drbd_disk_state )mdev->state.ldv_49522.disk;
#line 3039
  if ((unsigned int )mydisk == 3U) {
#line 3040
    mydisk = (enum drbd_disk_state )mdev->new_state_tmp.ldv_40024.disk;
  } else {

  }
#line 3042
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_sync_handshake:\n");
#line 3044
  spin_lock_irq(& (mdev->ldev)->md.uuid_lock);
#line 3045
  drbd_uuid_dump(mdev, (char *)"self", (u64 *)(& (mdev->ldev)->md.uuid), (u64 )mdev->comm_bm_set,
                 0ULL);
#line 3046
  drbd_uuid_dump(mdev, (char *)"peer", mdev->p_uuid, *(mdev->p_uuid + 4UL), *(mdev->p_uuid + 5UL));
#line 3049
  hg = drbd_uuid_compare(mdev, & rule_nr);
#line 3050
  spin_unlock_irq(& (mdev->ldev)->md.uuid_lock);
#line 3052
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "uuid_compare()=%d by rule %d\n",
            hg, rule_nr);
#line 3054
  if (hg == -1000) {
#line 3055
    dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Unrelated data, aborting!\n");
#line 3056
    return (C_MASK);
  } else {

  }
#line 3058
  if (hg < -1000) {
#line 3059
    dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "To resolve this both sides have to support at least protocol %d\n",
              -1000 - hg);
#line 3060
    return (C_MASK);
  } else {

  }
#line 3063
  if (((unsigned int )mydisk == 4U && (unsigned int )peer_disk > 4U) || ((unsigned int )peer_disk == 4U && (unsigned int )mydisk > 4U)) {
#line 3065
    if (hg == -100) {
#line 3065
      tmp = 1;
    } else {
#line 3065
      __x___0 = hg;
#line 3065
      ret = (long )(__x___0 < 0 ? - __x___0 : __x___0);
#line 3065
      if (ret == 2L) {
#line 3065
        tmp = 1;
      } else {
#line 3065
        tmp = 0;
      }
    }
#line 3065
    f = tmp;
#line 3066
    hg = (unsigned int )mydisk > 4U ? 1 : -1;
#line 3067
    if (f != 0) {
#line 3068
      hg = hg * 2;
    } else {

    }
#line 3069
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Becoming sync %s due to disk states.\n",
              hg > 0 ? (char *)"source" : (char *)"target");
  } else {

  }
#line 3073
  __x___2 = hg;
#line 3073
  ret___0 = (long )(__x___2 < 0 ? - __x___2 : __x___2);
#line 3073
  if (ret___0 == 100L) {
#line 3074
    drbd_khelper(mdev, (char *)"initial-split-brain");
  } else {

  }
#line 3076
  rcu_read_lock___2();
#line 3077
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 3077
  tmp___0 = debug_lockdep_rcu_enabled();
#line 3077
  if (tmp___0 != 0 && ! __warned) {
#line 3077
    tmp___1 = rcu_read_lock_held();
#line 3077
    if (tmp___1 == 0 && 1) {
#line 3077
      __warned = 1;
#line 3077
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             3077, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 3077
  nc = _________p1;
#line 3079
  if (hg == 100 || (hg == -100 && (int )((signed char )nc->always_asbp) != 0)) {
#line 3080
    pcount = ((unsigned int )*((unsigned char *)mdev + 748UL) == 1U) + ((unsigned int )peer_role == 1U);
#line 3082
    forced = hg == -100;
#line 3084
    switch (pcount) {
    case 0: 
#line 3086
    hg = drbd_asb_recover_0p(mdev);
#line 3087
    goto ldv_53638;
    case 1: 
#line 3089
    hg = drbd_asb_recover_1p(mdev);
#line 3090
    goto ldv_53638;
    case 2: 
#line 3092
    hg = drbd_asb_recover_2p(mdev);
#line 3093
    goto ldv_53638;
    }
    ldv_53638: 
#line 3095
    __x___4 = hg;
#line 3095
    ret___1 = (long )(__x___4 < 0 ? - __x___4 : __x___4);
#line 3095
    if (ret___1 <= 99L) {
#line 3096
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Split-Brain detected, %d primaries, automatically solved. Sync from %s node\n",
               pcount, hg < 0 ? (char *)"peer" : (char *)"this");
#line 3099
      if (forced != 0) {
#line 3100
        dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Doing a full sync, since UUIDs where ambiguous.\n");
#line 3102
        hg = hg * 2;
      } else {

      }
    } else {

    }
  } else {

  }
#line 3107
  if (hg == -100) {
#line 3108
    tmp___2 = constant_test_bit(21U, (unsigned long const volatile   *)(& mdev->flags));
#line 3108
    if (tmp___2 != 0 && (*(mdev->p_uuid + 5UL) & 1ULL) == 0ULL) {
#line 3109
      hg = -1;
    } else {

    }
#line 3110
    tmp___3 = constant_test_bit(21U, (unsigned long const volatile   *)(& mdev->flags));
#line 3110
    if (tmp___3 == 0 && (int )*(mdev->p_uuid + 5UL) & 1) {
#line 3111
      hg = 1;
    } else {

    }
#line 3113
    __x___6 = hg;
#line 3113
    ret___2 = (long )(__x___6 < 0 ? - __x___6 : __x___6);
#line 3113
    if (ret___2 <= 99L) {
#line 3114
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Split-Brain detected, manually solved. Sync from %s node\n",
               hg < 0 ? (char *)"peer" : (char *)"this");
    } else {

    }
  } else {

  }
#line 3118
  rr_conflict = (int )nc->rr_conflict;
#line 3119
  tentative = (int )nc->tentative;
#line 3120
  rcu_read_unlock___2();
#line 3122
  if (hg == -100) {
#line 3127
    dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Split-Brain detected but unresolved, dropping connection!\n");
#line 3128
    drbd_khelper(mdev, (char *)"split-brain");
#line 3129
    return (C_MASK);
  } else {

  }
#line 3132
  if (hg > 0 && (unsigned int )mydisk <= 4U) {
#line 3133
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "I shall become SyncSource, but I am inconsistent!\n");
#line 3134
    return (C_MASK);
  } else {

  }
#line 3137
  if ((hg < 0 && (unsigned int )*((unsigned char *)mdev + 748UL) == 1U) && (int )mdev->state.ldv_49522.disk > 6) {
#line 3139
    switch (rr_conflict) {
    case 9: 
#line 3141
    drbd_khelper(mdev, (char *)"pri-lost");
    case 0: 
#line 3144
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "I shall become SyncTarget, but I am primary!\n");
#line 3145
    return (C_MASK);
    case 10: 
#line 3147
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Becoming SyncTarget, violating the stable-dataassumption\n");
    }
  } else {

  }
#line 3152
  if (tentative != 0) {
#line 3152
    goto _L;
  } else {
#line 3152
    tmp___5 = constant_test_bit(8U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
#line 3152
    if (tmp___5 != 0) {
      _L: /* CIL Label */ 
#line 3153
      if (hg == 0) {
#line 3154
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "dry-run connect: No resync, would become Connected immediately.\n");
      } else {
#line 3156
        __x___8 = hg;
#line 3156
        ret___3 = (long )(__x___8 < 0 ? - __x___8 : __x___8);
#line 3156
        tmp___4 = drbd_conn_str(hg > 0 ? C_SYNC_SOURCE : C_SYNC_TARGET);
#line 3156
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "dry-run connect: Would become %s, doing a %s resync.",
                  tmp___4, ret___3 > 1L ? (char *)"full" : (char *)"bit-map based");
      }
#line 3159
      return (C_MASK);
    } else {

    }
  }
#line 3162
  __x___10 = hg;
#line 3162
  ret___4 = (long )(__x___10 < 0 ? - __x___10 : __x___10);
#line 3162
  if (ret___4 > 1L) {
#line 3163
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Writing the whole bitmap, full sync required after drbd_sync_handshake.\n");
#line 3164
    tmp___6 = drbd_bitmap_io(mdev, & drbd_bmio_set_n_write, (char *)"set_n_write from sync_handshake",
                             BM_LOCKED_SET_ALLOWED);
#line 3164
    if (tmp___6 != 0) {
#line 3166
      return (C_MASK);
    } else {

    }
  } else {

  }
#line 3169
  if (hg > 0) {
#line 3170
    rv = C_WF_BITMAP_S;
  } else
#line 3171
  if (hg < 0) {
#line 3172
    rv = C_WF_BITMAP_T;
  } else {
#line 3174
    rv = C_CONNECTED;
#line 3175
    tmp___8 = drbd_bm_total_weight(mdev);
#line 3175
    if (tmp___8 != 0UL) {
#line 3176
      tmp___7 = drbd_bm_total_weight(mdev);
#line 3176
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "No resync, but %lu bits in bitmap!\n",
                tmp___7);
    } else {

    }
  }
#line 3181
  return (rv);
}
}
#line 3184 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static enum drbd_after_sb_p convert_after_sb(enum drbd_after_sb_p peer ) 
{ 


  {
#line 3187
  if ((unsigned int )peer == 6U) {
#line 3188
    return (ASB_DISCARD_LOCAL);
  } else {

  }
#line 3191
  if ((unsigned int )peer == 5U) {
#line 3192
    return (ASB_DISCARD_REMOTE);
  } else {

  }
#line 3195
  return (peer);
}
}
#line 3198 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_protocol(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct p_protocol *p ;
  enum drbd_after_sb_p p_after_sb_0p ;
  enum drbd_after_sb_p p_after_sb_1p ;
  enum drbd_after_sb_p p_after_sb_2p ;
  int p_proto ;
  int p_discard_my_data ;
  int p_two_primaries ;
  int cf ;
  struct net_conf *nc ;
  struct net_conf *old_net_conf ;
  struct net_conf *new_net_conf ;
  char integrity_alg[64U] ;
  unsigned int tmp ;
  struct crypto_hash *peer_integrity_tfm ;
  void *int_dig_in ;
  void *int_dig_vv ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  int err ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___6 ;
  int tmp___7 ;
  enum drbd_after_sb_p tmp___8 ;
  enum drbd_after_sb_p tmp___9 ;
  enum drbd_after_sb_p tmp___10 ;
  int tmp___11 ;
  int hash_size ;
  unsigned int tmp___12 ;
  void *tmp___13 ;
  enum drbd_after_sb_p tmp___14 ;
  enum drbd_after_sb_p tmp___15 ;
  enum drbd_after_sb_p tmp___16 ;
  int tmp___17 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 3200
  p = (struct p_protocol *)pi->data;
#line 3203
  new_net_conf = 0;
#line 3204
  integrity_alg[0] = '\000';
#line 3204
  tmp = 1U;
#line 3204
  while (1) {
#line 3204
    if (tmp >= 64U) {
#line 3204
      break;
    } else {

    }
#line 3204
    integrity_alg[tmp] = (char)0;
#line 3204
    tmp = tmp + 1U;
  }
#line 3205
  peer_integrity_tfm = 0;
#line 3206
  int_dig_in = 0;
#line 3206
  int_dig_vv = 0;
#line 3208
  tmp___0 = __fswab32(p->protocol);
#line 3208
  p_proto = (int )tmp___0;
#line 3209
  tmp___1 = __fswab32(p->after_sb_0p);
#line 3209
  p_after_sb_0p = (enum drbd_after_sb_p )tmp___1;
#line 3210
  tmp___2 = __fswab32(p->after_sb_1p);
#line 3210
  p_after_sb_1p = (enum drbd_after_sb_p )tmp___2;
#line 3211
  tmp___3 = __fswab32(p->after_sb_2p);
#line 3211
  p_after_sb_2p = (enum drbd_after_sb_p )tmp___3;
#line 3212
  tmp___4 = __fswab32(p->two_primaries);
#line 3212
  p_two_primaries = (int )tmp___4;
#line 3213
  tmp___5 = __fswab32(p->conn_flags);
#line 3213
  cf = (int )tmp___5;
#line 3214
  p_discard_my_data = cf & 1;
#line 3216
  if (tconn->agreed_pro_version > 86) {
#line 3219
    if (pi->size > 64U) {
#line 3220
      return (-5);
    } else {

    }
#line 3221
    err = drbd_recv_all(tconn, (void *)(& integrity_alg), (size_t )pi->size);
#line 3222
    if (err != 0) {
#line 3223
      return (err);
    } else {

    }
#line 3224
    integrity_alg[63] = 0;
  } else {

  }
#line 3227
  if ((unsigned int )pi->cmd != 45U) {
#line 3228
    clear_bit(8, (unsigned long volatile   *)(& tconn->flags));
#line 3230
    if ((cf & 2) != 0) {
#line 3231
      set_bit(8U, (unsigned long volatile   *)(& tconn->flags));
    } else {

    }
#line 3233
    rcu_read_lock___2();
#line 3234
    _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 3234
    tmp___6 = debug_lockdep_rcu_enabled();
#line 3234
    if (tmp___6 != 0 && ! __warned) {
#line 3234
      tmp___7 = rcu_read_lock_held();
#line 3234
      if (tmp___7 == 0 && 1) {
#line 3234
        __warned = 1;
#line 3234
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                               3234, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 3234
    nc = _________p1;
#line 3236
    if ((__u32 )p_proto != nc->wire_protocol) {
#line 3237
      printk("\vd-con %s: incompatible %s settings\n", tconn->name, (char *)"protocol");
#line 3238
      goto disconnect_rcu_unlock;
    } else {

    }
#line 3241
    tmp___8 = convert_after_sb(p_after_sb_0p);
#line 3241
    if ((unsigned int )tmp___8 != nc->after_sb_0p) {
#line 3242
      printk("\vd-con %s: incompatible %s settings\n", tconn->name, (char *)"after-sb-0pri");
#line 3243
      goto disconnect_rcu_unlock;
    } else {

    }
#line 3246
    tmp___9 = convert_after_sb(p_after_sb_1p);
#line 3246
    if ((unsigned int )tmp___9 != nc->after_sb_1p) {
#line 3247
      printk("\vd-con %s: incompatible %s settings\n", tconn->name, (char *)"after-sb-1pri");
#line 3248
      goto disconnect_rcu_unlock;
    } else {

    }
#line 3251
    tmp___10 = convert_after_sb(p_after_sb_2p);
#line 3251
    if ((unsigned int )tmp___10 != nc->after_sb_2p) {
#line 3252
      printk("\vd-con %s: incompatible %s settings\n", tconn->name, (char *)"after-sb-2pri");
#line 3253
      goto disconnect_rcu_unlock;
    } else {

    }
#line 3256
    if (p_discard_my_data != 0 && (int )((signed char )nc->discard_my_data) != 0) {
#line 3257
      printk("\vd-con %s: incompatible %s settings\n", tconn->name, (char *)"discard-my-data");
#line 3258
      goto disconnect_rcu_unlock;
    } else {

    }
#line 3261
    if ((int )nc->two_primaries != p_two_primaries) {
#line 3262
      printk("\vd-con %s: incompatible %s settings\n", tconn->name, (char *)"allow-two-primaries");
#line 3263
      goto disconnect_rcu_unlock;
    } else {

    }
#line 3266
    tmp___11 = strcmp((char const   *)(& integrity_alg), (char const   *)(& nc->integrity_alg));
#line 3266
    if (tmp___11 != 0) {
#line 3267
      printk("\vd-con %s: incompatible %s settings\n", tconn->name, (char *)"data-integrity-alg");
#line 3268
      goto disconnect_rcu_unlock;
    } else {

    }
#line 3271
    rcu_read_unlock___2();
  } else {

  }
#line 3274
  if ((int )((signed char )integrity_alg[0]) != 0) {
#line 3286
    peer_integrity_tfm = crypto_alloc_hash((char const   *)(& integrity_alg), 0U,
                                           128U);
#line 3287
    if ((unsigned long )peer_integrity_tfm == (unsigned long )((struct crypto_hash *)0)) {
#line 3288
      printk("\vd-con %s: peer data-integrity-alg %s not supported\n", tconn->name,
             (char *)(& integrity_alg));
#line 3290
      goto disconnect;
    } else {

    }
#line 3293
    tmp___12 = crypto_hash_digestsize(peer_integrity_tfm);
#line 3293
    hash_size = (int )tmp___12;
#line 3294
    int_dig_in = kmalloc((size_t )hash_size, 208U);
#line 3295
    int_dig_vv = kmalloc((size_t )hash_size, 208U);
#line 3296
    if ((unsigned long )int_dig_in == (unsigned long )((void *)0) || (unsigned long )int_dig_vv == (unsigned long )((void *)0)) {
#line 3297
      printk("\vd-con %s: Allocation of buffers for data integrity checking failed\n",
             tconn->name);
#line 3298
      goto disconnect;
    } else {

    }
  } else {

  }
#line 3302
  tmp___13 = kmalloc(420UL, 208U);
#line 3302
  new_net_conf = (struct net_conf *)tmp___13;
#line 3303
  if ((unsigned long )new_net_conf == (unsigned long )((struct net_conf *)0)) {
#line 3304
    printk("\vd-con %s: Allocation of new net_conf failed\n", tconn->name);
#line 3305
    goto disconnect;
  } else {

  }
#line 3308
  ldv_mutex_lock_108(& tconn->data.mutex);
#line 3309
  ldv_mutex_lock_109(& tconn->conf_update);
#line 3310
  old_net_conf = tconn->net_conf;
#line 3311
  *new_net_conf = *old_net_conf;
#line 3313
  new_net_conf->wire_protocol = (__u32 )p_proto;
#line 3314
  tmp___14 = convert_after_sb(p_after_sb_0p);
#line 3314
  new_net_conf->after_sb_0p = (__u32 )tmp___14;
#line 3315
  tmp___15 = convert_after_sb(p_after_sb_1p);
#line 3315
  new_net_conf->after_sb_1p = (__u32 )tmp___15;
#line 3316
  tmp___16 = convert_after_sb(p_after_sb_2p);
#line 3316
  new_net_conf->after_sb_2p = (__u32 )tmp___16;
#line 3317
  new_net_conf->two_primaries = (char )p_two_primaries;
#line 3319
  __asm__  volatile   ("": : : "memory");
#line 3319
  tconn->net_conf = new_net_conf;
#line 3320
  ldv_mutex_unlock_110(& tconn->conf_update);
#line 3321
  ldv_mutex_unlock_111(& tconn->data.mutex);
#line 3323
  crypto_free_hash(tconn->peer_integrity_tfm);
#line 3324
  kfree((void const   *)tconn->int_dig_in);
#line 3325
  kfree((void const   *)tconn->int_dig_vv);
#line 3326
  tconn->peer_integrity_tfm = peer_integrity_tfm;
#line 3327
  tconn->int_dig_in = int_dig_in;
#line 3328
  tconn->int_dig_vv = int_dig_vv;
#line 3330
  tmp___17 = strcmp((char const   *)(& old_net_conf->integrity_alg), (char const   *)(& integrity_alg));
#line 3330
  if (tmp___17 != 0) {
#line 3331
    printk("\016d-con %s: peer data-integrity-alg: %s\n", tconn->name, (int )((signed char )integrity_alg[0]) != 0 ? (char *)(& integrity_alg) : (char *)"(none)");
  } else {

  }
#line 3334
  synchronize_rcu();
#line 3335
  kfree((void const   *)old_net_conf);
#line 3336
  return (0);
  disconnect_rcu_unlock: 
#line 3339
  rcu_read_unlock___2();
  disconnect: 
#line 3341
  crypto_free_hash(peer_integrity_tfm);
#line 3342
  kfree((void const   *)int_dig_in);
#line 3343
  kfree((void const   *)int_dig_vv);
#line 3344
  val.i = 0U;
#line 3344
  val.ldv_40024.conn = 1U;
#line 3344
  mask.i = 0U;
#line 3344
  mask.ldv_40024.conn = 31U;
#line 3344
  conn_request_state(tconn, mask, val, CS_HARD);
#line 3345
  return (-5);
}
}
#line 3353 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
struct crypto_hash *drbd_crypto_alloc_digest_safe(struct drbd_conf  const  *mdev ,
                                                  char const   *alg , char const   *name ) 
{ 
  struct crypto_hash *tfm ;
  long tmp ;
  long tmp___0 ;

  {
#line 3358
  if ((int )((signed char )*alg) == 0) {
#line 3359
    return (0);
  } else {

  }
#line 3361
  tfm = crypto_alloc_hash(alg, 0U, 128U);
#line 3362
  tmp___0 = IS_ERR((void const   *)tfm);
#line 3362
  if (tmp___0 != 0L) {
#line 3363
    tmp = PTR_ERR((void const   *)tfm);
#line 3363
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Can not allocate \"%s\" as %s (reason: %ld)\n",
            alg, name, tmp);
#line 3365
    return (tfm);
  } else {

  }
#line 3367
  return (tfm);
}
}
#line 3370 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int ignore_remaining_packet(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  void *buffer ;
  int size ;
  int s ;
  int __min1 ;
  int __min2 ;

  {
#line 3372
  buffer = tconn->data.rbuf;
#line 3373
  size = (int )pi->size;
#line 3375
  goto ldv_53711;
  ldv_53710: 
#line 3376
  __min1 = size;
#line 3376
  __min2 = 4096;
#line 3376
  s = __min1 < __min2 ? __min1 : __min2;
#line 3377
  s = drbd_recv(tconn, buffer, (size_t )s);
#line 3378
  if (s <= 0) {
#line 3379
    if (s < 0) {
#line 3380
      return (s);
    } else {

    }
#line 3381
    goto ldv_53709;
  } else {

  }
#line 3383
  size = size - s;
  ldv_53711: ;
#line 3375
  if (size != 0) {
#line 3376
    goto ldv_53710;
  } else {

  }
  ldv_53709: ;
#line 3385
  if (size != 0) {
#line 3386
    return (-5);
  } else {

  }
#line 3387
  return (0);
}
}
#line 3401 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int config_unknown_volume(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  char const   *tmp ;
  int tmp___0 ;

  {
#line 3403
  tmp = cmdname(pi->cmd);
#line 3403
  printk("\fd-con %s: %s packet received for volume %u, which is not configured locally\n",
         tconn->name, tmp, pi->vnr);
#line 3405
  tmp___0 = ignore_remaining_packet(tconn, pi);
#line 3405
  return (tmp___0);
}
}
#line 3408 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_SyncParam(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_rs_param_95 *p ;
  unsigned int header_size ;
  unsigned int data_size ;
  unsigned int exp_max_sz ;
  struct crypto_hash *verify_tfm ;
  struct crypto_hash *csums_tfm ;
  struct net_conf *old_net_conf ;
  struct net_conf *new_net_conf ;
  struct disk_conf *old_disk_conf ;
  struct disk_conf *new_disk_conf ;
  int apv ;
  struct fifo_buffer *old_plan ;
  struct fifo_buffer *new_plan ;
  int fifo_size ;
  int err ;
  int tmp ;
  void *tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  int tmp___4 ;
  long tmp___5 ;
  int tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  __u32 tmp___10 ;
  void *tmp___11 ;
  size_t tmp___12 ;
  size_t tmp___13 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 3413
  verify_tfm = 0;
#line 3414
  csums_tfm = 0;
#line 3415
  new_net_conf = 0;
#line 3416
  old_disk_conf = 0;
#line 3416
  new_disk_conf = 0;
#line 3417
  apv = tconn->agreed_pro_version;
#line 3418
  old_plan = 0;
#line 3418
  new_plan = 0;
#line 3419
  fifo_size = 0;
#line 3422
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 3423
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 3424
    tmp = config_unknown_volume(tconn, pi);
#line 3424
    return (tmp);
  } else {

  }
#line 3426
  exp_max_sz = apv > 87 ? (apv != 88 ? (apv <= 94 ? 132U : 148U) : 68U) : 4U;
#line 3432
  if (pi->size > exp_max_sz) {
#line 3433
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "SyncParam packet too long: received %u, expected <= %u bytes\n",
            pi->size, exp_max_sz);
#line 3435
    return (-5);
  } else {

  }
#line 3438
  if (apv <= 88) {
#line 3439
    header_size = 4U;
#line 3440
    data_size = pi->size - header_size;
  } else
#line 3441
  if (apv <= 94) {
#line 3442
    header_size = 132U;
#line 3443
    data_size = pi->size - header_size;
#line 3444
    if (data_size != 0U) {
#line 3444
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( data_size == 0 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              3444);
    } else {

    }
  } else {
#line 3446
    header_size = 148U;
#line 3447
    data_size = pi->size - header_size;
#line 3448
    if (data_size != 0U) {
#line 3448
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( data_size == 0 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              3448);
    } else {

    }
  }
#line 3452
  p = (struct p_rs_param_95 *)pi->data;
#line 3453
  memset((void *)(& p->verify_alg), 0, 128UL);
#line 3455
  err = drbd_recv_all(mdev->tconn, (void *)p, (size_t )header_size);
#line 3456
  if (err != 0) {
#line 3457
    return (err);
  } else {

  }
#line 3459
  ldv_mutex_lock_112(& (mdev->tconn)->conf_update);
#line 3460
  old_net_conf = (mdev->tconn)->net_conf;
#line 3461
  tmp___2 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 3461
  if (tmp___2 != 0) {
#line 3462
    tmp___0 = kzalloc(344UL, 208U);
#line 3462
    new_disk_conf = (struct disk_conf *)tmp___0;
#line 3463
    if ((unsigned long )new_disk_conf == (unsigned long )((struct disk_conf *)0)) {
#line 3464
      put_ldev(mdev);
#line 3465
      ldv_mutex_unlock_113(& (mdev->tconn)->conf_update);
#line 3466
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Allocation of new disk_conf failed\n");
#line 3467
      return (-12);
    } else {

    }
#line 3470
    old_disk_conf = (mdev->ldev)->disk_conf;
#line 3471
    *new_disk_conf = *old_disk_conf;
#line 3473
    tmp___1 = __fswab32(p->resync_rate);
#line 3473
    new_disk_conf->resync_rate = tmp___1;
  } else {

  }
#line 3476
  if (apv > 87) {
#line 3477
    if (apv == 88) {
#line 3478
      if (data_size > 64U || data_size == 0U) {
#line 3479
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "verify-alg of wrong size, peer wants %u, accepting only up to %u byte\n",
                data_size, 64);
#line 3482
        err = -5;
#line 3483
        goto reconnect;
      } else {

      }
#line 3486
      err = drbd_recv_all(mdev->tconn, (void *)(& p->verify_alg), (size_t )data_size);
#line 3487
      if (err != 0) {
#line 3488
        goto reconnect;
      } else {

      }
#line 3491
      if ((int )((signed char )p->verify_alg[data_size - 1U]) != 0) {
#line 3491
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( p->verify_alg[data_size-1] == 0 ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                3491);
      } else {

      }
#line 3492
      p->verify_alg[data_size - 1U] = 0;
    } else {
#line 3497
      if ((int )((signed char )p->verify_alg[63]) != 0) {
#line 3497
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( p->verify_alg[SHARED_SECRET_MAX-1] == 0 ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                3497);
      } else {

      }
#line 3498
      if ((int )((signed char )p->csums_alg[63]) != 0) {
#line 3498
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( p->csums_alg[SHARED_SECRET_MAX-1] == 0 ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                3498);
      } else {

      }
#line 3499
      p->verify_alg[63] = 0;
#line 3500
      p->csums_alg[63] = 0;
    }
#line 3503
    tmp___4 = strcmp((char const   *)(& old_net_conf->verify_alg), (char const   *)(& p->verify_alg));
#line 3503
    if (tmp___4 != 0) {
#line 3504
      if ((unsigned int )*((unsigned short *)mdev + 374UL) == 144U) {
#line 3505
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Different verify-alg settings. me=\"%s\" peer=\"%s\"\n",
                (char *)(& old_net_conf->verify_alg), (char *)(& p->verify_alg));
#line 3507
        goto disconnect;
      } else {

      }
#line 3509
      verify_tfm = drbd_crypto_alloc_digest_safe((struct drbd_conf  const  *)mdev,
                                                 (char const   *)(& p->verify_alg),
                                                 "verify-alg");
#line 3511
      tmp___3 = IS_ERR((void const   *)verify_tfm);
#line 3511
      if (tmp___3 != 0L) {
#line 3512
        verify_tfm = 0;
#line 3513
        goto disconnect;
      } else {

      }
    } else {

    }
#line 3517
    if (apv > 88) {
#line 3517
      tmp___6 = strcmp((char const   *)(& old_net_conf->csums_alg), (char const   *)(& p->csums_alg));
#line 3517
      if (tmp___6 != 0) {
#line 3518
        if ((unsigned int )*((unsigned short *)mdev + 374UL) == 144U) {
#line 3519
          dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Different csums-alg settings. me=\"%s\" peer=\"%s\"\n",
                  (char *)(& old_net_conf->csums_alg), (char *)(& p->csums_alg));
#line 3521
          goto disconnect;
        } else {

        }
#line 3523
        csums_tfm = drbd_crypto_alloc_digest_safe((struct drbd_conf  const  *)mdev,
                                                  (char const   *)(& p->csums_alg),
                                                  "csums-alg");
#line 3525
        tmp___5 = IS_ERR((void const   *)csums_tfm);
#line 3525
        if (tmp___5 != 0L) {
#line 3526
          csums_tfm = 0;
#line 3527
          goto disconnect;
        } else {

        }
      } else {

      }
    } else {

    }
#line 3531
    if (apv > 94 && (unsigned long )new_disk_conf != (unsigned long )((struct disk_conf *)0)) {
#line 3532
      tmp___7 = __fswab32(p->c_plan_ahead);
#line 3532
      new_disk_conf->c_plan_ahead = tmp___7;
#line 3533
      tmp___8 = __fswab32(p->c_delay_target);
#line 3533
      new_disk_conf->c_delay_target = tmp___8;
#line 3534
      tmp___9 = __fswab32(p->c_fill_target);
#line 3534
      new_disk_conf->c_fill_target = tmp___9;
#line 3535
      tmp___10 = __fswab32(p->c_max_rate);
#line 3535
      new_disk_conf->c_max_rate = tmp___10;
#line 3537
      fifo_size = (int )((new_disk_conf->c_plan_ahead * 250U) / 250U);
#line 3538
      if ((unsigned int )fifo_size != (mdev->rs_plan_s)->size) {
#line 3539
        new_plan = fifo_alloc(fifo_size);
#line 3540
        if ((unsigned long )new_plan == (unsigned long )((struct fifo_buffer *)0)) {
#line 3541
          dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "kmalloc of fifo_buffer failed");
#line 3542
          put_ldev(mdev);
#line 3543
          goto disconnect;
        } else {

        }
      } else {

      }
    } else {

    }
#line 3548
    if ((unsigned long )verify_tfm != (unsigned long )((struct crypto_hash *)0) || (unsigned long )csums_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 3549
      tmp___11 = kzalloc(420UL, 208U);
#line 3549
      new_net_conf = (struct net_conf *)tmp___11;
#line 3550
      if ((unsigned long )new_net_conf == (unsigned long )((struct net_conf *)0)) {
#line 3551
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Allocation of new net_conf failed\n");
#line 3552
        goto disconnect;
      } else {

      }
#line 3555
      *new_net_conf = *old_net_conf;
#line 3557
      if ((unsigned long )verify_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 3558
        strcpy((char *)(& new_net_conf->verify_alg), (char const   *)(& p->verify_alg));
#line 3559
        tmp___12 = strlen((char const   *)(& p->verify_alg));
#line 3559
        new_net_conf->verify_alg_len = (__u32 )tmp___12 + 1U;
#line 3560
        crypto_free_hash((mdev->tconn)->verify_tfm);
#line 3561
        (mdev->tconn)->verify_tfm = verify_tfm;
#line 3562
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "using verify-alg: \"%s\"\n",
                  (char *)(& p->verify_alg));
      } else {

      }
#line 3564
      if ((unsigned long )csums_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 3565
        strcpy((char *)(& new_net_conf->csums_alg), (char const   *)(& p->csums_alg));
#line 3566
        tmp___13 = strlen((char const   *)(& p->csums_alg));
#line 3566
        new_net_conf->csums_alg_len = (__u32 )tmp___13 + 1U;
#line 3567
        crypto_free_hash((mdev->tconn)->csums_tfm);
#line 3568
        (mdev->tconn)->csums_tfm = csums_tfm;
#line 3569
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "using csums-alg: \"%s\"\n",
                  (char *)(& p->csums_alg));
      } else {

      }
#line 3571
      __asm__  volatile   ("": : : "memory");
#line 3571
      tconn->net_conf = new_net_conf;
    } else {

    }
  } else {

  }
#line 3575
  if ((unsigned long )new_disk_conf != (unsigned long )((struct disk_conf *)0)) {
#line 3576
    __asm__  volatile   ("": : : "memory");
#line 3576
    (mdev->ldev)->disk_conf = new_disk_conf;
#line 3577
    put_ldev(mdev);
  } else {

  }
#line 3580
  if ((unsigned long )new_plan != (unsigned long )((struct fifo_buffer *)0)) {
#line 3581
    old_plan = mdev->rs_plan_s;
#line 3582
    __asm__  volatile   ("": : : "memory");
#line 3582
    mdev->rs_plan_s = new_plan;
  } else {

  }
#line 3585
  ldv_mutex_unlock_114(& (mdev->tconn)->conf_update);
#line 3586
  synchronize_rcu();
#line 3587
  if ((unsigned long )new_net_conf != (unsigned long )((struct net_conf *)0)) {
#line 3588
    kfree((void const   *)old_net_conf);
  } else {

  }
#line 3589
  kfree((void const   *)old_disk_conf);
#line 3590
  kfree((void const   *)old_plan);
#line 3592
  return (0);
  reconnect: ;
#line 3595
  if ((unsigned long )new_disk_conf != (unsigned long )((struct disk_conf *)0)) {
#line 3596
    put_ldev(mdev);
#line 3597
    kfree((void const   *)new_disk_conf);
  } else {

  }
#line 3599
  ldv_mutex_unlock_115(& (mdev->tconn)->conf_update);
#line 3600
  return (-5);
  disconnect: 
#line 3603
  kfree((void const   *)new_plan);
#line 3604
  if ((unsigned long )new_disk_conf != (unsigned long )((struct disk_conf *)0)) {
#line 3605
    put_ldev(mdev);
#line 3606
    kfree((void const   *)new_disk_conf);
  } else {

  }
#line 3608
  ldv_mutex_unlock_116(& (mdev->tconn)->conf_update);
#line 3611
  crypto_free_hash(csums_tfm);
#line 3613
  crypto_free_hash(verify_tfm);
#line 3614
  val.i = 0U;
#line 3614
  val.ldv_40024.conn = 1U;
#line 3614
  mask.i = 0U;
#line 3614
  mask.ldv_40024.conn = 31U;
#line 3614
  conn_request_state(mdev->tconn, mask, val, CS_HARD);
#line 3615
  return (-5);
}
}
#line 3619 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void warn_if_differ_considerably(struct drbd_conf *mdev , char const   *s ,
                                        sector_t a , sector_t b ) 
{ 
  sector_t d ;

  {
#line 3623
  if (a == 0UL || b == 0UL) {
#line 3624
    return;
  } else {

  }
#line 3625
  d = a > b ? a - b : b - a;
#line 3626
  if (a >> 3 < d || b >> 3 < d) {
#line 3627
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Considerable difference in %s: %llus vs. %llus\n",
             s, (unsigned long long )a, (unsigned long long )b);
  } else {

  }
#line 3629
  return;
}
}
#line 3631 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_sizes(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_sizes *p ;
  enum determine_dev_size dd ;
  sector_t p_size ;
  sector_t p_usize ;
  sector_t my_usize ;
  int ldsc ;
  enum dds_flags ddsf ;
  int tmp ;
  __u64 tmp___0 ;
  __u64 tmp___1 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___2 ;
  int tmp___3 ;
  sector_t tmp___4 ;
  sector_t __x ;
  sector_t __y ;
  sector_t _min1 ;
  sector_t _min2 ;
  sector_t tmp___5 ;
  sector_t tmp___6 ;
  union drbd_state val ;
  union drbd_state mask ;
  sector_t tmp___7 ;
  sector_t tmp___8 ;
  struct disk_conf *old_disk_conf ;
  struct disk_conf *new_disk_conf ;
  void *tmp___9 ;
  int tmp___10 ;
  __u16 tmp___11 ;
  int tmp___12 ;
  __u32 tmp___13 ;
  sector_t tmp___14 ;
  int tmp___15 ;
  __u64 tmp___16 ;
  sector_t tmp___17 ;
  int tmp___18 ;

  {
#line 3634
  p = (struct p_sizes *)pi->data;
#line 3635
  dd = 0;
#line 3637
  ldsc = 0;
#line 3640
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 3641
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 3642
    tmp = config_unknown_volume(tconn, pi);
#line 3642
    return (tmp);
  } else {

  }
#line 3644
  tmp___0 = __fswab64(p->d_size);
#line 3644
  p_size = (sector_t )tmp___0;
#line 3645
  tmp___1 = __fswab64(p->u_size);
#line 3645
  p_usize = (sector_t )tmp___1;
#line 3649
  mdev->p_size = p_size;
#line 3651
  tmp___10 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 3651
  if (tmp___10 != 0) {
#line 3652
    rcu_read_lock___2();
#line 3653
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 3653
    tmp___2 = debug_lockdep_rcu_enabled();
#line 3653
    if (tmp___2 != 0 && ! __warned) {
#line 3653
      tmp___3 = rcu_read_lock_held();
#line 3653
      if (tmp___3 == 0 && 1) {
#line 3653
        __warned = 1;
#line 3653
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                               3653, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 3653
    my_usize = (sector_t )_________p1->disk_size;
#line 3654
    rcu_read_unlock___2();
#line 3656
    tmp___4 = drbd_get_max_capacity(mdev->ldev);
#line 3656
    warn_if_differ_considerably(mdev, "lower level device sizes", p_size, tmp___4);
#line 3658
    warn_if_differ_considerably(mdev, "user requested size", p_usize, my_usize);
#line 3663
    if ((unsigned int )*((unsigned short *)mdev + 374UL) == 144U) {
#line 3664
      __x = my_usize;
#line 3664
      __y = p_usize;
#line 3664
      if (__x != 0UL) {
#line 3664
        if (__y != 0UL) {
#line 3664
          _min1 = __x;
#line 3664
          _min2 = __y;
#line 3664
          tmp___5 = _min1 < _min2 ? _min1 : _min2;
        } else {
#line 3664
          tmp___5 = __x;
        }
#line 3664
        tmp___6 = tmp___5;
      } else {
#line 3664
        tmp___6 = __y;
      }
#line 3664
      p_usize = tmp___6;
    } else {

    }
#line 3668
    tmp___7 = drbd_new_dev_size(mdev, mdev->ldev, p_usize, 0);
#line 3668
    tmp___8 = drbd_get_capacity(mdev->this_bdev);
#line 3668
    if ((tmp___7 < tmp___8 && (int )mdev->state.ldv_49522.disk > 4) && (int )mdev->state.ldv_49522.conn <= 9) {
#line 3672
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "The peer\'s disk size is too small!\n");
#line 3673
      val.i = 0U;
#line 3673
      val.ldv_40024.conn = 1U;
#line 3673
      mask.i = 0U;
#line 3673
      mask.ldv_40024.conn = 31U;
#line 3673
      conn_request_state(mdev->tconn, mask, val, CS_HARD);
#line 3674
      put_ldev(mdev);
#line 3675
      return (-5);
    } else {

    }
#line 3678
    if (my_usize != p_usize) {
#line 3679
      new_disk_conf = 0;
#line 3681
      tmp___9 = kzalloc(344UL, 208U);
#line 3681
      new_disk_conf = (struct disk_conf *)tmp___9;
#line 3682
      if ((unsigned long )new_disk_conf == (unsigned long )((struct disk_conf *)0)) {
#line 3683
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Allocation of new disk_conf failed\n");
#line 3684
        put_ldev(mdev);
#line 3685
        return (-12);
      } else {

      }
#line 3688
      ldv_mutex_lock_117(& (mdev->tconn)->conf_update);
#line 3689
      old_disk_conf = (mdev->ldev)->disk_conf;
#line 3690
      *new_disk_conf = *old_disk_conf;
#line 3691
      new_disk_conf->disk_size = (__u64 )p_usize;
#line 3693
      __asm__  volatile   ("": : : "memory");
#line 3693
      (mdev->ldev)->disk_conf = new_disk_conf;
#line 3694
      ldv_mutex_unlock_118(& (mdev->tconn)->conf_update);
#line 3695
      synchronize_rcu();
#line 3696
      kfree((void const   *)old_disk_conf);
#line 3698
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Peer sets u_size to %lu sectors\n",
                my_usize);
    } else {

    }
#line 3702
    put_ldev(mdev);
  } else {

  }
#line 3705
  tmp___11 = __fswab16((int )p->dds_flags);
#line 3705
  ddsf = (enum dds_flags )tmp___11;
#line 3706
  tmp___12 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 3706
  if (tmp___12 != 0) {
#line 3707
    dd = drbd_determine_dev_size(mdev, ddsf);
#line 3708
    put_ldev(mdev);
#line 3709
    if ((int )dd == -1) {
#line 3710
      return (-5);
    } else {

    }
#line 3711
    drbd_md_sync(mdev);
  } else {
#line 3714
    drbd_set_my_capacity(mdev, p_size);
  }
#line 3717
  tmp___13 = __fswab32(p->max_bio_size);
#line 3717
  mdev->peer_max_bio_size = tmp___13;
#line 3718
  drbd_reconsider_max_bio_size(mdev);
#line 3720
  tmp___15 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 3720
  if (tmp___15 != 0) {
#line 3721
    tmp___14 = drbd_get_capacity((mdev->ldev)->backing_bdev);
#line 3721
    if ((mdev->ldev)->known_size != tmp___14) {
#line 3722
      (mdev->ldev)->known_size = drbd_get_capacity((mdev->ldev)->backing_bdev);
#line 3723
      ldsc = 1;
    } else {

    }
#line 3726
    put_ldev(mdev);
  } else {

  }
#line 3729
  if ((int )mdev->state.ldv_49522.conn > 9) {
#line 3730
    tmp___16 = __fswab64(p->c_size);
#line 3730
    tmp___17 = drbd_get_capacity(mdev->this_bdev);
#line 3730
    if (tmp___16 != (unsigned long long )tmp___17 || ldsc != 0) {
#line 3734
      drbd_send_sizes(mdev, 0, ddsf);
    } else {

    }
#line 3736
    tmp___18 = test_and_clear_bit(16, (unsigned long volatile   *)(& mdev->flags));
#line 3736
    if (tmp___18 != 0 || ((int )dd == 2 && (unsigned int )*((unsigned short *)mdev + 374UL) == 160U)) {
#line 3738
      if ((int )mdev->state.ldv_49522.pdsk > 3 && (int )mdev->state.ldv_49522.disk > 3) {
#line 3740
        if (((unsigned int )ddsf & 2U) != 0U) {
#line 3741
          _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Resync of new storage suppressed with --assume-clean\n");
        } else {
#line 3743
          resync_after_online_grow(mdev);
        }
      } else {
#line 3745
        set_bit(15U, (unsigned long volatile   *)(& mdev->flags));
      }
    } else {

    }
  } else {

  }
#line 3749
  return (0);
}
}
#line 3752 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_uuids(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_uuids *p ;
  u64 *p_uuid ;
  int i ;
  int updated_uuids ;
  int tmp ;
  void *tmp___0 ;
  __u64 tmp___1 ;
  union drbd_state val ;
  union drbd_state mask ;
  int skip_initial_sync ;
  union drbd_state __ns ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 3755
  p = (struct p_uuids *)pi->data;
#line 3757
  updated_uuids = 0;
#line 3759
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 3760
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 3761
    tmp = config_unknown_volume(tconn, pi);
#line 3761
    return (tmp);
  } else {

  }
#line 3763
  tmp___0 = kmalloc(48UL, 16U);
#line 3763
  p_uuid = (u64 *)tmp___0;
#line 3764
  if ((unsigned long )p_uuid == (unsigned long )((u64 *)0)) {
#line 3765
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "kmalloc of p_uuid failed\n");
#line 3766
    return (0);
  } else {

  }
#line 3769
  i = 0;
#line 3769
  goto ldv_53786;
  ldv_53785: 
#line 3770
  tmp___1 = __fswab64(p->uuid[i]);
#line 3770
  *(p_uuid + (unsigned long )i) = tmp___1;
#line 3769
  i = i + 1;
  ldv_53786: ;
#line 3769
  if (i <= 5) {
#line 3770
    goto ldv_53785;
  } else {

  }
#line 3772
  kfree((void const   *)mdev->p_uuid);
#line 3773
  mdev->p_uuid = p_uuid;
#line 3775
  if ((((int )mdev->state.ldv_49522.conn <= 9 && (int )mdev->state.ldv_49522.disk <= 3) && (unsigned int )*((unsigned char *)mdev + 748UL) == 1U) && ((mdev->ed_uuid ^ *p_uuid) & 0xfffffffffffffffeULL) != 0ULL) {
#line 3779
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Can only connect to data with current UUID=%016llX\n",
            mdev->ed_uuid);
#line 3781
    val.i = 0U;
#line 3781
    val.ldv_40024.conn = 1U;
#line 3781
    mask.i = 0U;
#line 3781
    mask.ldv_40024.conn = 31U;
#line 3781
    conn_request_state(mdev->tconn, mask, val, CS_HARD);
#line 3782
    return (-5);
  } else {

  }
#line 3785
  tmp___2 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 3785
  if (tmp___2 != 0) {
#line 3786
    skip_initial_sync = (((unsigned int )*((unsigned short *)mdev + 374UL) == 160U && (mdev->tconn)->agreed_pro_version > 89) && (mdev->ldev)->md.uuid[0] == 4ULL) && (*(p_uuid + 5UL) & 8ULL) != 0ULL;
#line 3791
    if (skip_initial_sync != 0) {
#line 3792
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Accepted new current UUID, preparing to skip initial sync\n");
#line 3793
      drbd_bitmap_io(mdev, & drbd_bmio_clear_n_write, (char *)"clear_n_write from receive_uuids",
                     BM_LOCKED_TEST_ALLOWED);
#line 3796
      _drbd_uuid_set(mdev, 0, *p_uuid);
#line 3797
      _drbd_uuid_set(mdev, 1, 0ULL);
#line 3798
      __ns = drbd_read_state(mdev);
#line 3798
      __ns.ldv_40024.disk = 8U;
#line 3798
      __ns.ldv_40024.pdsk = 8U;
#line 3798
      _drbd_set_state(mdev, __ns, CS_VERBOSE, 0);
#line 3800
      drbd_md_sync(mdev);
#line 3801
      updated_uuids = 1;
    } else {

    }
#line 3803
    put_ldev(mdev);
  } else
#line 3804
  if ((int )mdev->state.ldv_49522.disk <= 3 && (unsigned int )*((unsigned char *)mdev + 748UL) == 1U) {
#line 3808
    updated_uuids = drbd_set_ed_uuid(mdev, *p_uuid);
  } else {

  }
#line 3815
  ldv_mutex_lock_119(mdev->state_mutex);
#line 3816
  ldv_mutex_unlock_120(mdev->state_mutex);
#line 3817
  if ((int )mdev->state.ldv_49522.conn > 9 && (int )mdev->state.ldv_49522.disk <= 3) {
#line 3818
    tmp___3 = drbd_set_ed_uuid(mdev, *p_uuid);
#line 3818
    updated_uuids = tmp___3 | updated_uuids;
  } else {

  }
#line 3820
  if (updated_uuids != 0) {
#line 3821
    drbd_print_uuids(mdev, "receiver updated UUIDs to");
  } else {

  }
#line 3823
  return (0);
}
}
#line 3830 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static union drbd_state convert_state(union drbd_state ps ) 
{ 
  union drbd_state ms ;
  enum drbd_conns c_tab[32U] ;

  {
#line 3834
  c_tab[0] = 0;
#line 3834
  c_tab[1] = C_TEAR_DOWN;
#line 3834
  c_tab[2] = 0;
#line 3834
  c_tab[3] = 0;
#line 3834
  c_tab[4] = 0;
#line 3834
  c_tab[5] = 0;
#line 3834
  c_tab[6] = 0;
#line 3834
  c_tab[7] = 0;
#line 3834
  c_tab[8] = 0;
#line 3834
  c_tab[9] = C_WF_REPORT_PARAMS;
#line 3834
  c_tab[10] = C_CONNECTED;
#line 3834
  c_tab[11] = C_STARTING_SYNC_T;
#line 3834
  c_tab[12] = C_STARTING_SYNC_S;
#line 3834
  c_tab[13] = 0;
#line 3834
  c_tab[14] = 0;
#line 3834
  c_tab[15] = 0;
#line 3834
  c_tab[16] = 0;
#line 3834
  c_tab[17] = 0;
#line 3834
  c_tab[18] = C_VERIFY_T;
#line 3834
  c_tab[19] = 0;
#line 3834
  c_tab[20] = 0;
#line 3834
  c_tab[21] = 0;
#line 3834
  c_tab[22] = 0;
#line 3834
  c_tab[23] = 0;
#line 3834
  c_tab[24] = 0;
#line 3834
  c_tab[25] = 0;
#line 3834
  c_tab[26] = 0;
#line 3834
  c_tab[27] = 0;
#line 3834
  c_tab[28] = 0;
#line 3834
  c_tab[29] = 0;
#line 3834
  c_tab[30] = 0;
#line 3834
  c_tab[31] = C_MASK;
#line 3845
  ms.i = ps.i;
#line 3847
  ms.ldv_40024.conn = (unsigned char )c_tab[(int )ps.ldv_40024.conn];
#line 3848
  ms.ldv_40024.peer = ps.ldv_40024.role;
#line 3849
  ms.ldv_40024.role = ps.ldv_40024.peer;
#line 3850
  ms.ldv_40024.pdsk = ps.ldv_40024.disk;
#line 3851
  ms.ldv_40024.disk = ps.ldv_40024.pdsk;
#line 3852
  ms.ldv_40024.peer_isp = (unsigned char )((int )ps.ldv_40024.aftr_isp | (int )ps.ldv_40024.user_isp);
#line 3854
  return (ms);
}
}
#line 3857 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_req_state(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_req_state *p ;
  union drbd_state mask ;
  union drbd_state val ;
  enum drbd_state_rv rv ;
  __u32 tmp ;
  __u32 tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 3860
  p = (struct p_req_state *)pi->data;
#line 3864
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 3865
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 3866
    return (-5);
  } else {

  }
#line 3868
  tmp = __fswab32(p->mask);
#line 3868
  mask.i = tmp;
#line 3869
  tmp___0 = __fswab32(p->val);
#line 3869
  val.i = tmp___0;
#line 3871
  tmp___1 = constant_test_bit(1U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
#line 3871
  if (tmp___1 != 0) {
#line 3871
    tmp___2 = ldv_mutex_is_locked_121(mdev->state_mutex);
#line 3871
    if (tmp___2 != 0) {
#line 3873
      drbd_send_sr_reply(mdev, SS_CONCURRENT_ST_CHG);
#line 3874
      return (0);
    } else {

    }
  } else {

  }
#line 3877
  mask = convert_state(mask);
#line 3878
  val = convert_state(val);
#line 3880
  rv = drbd_change_state(mdev, CS_VERBOSE, mask, val);
#line 3881
  drbd_send_sr_reply(mdev, rv);
#line 3883
  drbd_md_sync(mdev);
#line 3885
  return (0);
}
}
#line 3888 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_req_conn_state(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct p_req_state *p ;
  union drbd_state mask ;
  union drbd_state val ;
  enum drbd_state_rv rv ;
  __u32 tmp ;
  __u32 tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 3890
  p = (struct p_req_state *)pi->data;
#line 3894
  tmp = __fswab32(p->mask);
#line 3894
  mask.i = tmp;
#line 3895
  tmp___0 = __fswab32(p->val);
#line 3895
  val.i = tmp___0;
#line 3897
  tmp___1 = constant_test_bit(1U, (unsigned long const volatile   *)(& tconn->flags));
#line 3897
  if (tmp___1 != 0) {
#line 3897
    tmp___2 = ldv_mutex_is_locked_122(& tconn->cstate_mutex);
#line 3897
    if (tmp___2 != 0) {
#line 3899
      conn_send_sr_reply(tconn, SS_CONCURRENT_ST_CHG);
#line 3900
      return (0);
    } else {

    }
  } else {

  }
#line 3903
  mask = convert_state(mask);
#line 3904
  val = convert_state(val);
#line 3906
  rv = conn_request_state(tconn, mask, val, 2066);
#line 3907
  conn_send_sr_reply(tconn, rv);
#line 3909
  return (0);
}
}
#line 3912 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_state(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_state *p ;
  union drbd_state os ;
  union drbd_state ns ;
  union drbd_state peer_state ;
  enum drbd_disk_state real_peer_disk ;
  enum chg_state_flags cs_flags ;
  int rv ;
  int tmp ;
  __u32 tmp___0 ;
  char const   *tmp___1 ;
  unsigned long tmp___2 ;
  int cr ;
  int tmp___3 ;
  enum drbd_conns tmp___4 ;
  union drbd_state val ;
  union drbd_state mask ;
  int tmp___5 ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;
  int tmp___6 ;
  union drbd_state tmp___7 ;
  union drbd_state val___1 ;
  union drbd_state mask___1 ;
  int tmp___8 ;
  int tmp___9 ;
  enum drbd_state_rv tmp___10 ;
  union drbd_state val___2 ;
  union drbd_state mask___2 ;

  {
#line 3915
  p = (struct p_state *)pi->data;
#line 3921
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 3922
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 3923
    tmp = config_unknown_volume(tconn, pi);
#line 3923
    return (tmp);
  } else {

  }
#line 3925
  tmp___0 = __fswab32(p->state);
#line 3925
  peer_state.i = tmp___0;
#line 3927
  real_peer_disk = (enum drbd_disk_state )peer_state.ldv_40024.disk;
#line 3928
  if ((unsigned int )*((unsigned char *)(& peer_state) + 1UL) == 6U) {
#line 3929
    real_peer_disk = (*(mdev->p_uuid + 5UL) & 4ULL) != 0ULL ? D_INCONSISTENT : D_CONSISTENT;
#line 3930
    tmp___1 = drbd_disk_str(real_peer_disk);
#line 3930
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "real peer disk state = %s\n",
              tmp___1);
  } else {

  }
#line 3933
  spin_lock_irq(& (mdev->tconn)->req_lock);
  retry: 
#line 3935
  ns = drbd_read_state(mdev);
#line 3935
  os = ns;
#line 3936
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 3941
  if ((int )os.ldv_40024.conn <= 7) {
#line 3942
    return (-104);
  } else {

  }
#line 3950
  if ((((*((unsigned int *)(& os) + 0UL) == 32768U || *((unsigned int *)(& os) + 0UL) == 57344U) && (unsigned int )real_peer_disk == 8U) && (int )os.ldv_40024.conn > 10) && (unsigned int )*((unsigned char *)(& os) + 1UL) == 16U) {
#line 3959
    if ((int )peer_state.ldv_40024.conn > 10 && (int )peer_state.ldv_40024.conn <= 15) {
#line 3961
      real_peer_disk = D_INCONSISTENT;
    } else
#line 3966
    if ((int )os.ldv_40024.conn > 15 && (unsigned int )*((unsigned short *)(& peer_state) + 0UL) == 160U) {
#line 3968
      tmp___2 = drbd_bm_total_weight(mdev);
#line 3968
      if (tmp___2 <= mdev->rs_failed) {
#line 3969
        drbd_resync_finished(mdev);
      } else {

      }
#line 3970
      return (0);
    } else {

    }
  } else {

  }
#line 3975
  if ((((unsigned int )*((unsigned short *)(& os) + 0UL) == 304U && (unsigned int )*((unsigned char *)(& os) + 1UL) == 16U) && (unsigned int )*((unsigned short *)(& peer_state) + 0UL) == 160U) && (unsigned int )real_peer_disk == 8U) {
#line 3977
    ov_out_of_sync_print(mdev);
#line 3978
    drbd_resync_finished(mdev);
#line 3979
    return (0);
  } else {

  }
#line 3987
  if (((*((unsigned int *)(& os) + 0UL) == 65536U && (unsigned int )real_peer_disk == 4U) && (unsigned int )*((unsigned short *)(& os) + 0UL) == 160U) && (int )peer_state.ldv_40024.conn > 16) {
#line 3989
    real_peer_disk = D_UP_TO_DATE;
  } else {

  }
#line 3991
  if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 144U) {
#line 3992
    ns.ldv_40024.conn = 10U;
  } else {

  }
#line 3994
  if ((unsigned int )*((unsigned short *)(& peer_state) + 0UL) == 352U) {
#line 3995
    ns.ldv_40024.conn = 23U;
  } else {

  }
#line 3997
  if ((unsigned long )mdev->p_uuid != (unsigned long )((u64 *)0) && (int )peer_state.ldv_40024.disk > 2) {
#line 3997
    tmp___6 = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 3997
    if (tmp___6 != 0) {
#line 4002
      cr = (int )os.ldv_40024.conn <= 9;
#line 4005
      cr = ((unsigned int )*((unsigned short *)(& os) + 0UL) == 160U && ((unsigned int )*((unsigned char *)(& peer_state) + 1UL) == 6U || (unsigned int )*((unsigned char *)(& os) + 1UL) == 6U)) | cr;
#line 4010
      tmp___3 = constant_test_bit(6U, (unsigned long const volatile   *)(& mdev->flags));
#line 4010
      cr = tmp___3 | cr;
#line 4013
      cr = ((unsigned int )*((unsigned short *)(& os) + 0UL) == 160U && ((int )peer_state.ldv_40024.conn > 10 && (int )peer_state.ldv_40024.conn <= 14)) | cr;
#line 4017
      if (cr != 0) {
#line 4018
        tmp___4 = drbd_sync_handshake(mdev, (enum drbd_role )peer_state.ldv_40024.role,
                                      real_peer_disk);
#line 4018
        ns.ldv_40024.conn = (unsigned char )tmp___4;
      } else {

      }
#line 4020
      put_ldev(mdev);
#line 4021
      if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 496U) {
#line 4022
        ns.ldv_40024.conn = 10U;
#line 4023
        if ((unsigned int )*((unsigned char *)mdev + 749UL) == 6U) {
#line 4024
          val.i = 0U;
#line 4024
          val.ldv_40024.disk = 2U;
#line 4024
          mask.i = 0U;
#line 4024
          mask.ldv_40024.disk = 15U;
#line 4024
          drbd_force_state(mdev, mask, val);
        } else
#line 4025
        if ((unsigned int )*((unsigned char *)(& peer_state) + 1UL) == 6U) {
#line 4026
          dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Disk attach process on the peer node was aborted.\n");
#line 4027
          peer_state.ldv_40024.disk = 0U;
#line 4028
          real_peer_disk = D_DISKLESS;
        } else {
#line 4030
          tmp___5 = test_and_clear_bit(8, (unsigned long volatile   *)(& (mdev->tconn)->flags));
#line 4030
          if (tmp___5 != 0) {
#line 4031
            return (-5);
          } else {

          }
#line 4032
          if ((unsigned int )*((unsigned short *)(& os) + 0UL) != 144U) {
#line 4032
            dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( os.conn == C_WF_REPORT_PARAMS ) in %s:%d\n",
                    (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                    4032);
          } else {

          }
#line 4033
          val___0.i = 0U;
#line 4033
          val___0.ldv_40024.conn = 1U;
#line 4033
          mask___0.i = 0U;
#line 4033
          mask___0.ldv_40024.conn = 31U;
#line 4033
          conn_request_state(mdev->tconn, mask___0, val___0, CS_HARD);
#line 4034
          return (-5);
        }
      } else {

      }
    } else {

    }
  } else {

  }
#line 4039
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 4040
  tmp___7 = drbd_read_state(mdev);
#line 4040
  if (os.i != tmp___7.i) {
#line 4041
    goto retry;
  } else {

  }
#line 4042
  clear_bit(6, (unsigned long volatile   *)(& mdev->flags));
#line 4043
  ns.ldv_40024.peer = peer_state.ldv_40024.role;
#line 4044
  ns.ldv_40024.pdsk = (unsigned char )real_peer_disk;
#line 4045
  ns.ldv_40024.peer_isp = (unsigned char )((int )peer_state.ldv_40024.aftr_isp | (int )peer_state.ldv_40024.user_isp);
#line 4046
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 160U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 208U) && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 6U) {
#line 4047
    ns.ldv_40024.disk = mdev->new_state_tmp.ldv_40024.disk;
  } else {

  }
#line 4048
  cs_flags = (enum chg_state_flags )(((int )os.ldv_40024.conn > 9 || (int )ns.ldv_40024.conn <= 9) + 2);
#line 4049
  if (*((unsigned int *)(& ns) + 0UL) == 57344U) {
#line 4049
    tmp___8 = drbd_suspended(mdev);
#line 4049
    if (tmp___8 != 0) {
#line 4049
      if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 160U) {
#line 4049
        if ((int )os.ldv_40024.conn <= 9) {
#line 4049
          tmp___9 = constant_test_bit(17U, (unsigned long const volatile   *)(& mdev->flags));
#line 4049
          if (tmp___9 != 0) {
#line 4053
            spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 4054
            dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Aborting Connect, can not thaw IO with an only Consistent peer\n");
#line 4055
            tl_clear(mdev->tconn);
#line 4056
            drbd_uuid_new_current(mdev);
#line 4057
            clear_bit(17, (unsigned long volatile   *)(& mdev->flags));
#line 4058
            val___1.i = 0U;
#line 4058
            val___1.ldv_40024.conn = 6U;
#line 4058
            val___1.ldv_40024.susp = 0U;
#line 4058
            mask___1.i = 0U;
#line 4058
            mask___1.ldv_40024.conn = 31U;
#line 4058
            mask___1.ldv_40024.susp = 1U;
#line 4058
            conn_request_state(mdev->tconn, mask___1, val___1, CS_HARD);
#line 4059
            return (-5);
          } else {

          }
        } else {

        }
      } else {

      }
    } else {

    }
  } else {

  }
#line 4061
  tmp___10 = _drbd_set_state(mdev, ns, cs_flags, 0);
#line 4061
  rv = (int )tmp___10;
#line 4062
  ns = drbd_read_state(mdev);
#line 4063
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 4065
  if (rv <= 0) {
#line 4066
    val___2.i = 0U;
#line 4066
    val___2.ldv_40024.conn = 1U;
#line 4066
    mask___2.i = 0U;
#line 4066
    mask___2.ldv_40024.conn = 31U;
#line 4066
    conn_request_state(mdev->tconn, mask___2, val___2, CS_HARD);
#line 4067
    return (-5);
  } else {

  }
#line 4070
  if ((int )os.ldv_40024.conn > 9) {
#line 4071
    if (((int )ns.ldv_40024.conn > 10 && (int )peer_state.ldv_40024.conn <= 10) && (unsigned int )*((unsigned char *)(& peer_state) + 1UL) != 6U) {
#line 4076
      drbd_send_uuids(mdev);
#line 4077
      drbd_send_current_state(mdev);
    } else {

    }
  } else {

  }
#line 4081
  clear_bit(21, (unsigned long volatile   *)(& mdev->flags));
#line 4083
  drbd_md_sync(mdev);
#line 4085
  return (0);
}
}
#line 4088 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_sync_uuid(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_rs_uuid *p ;
  wait_queue_t __wait ;
  struct task_struct *tmp ;
  __u64 tmp___0 ;
  int tmp___1 ;

  {
#line 4091
  p = (struct p_rs_uuid *)pi->data;
#line 4093
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 4094
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 4095
    return (-5);
  } else {

  }
#line 4097
  if ((((unsigned int )*((unsigned short *)mdev + 374UL) == 240U || (unsigned int )*((unsigned short *)mdev + 374UL) == 368U) || (int )mdev->state.ldv_49522.conn <= 9) || (int )mdev->state.ldv_49522.disk <= 2) {
#line 4097
    goto ldv_53853;
  } else {

  }
#line 4097
  tmp = get_current();
#line 4097
  __wait.flags = 0U;
#line 4097
  __wait.private = (void *)tmp;
#line 4097
  __wait.func = & autoremove_wake_function;
#line 4097
  __wait.task_list.next = & __wait.task_list;
#line 4097
  __wait.task_list.prev = & __wait.task_list;
  ldv_53856: 
#line 4097
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 4097
  if ((((unsigned int )*((unsigned short *)mdev + 374UL) == 240U || (unsigned int )*((unsigned short *)mdev + 374UL) == 368U) || (int )mdev->state.ldv_49522.conn <= 9) || (int )mdev->state.ldv_49522.disk <= 2) {
#line 4097
    goto ldv_53855;
  } else {

  }
#line 4097
  schedule();
#line 4097
  goto ldv_53856;
  ldv_53855: 
#line 4097
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_53853: 
#line 4107
  tmp___1 = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 4107
  if (tmp___1 != 0) {
#line 4108
    tmp___0 = __fswab64(p->uuid);
#line 4108
    _drbd_uuid_set(mdev, 0, tmp___0);
#line 4109
    _drbd_uuid_set(mdev, 1, 0ULL);
#line 4111
    drbd_print_uuids(mdev, "updated sync uuid");
#line 4112
    drbd_start_resync(mdev, C_SYNC_TARGET);
#line 4114
    put_ldev(mdev);
  } else {
#line 4116
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Ignoring SyncUUID packet!\n");
  }
#line 4118
  return (0);
}
}
#line 4128 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_bitmap_plain(struct drbd_conf *mdev , unsigned int size , unsigned long *p ,
                                struct bm_xfer_ctx *c ) 
{ 
  unsigned int data_size ;
  unsigned int tmp ;
  unsigned int num_words ;
  size_t __min1 ;
  size_t __min2 ;
  unsigned int want ;
  int err ;

  {
#line 4131
  tmp = drbd_header_size(mdev->tconn);
#line 4131
  data_size = 4096U - tmp;
#line 4133
  __min1 = (unsigned long )(data_size / 8U);
#line 4133
  __min2 = c->bm_words - c->word_offset;
#line 4133
  num_words = (unsigned int )(__min1 < __min2 ? __min1 : __min2);
#line 4135
  want = num_words * 8U;
#line 4138
  if (want != size) {
#line 4139
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s:want (%u) != size (%u)\n",
            "receive_bitmap_plain", want, size);
#line 4140
    return (-5);
  } else {

  }
#line 4142
  if (want == 0U) {
#line 4143
    return (0);
  } else {

  }
#line 4144
  err = drbd_recv_all(mdev->tconn, (void *)p, (size_t )want);
#line 4145
  if (err != 0) {
#line 4146
    return (err);
  } else {

  }
#line 4148
  drbd_bm_merge_lel(mdev, c->word_offset, (size_t )num_words, p);
#line 4150
  c->word_offset = c->word_offset + (unsigned long )num_words;
#line 4151
  c->bit_offset = c->word_offset * 64UL;
#line 4152
  if (c->bit_offset > c->bm_bits) {
#line 4153
    c->bit_offset = c->bm_bits;
  } else {

  }
#line 4155
  return (1);
}
}
#line 4158 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static enum drbd_bitmap_code dcbp_get_code(struct p_compressed_bm *p ) 
{ 


  {
#line 4160
  return ((enum drbd_bitmap_code )((int )p->encoding & 15));
}
}
#line 4163 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int dcbp_get_start(struct p_compressed_bm *p ) 
{ 


  {
#line 4165
  return ((int )((signed char )p->encoding) < 0);
}
}
#line 4168 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int dcbp_get_pad_bits(struct p_compressed_bm *p ) 
{ 


  {
#line 4170
  return (((int )p->encoding >> 4) & 7);
}
}
#line 4180 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int recv_bm_rle_bits(struct drbd_conf *mdev , struct p_compressed_bm *p , struct bm_xfer_ctx *c ,
                            unsigned int len ) 
{ 
  struct bitstream bs ;
  u64 look_ahead ;
  u64 rl ;
  u64 tmp ;
  unsigned long s ;
  unsigned long e ;
  int toggle ;
  int tmp___0 ;
  int have ;
  int bits ;
  int tmp___1 ;

  {
#line 4189
  s = c->bit_offset;
#line 4191
  tmp___0 = dcbp_get_start(p);
#line 4191
  toggle = tmp___0;
#line 4195
  tmp___1 = dcbp_get_pad_bits(p);
#line 4195
  bitstream_init(& bs, (void *)(& p->code), (size_t )len, (unsigned int )tmp___1);
#line 4197
  bits = bitstream_get_bits(& bs, & look_ahead, 64);
#line 4198
  if (bits < 0) {
#line 4199
    return (-5);
  } else {

  }
#line 4201
  have = bits;
#line 4201
  goto ldv_53896;
  ldv_53895: 
#line 4202
  bits = vli_decode_bits(& rl, look_ahead);
#line 4203
  if (bits <= 0) {
#line 4204
    return (-5);
  } else {

  }
#line 4206
  if (toggle != 0) {
#line 4207
    e = (unsigned long )(((unsigned long long )s + rl) - 1ULL);
#line 4208
    if (c->bm_bits <= e) {
#line 4209
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bitmap overflow (e:%lu) while decoding bm RLE packet\n",
              e);
#line 4210
      return (-5);
    } else {

    }
#line 4212
    _drbd_bm_set_bits(mdev, s, e);
  } else {

  }
#line 4215
  if (have < bits) {
#line 4216
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bitmap decoding error: h:%d b:%d la:0x%08llx l:%u/%u\n",
            have, bits, look_ahead, (unsigned int )((long )bs.cur.b) - (unsigned int )((long )(& p->code)),
            (unsigned int )bs.buf_len);
#line 4220
    return (-5);
  } else {

  }
#line 4222
  look_ahead = look_ahead >> bits;
#line 4223
  have = have - bits;
#line 4225
  bits = bitstream_get_bits(& bs, & tmp, 64 - have);
#line 4226
  if (bits < 0) {
#line 4227
    return (-5);
  } else {

  }
#line 4228
  look_ahead = (tmp << have) | look_ahead;
#line 4229
  have = have + bits;
#line 4201
  s = (unsigned long )((unsigned long long )s + rl);
#line 4201
  toggle = toggle == 0;
  ldv_53896: ;
#line 4201
  if (have > 0) {
#line 4202
    goto ldv_53895;
  } else {

  }
#line 4232
  c->bit_offset = s;
#line 4233
  bm_xfer_ctx_bit_to_word_offset(c);
#line 4235
  return (c->bm_bits != s);
}
}
#line 4245 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int decode_bitmap_c(struct drbd_conf *mdev , struct p_compressed_bm *p , struct bm_xfer_ctx *c ,
                           unsigned int len ) 
{ 
  int tmp ;
  enum drbd_bitmap_code tmp___0 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 4250
  tmp___0 = dcbp_get_code(p);
#line 4250
  if ((unsigned int )tmp___0 == 2U) {
#line 4251
    tmp = recv_bm_rle_bits(mdev, p, c, len - 1U);
#line 4251
    return (tmp);
  } else {

  }
#line 4257
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "receive_bitmap_c: unknown encoding %u\n",
          (int )p->encoding);
#line 4258
  val.i = 0U;
#line 4258
  val.ldv_40024.conn = 6U;
#line 4258
  mask.i = 0U;
#line 4258
  mask.ldv_40024.conn = 31U;
#line 4258
  conn_request_state(mdev->tconn, mask, val, CS_HARD);
#line 4259
  return (-5);
}
}
#line 4262 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void INFO_bm_xfer_stats(struct drbd_conf *mdev , char const   *direction , struct bm_xfer_ctx *c ) 
{ 
  unsigned int header_size ;
  unsigned int tmp ;
  unsigned int data_size ;
  unsigned int plain ;
  unsigned int total ;
  unsigned int r ;

  {
#line 4266
  tmp = drbd_header_size(mdev->tconn);
#line 4266
  header_size = tmp;
#line 4267
  data_size = 4096U - header_size;
#line 4268
  plain = (unsigned int )(((c->bm_words + (unsigned long )data_size) - 1UL) / (unsigned long )data_size + 1UL) * header_size + (unsigned int )c->bm_words * 8U;
#line 4271
  total = c->bytes[0] + c->bytes[1];
#line 4275
  if (total == 0U) {
#line 4276
    return;
  } else {

  }
#line 4279
  if (total >= plain) {
#line 4280
    return;
  } else {

  }
#line 4283
  r = total > 4294967U ? total / (plain / 1000U) : (total * 1000U) / plain;
#line 4286
  if (r > 1000U) {
#line 4287
    r = 1000U;
  } else {

  }
#line 4289
  r = 1000U - r;
#line 4290
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s bitmap stats [Bytes(packets)]: plain %u(%u), RLE %u(%u), total %u; compression: %u.%u%%\n",
            direction, c->bytes[1], c->packets[1], c->bytes[0], c->packets[0], total,
            r / 10U, r % 10U);
#line 4291
  return;
}
}
#line 4306 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_bitmap(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct bm_xfer_ctx c ;
  int err ;
  struct bm_xfer_ctx __constr_expr_0 ;
  unsigned long tmp ;
  size_t tmp___0 ;
  struct p_compressed_bm *p ;
  unsigned int tmp___1 ;
  unsigned int tmp___2 ;
  enum drbd_state_rv rv ;
  union drbd_state val ;
  union drbd_state mask ;
  char const   *tmp___3 ;

  {
#line 4312
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 4313
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 4314
    return (-5);
  } else {

  }
#line 4316
  drbd_bm_lock(mdev, (char *)"receive bitmap", BM_LOCKED_SET_ALLOWED);
#line 4320
  tmp = drbd_bm_bits(mdev);
#line 4320
  tmp___0 = drbd_bm_words(mdev);
#line 4320
  __constr_expr_0.bm_bits = tmp;
#line 4320
  __constr_expr_0.bm_words = tmp___0;
#line 4320
  __constr_expr_0.bit_offset = 0UL;
#line 4320
  __constr_expr_0.word_offset = 0UL;
#line 4320
  __constr_expr_0.packets[0] = 0U;
#line 4320
  __constr_expr_0.packets[1] = 0U;
#line 4320
  __constr_expr_0.bytes[0] = 0U;
#line 4320
  __constr_expr_0.bytes[1] = 0U;
#line 4320
  c = __constr_expr_0;
  ldv_53929: ;
#line 4326
  if ((unsigned int )pi->cmd == 4U) {
#line 4327
    err = receive_bitmap_plain(mdev, pi->size, (unsigned long *)pi->data, & c);
  } else
#line 4328
  if ((unsigned int )pi->cmd == 36U) {
#line 4331
    p = (struct p_compressed_bm *)pi->data;
#line 4333
    tmp___1 = drbd_header_size(tconn);
#line 4333
    if (pi->size > 4096U - tmp___1) {
#line 4334
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ReportCBitmap packet too large\n");
#line 4335
      err = -5;
#line 4336
      goto out;
    } else {

    }
#line 4338
    if (pi->size <= 1U) {
#line 4339
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ReportCBitmap packet too small (l:%u)\n",
              pi->size);
#line 4340
      err = -5;
#line 4341
      goto out;
    } else {

    }
#line 4343
    err = drbd_recv_all(mdev->tconn, (void *)p, (size_t )pi->size);
#line 4344
    if (err != 0) {
#line 4345
      goto out;
    } else {

    }
#line 4346
    err = decode_bitmap_c(mdev, p, & c, pi->size);
  } else {
#line 4348
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "receive_bitmap: cmd neither ReportBitMap nor ReportCBitMap (is 0x%x)",
             (unsigned int )pi->cmd);
#line 4349
    err = -5;
#line 4350
    goto out;
  }
#line 4353
  c.packets[(unsigned int )pi->cmd == 4U] = c.packets[(unsigned int )pi->cmd == 4U] + 1U;
#line 4354
  tmp___2 = drbd_header_size(tconn);
#line 4354
  c.bytes[(unsigned int )pi->cmd == 4U] = c.bytes[(unsigned int )pi->cmd == 4U] + (tmp___2 + pi->size);
#line 4356
  if (err <= 0) {
#line 4357
    if (err < 0) {
#line 4358
      goto out;
    } else {

    }
#line 4359
    goto ldv_53928;
  } else {

  }
#line 4361
  err = drbd_recv_header(mdev->tconn, pi);
#line 4362
  if (err != 0) {
#line 4363
    goto out;
  } else {

  }
#line 4364
  goto ldv_53929;
  ldv_53928: 
#line 4366
  INFO_bm_xfer_stats(mdev, "receive", & c);
#line 4368
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 224U) {
#line 4371
    err = drbd_send_bitmap(mdev);
#line 4372
    if (err != 0) {
#line 4373
      goto out;
    } else {

    }
#line 4375
    val.i = 0U;
#line 4375
    val.ldv_40024.conn = 15U;
#line 4375
    mask.i = 0U;
#line 4375
    mask.ldv_40024.conn = 31U;
#line 4375
    rv = _drbd_request_state(mdev, mask, val, CS_VERBOSE);
#line 4376
    if ((int )rv != 1) {
#line 4376
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( rv == SS_SUCCESS ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              4376);
    } else {

    }
  } else
#line 4377
  if ((unsigned int )*((unsigned short *)mdev + 374UL) != 208U) {
#line 4380
    tmp___3 = drbd_conn_str((enum drbd_conns )mdev->state.ldv_49522.conn);
#line 4380
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "unexpected cstate (%s) in receive_bitmap\n",
              tmp___3);
  } else {

  }
#line 4383
  err = 0;
  out: 
#line 4386
  drbd_bm_unlock(mdev);
#line 4387
  if (err == 0 && (unsigned int )*((unsigned short *)mdev + 374UL) == 208U) {
#line 4388
    drbd_start_resync(mdev, C_SYNC_SOURCE);
  } else {

  }
#line 4389
  return (err);
}
}
#line 4392 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_skip(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  int tmp ;

  {
#line 4394
  printk("\fd-con %s: skipping unknown optional packet type %d, l: %d!\n", tconn->name,
         (unsigned int )pi->cmd, pi->size);
#line 4397
  tmp = ignore_remaining_packet(tconn, pi);
#line 4397
  return (tmp);
}
}
#line 4400 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_UnplugRemote(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 


  {
#line 4404
  drbd_tcp_quickack(tconn->data.socket);
#line 4406
  return (0);
}
}
#line 4409 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int receive_out_of_sync(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_block_desc *p ;
  char const   *tmp ;
  __u32 tmp___0 ;
  __u64 tmp___1 ;

  {
#line 4412
  p = (struct p_block_desc *)pi->data;
#line 4414
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 4415
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 4416
    return (-5);
  } else {

  }
#line 4418
  switch ((int )mdev->state.ldv_49522.conn) {
  case 15: ;
  case 14: ;
  case 23: ;
#line 4422
  goto ldv_53952;
  default: 
#line 4424
  tmp = drbd_conn_str((enum drbd_conns )mdev->state.ldv_49522.conn);
#line 4424
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED cstate = %s, expected: WFSyncUUID|WFBitMapT|Behind\n",
          tmp);
  }
  ldv_53952: 
#line 4428
  tmp___0 = __fswab32(p->blksize);
#line 4428
  tmp___1 = __fswab64(p->sector);
#line 4428
  __drbd_set_out_of_sync(mdev, (sector_t )tmp___1, (int )tmp___0, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                         4428U);
#line 4430
  return (0);
}
}
#line 4439 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct data_cmd drbd_cmd_handler[46U]  = 
#line 4439
  {      {1, 24UL, & receive_Data}, 
        {1, 24UL, & receive_DataReply}, 
        {1, 24UL, & receive_RSDataReply}, 
        {0, 8UL, & receive_Barrier}, 
        {1, 0UL, & receive_bitmap}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, & receive_UnplugRemote}, 
        {0, 24UL, & receive_DataRequest}, 
        {0, 24UL, & receive_DataRequest}, 
        {1, 0UL, & receive_SyncParam}, 
        {1, 24UL, & receive_protocol}, 
        {0, 48UL, & receive_uuids}, 
        {0, 32UL, & receive_sizes}, 
        {0, 4UL, & receive_state}, 
        {0, 8UL, & receive_sync_uuid}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 8UL, & receive_req_state}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 24UL, & receive_DataRequest}, 
        {1, 24UL, & receive_DataRequest}, 
        {0, 0UL, 0}, 
        {1, 24UL, & receive_DataRequest}, 
        {0, 0UL, 0}, 
        {1, 0UL, & receive_SyncParam}, 
        {1, 0UL, & receive_bitmap}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {0, 8UL, & receive_skip}, 
        {0, 16UL, & receive_out_of_sync}, 
        {0, 0UL, 0}, 
        {0, 8UL, & receive_req_conn_state}, 
        {0, 0UL, 0}, 
        {0, 0UL, 0}, 
        {1, 24UL, & receive_protocol}};
#line 4466 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void drbdd(struct drbd_tconn *tconn ) 
{ 
  struct packet_info pi ;
  size_t shs ;
  int err ;
  struct data_cmd *cmd ;
  int tmp ;
  char const   *tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  char const   *tmp___3 ;
  char const   *tmp___4 ;
  enum drbd_thread_state tmp___5 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 4472
  goto ldv_53972;
  ldv_53971: 
#line 4475
  drbd_thread_current_set_cpu(& tconn->receiver);
#line 4476
  tmp = drbd_recv_header(tconn, & pi);
#line 4476
  if (tmp != 0) {
#line 4477
    goto err_out;
  } else {

  }
#line 4479
  cmd = (struct data_cmd *)(& drbd_cmd_handler) + (unsigned long )pi.cmd;
#line 4480
  tmp___1 = __builtin_expect((unsigned int )pi.cmd > (unsigned int )P_PROTOCOL_UPDATE,
                             0L);
#line 4480
  if (tmp___1 != 0L) {
#line 4481
    tmp___0 = cmdname(pi.cmd);
#line 4481
    printk("\vd-con %s: Unexpected data packet %s (0x%04x)", tconn->name, tmp___0,
           (unsigned int )pi.cmd);
#line 4483
    goto err_out;
  } else {
#line 4480
    tmp___2 = __builtin_expect((unsigned long )cmd->fn == (unsigned long )((int (*)(struct drbd_tconn * ,
                                                                                    struct packet_info * ))0),
                               0L);
#line 4480
    if (tmp___2 != 0L) {
#line 4481
      tmp___0 = cmdname(pi.cmd);
#line 4481
      printk("\vd-con %s: Unexpected data packet %s (0x%04x)", tconn->name, tmp___0,
             (unsigned int )pi.cmd);
#line 4483
      goto err_out;
    } else {

    }
  }
#line 4486
  shs = cmd->pkt_size;
#line 4487
  if ((size_t )pi.size > shs && cmd->expect_payload == 0) {
#line 4488
    tmp___3 = cmdname(pi.cmd);
#line 4488
    printk("\vd-con %s: No payload expected %s l:%d\n", tconn->name, tmp___3, pi.size);
#line 4490
    goto err_out;
  } else {

  }
#line 4493
  if (shs != 0UL) {
#line 4494
    err = drbd_recv_all_warn(tconn, pi.data, shs);
#line 4495
    if (err != 0) {
#line 4496
      goto err_out;
    } else {

    }
#line 4497
    pi.size = pi.size - (unsigned int )shs;
  } else {

  }
#line 4500
  err = (*(cmd->fn))(tconn, & pi);
#line 4501
  if (err != 0) {
#line 4502
    tmp___4 = cmdname(pi.cmd);
#line 4502
    printk("\vd-con %s: error receiving %s, e: %d l: %d!\n", tconn->name, tmp___4,
           err, pi.size);
#line 4504
    goto err_out;
  } else {

  }
  ldv_53972: 
#line 4472
  tmp___5 = get_t_state(& tconn->receiver);
#line 4472
  if ((unsigned int )tmp___5 == 1U) {
#line 4473
    goto ldv_53971;
  } else {

  }

#line 4507
  return;
  err_out: 
#line 4510
  val.i = 0U;
#line 4510
  val.ldv_40024.conn = 6U;
#line 4510
  mask.i = 0U;
#line 4510
  mask.ldv_40024.conn = 31U;
#line 4510
  conn_request_state(tconn, mask, val, CS_HARD);
#line 4512
  return;
}
}
#line 4513 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void conn_flush_workqueue(struct drbd_tconn *tconn ) 
{ 
  struct drbd_wq_barrier barr ;

  {
#line 4517
  barr.w.cb = & w_prev_work_done;
#line 4518
  barr.w.ldv_49807.tconn = tconn;
#line 4519
  init_completion(& barr.done);
#line 4520
  drbd_queue_work(& tconn->sender_work, & barr.w);
#line 4521
  wait_for_completion(& barr.done);
#line 4522
  return;
}
}
#line 4524 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static void conn_disconnect(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  enum drbd_conns oc ;
  int vnr ;
  union drbd_state val ;
  union drbd_state mask ;
  void *tmp ;
  void *tmp___0 ;
  int tmp___1 ;
  enum drbd_role tmp___2 ;
  enum drbd_disk_state tmp___3 ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;
  union drbd_state val___1 ;
  union drbd_state mask___1 ;

  {
#line 4530
  if ((unsigned int )tconn->cstate == 0U) {
#line 4531
    return;
  } else {

  }
#line 4538
  val.i = 0U;
#line 4538
  val.ldv_40024.conn = 5U;
#line 4538
  mask.i = 0U;
#line 4538
  mask.ldv_40024.conn = 31U;
#line 4538
  conn_request_state(tconn, mask, val, CS_HARD);
#line 4541
  drbd_thread_stop(& tconn->asender);
#line 4542
  drbd_free_sock(tconn);
#line 4544
  rcu_read_lock___2();
#line 4545
  vnr = 0;
#line 4545
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 4545
  mdev = (struct drbd_conf *)tmp;
#line 4545
  goto ldv_53993;
  ldv_53992: 
#line 4546
  kref_get(& mdev->kref);
#line 4547
  rcu_read_unlock___2();
#line 4548
  drbd_disconnected(mdev);
#line 4549
  kref_put(& mdev->kref, & drbd_minor_destroy);
#line 4550
  rcu_read_lock___2();
#line 4545
  vnr = vnr + 1;
#line 4545
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 4545
  mdev = (struct drbd_conf *)tmp___0;
  ldv_53993: ;
#line 4545
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 4546
    goto ldv_53992;
  } else {

  }
#line 4552
  rcu_read_unlock___2();
#line 4554
  tmp___1 = list_empty((struct list_head  const  *)(& (tconn->current_epoch)->list));
#line 4554
  if (tmp___1 == 0) {
#line 4555
    printk("\vd-con %s: ASSERTION FAILED: tconn->current_epoch->list not empty\n",
           tconn->name);
  } else {

  }
#line 4557
  atomic_set(& (tconn->current_epoch)->epoch_size, 0);
#line 4558
  tconn->send.seen_any_write_yet = 0;
#line 4560
  printk("\016d-con %s: Connection closed\n", tconn->name);
#line 4562
  tmp___2 = conn_highest_role(tconn);
#line 4562
  if ((unsigned int )tmp___2 == 1U) {
#line 4562
    tmp___3 = conn_highest_pdsk(tconn);
#line 4562
    if ((unsigned int )tmp___3 > 5U) {
#line 4563
      conn_try_outdate_peer_async(tconn);
    } else {

    }
  } else {

  }
#line 4565
  spin_lock_irq(& tconn->req_lock);
#line 4566
  oc = tconn->cstate;
#line 4567
  if ((unsigned int )oc > 1U) {
#line 4568
    val___0.i = 0U;
#line 4568
    val___0.ldv_40024.conn = 2U;
#line 4568
    mask___0.i = 0U;
#line 4568
    mask___0.ldv_40024.conn = 31U;
#line 4568
    _conn_request_state(tconn, mask___0, val___0, CS_VERBOSE);
  } else {

  }
#line 4570
  spin_unlock_irq(& tconn->req_lock);
#line 4572
  if ((unsigned int )oc == 1U) {
#line 4573
    val___1.i = 0U;
#line 4573
    val___1.ldv_40024.conn = 0U;
#line 4573
    mask___1.i = 0U;
#line 4573
    mask___1.ldv_40024.conn = 31U;
#line 4573
    conn_request_state(tconn, mask___1, val___1, 3);
  } else {

  }
#line 4575
  return;
}
}
#line 4576 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_disconnected(struct drbd_conf *mdev ) 
{ 
  unsigned int i ;
  int tmp ;
  int tmp___0 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;

  {
#line 4581
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 4582
  _drbd_wait_ee_list_empty(mdev, & mdev->active_ee);
#line 4583
  _drbd_wait_ee_list_empty(mdev, & mdev->sync_ee);
#line 4584
  _drbd_wait_ee_list_empty(mdev, & mdev->read_ee);
#line 4585
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 4597
  drbd_rs_cancel_all(mdev);
#line 4598
  mdev->rs_total = 0UL;
#line 4599
  mdev->rs_failed = 0UL;
#line 4600
  atomic_set(& mdev->rs_pending_cnt, 0);
#line 4601
  __wake_up(& mdev->misc_wait, 3U, 1, 0);
#line 4603
  del_timer_sync(& mdev->resync_timer);
#line 4604
  resync_timer_fn((unsigned long )mdev);
#line 4609
  drbd_flush_workqueue(mdev);
#line 4611
  drbd_finish_peer_reqs(mdev);
#line 4616
  drbd_flush_workqueue(mdev);
#line 4620
  drbd_rs_cancel_all(mdev);
#line 4622
  kfree((void const   *)mdev->p_uuid);
#line 4623
  mdev->p_uuid = 0;
#line 4625
  tmp = drbd_suspended(mdev);
#line 4625
  if (tmp == 0) {
#line 4626
    tl_clear(mdev->tconn);
  } else {

  }
#line 4628
  drbd_md_sync(mdev);
#line 4632
  tmp___0 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 4632
  if (tmp___0 == 0) {
#line 4632
    goto ldv_54007;
  } else {

  }
#line 4632
  tmp___1 = get_current();
#line 4632
  __wait.flags = 0U;
#line 4632
  __wait.private = (void *)tmp___1;
#line 4632
  __wait.func = & autoremove_wake_function;
#line 4632
  __wait.task_list.next = & __wait.task_list;
#line 4632
  __wait.task_list.prev = & __wait.task_list;
  ldv_54010: 
#line 4632
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 4632
  tmp___2 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 4632
  if (tmp___2 == 0) {
#line 4632
    goto ldv_54009;
  } else {

  }
#line 4632
  schedule();
#line 4632
  goto ldv_54010;
  ldv_54009: 
#line 4632
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_54007: 
#line 4641
  tmp___3 = drbd_free_peer_reqs(mdev, & mdev->net_ee);
#line 4641
  i = (unsigned int )tmp___3;
#line 4642
  if (i != 0U) {
#line 4643
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "net_ee not empty, killed %u entries\n",
              i);
  } else {

  }
#line 4644
  tmp___4 = atomic_read((atomic_t const   *)(& mdev->pp_in_use_by_net));
#line 4644
  i = (unsigned int )tmp___4;
#line 4645
  if (i != 0U) {
#line 4646
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "pp_in_use_by_net = %d, expected 0\n",
              i);
  } else {

  }
#line 4647
  tmp___5 = atomic_read((atomic_t const   *)(& mdev->pp_in_use));
#line 4647
  i = (unsigned int )tmp___5;
#line 4648
  if (i != 0U) {
#line 4649
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "pp_in_use = %d, expected 0\n",
              i);
  } else {

  }
#line 4651
  tmp___6 = list_empty((struct list_head  const  *)(& mdev->read_ee));
#line 4651
  if (tmp___6 == 0) {
#line 4651
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->read_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            4651);
  } else {

  }
#line 4652
  tmp___7 = list_empty((struct list_head  const  *)(& mdev->active_ee));
#line 4652
  if (tmp___7 == 0) {
#line 4652
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->active_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            4652);
  } else {

  }
#line 4653
  tmp___8 = list_empty((struct list_head  const  *)(& mdev->sync_ee));
#line 4653
  if (tmp___8 == 0) {
#line 4653
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->sync_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            4653);
  } else {

  }
#line 4654
  tmp___9 = list_empty((struct list_head  const  *)(& mdev->done_ee));
#line 4654
  if (tmp___9 == 0) {
#line 4654
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->done_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            4654);
  } else {

  }
#line 4656
  return (0);
}
}
#line 4668 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_send_features(struct drbd_tconn *tconn ) 
{ 
  struct drbd_socket *sock ;
  struct p_connection_features *p ;
  void *tmp ;
  int tmp___0 ;

  {
#line 4673
  sock = & tconn->data;
#line 4674
  tmp = conn_prepare_command(tconn, sock);
#line 4674
  p = (struct p_connection_features *)tmp;
#line 4675
  if ((unsigned long )p == (unsigned long )((struct p_connection_features *)0)) {
#line 4676
    return (-5);
  } else {

  }
#line 4677
  memset((void *)p, 0, 72UL);
#line 4678
  p->protocol_min = 1442840576U;
#line 4679
  p->protocol_max = 1694498816U;
#line 4680
  tmp___0 = conn_send_command(tconn, sock, P_CONNECTION_FEATURES, 72U, 0, 0U);
#line 4680
  return (tmp___0);
}
}
#line 4690 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_do_features(struct drbd_tconn *tconn ) 
{ 
  struct p_connection_features *p ;
  int expect ;
  struct packet_info pi ;
  int err ;
  char const   *tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  int __min1 ;
  int __min2 ;

  {
#line 4694
  expect = 72;
#line 4698
  err = drbd_send_features(tconn);
#line 4699
  if (err != 0) {
#line 4700
    return (0);
  } else {

  }
#line 4702
  err = drbd_recv_header(tconn, & pi);
#line 4703
  if (err != 0) {
#line 4704
    return (0);
  } else {

  }
#line 4706
  if ((unsigned int )pi.cmd != 65534U) {
#line 4707
    tmp = cmdname(pi.cmd);
#line 4707
    printk("\vd-con %s: expected ConnectionFeatures packet, received: %s (0x%04x)\n",
           tconn->name, tmp, (unsigned int )pi.cmd);
#line 4709
    return (-1);
  } else {

  }
#line 4712
  if (pi.size != (unsigned int )expect) {
#line 4713
    printk("\vd-con %s: expected ConnectionFeatures length: %u, received: %u\n", tconn->name,
           expect, pi.size);
#line 4715
    return (-1);
  } else {

  }
#line 4718
  p = (struct p_connection_features *)pi.data;
#line 4719
  err = drbd_recv_all_warn(tconn, (void *)p, (size_t )expect);
#line 4720
  if (err != 0) {
#line 4721
    return (0);
  } else {

  }
#line 4723
  tmp___0 = __fswab32(p->protocol_min);
#line 4723
  p->protocol_min = tmp___0;
#line 4724
  tmp___1 = __fswab32(p->protocol_max);
#line 4724
  p->protocol_max = tmp___1;
#line 4725
  if (p->protocol_max == 0U) {
#line 4726
    p->protocol_max = p->protocol_min;
  } else {

  }
#line 4728
  if (p->protocol_min > 101U || p->protocol_max <= 85U) {
#line 4730
    goto incompat;
  } else {

  }
#line 4732
  __min1 = 101;
#line 4732
  __min2 = (int )p->protocol_max;
#line 4732
  tconn->agreed_pro_version = __min1 < __min2 ? __min1 : __min2;
#line 4734
  printk("\016d-con %s: Handshake successful: Agreed network protocol version %d\n",
         tconn->name, tconn->agreed_pro_version);
#line 4737
  return (1);
  incompat: 
#line 4740
  printk("\vd-con %s: incompatible DRBD dialects: I support %d-%d, peer supports %d-%d\n",
         tconn->name, 86, 101, p->protocol_min, p->protocol_max);
#line 4744
  return (-1);
}
}
#line 4763 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int drbd_do_auth(struct drbd_tconn *tconn ) 
{ 
  struct drbd_socket *sock ;
  char my_challenge[64U] ;
  struct scatterlist sg ;
  char *response ;
  char *right_response ;
  char *peers_ch ;
  unsigned int key_len ;
  char secret[64U] ;
  unsigned int resp_size ;
  struct hash_desc desc ;
  struct packet_info pi ;
  struct net_conf *nc ;
  int err ;
  int rv ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  size_t tmp___1 ;
  size_t __len ;
  void *__ret ;
  void *tmp___2 ;
  int tmp___3 ;
  char const   *tmp___4 ;
  void *tmp___5 ;
  void *tmp___6 ;
  void *tmp___7 ;
  int tmp___8 ;
  char const   *tmp___9 ;
  void *tmp___10 ;
  int tmp___11 ;

  {
#line 4768
  response = 0;
#line 4769
  right_response = 0;
#line 4770
  peers_ch = 0;
#line 4781
  rcu_read_lock___2();
#line 4782
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 4782
  tmp = debug_lockdep_rcu_enabled();
#line 4782
  if (tmp != 0 && ! __warned) {
#line 4782
    tmp___0 = rcu_read_lock_held();
#line 4782
    if (tmp___0 == 0 && 1) {
#line 4782
      __warned = 1;
#line 4782
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             4782, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 4782
  nc = _________p1;
#line 4783
  tmp___1 = strlen((char const   *)(& nc->shared_secret));
#line 4783
  key_len = (unsigned int )tmp___1;
#line 4784
  __len = (size_t )key_len;
#line 4784
  __ret = __builtin_memcpy((void *)(& secret), (void const   *)(& nc->shared_secret),
                           __len);
#line 4785
  rcu_read_unlock___2();
#line 4787
  desc.tfm = tconn->cram_hmac_tfm;
#line 4788
  desc.flags = 0U;
#line 4790
  rv = crypto_hash_setkey(tconn->cram_hmac_tfm, (u8 const   *)(& secret), key_len);
#line 4791
  if (rv != 0) {
#line 4792
    printk("\vd-con %s: crypto_hash_setkey() failed with %d\n", tconn->name, rv);
#line 4793
    rv = -1;
#line 4794
    goto fail;
  } else {

  }
#line 4797
  get_random_bytes((void *)(& my_challenge), 64);
#line 4799
  sock = & tconn->data;
#line 4800
  tmp___2 = conn_prepare_command(tconn, sock);
#line 4800
  if ((unsigned long )tmp___2 == (unsigned long )((void *)0)) {
#line 4801
    rv = 0;
#line 4802
    goto fail;
  } else {

  }
#line 4804
  tmp___3 = conn_send_command(tconn, sock, P_AUTH_CHALLENGE, 0U, (void *)(& my_challenge),
                              64U);
#line 4804
  rv = tmp___3 == 0;
#line 4806
  if (rv == 0) {
#line 4807
    goto fail;
  } else {

  }
#line 4809
  err = drbd_recv_header(tconn, & pi);
#line 4810
  if (err != 0) {
#line 4811
    rv = 0;
#line 4812
    goto fail;
  } else {

  }
#line 4815
  if ((unsigned int )pi.cmd != 16U) {
#line 4816
    tmp___4 = cmdname(pi.cmd);
#line 4816
    printk("\vd-con %s: expected AuthChallenge packet, received: %s (0x%04x)\n", tconn->name,
           tmp___4, (unsigned int )pi.cmd);
#line 4818
    rv = 0;
#line 4819
    goto fail;
  } else {

  }
#line 4822
  if (pi.size > 128U) {
#line 4823
    printk("\vd-con %s: expected AuthChallenge payload too big.\n", tconn->name);
#line 4824
    rv = -1;
#line 4825
    goto fail;
  } else {

  }
#line 4828
  tmp___5 = kmalloc((size_t )pi.size, 16U);
#line 4828
  peers_ch = (char *)tmp___5;
#line 4829
  if ((unsigned long )peers_ch == (unsigned long )((char *)0)) {
#line 4830
    printk("\vd-con %s: kmalloc of peers_ch failed\n", tconn->name);
#line 4831
    rv = -1;
#line 4832
    goto fail;
  } else {

  }
#line 4835
  err = drbd_recv_all_warn(tconn, (void *)peers_ch, (size_t )pi.size);
#line 4836
  if (err != 0) {
#line 4837
    rv = 0;
#line 4838
    goto fail;
  } else {

  }
#line 4841
  resp_size = crypto_hash_digestsize(tconn->cram_hmac_tfm);
#line 4842
  tmp___6 = kmalloc((size_t )resp_size, 16U);
#line 4842
  response = (char *)tmp___6;
#line 4843
  if ((unsigned long )response == (unsigned long )((char *)0)) {
#line 4844
    printk("\vd-con %s: kmalloc of response failed\n", tconn->name);
#line 4845
    rv = -1;
#line 4846
    goto fail;
  } else {

  }
#line 4849
  sg_init_table(& sg, 1U);
#line 4850
  sg_set_buf(& sg, (void const   *)peers_ch, pi.size);
#line 4852
  rv = crypto_hash_digest(& desc, & sg, sg.length, (u8 *)response);
#line 4853
  if (rv != 0) {
#line 4854
    printk("\vd-con %s: crypto_hash_digest() failed with %d\n", tconn->name, rv);
#line 4855
    rv = -1;
#line 4856
    goto fail;
  } else {

  }
#line 4859
  tmp___7 = conn_prepare_command(tconn, sock);
#line 4859
  if ((unsigned long )tmp___7 == (unsigned long )((void *)0)) {
#line 4860
    rv = 0;
#line 4861
    goto fail;
  } else {

  }
#line 4863
  tmp___8 = conn_send_command(tconn, sock, P_AUTH_RESPONSE, 0U, (void *)response,
                              resp_size);
#line 4863
  rv = tmp___8 == 0;
#line 4865
  if (rv == 0) {
#line 4866
    goto fail;
  } else {

  }
#line 4868
  err = drbd_recv_header(tconn, & pi);
#line 4869
  if (err != 0) {
#line 4870
    rv = 0;
#line 4871
    goto fail;
  } else {

  }
#line 4874
  if ((unsigned int )pi.cmd != 17U) {
#line 4875
    tmp___9 = cmdname(pi.cmd);
#line 4875
    printk("\vd-con %s: expected AuthResponse packet, received: %s (0x%04x)\n", tconn->name,
           tmp___9, (unsigned int )pi.cmd);
#line 4877
    rv = 0;
#line 4878
    goto fail;
  } else {

  }
#line 4881
  if (pi.size != resp_size) {
#line 4882
    printk("\vd-con %s: expected AuthResponse payload of wrong size\n", tconn->name);
#line 4883
    rv = 0;
#line 4884
    goto fail;
  } else {

  }
#line 4887
  err = drbd_recv_all_warn(tconn, (void *)response, (size_t )resp_size);
#line 4888
  if (err != 0) {
#line 4889
    rv = 0;
#line 4890
    goto fail;
  } else {

  }
#line 4893
  tmp___10 = kmalloc((size_t )resp_size, 16U);
#line 4893
  right_response = (char *)tmp___10;
#line 4894
  if ((unsigned long )right_response == (unsigned long )((char *)0)) {
#line 4895
    printk("\vd-con %s: kmalloc of right_response failed\n", tconn->name);
#line 4896
    rv = -1;
#line 4897
    goto fail;
  } else {

  }
#line 4900
  sg_set_buf(& sg, (void const   *)(& my_challenge), 64U);
#line 4902
  rv = crypto_hash_digest(& desc, & sg, sg.length, (u8 *)right_response);
#line 4903
  if (rv != 0) {
#line 4904
    printk("\vd-con %s: crypto_hash_digest() failed with %d\n", tconn->name, rv);
#line 4905
    rv = -1;
#line 4906
    goto fail;
  } else {

  }
#line 4909
  tmp___11 = memcmp((void const   *)response, (void const   *)right_response, (size_t )resp_size);
#line 4909
  rv = tmp___11 == 0;
#line 4911
  if (rv != 0) {
#line 4912
    printk("\016d-con %s: Peer authenticated using %d bytes HMAC\n", tconn->name,
           resp_size);
  } else {
#line 4915
    rv = -1;
  }
  fail: 
#line 4918
  kfree((void const   *)peers_ch);
#line 4919
  kfree((void const   *)response);
#line 4920
  kfree((void const   *)right_response);
#line 4922
  return (rv);
}
}
#line 4926 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
int drbdd_init(struct drbd_thread *thi ) 
{ 
  struct drbd_tconn *tconn ;
  int h ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 4928
  tconn = thi->tconn;
#line 4931
  printk("\016d-con %s: receiver (re)started\n", tconn->name);
  ldv_54060: 
#line 4934
  h = conn_connect(tconn);
#line 4935
  if (h == 0) {
#line 4936
    conn_disconnect(tconn);
#line 4937
    schedule_timeout_interruptible(250L);
  } else {

  }
#line 4939
  if (h == -1) {
#line 4940
    printk("\fd-con %s: Discarding network configuration.\n", tconn->name);
#line 4941
    val.i = 0U;
#line 4941
    val.ldv_40024.conn = 1U;
#line 4941
    mask.i = 0U;
#line 4941
    mask.ldv_40024.conn = 31U;
#line 4941
    conn_request_state(tconn, mask, val, CS_HARD);
  } else {

  }
#line 4943
  if (h == 0) {
#line 4944
    goto ldv_54060;
  } else {

  }

#line 4945
  if (h > 0) {
#line 4946
    drbdd(tconn);
  } else {

  }
#line 4948
  conn_disconnect(tconn);
#line 4950
  printk("\016d-con %s: receiver terminated\n", tconn->name);
#line 4951
  return (0);
}
}
#line 4956 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_conn_RqSReply(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct p_req_state_reply *p ;
  int retcode ;
  __u32 tmp ;
  char const   *tmp___0 ;

  {
#line 4958
  p = (struct p_req_state_reply *)pi->data;
#line 4959
  tmp = __fswab32(p->retcode);
#line 4959
  retcode = (int )tmp;
#line 4961
  if (retcode > 0) {
#line 4962
    set_bit(6U, (unsigned long volatile   *)(& tconn->flags));
  } else {
#line 4964
    set_bit(7U, (unsigned long volatile   *)(& tconn->flags));
#line 4965
    tmp___0 = drbd_set_st_err_str((enum drbd_state_rv )retcode);
#line 4965
    printk("\vd-con %s: Requested state change failed by peer: %s (%d)\n", tconn->name,
           tmp___0, retcode);
  }
#line 4968
  __wake_up(& tconn->ping_wait, 3U, 1, 0);
#line 4970
  return (0);
}
}
#line 4973 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_RqSReply(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_req_state_reply *p ;
  int retcode ;
  __u32 tmp ;
  int tmp___0 ;
  int tmp___1 ;
  char const   *tmp___2 ;

  {
#line 4976
  p = (struct p_req_state_reply *)pi->data;
#line 4977
  tmp = __fswab32(p->retcode);
#line 4977
  retcode = (int )tmp;
#line 4979
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 4980
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 4981
    return (-5);
  } else {

  }
#line 4983
  tmp___1 = constant_test_bit(5U, (unsigned long const volatile   *)(& tconn->flags));
#line 4983
  if (tmp___1 != 0) {
#line 4984
    if (tconn->agreed_pro_version > 99) {
#line 4984
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( tconn->agreed_pro_version < 100 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
              4984);
    } else {

    }
#line 4985
    tmp___0 = got_conn_RqSReply(tconn, pi);
#line 4985
    return (tmp___0);
  } else {

  }
#line 4988
  if (retcode > 0) {
#line 4989
    set_bit(3U, (unsigned long volatile   *)(& mdev->flags));
  } else {
#line 4991
    set_bit(4U, (unsigned long volatile   *)(& mdev->flags));
#line 4992
    tmp___2 = drbd_set_st_err_str((enum drbd_state_rv )retcode);
#line 4992
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Requested state change failed by peer: %s (%d)\n",
            tmp___2, retcode);
  }
#line 4995
  __wake_up(& mdev->state_wait, 3U, 1, 0);
#line 4997
  return (0);
}
}
#line 5000 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_Ping(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  int tmp ;

  {
#line 5002
  tmp = drbd_send_ping_ack(tconn);
#line 5002
  return (tmp);
}
}
#line 5006 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_PingAck(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  int tmp ;

  {
#line 5009
  ((tconn->meta.socket)->sk)->sk_rcvtimeo = (long )((tconn->net_conf)->ping_int * 250U);
#line 5010
  tmp = test_and_set_bit(4, (unsigned long volatile   *)(& tconn->flags));
#line 5010
  if (tmp == 0) {
#line 5011
    __wake_up(& tconn->ping_wait, 3U, 1, 0);
  } else {

  }
#line 5013
  return (0);
}
}
#line 5016 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_IsInSync(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_block_ack *p ;
  sector_t sector ;
  __u64 tmp ;
  int blksize ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 5019
  p = (struct p_block_ack *)pi->data;
#line 5020
  tmp = __fswab64(p->sector);
#line 5020
  sector = (sector_t )tmp;
#line 5021
  tmp___0 = __fswab32(p->blksize);
#line 5021
  blksize = (int )tmp___0;
#line 5023
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 5024
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 5025
    return (-5);
  } else {

  }
#line 5027
  if ((mdev->tconn)->agreed_pro_version <= 88) {
#line 5027
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->tconn->agreed_pro_version >= 89 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
            5027);
  } else {

  }
#line 5029
  tmp___1 = __fswab32(p->seq_num);
#line 5029
  update_peer_seq(mdev, tmp___1);
#line 5031
  tmp___2 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 5031
  if (tmp___2 != 0) {
#line 5032
    drbd_rs_complete_io(mdev, sector);
#line 5033
    __drbd_set_in_sync(mdev, sector, blksize, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                       5033U);
#line 5035
    mdev->rs_same_csum = mdev->rs_same_csum + (unsigned long )(blksize >> 12);
#line 5036
    put_ldev(mdev);
  } else {

  }
#line 5038
  _dec_rs_pending(mdev, "got_IsInSync", 5038);
#line 5039
  atomic_add(blksize >> 9, & mdev->rs_sect_in);
#line 5041
  return (0);
}
}
#line 5045 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int validate_req_change_req_state(struct drbd_conf *mdev , u64 id , sector_t sector ,
                                         struct rb_root *root , char const   *func ,
                                         enum drbd_req_event what , bool missing_ok ) 
{ 
  struct drbd_request *req ;
  struct bio_and_error m ;
  long tmp ;

  {
#line 5052
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 5053
  req = find_request(mdev, root, id, sector, (int )missing_ok, func);
#line 5054
  tmp = __builtin_expect((unsigned long )req == (unsigned long )((struct drbd_request *)0),
                         0L);
#line 5054
  if (tmp != 0L) {
#line 5055
    spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 5056
    return (-5);
  } else {

  }
#line 5058
  __req_mod(req, what, & m);
#line 5059
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 5061
  if ((unsigned long )m.bio != (unsigned long )((struct bio *)0)) {
#line 5062
    complete_master_bio(mdev, & m);
  } else {

  }
#line 5063
  return (0);
}
}
#line 5066 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_BlockAck(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_block_ack *p ;
  sector_t sector ;
  __u64 tmp ;
  int blksize ;
  __u32 tmp___0 ;
  enum drbd_req_event what ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 5069
  p = (struct p_block_ack *)pi->data;
#line 5070
  tmp = __fswab64(p->sector);
#line 5070
  sector = (sector_t )tmp;
#line 5071
  tmp___0 = __fswab32(p->blksize);
#line 5071
  blksize = (int )tmp___0;
#line 5074
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 5075
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 5076
    return (-5);
  } else {

  }
#line 5078
  tmp___1 = __fswab32(p->seq_num);
#line 5078
  update_peer_seq(mdev, tmp___1);
#line 5080
  if (p->block_id == 0xffffffffffffffffULL) {
#line 5081
    __drbd_set_in_sync(mdev, sector, blksize, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                       5081U);
#line 5082
    _dec_rs_pending(mdev, "got_BlockAck", 5082);
#line 5083
    return (0);
  } else {

  }
#line 5085
  switch ((unsigned int )pi->cmd) {
  case 23U: 
#line 5087
  what = WRITE_ACKED_BY_PEER_AND_SIS;
#line 5088
  goto ldv_54114;
  case 22U: 
#line 5090
  what = WRITE_ACKED_BY_PEER;
#line 5091
  goto ldv_54114;
  case 21U: 
#line 5093
  what = RECV_ACKED_BY_PEER;
#line 5094
  goto ldv_54114;
  case 24U: 
#line 5096
  what = CONFLICT_RESOLVED;
#line 5097
  goto ldv_54114;
  case 44U: 
#line 5099
  what = POSTPONE_WRITE;
#line 5100
  goto ldv_54114;
  default: 
#line 5102
  __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"),
                       "i" (5102), "i" (12UL));
  ldv_54120: ;
#line 5102
  goto ldv_54120;
  }
  ldv_54114: 
#line 5105
  tmp___2 = validate_req_change_req_state(mdev, p->block_id, sector, & mdev->write_requests,
                                          "got_BlockAck", what, 0);
#line 5105
  return (tmp___2);
}
}
#line 5110 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_NegAck(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_block_ack *p ;
  sector_t sector ;
  __u64 tmp ;
  int size ;
  __u32 tmp___0 ;
  int err ;
  __u32 tmp___1 ;

  {
#line 5113
  p = (struct p_block_ack *)pi->data;
#line 5114
  tmp = __fswab64(p->sector);
#line 5114
  sector = (sector_t )tmp;
#line 5115
  tmp___0 = __fswab32(p->blksize);
#line 5115
  size = (int )tmp___0;
#line 5118
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 5119
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 5120
    return (-5);
  } else {

  }
#line 5122
  tmp___1 = __fswab32(p->seq_num);
#line 5122
  update_peer_seq(mdev, tmp___1);
#line 5124
  if (p->block_id == 0xffffffffffffffffULL) {
#line 5125
    _dec_rs_pending(mdev, "got_NegAck", 5125);
#line 5126
    drbd_rs_failed_io(mdev, sector, size);
#line 5127
    return (0);
  } else {

  }
#line 5130
  err = validate_req_change_req_state(mdev, p->block_id, sector, & mdev->write_requests,
                                      "got_NegAck", NEG_ACKED, 1);
#line 5133
  if (err != 0) {
#line 5139
    __drbd_set_out_of_sync(mdev, sector, size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                           5139U);
  } else {

  }
#line 5141
  return (0);
}
}
#line 5144 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_NegDReply(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_block_ack *p ;
  sector_t sector ;
  __u64 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 5147
  p = (struct p_block_ack *)pi->data;
#line 5148
  tmp = __fswab64(p->sector);
#line 5148
  sector = (sector_t )tmp;
#line 5150
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 5151
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 5152
    return (-5);
  } else {

  }
#line 5154
  tmp___0 = __fswab32(p->seq_num);
#line 5154
  update_peer_seq(mdev, tmp___0);
#line 5156
  tmp___1 = __fswab32(p->blksize);
#line 5156
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Got NegDReply; Sector %llus, len %u.\n",
          (unsigned long long )sector, tmp___1);
#line 5159
  tmp___2 = validate_req_change_req_state(mdev, p->block_id, sector, & mdev->read_requests,
                                          "got_NegDReply", NEG_ACKED, 0);
#line 5159
  return (tmp___2);
}
}
#line 5164 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_NegRSDReply(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  sector_t sector ;
  int size ;
  struct p_block_ack *p ;
  __u64 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 5169
  p = (struct p_block_ack *)pi->data;
#line 5171
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 5172
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 5173
    return (-5);
  } else {

  }
#line 5175
  tmp = __fswab64(p->sector);
#line 5175
  sector = (sector_t )tmp;
#line 5176
  tmp___0 = __fswab32(p->blksize);
#line 5176
  size = (int )tmp___0;
#line 5178
  tmp___1 = __fswab32(p->seq_num);
#line 5178
  update_peer_seq(mdev, tmp___1);
#line 5180
  _dec_rs_pending(mdev, "got_NegRSDReply", 5180);
#line 5182
  tmp___2 = _get_ldev_if_state(mdev, D_FAILED);
#line 5182
  if (tmp___2 != 0) {
#line 5183
    drbd_rs_complete_io(mdev, sector);
#line 5184
    switch ((unsigned int )pi->cmd) {
    case 27U: 
#line 5186
    drbd_rs_failed_io(mdev, sector, size);
    case 41U: ;
#line 5188
    goto ldv_54150;
    default: 
#line 5190
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"),
                         "i" (5190), "i" (12UL));
    ldv_54152: ;
#line 5190
    goto ldv_54152;
    }
    ldv_54150: 
#line 5192
    put_ldev(mdev);
  } else {

  }
#line 5195
  return (0);
}
}
#line 5198 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_BarrierAck(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct p_barrier_ack *p ;
  struct drbd_conf *mdev ;
  int vnr ;
  __u32 tmp ;
  void *tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  void *tmp___3 ;

  {
#line 5200
  p = (struct p_barrier_ack *)pi->data;
#line 5204
  tmp = __fswab32(p->set_size);
#line 5204
  tl_release(tconn, p->barrier, tmp);
#line 5206
  rcu_read_lock___2();
#line 5207
  vnr = 0;
#line 5207
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 5207
  mdev = (struct drbd_conf *)tmp___0;
#line 5207
  goto ldv_54161;
  ldv_54160: ;
#line 5208
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 352U) {
#line 5208
    tmp___1 = atomic_read((atomic_t const   *)(& mdev->ap_in_flight));
#line 5208
    if (tmp___1 == 0) {
#line 5208
      tmp___2 = test_and_set_bit(19, (unsigned long volatile   *)(& mdev->flags));
#line 5208
      if (tmp___2 == 0) {
#line 5211
        mdev->start_resync_timer.expires = (unsigned long )jiffies + 250UL;
#line 5212
        add_timer(& mdev->start_resync_timer);
      } else {

      }
    } else {

    }
  } else {

  }
#line 5207
  vnr = vnr + 1;
#line 5207
  tmp___3 = idr_get_next(& tconn->volumes, & vnr);
#line 5207
  mdev = (struct drbd_conf *)tmp___3;
  ldv_54161: ;
#line 5207
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 5208
    goto ldv_54160;
  } else {

  }
#line 5215
  rcu_read_unlock___2();
#line 5217
  return (0);
}
}
#line 5220 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_OVResult(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 
  struct drbd_conf *mdev ;
  struct p_block_ack *p ;
  struct drbd_work *w ;
  sector_t sector ;
  int size ;
  __u64 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u64 tmp___2 ;
  int tmp___3 ;
  void *tmp___4 ;

  {
#line 5223
  p = (struct p_block_ack *)pi->data;
#line 5228
  mdev = vnr_to_mdev(tconn, (int )pi->vnr);
#line 5229
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 5230
    return (-5);
  } else {

  }
#line 5232
  tmp = __fswab64(p->sector);
#line 5232
  sector = (sector_t )tmp;
#line 5233
  tmp___0 = __fswab32(p->blksize);
#line 5233
  size = (int )tmp___0;
#line 5235
  tmp___1 = __fswab32(p->seq_num);
#line 5235
  update_peer_seq(mdev, tmp___1);
#line 5237
  tmp___2 = __fswab64(p->block_id);
#line 5237
  if (tmp___2 == 4712ULL) {
#line 5238
    drbd_ov_out_of_sync_found(mdev, sector, size);
  } else {
#line 5240
    ov_out_of_sync_print(mdev);
  }
#line 5242
  tmp___3 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 5242
  if (tmp___3 == 0) {
#line 5243
    return (0);
  } else {

  }
#line 5245
  drbd_rs_complete_io(mdev, sector);
#line 5246
  _dec_rs_pending(mdev, "got_OVResult", 5246);
#line 5248
  mdev->ov_left = mdev->ov_left - 1UL;
#line 5251
  if ((mdev->ov_left & 512UL) != 0UL) {
#line 5252
    drbd_advance_rs_marks(mdev, mdev->ov_left);
  } else {

  }
#line 5254
  if (mdev->ov_left == 0UL) {
#line 5255
    tmp___4 = kmalloc(32UL, 16U);
#line 5255
    w = (struct drbd_work *)tmp___4;
#line 5256
    if ((unsigned long )w != (unsigned long )((struct drbd_work *)0)) {
#line 5257
      w->cb = & w_ov_finished;
#line 5258
      w->ldv_49807.mdev = mdev;
#line 5259
      drbd_queue_work(& (mdev->tconn)->sender_work, w);
    } else {
#line 5261
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "kmalloc(w) failed.");
#line 5262
      ov_out_of_sync_print(mdev);
#line 5263
      drbd_resync_finished(mdev);
    }
  } else {

  }
#line 5266
  put_ldev(mdev);
#line 5267
  return (0);
}
}
#line 5270 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int got_skip(struct drbd_tconn *tconn , struct packet_info *pi ) 
{ 


  {
#line 5272
  return (0);
}
}
#line 5275 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static int tconn_finish_peer_reqs(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  int vnr ;
  int not_empty ;
  struct task_struct *tmp ;
  void *tmp___0 ;
  int tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  int tmp___4 ;
  void *tmp___5 ;

  {
#line 5278
  not_empty = 0;
  ldv_54189: 
#line 5281
  clear_bit(3, (unsigned long volatile   *)(& tconn->flags));
#line 5282
  tmp = get_current();
#line 5282
  flush_signals(tmp);
#line 5284
  rcu_read_lock___2();
#line 5285
  vnr = 0;
#line 5285
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 5285
  mdev = (struct drbd_conf *)tmp___0;
#line 5285
  goto ldv_54184;
  ldv_54183: 
#line 5286
  kref_get(& mdev->kref);
#line 5287
  rcu_read_unlock___2();
#line 5288
  tmp___1 = drbd_finish_peer_reqs(mdev);
#line 5288
  if (tmp___1 != 0) {
#line 5289
    kref_put(& mdev->kref, & drbd_minor_destroy);
#line 5290
    return (1);
  } else {

  }
#line 5292
  kref_put(& mdev->kref, & drbd_minor_destroy);
#line 5293
  rcu_read_lock___2();
#line 5285
  vnr = vnr + 1;
#line 5285
  tmp___2 = idr_get_next(& tconn->volumes, & vnr);
#line 5285
  mdev = (struct drbd_conf *)tmp___2;
  ldv_54184: ;
#line 5285
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 5286
    goto ldv_54183;
  } else {

  }
#line 5295
  set_bit(3U, (unsigned long volatile   *)(& tconn->flags));
#line 5297
  spin_lock_irq(& tconn->req_lock);
#line 5298
  vnr = 0;
#line 5298
  tmp___3 = idr_get_next(& tconn->volumes, & vnr);
#line 5298
  mdev = (struct drbd_conf *)tmp___3;
#line 5298
  goto ldv_54188;
  ldv_54187: 
#line 5299
  tmp___4 = list_empty((struct list_head  const  *)(& mdev->done_ee));
#line 5299
  not_empty = tmp___4 == 0;
#line 5300
  if (not_empty != 0) {
#line 5301
    goto ldv_54186;
  } else {

  }
#line 5298
  vnr = vnr + 1;
#line 5298
  tmp___5 = idr_get_next(& tconn->volumes, & vnr);
#line 5298
  mdev = (struct drbd_conf *)tmp___5;
  ldv_54188: ;
#line 5298
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 5299
    goto ldv_54187;
  } else {

  }
  ldv_54186: 
#line 5303
  spin_unlock_irq(& tconn->req_lock);
#line 5304
  rcu_read_unlock___2();
#line 5305
  if (not_empty != 0) {
#line 5306
    goto ldv_54189;
  } else {

  }

#line 5307
  return (0);
}
}
#line 5315 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
static struct asender_cmd asender_tbl[45U]  = 
#line 5315
  {      {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, & got_Ping}, 
        {0UL, & got_PingAck}, 
        {24UL, & got_BlockAck}, 
        {24UL, & got_BlockAck}, 
        {24UL, & got_BlockAck}, 
        {24UL, & got_BlockAck}, 
        {24UL, & got_NegAck}, 
        {24UL, & got_NegDReply}, 
        {24UL, & got_NegRSDReply}, 
        {8UL, & got_BarrierAck}, 
        {4UL, & got_RqSReply}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {24UL, & got_OVResult}, 
        {0UL, 0}, 
        {24UL, & got_IsInSync}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {0UL, 0}, 
        {8UL, & got_skip}, 
        {0UL, 0}, 
        {24UL, & got_NegRSDReply}, 
        {0UL, 0}, 
        {4UL, & got_conn_RqSReply}, 
        {24UL, & got_BlockAck}};
#line 5335 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
int drbd_asender(struct drbd_thread *thi ) 
{ 
  struct drbd_tconn *tconn ;
  struct asender_cmd *cmd ;
  struct packet_info pi ;
  int rv ;
  void *buf ;
  int received ;
  unsigned int header_size ;
  unsigned int tmp ;
  int expect ;
  bool ping_timeout_active ;
  struct net_conf *nc ;
  int ping_timeo ;
  int tcp_cork ;
  int ping_int ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  struct task_struct *tmp___7 ;
  int tmp___8 ;
  struct task_struct *tmp___9 ;
  long t ;
  struct net_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___10 ;
  int tmp___11 ;
  long __ret ;
  wait_queue_t __wait ;
  struct task_struct *tmp___12 ;
  int tmp___13 ;
  long tmp___14 ;
  int tmp___15 ;
  char const   *tmp___16 ;
  bool err ;
  int tmp___17 ;
  enum drbd_thread_state tmp___18 ;
  union drbd_state val ;
  union drbd_state mask ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;

  {
#line 5337
  tconn = thi->tconn;
#line 5338
  cmd = 0;
#line 5341
  buf = tconn->meta.rbuf;
#line 5342
  received = 0;
#line 5343
  tmp = drbd_header_size(tconn);
#line 5343
  header_size = tmp;
#line 5344
  expect = (int )header_size;
#line 5345
  ping_timeout_active = 0;
#line 5349
  tmp___0 = get_current();
#line 5349
  tmp___0->policy = 2U;
#line 5350
  tmp___1 = get_current();
#line 5350
  tmp___1->rt_priority = 2U;
#line 5352
  goto ldv_54217;
  ldv_54238: 
#line 5353
  drbd_thread_current_set_cpu(thi);
#line 5355
  rcu_read_lock___2();
#line 5356
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 5356
  tmp___2 = debug_lockdep_rcu_enabled();
#line 5356
  if (tmp___2 != 0 && ! __warned) {
#line 5356
    tmp___3 = rcu_read_lock_held();
#line 5356
    if (tmp___3 == 0 && 1) {
#line 5356
      __warned = 1;
#line 5356
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                             5356, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 5356
  nc = _________p1;
#line 5357
  ping_timeo = (int )nc->ping_timeo;
#line 5358
  tcp_cork = (int )nc->tcp_cork;
#line 5359
  ping_int = (int )nc->ping_int;
#line 5360
  rcu_read_unlock___2();
#line 5362
  tmp___5 = test_and_clear_bit(2, (unsigned long volatile   *)(& tconn->flags));
#line 5362
  if (tmp___5 != 0) {
#line 5363
    tmp___4 = drbd_send_ping(tconn);
#line 5363
    if (tmp___4 != 0) {
#line 5364
      printk("\vd-con %s: drbd_send_ping has failed\n", tconn->name);
#line 5365
      goto reconnect;
    } else {

    }
#line 5367
    ((tconn->meta.socket)->sk)->sk_rcvtimeo = (long )((ping_timeo * 250) / 10);
#line 5368
    ping_timeout_active = 1;
  } else {

  }
#line 5373
  if (tcp_cork != 0) {
#line 5374
    drbd_tcp_cork___0(tconn->meta.socket);
  } else {

  }
#line 5375
  tmp___6 = tconn_finish_peer_reqs(tconn);
#line 5375
  if (tmp___6 != 0) {
#line 5376
    printk("\vd-con %s: tconn_finish_peer_reqs() failed\n", tconn->name);
#line 5377
    goto reconnect;
  } else {

  }
#line 5380
  if (tcp_cork != 0) {
#line 5381
    drbd_tcp_uncork___0(tconn->meta.socket);
  } else {

  }
#line 5384
  tmp___7 = get_current();
#line 5384
  tmp___8 = signal_pending(tmp___7);
#line 5384
  if (tmp___8 != 0) {
#line 5385
    goto ldv_54217;
  } else {

  }
#line 5387
  rv = drbd_recv_short(tconn->meta.socket, buf, (size_t )(expect - received), 0);
#line 5388
  clear_bit(3, (unsigned long volatile   *)(& tconn->flags));
#line 5390
  tmp___9 = get_current();
#line 5390
  flush_signals(tmp___9);
#line 5402
  tmp___14 = __builtin_expect(rv > 0, 1L);
#line 5402
  if (tmp___14 != 0L) {
#line 5403
    received = received + rv;
#line 5404
    buf = buf + (unsigned long )rv;
  } else
#line 5405
  if (rv == 0) {
#line 5406
    tmp___13 = constant_test_bit(12U, (unsigned long const volatile   *)(& tconn->flags));
#line 5406
    if (tmp___13 != 0) {
#line 5408
      rcu_read_lock___2();
#line 5409
      _________p1___0 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 5409
      tmp___10 = debug_lockdep_rcu_enabled();
#line 5409
      if (tmp___10 != 0 && ! __warned___0) {
#line 5409
        tmp___11 = rcu_read_lock_held();
#line 5409
        if (tmp___11 == 0 && 1) {
#line 5409
          __warned___0 = 1;
#line 5409
          lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared",
                                 5409, "suspicious rcu_dereference_check() usage");
        } else {

        }
      } else {

      }
#line 5409
      t = (long )((_________p1___0->ping_timeo * 250U) / 10U);
#line 5410
      rcu_read_unlock___2();
#line 5412
      __ret = t;
#line 5412
      if ((unsigned int )tconn->cstate > 8U) {
#line 5412
        tmp___12 = get_current();
#line 5412
        __wait.flags = 0U;
#line 5412
        __wait.private = (void *)tmp___12;
#line 5412
        __wait.func = & autoremove_wake_function;
#line 5412
        __wait.task_list.next = & __wait.task_list;
#line 5412
        __wait.task_list.prev = & __wait.task_list;
        ldv_54225: 
#line 5412
        prepare_to_wait(& tconn->ping_wait, & __wait, 2);
#line 5412
        if ((unsigned int )tconn->cstate <= 8U) {
#line 5412
          goto ldv_54224;
        } else {

        }
#line 5412
        __ret = schedule_timeout(__ret);
#line 5412
        if (__ret == 0L) {
#line 5412
          goto ldv_54224;
        } else {

        }
#line 5412
        goto ldv_54225;
        ldv_54224: 
#line 5412
        finish_wait(& tconn->ping_wait, & __wait);
      } else {

      }
#line 5412
      t = __ret;
#line 5415
      if (t != 0L) {
#line 5416
        goto ldv_54227;
      } else {

      }
    } else {

    }
#line 5418
    printk("\vd-con %s: meta connection shut down by peer.\n", tconn->name);
#line 5419
    goto reconnect;
  } else
#line 5420
  if (rv == -11) {
#line 5423
    if ((1 != 0 && 1 != 0) && (long )((unsigned long )jiffies - (unsigned long )((tconn->meta.socket)->sk)->sk_rcvtimeo) - (long )tconn->last_received < 0L) {
#line 5425
      goto ldv_54217;
    } else {

    }
#line 5426
    if ((int )ping_timeout_active) {
#line 5427
      printk("\vd-con %s: PingAck did not arrive in time.\n", tconn->name);
#line 5428
      goto reconnect;
    } else {

    }
#line 5430
    set_bit(2U, (unsigned long volatile   *)(& tconn->flags));
#line 5431
    goto ldv_54217;
  } else
#line 5432
  if (rv == -4) {
#line 5433
    goto ldv_54217;
  } else {
#line 5435
    printk("\vd-con %s: sock_recvmsg returned %d\n", tconn->name, rv);
#line 5436
    goto reconnect;
  }
#line 5439
  if (received == expect && (unsigned long )cmd == (unsigned long )((struct asender_cmd *)0)) {
#line 5440
    tmp___15 = decode_header(tconn, tconn->meta.rbuf, & pi);
#line 5440
    if (tmp___15 != 0) {
#line 5441
      goto reconnect;
    } else {

    }
#line 5442
    cmd = (struct asender_cmd *)(& asender_tbl) + (unsigned long )pi.cmd;
#line 5443
    if ((unsigned int )pi.cmd > (unsigned int )P_RETRY_WRITE || (unsigned long )cmd->fn == (unsigned long )((int (*)(struct drbd_tconn * ,
                                                                                                                     struct packet_info * ))0)) {
#line 5444
      tmp___16 = cmdname(pi.cmd);
#line 5444
      printk("\vd-con %s: Unexpected meta packet %s (0x%04x)\n", tconn->name, tmp___16,
             (unsigned int )pi.cmd);
#line 5446
      goto disconnect;
    } else {

    }
#line 5448
    expect = (int )((unsigned int )cmd->pkt_size + header_size);
#line 5449
    if (pi.size != (unsigned int )expect - header_size) {
#line 5450
      printk("\vd-con %s: Wrong packet size on meta (c: %d, l: %d)\n", tconn->name,
             (unsigned int )pi.cmd, pi.size);
#line 5452
      goto reconnect;
    } else {

    }
  } else {

  }
#line 5455
  if (received == expect) {
#line 5458
    tmp___17 = (*(cmd->fn))(tconn, & pi);
#line 5458
    err = tmp___17 != 0;
#line 5459
    if ((int )err) {
#line 5460
      printk("\vd-con %s: %pf failed\n", tconn->name, cmd->fn);
#line 5461
      goto reconnect;
    } else {

    }
#line 5464
    tconn->last_received = jiffies;
#line 5466
    if ((unsigned long )cmd == (unsigned long )((struct asender_cmd *)(& asender_tbl) + 20UL)) {
#line 5468
      ((tconn->meta.socket)->sk)->sk_rcvtimeo = (long )(ping_int * 250);
#line 5469
      ping_timeout_active = 0;
    } else {

    }
#line 5472
    buf = tconn->meta.rbuf;
#line 5473
    received = 0;
#line 5474
    expect = (int )header_size;
#line 5475
    cmd = 0;
  } else {

  }
  ldv_54217: 
#line 5352
  tmp___18 = get_t_state(thi);
#line 5352
  if ((unsigned int )tmp___18 == 1U) {
#line 5353
    goto ldv_54238;
  } else {

  }
  ldv_54227: ;
#line 5479
  if (0) {
    reconnect: 
#line 5481
    val.i = 0U;
#line 5481
    val.ldv_40024.conn = 5U;
#line 5481
    mask.i = 0U;
#line 5481
    mask.ldv_40024.conn = 31U;
#line 5481
    conn_request_state(tconn, mask, val, CS_HARD);
#line 5482
    conn_md_sync(tconn);
  } else {

  }
#line 5484
  if (0) {
    disconnect: 
#line 5486
    val___0.i = 0U;
#line 5486
    val___0.ldv_40024.conn = 1U;
#line 5486
    mask___0.i = 0U;
#line 5486
    mask___0.ldv_40024.conn = 31U;
#line 5486
    conn_request_state(tconn, mask___0, val___0, CS_HARD);
  } else {

  }
#line 5488
  clear_bit(3, (unsigned long volatile   *)(& tconn->flags));
#line 5490
  printk("\016d-con %s: asender terminated\n", tconn->name);
#line 5492
  return (0);
}
}
#line 5532 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_main3_sequence_infinite_withcheck_stateful(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
#line 5544
  LDV_IN_INTERRUPT = 1;
#line 5553
  ldv_initialize();
#line 5555
  goto ldv_54266;
  ldv_54265: 
#line 5558
  tmp = nondet_int();
#line 5558
  switch (tmp) {
  default: ;
#line 5560
  goto ldv_54264;
  }
  ldv_54264: ;
  ldv_54266: 
#line 5555
  tmp___0 = nondet_int();
#line 5555
  if (tmp___0 != 0) {
#line 5556
    goto ldv_54265;
  } else {

  }


#line 5569
  ldv_check_final_state();
#line 5572
  return;
}
}
#line 5576 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_93(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5581
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 5583
  mutex_lock(ldv_func_arg1);
#line 5584
  return;
}
}
#line 5586 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_94(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5591
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 5593
  mutex_unlock(ldv_func_arg1);
#line 5594
  return;
}
}
#line 5596 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_95(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5601
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 5603
  mutex_lock(ldv_func_arg1);
#line 5604
  return;
}
}
#line 5606 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
int ldv_mutex_trylock_96(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 5611
  tmp = mutex_trylock(ldv_func_arg1);
#line 5611
  ldv_func_res = tmp;
#line 5613
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 5613
  return (tmp___0);
#line 5615
  return (ldv_func_res);
}
}
#line 5618 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_97(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5623
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 5625
  mutex_unlock(ldv_func_arg1);
#line 5626
  return;
}
}
#line 5628 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_98(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5633
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 5635
  mutex_lock(ldv_func_arg1);
#line 5636
  return;
}
}
#line 5638 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_99(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5643
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 5645
  mutex_unlock(ldv_func_arg1);
#line 5646
  return;
}
}
#line 5648 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_100(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5653
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 5655
  mutex_lock(ldv_func_arg1);
#line 5656
  return;
}
}
#line 5658 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_101(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5663
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 5665
  mutex_unlock(ldv_func_arg1);
#line 5666
  return;
}
}
#line 5668 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_102(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5673
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 5675
  mutex_lock(ldv_func_arg1);
#line 5676
  return;
}
}
#line 5678 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_103(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5683
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 5685
  mutex_unlock(ldv_func_arg1);
#line 5686
  return;
}
}
#line 5688 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_104(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5693
  ldv_mutex_lock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 5695
  mutex_lock(ldv_func_arg1);
#line 5696
  return;
}
}
#line 5698 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_105(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5703
  ldv_mutex_unlock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 5705
  mutex_unlock(ldv_func_arg1);
#line 5706
  return;
}
}
#line 5708 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_106(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5713
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5715
  mutex_lock(ldv_func_arg1);
#line 5716
  return;
}
}
#line 5718 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_107(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5723
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5725
  mutex_unlock(ldv_func_arg1);
#line 5726
  return;
}
}
#line 5728 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_108(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5733
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 5735
  mutex_lock(ldv_func_arg1);
#line 5736
  return;
}
}
#line 5738 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_109(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5743
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5745
  mutex_lock(ldv_func_arg1);
#line 5746
  return;
}
}
#line 5748 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_110(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5753
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5755
  mutex_unlock(ldv_func_arg1);
#line 5756
  return;
}
}
#line 5758 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_111(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5763
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 5765
  mutex_unlock(ldv_func_arg1);
#line 5766
  return;
}
}
#line 5768 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_112(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5773
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5775
  mutex_lock(ldv_func_arg1);
#line 5776
  return;
}
}
#line 5778 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_113(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5783
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5785
  mutex_unlock(ldv_func_arg1);
#line 5786
  return;
}
}
#line 5788 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_114(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5793
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5795
  mutex_unlock(ldv_func_arg1);
#line 5796
  return;
}
}
#line 5798 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_115(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5803
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5805
  mutex_unlock(ldv_func_arg1);
#line 5806
  return;
}
}
#line 5808 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_116(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5813
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5815
  mutex_unlock(ldv_func_arg1);
#line 5816
  return;
}
}
#line 5818 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_117(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5823
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5825
  mutex_lock(ldv_func_arg1);
#line 5826
  return;
}
}
#line 5828 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_118(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5833
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 5835
  mutex_unlock(ldv_func_arg1);
#line 5836
  return;
}
}
#line 5838 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_lock_119(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5843
  ldv_mutex_lock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 5845
  mutex_lock(ldv_func_arg1);
#line 5846
  return;
}
}
#line 5848 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
void ldv_mutex_unlock_120(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 5853
  ldv_mutex_unlock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 5855
  mutex_unlock(ldv_func_arg1);
#line 5856
  return;
}
}
#line 5858 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
__inline static int ldv_mutex_is_locked_121(struct mutex *lock ) 
{ 
  ldv_func_ret_type___27 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 5863
  tmp = mutex_is_locked(lock);
#line 5863
  ldv_func_res = tmp;
#line 5865
  tmp___0 = ldv_mutex_is_locked_state_mutex_of_drbd_conf(lock);
#line 5865
  return (tmp___0);
#line 5867
  return (ldv_func_res);
}
}
#line 5870 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_receiver.c.prepared"
__inline static int ldv_mutex_is_locked_122(struct mutex *lock ) 
{ 
  ldv_func_ret_type___28 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 5875
  tmp = mutex_is_locked(lock);
#line 5875
  ldv_func_res = tmp;
#line 5877
  tmp___0 = ldv_mutex_is_locked_cstate_mutex_of_drbd_tconn(lock);
#line 5877
  return (tmp___0);
#line 5879
  return (ldv_func_res);
}
}
#line 307 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int test_and_change_bit(int nr , unsigned long volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 311
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btc %2,%1\n\tsbb %0,%0": "=r" (oldbit),
                       "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
#line 315
  return (oldbit);
}
}
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_156(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_154(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_157(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_159(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_161(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_163(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_lock_153(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_155(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_158(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_160(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_162(struct mutex *ldv_func_arg1 ) ;
#line 39 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/smp.h"
extern int cpu_number ;
#line 173 "include/linux/percpu.h"
extern void __bad_size_call_parameter(void) ;
#line 31 "include/linux/kref.h"
__inline static void kref_init(struct kref *kref ) 
{ 


  {
#line 33
  atomic_set(& kref->refcount, 1);
#line 34
  return;
}
}
#line 2145 "include/linux/fs.h"
extern char const   *bdevname(struct block_device * , char * ) ;
#line 205 "include/linux/genhd.h"
__inline static struct gendisk *part_to_disk(struct hd_struct *part ) 
{ 
  struct device  const  *__mptr ;
  struct device  const  *__mptr___0 ;
  long tmp ;

  {
#line 207
  tmp = __builtin_expect((unsigned long )part != (unsigned long )((struct hd_struct *)0),
                         1L);
#line 207
  if (tmp != 0L) {
#line 208
    if (part->partno != 0) {
#line 209
      __mptr = (struct device  const  *)part->__dev.parent;
#line 209
      return ((struct gendisk *)__mptr + 0xffffffffffffff90UL);
    } else {
#line 211
      __mptr___0 = (struct device  const  *)(& part->__dev);
#line 211
      return ((struct gendisk *)__mptr___0 + 0xffffffffffffff90UL);
    }
  } else {

  }
#line 213
  return (0);
}
}
#line 377 "include/linux/genhd.h"
__inline static void part_inc_in_flight(struct hd_struct *part , int rw ) 
{ 
  struct gendisk *tmp ;

  {
#line 379
  atomic_inc((atomic_t *)(& part->in_flight) + (unsigned long )rw);
#line 380
  if (part->partno != 0) {
#line 381
    tmp = part_to_disk(part);
#line 381
    atomic_inc((atomic_t *)(& tmp->part0.in_flight) + (unsigned long )rw);
  } else {

  }
#line 382
  return;
}
}
#line 384 "include/linux/genhd.h"
__inline static void part_dec_in_flight(struct hd_struct *part , int rw ) 
{ 
  struct gendisk *tmp ;

  {
#line 386
  atomic_dec((atomic_t *)(& part->in_flight) + (unsigned long )rw);
#line 387
  if (part->partno != 0) {
#line 388
    tmp = part_to_disk(part);
#line 388
    atomic_dec((atomic_t *)(& tmp->part0.in_flight) + (unsigned long )rw);
  } else {

  }
#line 389
  return;
}
}
#line 410
extern void part_round_stats(int  , struct hd_struct * ) ;
#line 282 "include/linux/backing-dev.h"
__inline static int bdi_read_congested(struct backing_dev_info *bdi ) 
{ 
  int tmp ;

  {
#line 284
  tmp = bdi_congested(bdi, 8);
#line 284
  return (tmp);
}
}
#line 1369 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
mempool_t *drbd_request_mempool ;
#line 1421
void __drbd_make_request(struct drbd_conf *mdev , struct bio *bio , unsigned long start_time ) ;
#line 1422
void drbd_make_request(struct request_queue *q , struct bio *bio ) ;
#line 1424
int drbd_merge_bvec(struct request_queue *q , struct bvec_merge_data *bvm , struct bio_vec *bvec ) ;
#line 1675 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void __drbd_chk_io_error____1(struct drbd_conf *mdev , enum drbd_force_detach_flags df ,
                                              char const   *where ) 
{ 
  enum drbd_io_error_p ep ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  union drbd_state __ns ;
  union drbd_state __ns___0 ;

  {
#line 1681
  rcu_read_lock___0();
#line 1682
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1682
  tmp = debug_lockdep_rcu_enabled();
#line 1682
  if (tmp != 0 && ! __warned) {
#line 1682
    tmp___0 = rcu_read_lock_held();
#line 1682
    if (tmp___0 == 0 && 1) {
#line 1682
      __warned = 1;
#line 1682
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1682, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1682
  ep = (enum drbd_io_error_p )_________p1->on_io_error;
#line 1683
  rcu_read_unlock___0();
#line 1684
  switch ((unsigned int )ep) {
  case 0U: ;
#line 1686
  if ((unsigned int )df == 0U || (unsigned int )df == 1U) {
#line 1687
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "__drbd_chk_io_error_");
#line 1687
    if (tmp___1 != 0) {
#line 1688
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s.\n",
              where);
    } else {

    }
#line 1689
    if ((int )mdev->state.ldv_49522.disk > 4) {
#line 1690
      __ns = drbd_read_state(mdev);
#line 1690
      __ns.ldv_40024.disk = 4U;
#line 1690
      _drbd_set_state(mdev, __ns, CS_HARD, 0);
    } else {

    }
#line 1691
    goto ldv_51571;
  } else {

  }
  case 2U: ;
  case 1U: 
#line 1716
  set_bit(12U, (unsigned long volatile   *)(& mdev->flags));
#line 1717
  if ((unsigned int )df == 0U) {
#line 1718
    set_bit(13U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1719
  if ((unsigned int )df == 3U) {
#line 1720
    set_bit(14U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1721
  if ((int )mdev->state.ldv_49522.disk > 2) {
#line 1722
    __ns___0 = drbd_read_state(mdev);
#line 1722
    __ns___0.ldv_40024.disk = 2U;
#line 1722
    _drbd_set_state(mdev, __ns___0, CS_HARD, 0);
#line 1723
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s. Detaching...\n",
            where);
  } else {

  }
#line 1726
  goto ldv_51571;
  }
  ldv_51571: ;
#line 1729
  return;
}
}
#line 1969 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void inc_ap_pending(struct drbd_conf *mdev ) 
{ 


  {
#line 1971
  atomic_inc(& mdev->ap_pending_cnt);
#line 1972
  return;
}
}
#line 1981 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void _dec_ap_pending(struct drbd_conf *mdev , char const   *func ,
                                     int line ) 
{ 
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 1983
  tmp = atomic_dec_and_test(& mdev->ap_pending_cnt);
#line 1983
  if (tmp != 0) {
#line 1984
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 1985
  tmp___1 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 1985
  if (tmp___1 < 0) {
#line 1985
    tmp___0 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 1985
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "in %s:%d: ap_pending_cnt = %d < 0 !\n",
            func, line, tmp___0);
  } else {

  }
#line 1986
  return;
}
}
#line 2133 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_get_max_buffers(struct drbd_conf *mdev ) 
{ 
  struct net_conf *nc ;
  int mxb ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 2138
  rcu_read_lock___0();
#line 2139
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2139
  tmp = debug_lockdep_rcu_enabled();
#line 2139
  if (tmp != 0 && ! __warned) {
#line 2139
    tmp___0 = rcu_read_lock_held();
#line 2139
    if (tmp___0 == 0 && 1) {
#line 2139
      __warned = 1;
#line 2139
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             2139, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2139
  nc = _________p1;
#line 2140
  mxb = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (int )nc->max_buffers : 1000000;
#line 2141
  rcu_read_unlock___0();
#line 2143
  return (mxb);
}
}
#line 2146 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_state_is_stable(struct drbd_conf *mdev ) 
{ 
  union drbd_dev_state s ;

  {
#line 2148
  s = mdev->state;
#line 2153
  switch ((unsigned int )s.ldv_49522.conn) {
  case 0U: ;
  case 8U: ;
  case 10U: ;
  case 16U: ;
  case 17U: ;
  case 18U: ;
  case 19U: ;
  case 20U: ;
  case 21U: ;
  case 22U: ;
  case 23U: ;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 9U: ;
  case 11U: ;
  case 12U: ;
#line 2178
  goto ldv_51800;
  case 13U: ;
#line 2182
  if ((mdev->tconn)->agreed_pro_version <= 95) {
#line 2183
    return (0);
  } else {

  }
#line 2184
  goto ldv_51800;
  case 14U: ;
  case 15U: ;
  case 31U: ;
#line 2191
  return (0);
  }
  ldv_51800: ;
#line 2194
  switch ((unsigned int )s.ldv_49522.disk) {
  case 0U: ;
  case 4U: ;
  case 5U: ;
  case 7U: ;
  case 8U: ;
  case 2U: ;
#line 2202
  goto ldv_51811;
  case 1U: ;
  case 3U: ;
  case 6U: ;
  case 15U: ;
#line 2210
  return (0);
  }
  ldv_51811: ;
#line 2213
  return (1);
}
}
#line 2223 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static bool may_inc_ap_bio(struct drbd_conf *mdev ) 
{ 
  int mxb ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
#line 2225
  tmp = drbd_get_max_buffers(mdev);
#line 2225
  mxb = tmp;
#line 2227
  tmp___0 = drbd_suspended(mdev);
#line 2227
  if (tmp___0 != 0) {
#line 2228
    return (0);
  } else {

  }
#line 2229
  tmp___1 = constant_test_bit(8U, (unsigned long const volatile   *)(& mdev->flags));
#line 2229
  if (tmp___1 != 0) {
#line 2230
    return (0);
  } else {

  }
#line 2237
  tmp___2 = drbd_state_is_stable(mdev);
#line 2237
  if (tmp___2 == 0) {
#line 2238
    return (0);
  } else {

  }
#line 2242
  tmp___3 = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 2242
  if (tmp___3 > mxb) {
#line 2243
    return (0);
  } else {

  }
#line 2244
  tmp___4 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2244
  if (tmp___4 != 0) {
#line 2245
    return (0);
  } else {

  }
#line 2246
  return (1);
}
}
#line 2249 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static bool inc_ap_bio_cond(struct drbd_conf *mdev ) 
{ 
  bool rv ;

  {
#line 2251
  rv = 0;
#line 2253
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2254
  rv = may_inc_ap_bio(mdev);
#line 2255
  if ((int )rv) {
#line 2256
    atomic_inc(& mdev->ap_bio_cnt);
  } else {

  }
#line 2257
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2259
  return (rv);
}
}
#line 2262 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void inc_ap_bio(struct drbd_conf *mdev ) 
{ 
  bool tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  bool tmp___1 ;

  {
#line 2272
  tmp = inc_ap_bio_cond(mdev);
#line 2272
  if ((int )tmp) {
#line 2272
    goto ldv_51831;
  } else {

  }
#line 2272
  tmp___0 = get_current();
#line 2272
  __wait.flags = 0U;
#line 2272
  __wait.private = (void *)tmp___0;
#line 2272
  __wait.func = & autoremove_wake_function;
#line 2272
  __wait.task_list.next = & __wait.task_list;
#line 2272
  __wait.task_list.prev = & __wait.task_list;
  ldv_51834: 
#line 2272
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 2272
  tmp___1 = inc_ap_bio_cond(mdev);
#line 2272
  if ((int )tmp___1) {
#line 2272
    goto ldv_51833;
  } else {

  }
#line 2272
  schedule();
#line 2272
  goto ldv_51834;
  ldv_51833: 
#line 2272
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_51831: ;
#line 2275
  return;
}
}
#line 2275 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void dec_ap_bio(struct drbd_conf *mdev ) 
{ 
  int mxb ;
  int tmp ;
  int ap_bio ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 2277
  tmp = drbd_get_max_buffers(mdev);
#line 2277
  mxb = tmp;
#line 2278
  tmp___0 = atomic_sub_return(1, & mdev->ap_bio_cnt);
#line 2278
  ap_bio = tmp___0;
#line 2280
  if (ap_bio < 0) {
#line 2280
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( ap_bio >= 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
            2280);
  } else {

  }
#line 2282
  if (ap_bio == 0) {
#line 2282
    tmp___2 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2282
    if (tmp___2 != 0) {
#line 2283
      tmp___1 = test_and_set_bit(10, (unsigned long volatile   *)(& mdev->flags));
#line 2283
      if (tmp___1 == 0) {
#line 2284
        drbd_queue_work(& (mdev->tconn)->sender_work, & mdev->bm_io_work.w);
      } else {

      }
    } else {

    }
  } else {

  }
#line 2290
  if (ap_bio < mxb) {
#line 2291
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 2292
  return;
}
}
#line 270 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
void drbd_req_destroy(struct kref *kref ) ;
#line 277
void request_timer_fn(unsigned long data ) ;
#line 282
void drbd_restart_request(struct drbd_request *req ) ;
#line 286 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
__inline static int _req_mod(struct drbd_request *req , enum drbd_req_event what ) 
{ 
  struct drbd_conf *mdev ;
  struct bio_and_error m ;
  int rv ;

  {
#line 288
  mdev = req->w.ldv_49807.mdev;
#line 293
  rv = __req_mod(req, what, & m);
#line 294
  if ((unsigned long )m.bio != (unsigned long )((struct bio *)0)) {
#line 295
    complete_master_bio(mdev, & m);
  } else {

  }
#line 297
  return (rv);
}
}
#line 322 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
__inline static bool drbd_should_do_remote(union drbd_dev_state s ) 
{ 


  {
#line 324
  return ((bool )(*((unsigned int *)(& s) + 0UL) == 65536U || (((int )s.ldv_49522.pdsk > 3 && (int )s.ldv_49522.conn > 13) && (int )s.ldv_49522.conn <= 21)));
}
}
#line 332 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
__inline static bool drbd_should_send_out_of_sync(union drbd_dev_state s ) 
{ 


  {
#line 334
  return ((bool )((unsigned int )*((unsigned short *)(& s) + 0UL) == 352U || (unsigned int )*((unsigned short *)(& s) + 0UL) == 208U));
}
}
#line 121 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static bool drbd_may_do_local_read(struct drbd_conf *mdev , sector_t sector , int size ) ;
#line 124 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void _drbd_start_io_acct(struct drbd_conf *mdev , struct drbd_request *req ,
                                struct bio *bio ) 
{ 
  int rw ;
  int cpu ;
  struct thread_info *tmp ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  void const   *__vpp_verify___0 ;
  unsigned long __ptr ;
  void const   *__vpp_verify___1 ;
  unsigned long __ptr___0 ;
  struct gendisk *tmp___0 ;
  void const   *__vpp_verify___2 ;
  unsigned long __ptr___1 ;
  void const   *__vpp_verify___3 ;
  unsigned long __ptr___2 ;
  struct gendisk *tmp___1 ;
  struct thread_info *tmp___2 ;

  {
#line 126
  rw = (int const   )bio->bi_rw & (int const   )1;
#line 128
  rcu_read_lock___0();
#line 128
  tmp = current_thread_info___0();
#line 128
  tmp->preempt_count = tmp->preempt_count + 1;
#line 128
  __asm__  volatile   ("": : : "memory");
#line 128
  __vpp_verify = 0;
#line 128
  switch (4UL) {
  case 1UL: ;
#line 128
  switch (4UL) {
  case 1UL: 
#line 128
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "m" (cpu_number));
#line 128
  goto ldv_52003;
  case 2UL: 
#line 128
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "m" (cpu_number));
#line 128
  goto ldv_52003;
  case 4UL: 
#line 128
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "m" (cpu_number));
#line 128
  goto ldv_52003;
  case 8UL: 
#line 128
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "m" (cpu_number));
#line 128
  goto ldv_52003;
  default: 
#line 128
  __bad_percpu_size();
  }
  ldv_52003: 
#line 128
  pscr_ret__ = pfo_ret__;
#line 128
  goto ldv_52009;
  case 2UL: ;
#line 128
  switch (4UL) {
  case 1UL: 
#line 128
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
#line 128
  goto ldv_52013;
  case 2UL: 
#line 128
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
#line 128
  goto ldv_52013;
  case 4UL: 
#line 128
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
#line 128
  goto ldv_52013;
  case 8UL: 
#line 128
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
#line 128
  goto ldv_52013;
  default: 
#line 128
  __bad_percpu_size();
  }
  ldv_52013: 
#line 128
  pscr_ret__ = pfo_ret_____0;
#line 128
  goto ldv_52009;
  case 4UL: ;
#line 128
  switch (4UL) {
  case 1UL: 
#line 128
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
#line 128
  goto ldv_52022;
  case 2UL: 
#line 128
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
#line 128
  goto ldv_52022;
  case 4UL: 
#line 128
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
#line 128
  goto ldv_52022;
  case 8UL: 
#line 128
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
#line 128
  goto ldv_52022;
  default: 
#line 128
  __bad_percpu_size();
  }
  ldv_52022: 
#line 128
  pscr_ret__ = pfo_ret_____1;
#line 128
  goto ldv_52009;
  case 8UL: ;
#line 128
  switch (4UL) {
  case 1UL: 
#line 128
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
#line 128
  goto ldv_52031;
  case 2UL: 
#line 128
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
#line 128
  goto ldv_52031;
  case 4UL: 
#line 128
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
#line 128
  goto ldv_52031;
  case 8UL: 
#line 128
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
#line 128
  goto ldv_52031;
  default: 
#line 128
  __bad_percpu_size();
  }
  ldv_52031: 
#line 128
  pscr_ret__ = pfo_ret_____2;
#line 128
  goto ldv_52009;
  default: 
#line 128
  __bad_size_call_parameter();
#line 128
  goto ldv_52009;
  }
  ldv_52009: 
#line 128
  cpu = pscr_ret__;
#line 129
  part_round_stats(cpu, & (mdev->vdisk)->part0);
#line 130
  __vpp_verify___0 = 0;
#line 130
  __asm__  ("": "=r" (__ptr): "0" ((mdev->vdisk)->part0.dkstats));
#line 130
  ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr))->ios[rw] = ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr))->ios[rw] + 1UL;
#line 130
  if ((mdev->vdisk)->part0.partno != 0) {
#line 130
    __vpp_verify___1 = 0;
#line 130
    tmp___0 = part_to_disk(& (mdev->vdisk)->part0);
#line 130
    __asm__  ("": "=r" (__ptr___0): "0" (tmp___0->part0.dkstats));
#line 130
    ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___0))->ios[rw] = ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___0))->ios[rw] + 1UL;
  } else {

  }
#line 131
  __vpp_verify___2 = 0;
#line 131
  __asm__  ("": "=r" (__ptr___1): "0" ((mdev->vdisk)->part0.dkstats));
#line 131
  ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___1))->sectors[rw] = ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___1))->sectors[rw] + (unsigned long )(bio->bi_size >> 9);
#line 131
  if ((mdev->vdisk)->part0.partno != 0) {
#line 131
    __vpp_verify___3 = 0;
#line 131
    tmp___1 = part_to_disk(& (mdev->vdisk)->part0);
#line 131
    __asm__  ("": "=r" (__ptr___2): "0" (tmp___1->part0.dkstats));
#line 131
    ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___2))->sectors[rw] = ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___2))->sectors[rw] + (unsigned long )(bio->bi_size >> 9);
  } else {

  }
#line 134
  part_inc_in_flight(& (mdev->vdisk)->part0, rw);
#line 135
  __asm__  volatile   ("": : : "memory");
#line 135
  tmp___2 = current_thread_info___0();
#line 135
  tmp___2->preempt_count = tmp___2->preempt_count + -1;
#line 135
  __asm__  volatile   ("": : : "memory");
#line 135
  rcu_read_unlock___0();
#line 136
  return;
}
}
#line 139 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void _drbd_end_io_acct(struct drbd_conf *mdev , struct drbd_request *req ) 
{ 
  int rw ;
  unsigned long duration ;
  int cpu ;
  struct thread_info *tmp ;
  int pscr_ret__ ;
  void const   *__vpp_verify ;
  int pfo_ret__ ;
  int pfo_ret_____0 ;
  int pfo_ret_____1 ;
  int pfo_ret_____2 ;
  void const   *__vpp_verify___0 ;
  unsigned long __ptr ;
  void const   *__vpp_verify___1 ;
  unsigned long __ptr___0 ;
  struct gendisk *tmp___0 ;
  struct thread_info *tmp___1 ;

  {
#line 141
  rw = (int )(req->master_bio)->bi_rw & 1;
#line 142
  duration = (unsigned long )jiffies - req->start_time;
#line 144
  rcu_read_lock___0();
#line 144
  tmp = current_thread_info___0();
#line 144
  tmp->preempt_count = tmp->preempt_count + 1;
#line 144
  __asm__  volatile   ("": : : "memory");
#line 144
  __vpp_verify = 0;
#line 144
  switch (4UL) {
  case 1UL: ;
#line 144
  switch (4UL) {
  case 1UL: 
#line 144
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "m" (cpu_number));
#line 144
  goto ldv_52069;
  case 2UL: 
#line 144
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "m" (cpu_number));
#line 144
  goto ldv_52069;
  case 4UL: 
#line 144
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "m" (cpu_number));
#line 144
  goto ldv_52069;
  case 8UL: 
#line 144
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "m" (cpu_number));
#line 144
  goto ldv_52069;
  default: 
#line 144
  __bad_percpu_size();
  }
  ldv_52069: 
#line 144
  pscr_ret__ = pfo_ret__;
#line 144
  goto ldv_52075;
  case 2UL: ;
#line 144
  switch (4UL) {
  case 1UL: 
#line 144
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret_____0): "m" (cpu_number));
#line 144
  goto ldv_52079;
  case 2UL: 
#line 144
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
#line 144
  goto ldv_52079;
  case 4UL: 
#line 144
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
#line 144
  goto ldv_52079;
  case 8UL: 
#line 144
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret_____0): "m" (cpu_number));
#line 144
  goto ldv_52079;
  default: 
#line 144
  __bad_percpu_size();
  }
  ldv_52079: 
#line 144
  pscr_ret__ = pfo_ret_____0;
#line 144
  goto ldv_52075;
  case 4UL: ;
#line 144
  switch (4UL) {
  case 1UL: 
#line 144
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret_____1): "m" (cpu_number));
#line 144
  goto ldv_52088;
  case 2UL: 
#line 144
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
#line 144
  goto ldv_52088;
  case 4UL: 
#line 144
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
#line 144
  goto ldv_52088;
  case 8UL: 
#line 144
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret_____1): "m" (cpu_number));
#line 144
  goto ldv_52088;
  default: 
#line 144
  __bad_percpu_size();
  }
  ldv_52088: 
#line 144
  pscr_ret__ = pfo_ret_____1;
#line 144
  goto ldv_52075;
  case 8UL: ;
#line 144
  switch (4UL) {
  case 1UL: 
#line 144
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret_____2): "m" (cpu_number));
#line 144
  goto ldv_52097;
  case 2UL: 
#line 144
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
#line 144
  goto ldv_52097;
  case 4UL: 
#line 144
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
#line 144
  goto ldv_52097;
  case 8UL: 
#line 144
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret_____2): "m" (cpu_number));
#line 144
  goto ldv_52097;
  default: 
#line 144
  __bad_percpu_size();
  }
  ldv_52097: 
#line 144
  pscr_ret__ = pfo_ret_____2;
#line 144
  goto ldv_52075;
  default: 
#line 144
  __bad_size_call_parameter();
#line 144
  goto ldv_52075;
  }
  ldv_52075: 
#line 144
  cpu = pscr_ret__;
#line 145
  __vpp_verify___0 = 0;
#line 145
  __asm__  ("": "=r" (__ptr): "0" ((mdev->vdisk)->part0.dkstats));
#line 145
  ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr))->ticks[rw] = ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr))->ticks[rw] + duration;
#line 145
  if ((mdev->vdisk)->part0.partno != 0) {
#line 145
    __vpp_verify___1 = 0;
#line 145
    tmp___0 = part_to_disk(& (mdev->vdisk)->part0);
#line 145
    __asm__  ("": "=r" (__ptr___0): "0" (tmp___0->part0.dkstats));
#line 145
    ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___0))->ticks[rw] = ((struct disk_stats *)(__per_cpu_offset[cpu] + __ptr___0))->ticks[rw] + duration;
  } else {

  }
#line 146
  part_round_stats(cpu, & (mdev->vdisk)->part0);
#line 147
  part_dec_in_flight(& (mdev->vdisk)->part0, rw);
#line 148
  __asm__  volatile   ("": : : "memory");
#line 148
  tmp___1 = current_thread_info___0();
#line 148
  tmp___1->preempt_count = tmp___1->preempt_count + -1;
#line 148
  __asm__  volatile   ("": : : "memory");
#line 148
  rcu_read_unlock___0();
#line 149
  return;
}
}
#line 151 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static struct drbd_request *drbd_req_new(struct drbd_conf *mdev , struct bio *bio_src ) 
{ 
  struct drbd_request *req ;
  void *tmp ;

  {
#line 156
  tmp = mempool_alloc(drbd_request_mempool, 16U);
#line 156
  req = (struct drbd_request *)tmp;
#line 157
  if ((unsigned long )req == (unsigned long )((struct drbd_request *)0)) {
#line 158
    return (0);
  } else {

  }
#line 160
  drbd_req_make_private_bio(req, bio_src);
#line 161
  req->rq_state = (int )bio_src->bi_rw & 1 ? 2048U : 0U;
#line 162
  req->w.ldv_49807.mdev = mdev;
#line 163
  req->master_bio = bio_src;
#line 164
  req->epoch = 0U;
#line 166
  drbd_clear_interval(& req->i);
#line 167
  req->i.sector = bio_src->bi_sector;
#line 168
  req->i.size = bio_src->bi_size;
#line 169
  req->i.local = -1;
#line 170
  req->i.waiting = 0;
#line 172
  INIT_LIST_HEAD(& req->tl_requests);
#line 173
  INIT_LIST_HEAD(& req->w.list);
#line 176
  atomic_set(& req->completion_ref, 1);
#line 178
  kref_init(& req->kref);
#line 179
  return (req);
}
}
#line 182 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void drbd_req_destroy(struct kref *kref ) 
{ 
  struct drbd_request *req ;
  struct kref  const  *__mptr ;
  struct drbd_conf *mdev ;
  unsigned int s ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 184
  __mptr = (struct kref  const  *)kref;
#line 184
  req = (struct drbd_request *)__mptr + 0xffffffffffffff74UL;
#line 185
  mdev = req->w.ldv_49807.mdev;
#line 186
  s = req->rq_state;
#line 188
  if ((unsigned long )req->master_bio != (unsigned long )((struct bio *)0) && ((unsigned long )s & 8192UL) == 0UL) {
#line 192
    tmp = atomic_read((atomic_t const   *)(& req->completion_ref));
#line 192
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_req_destroy: Logic BUG rq_state = 0x%x, completion_ref = %d\n",
            s, tmp);
#line 194
    return;
  } else {
#line 188
    tmp___0 = atomic_read((atomic_t const   *)(& req->completion_ref));
#line 188
    if (tmp___0 != 0) {
#line 192
      tmp = atomic_read((atomic_t const   *)(& req->completion_ref));
#line 192
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_req_destroy: Logic BUG rq_state = 0x%x, completion_ref = %d\n",
              s, tmp);
#line 194
      return;
    } else
#line 188
    if ((int )s & 1) {
#line 192
      tmp = atomic_read((atomic_t const   *)(& req->completion_ref));
#line 192
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_req_destroy: Logic BUG rq_state = 0x%x, completion_ref = %d\n",
              s, tmp);
#line 194
      return;
    } else
#line 188
    if (((unsigned long )s & 1008UL) != 0UL && ((unsigned long )s & 128UL) == 0UL) {
#line 192
      tmp = atomic_read((atomic_t const   *)(& req->completion_ref));
#line 192
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_req_destroy: Logic BUG rq_state = 0x%x, completion_ref = %d\n",
              s, tmp);
#line 194
      return;
    } else {

    }
  }
#line 203
  list_del_init(& req->tl_requests);
#line 208
  if (((unsigned long )s & 2048UL) != 0UL) {
#line 220
    if (((unsigned long )s & 9215UL) != 8192UL) {
#line 221
      if (((unsigned long )s & 256UL) == 0UL || ((unsigned long )s & 4UL) == 0UL) {
#line 222
        __drbd_set_out_of_sync(mdev, req->i.sector, (int )req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                               222U);
      } else {

      }
#line 224
      if ((((unsigned long )s & 256UL) != 0UL && ((unsigned long )s & 4UL) != 0UL) && ((unsigned long )s & 512UL) != 0UL) {
#line 225
        __drbd_set_in_sync(mdev, req->i.sector, (int )req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                           225U);
      } else {

      }
    } else {

    }
#line 238
    if (((unsigned long )s & 4096UL) != 0UL) {
#line 239
      tmp___2 = _get_ldev_if_state(mdev, D_FAILED);
#line 239
      if (tmp___2 != 0) {
#line 240
        drbd_al_complete_io(mdev, & req->i);
#line 241
        put_ldev(mdev);
      } else {
#line 242
        tmp___1 = ___ratelimit(& drbd_ratelimit_state, "drbd_req_destroy");
#line 242
        if (tmp___1 != 0) {
#line 243
          dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Should have called drbd_al_complete_io(, %llu, %u), but my Disk seems to have failed :(\n",
                   (unsigned long long )req->i.sector, req->i.size);
        } else {

        }
      }
    } else {

    }
  } else {

  }
#line 250
  mempool_free((void *)req, drbd_request_mempool);
#line 251
  return;
}
}
#line 253 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void wake_all_senders(struct drbd_tconn *tconn ) 
{ 


  {
#line 254
  __wake_up(& tconn->sender_work.q_wait, 3U, 1, 0);
#line 255
  return;
}
}
#line 258 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void start_new_tl_epoch(struct drbd_tconn *tconn ) 
{ 


  {
#line 261
  if (tconn->current_tle_writes == 0U) {
#line 262
    return;
  } else {

  }
#line 264
  tconn->current_tle_writes = 0U;
#line 265
  atomic_inc(& tconn->current_tle_nr);
#line 266
  wake_all_senders(tconn);
#line 267
  return;
}
}
#line 269 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void complete_master_bio(struct drbd_conf *mdev , struct bio_and_error *m ) 
{ 


  {
#line 272
  bio_endio(m->bio, m->error);
#line 273
  dec_ap_bio(mdev);
#line 274
  return;
}
}
#line 277 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void drbd_remove_request_interval(struct rb_root *root , struct drbd_request *req ) 
{ 
  struct drbd_conf *mdev ;
  struct drbd_interval *i ;

  {
#line 280
  mdev = req->w.ldv_49807.mdev;
#line 281
  i = & req->i;
#line 283
  drbd_remove_interval(root, i);
#line 286
  if ((unsigned int )*((unsigned char *)i + 48UL) != 0U) {
#line 287
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 288
  return;
}
}
#line 297 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void drbd_req_complete(struct drbd_request *req , struct bio_and_error *m ) 
{ 
  unsigned int s ;
  struct drbd_conf *mdev ;
  int rw ;
  int error ;
  int ok ;
  long tmp ;
  struct rb_root *root ;
  bool tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 299
  s = req->rq_state;
#line 300
  mdev = req->w.ldv_49807.mdev;
#line 313
  if (((((int )s & 1 && ((unsigned long )s & 8UL) == 0UL) || ((unsigned long )s & 32UL) != 0UL) || ((unsigned long )s & 16UL) != 0UL) || ((unsigned long )s & 16384UL) != 0UL) {
#line 316
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_req_complete: Logic BUG rq_state = 0x%x\n",
            s);
#line 317
    return;
  } else {

  }
#line 320
  if ((unsigned long )req->master_bio == (unsigned long )((struct bio *)0)) {
#line 321
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_req_complete: Logic BUG, master_bio == NULL!\n");
#line 322
    return;
  } else {

  }
#line 325
  rw = (int )(req->master_bio)->bi_rw & 8193;
#line 340
  ok = ((unsigned long )s & 4UL) != 0UL || ((unsigned long )s & 256UL) != 0UL;
#line 341
  tmp = PTR_ERR((void const   *)req->private_bio);
#line 341
  error = (int )tmp;
#line 345
  tmp___0 = drbd_interval_empty(& req->i);
#line 345
  if (tmp___0) {
#line 345
    tmp___1 = 0;
  } else {
#line 345
    tmp___1 = 1;
  }
#line 345
  if (tmp___1) {
#line 348
    if (rw == 1) {
#line 349
      root = & mdev->write_requests;
    } else {
#line 351
      root = & mdev->read_requests;
    }
#line 352
    drbd_remove_request_interval(root, req);
  } else
#line 353
  if (((unsigned long )s & 8192UL) == 0UL) {
#line 354
    if (((unsigned long )s & 880UL) != 0UL) {
#line 354
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( (s & (RQ_NET_MASK & ~RQ_NET_DONE)) == 0 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
              354);
    } else {

    }
  } else {

  }
#line 363
  if (rw == 1) {
#line 363
    tmp___2 = atomic_read((atomic_t const   *)(& (mdev->tconn)->current_tle_nr));
#line 363
    if (req->epoch == (unsigned int )tmp___2) {
#line 365
      start_new_tl_epoch(mdev->tconn);
    } else {

    }
  } else {

  }
#line 368
  _drbd_end_io_acct(mdev, req);
#line 384
  if (ok == 0 && rw == 0) {
#line 384
    tmp___3 = list_empty((struct list_head  const  *)(& req->tl_requests));
#line 384
    if (tmp___3 == 0) {
#line 385
      req->rq_state = req->rq_state | 8192U;
    } else {

    }
  } else {

  }
#line 387
  if (((unsigned long )req->rq_state & 8192UL) == 0UL) {
#line 388
    m->error = ok == 0 ? (error != 0 ? error : -5) : 0;
#line 389
    m->bio = req->master_bio;
#line 390
    req->master_bio = 0;
  } else {

  }
#line 392
  return;
}
}
#line 394 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static int drbd_req_put_completion_ref(struct drbd_request *req , struct bio_and_error *m ,
                                       int put ) 
{ 
  struct drbd_conf *mdev ;
  int tmp ;

  {
#line 396
  mdev = req->w.ldv_49807.mdev;
#line 397
  if ((unsigned long )m == (unsigned long )((struct bio_and_error *)0) && ((unsigned long )req->rq_state & 8192UL) == 0UL) {
#line 397
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( m || (req->rq_state & RQ_POSTPONED) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            397);
  } else {

  }
#line 399
  tmp = atomic_sub_and_test(put, & req->completion_ref);
#line 399
  if (tmp == 0) {
#line 400
    return (0);
  } else {

  }
#line 402
  drbd_req_complete(req, m);
#line 404
  if (((unsigned long )req->rq_state & 8192UL) != 0UL) {
#line 407
    drbd_restart_request(req);
#line 408
    return (0);
  } else {

  }
#line 411
  return (1);
}
}
#line 416 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void mod_rq_state(struct drbd_request *req , struct bio_and_error *m , int clear ,
                         int set ) 
{ 
  struct drbd_conf *mdev ;
  unsigned int s ;
  int c_put ;
  int k_put ;
  int tmp ;
  int at_least ;
  int refcount ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 419
  mdev = req->w.ldv_49807.mdev;
#line 420
  s = req->rq_state;
#line 421
  c_put = 0;
#line 422
  k_put = 0;
#line 424
  tmp = drbd_suspended(mdev);
#line 424
  if (tmp != 0 && ((unsigned long )(s | (unsigned int )clear) & 16384UL) == 0UL) {
#line 425
    set = set | 16384;
  } else {

  }
#line 429
  req->rq_state = req->rq_state & (unsigned int )(~ clear);
#line 430
  req->rq_state = req->rq_state | (unsigned int )set;
#line 433
  if (req->rq_state == s) {
#line 434
    return;
  } else {

  }
#line 438
  if (((unsigned long )s & 1UL) == 0UL && set & 1) {
#line 439
    atomic_inc(& req->completion_ref);
  } else {

  }
#line 441
  if (((unsigned long )s & 16UL) == 0UL && ((unsigned long )set & 16UL) != 0UL) {
#line 442
    inc_ap_pending(mdev);
#line 443
    atomic_inc(& req->completion_ref);
  } else {

  }
#line 446
  if (((unsigned long )s & 32UL) == 0UL && ((unsigned long )set & 32UL) != 0UL) {
#line 447
    atomic_inc(& req->completion_ref);
  } else {

  }
#line 449
  if (((unsigned long )s & 131072UL) == 0UL && ((unsigned long )set & 131072UL) != 0UL) {
#line 450
    kref_get(& req->kref);
  } else {

  }
#line 452
  if (((unsigned long )s & 64UL) == 0UL && ((unsigned long )set & 64UL) != 0UL) {
#line 453
    atomic_add((int )(req->i.size >> 9), & mdev->ap_in_flight);
  } else {

  }
#line 455
  if (((unsigned long )s & 16384UL) == 0UL && ((unsigned long )set & 16384UL) != 0UL) {
#line 456
    atomic_inc(& req->completion_ref);
  } else {

  }
#line 460
  if (((unsigned long )s & 16384UL) != 0UL && ((unsigned long )clear & 16384UL) != 0UL) {
#line 461
    c_put = c_put + 1;
  } else {

  }
#line 463
  if (((unsigned long )s & 8UL) == 0UL && ((unsigned long )set & 8UL) != 0UL) {
#line 464
    if (((unsigned long )req->rq_state & 1UL) == 0UL) {
#line 464
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_LOCAL_PENDING ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
              464);
    } else {

    }
#line 467
    kref_get(& req->kref);
#line 468
    c_put = c_put + 1;
  } else {

  }
#line 471
  if ((int )s & 1 && clear & 1) {
#line 472
    if (((unsigned long )req->rq_state & 8UL) != 0UL) {
#line 473
      k_put = k_put + 1;
    } else {
#line 475
      c_put = c_put + 1;
    }
  } else {

  }
#line 478
  if (((unsigned long )s & 16UL) != 0UL && ((unsigned long )clear & 16UL) != 0UL) {
#line 479
    _dec_ap_pending(mdev, "mod_rq_state", 479);
#line 480
    c_put = c_put + 1;
  } else {

  }
#line 483
  if (((unsigned long )s & 32UL) != 0UL && ((unsigned long )clear & 32UL) != 0UL) {
#line 484
    c_put = c_put + 1;
  } else {

  }
#line 486
  if ((((unsigned long )s & 131072UL) != 0UL && ((unsigned long )s & 128UL) == 0UL) && ((unsigned long )set & 128UL) != 0UL) {
#line 487
    if (((unsigned long )req->rq_state & 64UL) != 0UL) {
#line 488
      atomic_sub((int )(req->i.size >> 9), & mdev->ap_in_flight);
    } else {

    }
#line 489
    k_put = k_put + 1;
  } else {

  }
#line 494
  if (k_put != 0 || c_put != 0) {
#line 497
    at_least = (c_put != 0) + k_put;
#line 498
    tmp___0 = atomic_read((atomic_t const   *)(& req->kref.refcount));
#line 498
    refcount = tmp___0;
#line 499
    if (refcount < at_least) {
#line 500
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "mod_rq_state: Logic BUG: %x -> %x: refcount = %d, should be >= %d\n",
              s, req->rq_state, refcount, at_least);
    } else {

    }
  } else {

  }
#line 506
  if ((unsigned int )*((unsigned char *)req + 88UL) != 0U) {
#line 507
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 509
  if (c_put != 0) {
#line 510
    tmp___1 = drbd_req_put_completion_ref(req, m, c_put);
#line 510
    k_put = tmp___1 + k_put;
  } else {

  }
#line 511
  if (k_put != 0) {
#line 512
    kref_sub(& req->kref, (unsigned int )k_put, & drbd_req_destroy);
  } else {

  }
#line 513
  return;
}
}
#line 515 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void drbd_report_io_error(struct drbd_conf *mdev , struct drbd_request *req ) 
{ 
  char b[32U] ;
  int tmp ;
  char const   *tmp___0 ;

  {
#line 519
  tmp = ___ratelimit(& drbd_ratelimit_state, "drbd_report_io_error");
#line 519
  if (tmp == 0) {
#line 520
    return;
  } else {

  }
#line 522
  tmp___0 = bdevname((mdev->ldev)->backing_bdev, (char *)(& b));
#line 522
  dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "local %s IO error sector %llu+%u on %s\n",
           ((unsigned long )req->rq_state & 2048UL) != 0UL ? (char *)"WRITE" : (char *)"READ",
           (unsigned long long )req->i.sector, req->i.size >> 9, tmp___0);
#line 527
  return;
}
}
#line 541 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
int __req_mod(struct drbd_request *req , enum drbd_req_event what , struct bio_and_error *m ) 
{ 
  struct drbd_conf *mdev ;
  struct net_conf *nc ;
  int p ;
  int rv ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;
  struct net_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___5 ;
  int tmp___6 ;

  {
#line 544
  mdev = req->w.ldv_49807.mdev;
#line 546
  rv = 0;
#line 548
  if ((unsigned long )m != (unsigned long )((struct bio_and_error *)0)) {
#line 549
    m->bio = 0;
  } else {

  }
#line 551
  switch ((unsigned int )what) {
  default: 
#line 553
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "LOGIC BUG in %s:%u\n",
          (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
          553);
#line 554
  goto ldv_52190;
  case 1U: ;
#line 565
  if (((unsigned long )req->rq_state & 1008UL) != 0UL) {
#line 565
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !(req->rq_state & RQ_NET_MASK) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            565);
  } else {

  }
#line 566
  rcu_read_lock___0();
#line 567
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 567
  tmp = debug_lockdep_rcu_enabled();
#line 567
  if (tmp != 0 && ! __warned) {
#line 567
    tmp___0 = rcu_read_lock_held();
#line 567
    if (tmp___0 == 0 && 1) {
#line 567
      __warned = 1;
#line 567
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                             567, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 567
  nc = _________p1;
#line 568
  p = (int )nc->wire_protocol;
#line 569
  rcu_read_unlock___0();
#line 570
  req->rq_state = req->rq_state | (p != 3 ? (p == 2 ? 32768U : 0U) : 65536U);
#line 573
  mod_rq_state(req, m, 0, 16);
#line 574
  goto ldv_52190;
  case 2U: ;
#line 578
  if (((unsigned long )req->rq_state & 15UL) != 0UL) {
#line 578
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !(req->rq_state & RQ_LOCAL_MASK) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            578);
  } else {

  }
#line 579
  mod_rq_state(req, m, 0, 1);
#line 580
  goto ldv_52190;
  case 24U: ;
#line 583
  if (((unsigned long )req->rq_state & 2048UL) != 0UL) {
#line 584
    mdev->writ_cnt = mdev->writ_cnt + (req->i.size >> 9);
  } else {
#line 586
    mdev->read_cnt = mdev->read_cnt + (req->i.size >> 9);
  }
#line 588
  mod_rq_state(req, m, 1, 6);
#line 590
  goto ldv_52190;
  case 23U: 
#line 593
  mod_rq_state(req, m, 0, 8);
#line 594
  goto ldv_52190;
  case 22U: 
#line 597
  drbd_report_io_error(mdev, req);
#line 598
  __drbd_chk_io_error____1(mdev, DRBD_WRITE_ERROR, "__req_mod");
#line 599
  mod_rq_state(req, m, 1, 2);
#line 600
  goto ldv_52190;
  case 20U: 
#line 603
  __drbd_set_out_of_sync(mdev, req->i.sector, (int )req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                         603U);
#line 604
  drbd_report_io_error(mdev, req);
#line 605
  __drbd_chk_io_error____1(mdev, DRBD_READ_ERROR, "__req_mod");
  case 21U: 
#line 609
  mod_rq_state(req, m, 1, 2);
#line 610
  goto ldv_52190;
  case 4U: 
#line 623
  tmp___1 = drbd_interval_empty(& req->i);
#line 623
  if (tmp___1) {
#line 623
    tmp___2 = 0;
  } else {
#line 623
    tmp___2 = 1;
  }
#line 623
  if (tmp___2) {
#line 623
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( drbd_interval_empty(&req->i) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            623);
  } else {

  }
#line 624
  drbd_insert_interval(& mdev->read_requests, & req->i);
#line 626
  set_bit(0U, (unsigned long volatile   *)(& mdev->flags));
#line 628
  if (((unsigned long )req->rq_state & 16UL) == 0UL) {
#line 628
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_NET_PENDING ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            628);
  } else {

  }
#line 629
  if (((unsigned long )req->rq_state & 15UL) != 0UL) {
#line 629
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( (req->rq_state & RQ_LOCAL_MASK) == 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            629);
  } else {

  }
#line 630
  mod_rq_state(req, m, 0, 32);
#line 631
  req->w.cb = & w_send_read_req;
#line 632
  drbd_queue_work(& (mdev->tconn)->sender_work, & req->w);
#line 633
  goto ldv_52190;
  case 3U: 
#line 641
  tmp___3 = drbd_interval_empty(& req->i);
#line 641
  if (tmp___3) {
#line 641
    tmp___4 = 0;
  } else {
#line 641
    tmp___4 = 1;
  }
#line 641
  if (tmp___4) {
#line 641
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( drbd_interval_empty(&req->i) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            641);
  } else {

  }
#line 642
  drbd_insert_interval(& mdev->write_requests, & req->i);
#line 661
  set_bit(0U, (unsigned long volatile   *)(& mdev->flags));
#line 664
  if (((unsigned long )req->rq_state & 16UL) == 0UL) {
#line 664
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_NET_PENDING ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            664);
  } else {

  }
#line 665
  mod_rq_state(req, m, 0, 131104);
#line 666
  req->w.cb = & w_send_dblock;
#line 667
  drbd_queue_work(& (mdev->tconn)->sender_work, & req->w);
#line 670
  rcu_read_lock___0();
#line 671
  _________p1___0 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 671
  tmp___5 = debug_lockdep_rcu_enabled();
#line 671
  if (tmp___5 != 0 && ! __warned___0) {
#line 671
    tmp___6 = rcu_read_lock_held();
#line 671
    if (tmp___6 == 0 && 1) {
#line 671
      __warned___0 = 1;
#line 671
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                             671, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 671
  nc = _________p1___0;
#line 672
  p = (int )nc->max_epoch_size;
#line 673
  rcu_read_unlock___0();
#line 674
  if ((mdev->tconn)->current_tle_writes >= (unsigned int )p) {
#line 675
    start_new_tl_epoch(mdev->tconn);
  } else {

  }
#line 677
  goto ldv_52190;
  case 5U: 
#line 680
  mod_rq_state(req, m, 0, 32);
#line 681
  req->w.cb = & w_send_out_of_sync;
#line 682
  drbd_queue_work(& (mdev->tconn)->sender_work, & req->w);
#line 683
  goto ldv_52190;
  case 11U: ;
  case 6U: ;
  case 7U: 
#line 690
  mod_rq_state(req, m, 32, 0);
#line 691
  goto ldv_52190;
  case 8U: ;
#line 695
  if ((int )(req->master_bio)->bi_rw & 1 && ((unsigned long )req->rq_state & 98304UL) == 0UL) {
#line 699
    if (((unsigned long )req->rq_state & 16UL) != 0UL) {
#line 700
      mod_rq_state(req, m, 16, 256);
    } else {

    }
  } else {

  }
#line 706
  mod_rq_state(req, m, 32, 64);
#line 707
  goto ldv_52190;
  case 9U: 
#line 712
  mod_rq_state(req, m, 32, 128);
#line 713
  goto ldv_52190;
  case 10U: 
#line 717
  mod_rq_state(req, m, 16656, 128);
#line 720
  goto ldv_52190;
  case 15U: ;
#line 730
  if (((unsigned long )req->rq_state & 16UL) == 0UL) {
#line 730
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_NET_PENDING ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            730);
  } else {

  }
#line 731
  if (((unsigned long )req->rq_state & 65536UL) == 0UL) {
#line 731
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_EXP_WRITE_ACK ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            731);
  } else {

  }
#line 732
  mod_rq_state(req, m, 16, 384);
#line 733
  goto ldv_52190;
  case 14U: 
#line 736
  req->rq_state = req->rq_state | 512U;
  case 13U: ;
#line 738
  if (((unsigned long )req->rq_state & 65536UL) == 0UL) {
#line 738
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_EXP_WRITE_ACK ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            738);
  } else {

  }
#line 744
  goto ack_common;
  case 12U: ;
#line 746
  if (((unsigned long )req->rq_state & 32768UL) == 0UL) {
#line 746
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_EXP_RECEIVE_ACK ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            746);
  } else {

  }
  ack_common: ;
#line 751
  if (((unsigned long )req->rq_state & 16UL) == 0UL) {
#line 751
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_NET_PENDING ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            751);
  } else {

  }
#line 752
  mod_rq_state(req, m, 16, 256);
#line 753
  goto ldv_52190;
  case 16U: ;
#line 756
  if (((unsigned long )req->rq_state & 65536UL) == 0UL) {
#line 756
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_EXP_WRITE_ACK ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            756);
  } else {

  }
#line 761
  if (((unsigned long )req->rq_state & 16UL) == 0UL) {
#line 761
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_NET_PENDING ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            761);
  } else {

  }
#line 762
  req->rq_state = req->rq_state | 8192U;
#line 763
  if ((unsigned int )*((unsigned char *)req + 88UL) != 0U) {
#line 764
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 768
  goto ldv_52190;
  case 17U: 
#line 771
  mod_rq_state(req, m, 272, 0);
#line 772
  goto ldv_52190;
  case 26U: ;
#line 775
  if (((unsigned long )req->rq_state & 2UL) == 0UL) {
#line 776
    goto ldv_52190;
  } else {

  }
#line 777
  mod_rq_state(req, m, 16384, 0);
#line 778
  goto ldv_52190;
  case 27U: ;
#line 781
  if (((unsigned long )req->rq_state & 2UL) == 0UL) {
#line 782
    goto ldv_52190;
  } else {

  }
#line 784
  mod_rq_state(req, m, 16386, 1);
#line 788
  rv = 2;
#line 789
  if ((int )(req->master_bio)->bi_rw & 1) {
#line 790
    rv = 1;
  } else {

  }
#line 792
  _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 793
  req->w.cb = & w_restart_disk_io;
#line 794
  drbd_queue_work(& (mdev->tconn)->sender_work, & req->w);
#line 795
  goto ldv_52190;
  case 25U: ;
#line 799
  if (((unsigned long )req->rq_state & 2048UL) == 0UL && (unsigned long )req->w.cb == (unsigned long )((int (*)(struct drbd_work * ,
                                                                                                                int  ))0)) {
#line 800
    mod_rq_state(req, m, 16384, 0);
#line 801
    goto ldv_52190;
  } else {

  }
#line 809
  if (((unsigned long )req->rq_state & 256UL) == 0UL) {
#line 813
    mod_rq_state(req, m, 16384, 48);
#line 814
    if ((unsigned long )req->w.cb != (unsigned long )((int (*)(struct drbd_work * ,
                                                               int  ))0)) {
#line 815
      drbd_queue_work(& (mdev->tconn)->sender_work, & req->w);
#line 816
      rv = ((unsigned long )req->rq_state & 2048UL) != 0UL ? 1 : 2;
    } else {

    }
#line 818
    goto ldv_52190;
  } else {

  }
  case 18U: ;
#line 824
  if (((unsigned long )req->rq_state & 2048UL) == 0UL) {
#line 825
    goto ldv_52190;
  } else {

  }
#line 827
  if (((unsigned long )req->rq_state & 16UL) != 0UL) {
#line 831
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "FIXME (BARRIER_ACKED but pending)\n");
  } else {

  }
#line 837
  mod_rq_state(req, m, 16384, ((unsigned long )req->rq_state & 1008UL) != 0UL ? 128 : 0);
#line 839
  goto ldv_52190;
  case 19U: ;
#line 842
  if (((unsigned long )req->rq_state & 16UL) == 0UL) {
#line 842
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->rq_state & RQ_NET_PENDING ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            842);
  } else {

  }
#line 843
  mod_rq_state(req, m, 16, 384);
#line 844
  goto ldv_52190;
  }
  ldv_52190: ;
#line 847
  return (rv);
}
}
#line 857 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static bool drbd_may_do_local_read(struct drbd_conf *mdev , sector_t sector , int size ) 
{ 
  unsigned long sbnr ;
  unsigned long ebnr ;
  sector_t esector ;
  sector_t nr_sectors ;
  int tmp ;

  {
#line 862
  if ((unsigned int )*((unsigned char *)mdev + 749UL) == 16U) {
#line 863
    return (1);
  } else {

  }
#line 864
  if ((unsigned int )*((unsigned char *)mdev + 749UL) != 8U) {
#line 865
    return (0);
  } else {

  }
#line 866
  esector = ((sector_t )(size >> 9) + sector) - 1UL;
#line 867
  nr_sectors = drbd_get_capacity(mdev->this_bdev);
#line 868
  if (sector >= nr_sectors) {
#line 868
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( sector < nr_sectors ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            868);
  } else {

  }
#line 869
  if (esector >= nr_sectors) {
#line 869
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( esector < nr_sectors ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            869);
  } else {

  }
#line 871
  sbnr = sector >> 3;
#line 872
  ebnr = esector >> 3;
#line 874
  tmp = drbd_bm_count_bits(mdev, sbnr, ebnr);
#line 874
  return (tmp == 0);
}
}
#line 877 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static bool remote_due_to_read_balancing(struct drbd_conf *mdev , sector_t sector ,
                                         enum drbd_read_balancing rbm ) 
{ 
  struct backing_dev_info *bdi ;
  int stripe_shift ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 883
  switch ((unsigned int )rbm) {
  case 4U: 
#line 885
  bdi = & ((((mdev->ldev)->backing_bdev)->bd_disk)->queue)->backing_dev_info;
#line 886
  tmp = bdi_read_congested(bdi);
#line 886
  return (tmp != 0);
  case 3U: 
#line 888
  tmp___0 = atomic_read((atomic_t const   *)(& mdev->local_cnt));
#line 888
  tmp___1 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 888
  tmp___2 = atomic_read((atomic_t const   *)(& mdev->rs_pending_cnt));
#line 888
  return (tmp___0 > tmp___1 + tmp___2);
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 8U: ;
  case 9U: ;
  case 10U: 
#line 896
  stripe_shift = (int )((unsigned int )rbm + 10U);
#line 897
  return (((sector >> (stripe_shift + -9)) & 1UL) != 0UL);
  case 2U: 
#line 899
  tmp___3 = test_and_change_bit(22, (unsigned long volatile   *)(& mdev->flags));
#line 899
  return (tmp___3 != 0);
  case 1U: ;
#line 901
  return (1);
  case 0U: ;
  default: ;
#line 904
  return (0);
  }
}
}
#line 917 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void complete_conflicting_writes(struct drbd_request *req ) 
{ 
  wait_queue_t wait ;
  struct task_struct *tmp ;
  struct drbd_conf *mdev ;
  struct drbd_interval *i ;
  sector_t sector ;
  int size ;

  {
#line 919
  tmp = get_current();
#line 919
  wait.flags = 0U;
#line 919
  wait.private = (void *)tmp;
#line 919
  wait.func = & autoremove_wake_function;
#line 919
  wait.task_list.next = & wait.task_list;
#line 919
  wait.task_list.prev = & wait.task_list;
#line 920
  mdev = req->w.ldv_49807.mdev;
#line 922
  sector = req->i.sector;
#line 923
  size = (int )req->i.size;
#line 925
  i = drbd_find_overlap(& mdev->write_requests, sector, (unsigned int )size);
#line 926
  if ((unsigned long )i == (unsigned long )((struct drbd_interval *)0)) {
#line 927
    return;
  } else {

  }
  ldv_52263: 
#line 930
  prepare_to_wait(& mdev->misc_wait, & wait, 2);
#line 931
  i = drbd_find_overlap(& mdev->write_requests, sector, (unsigned int )size);
#line 932
  if ((unsigned long )i == (unsigned long )((struct drbd_interval *)0)) {
#line 933
    goto ldv_52262;
  } else {

  }
#line 935
  i->waiting = -1;
#line 936
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 937
  schedule();
#line 938
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 939
  goto ldv_52263;
  ldv_52262: 
#line 940
  finish_wait(& mdev->misc_wait, & wait);
#line 941
  return;
}
}
#line 944 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void maybe_pull_ahead(struct drbd_conf *mdev ) 
{ 
  struct drbd_tconn *tconn ;
  struct net_conf *nc ;
  bool congested ;
  enum drbd_on_congestion on_congestion ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  union drbd_state __ns ;
  union drbd_state __ns___0 ;

  {
#line 946
  tconn = mdev->tconn;
#line 948
  congested = 0;
#line 951
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 951
  tmp = debug_lockdep_rcu_enabled();
#line 951
  if (tmp != 0 && ! __warned) {
#line 951
    tmp___0 = rcu_read_lock_held();
#line 951
    if (tmp___0 == 0 && 1) {
#line 951
      __warned = 1;
#line 951
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                             951, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 951
  nc = _________p1;
#line 952
  on_congestion = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (enum drbd_on_congestion )nc->on_congestion : OC_BLOCK;
#line 953
  if ((unsigned int )on_congestion == 0U || tconn->agreed_pro_version <= 95) {
#line 955
    return;
  } else {

  }
#line 961
  tmp___1 = _get_ldev_if_state(mdev, D_UP_TO_DATE);
#line 961
  if (tmp___1 == 0) {
#line 962
    return;
  } else {

  }
#line 964
  if (nc->cong_fill != 0U) {
#line 964
    tmp___2 = atomic_read((atomic_t const   *)(& mdev->ap_in_flight));
#line 964
    if ((__u32 )tmp___2 >= nc->cong_fill) {
#line 966
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Congestion-fill threshold reached\n");
#line 967
      congested = 1;
    } else {

    }
  } else {

  }
#line 970
  if ((mdev->act_log)->used >= nc->cong_extents) {
#line 971
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Congestion-extents threshold reached\n");
#line 972
    congested = 1;
  } else {

  }
#line 975
  if ((int )congested) {
#line 977
    start_new_tl_epoch(mdev->tconn);
#line 979
    if ((unsigned int )on_congestion == 1U) {
#line 980
      __ns = drbd_read_state(mdev);
#line 980
      __ns.ldv_40024.conn = 22U;
#line 980
      _drbd_set_state(mdev, __ns, 0, 0);
    } else {
#line 982
      __ns___0 = drbd_read_state(mdev);
#line 982
      __ns___0.ldv_40024.conn = 1U;
#line 982
      _drbd_set_state(mdev, __ns___0, 0, 0);
    }
  } else {

  }
#line 984
  put_ldev(mdev);
#line 985
  return;
}
}
#line 996 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static bool do_remote_read(struct drbd_request *req ) 
{ 
  struct drbd_conf *mdev ;
  enum drbd_read_balancing rbm ;
  bool tmp ;
  int tmp___0 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;

  {
#line 998
  mdev = req->w.ldv_49807.mdev;
#line 1001
  if ((unsigned long )req->private_bio != (unsigned long )((struct bio *)0)) {
#line 1002
    tmp = drbd_may_do_local_read(mdev, req->i.sector, (int )req->i.size);
#line 1002
    if (tmp) {
#line 1002
      tmp___0 = 0;
    } else {
#line 1002
      tmp___0 = 1;
    }
#line 1002
    if (tmp___0) {
#line 1004
      bio_put(req->private_bio);
#line 1005
      req->private_bio = 0;
#line 1006
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 1010
  if (*((unsigned int *)mdev + 187UL) != 65536U) {
#line 1011
    return (0);
  } else {

  }
#line 1013
  if ((unsigned long )req->private_bio == (unsigned long )((struct bio *)0)) {
#line 1014
    return (1);
  } else {

  }
#line 1019
  rcu_read_lock___0();
#line 1020
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1020
  tmp___1 = debug_lockdep_rcu_enabled();
#line 1020
  if (tmp___1 != 0 && ! __warned) {
#line 1020
    tmp___2 = rcu_read_lock_held();
#line 1020
    if (tmp___2 == 0 && 1) {
#line 1020
      __warned = 1;
#line 1020
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                             1020, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1020
  rbm = (enum drbd_read_balancing )_________p1->read_balancing;
#line 1021
  rcu_read_unlock___0();
#line 1023
  if ((unsigned int )rbm == 0U && (unsigned long )req->private_bio != (unsigned long )((struct bio *)0)) {
#line 1024
    return (0);
  } else {

  }
#line 1026
  tmp___3 = remote_due_to_read_balancing(mdev, req->i.sector, rbm);
#line 1026
  if ((int )tmp___3) {
#line 1027
    if ((unsigned long )req->private_bio != (unsigned long )((struct bio *)0)) {
#line 1028
      bio_put(req->private_bio);
#line 1029
      req->private_bio = 0;
#line 1030
      put_ldev(mdev);
    } else {

    }
#line 1032
    return (1);
  } else {

  }
#line 1035
  return (0);
}
}
#line 1041 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static int drbd_process_write_request(struct drbd_request *req ) 
{ 
  struct drbd_conf *mdev ;
  int remote ;
  int send_oos ;
  bool tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;

  {
#line 1043
  mdev = req->w.ldv_49807.mdev;
#line 1046
  rcu_read_lock___0();
#line 1047
  tmp = drbd_should_do_remote(mdev->state);
#line 1047
  remote = (int )tmp;
#line 1048
  if (remote != 0) {
#line 1049
    maybe_pull_ahead(mdev);
#line 1050
    tmp___0 = drbd_should_do_remote(mdev->state);
#line 1050
    remote = (int )tmp___0;
  } else {

  }
#line 1052
  tmp___1 = drbd_should_send_out_of_sync(mdev->state);
#line 1052
  send_oos = (int )tmp___1;
#line 1053
  rcu_read_unlock___0();
#line 1061
  tmp___2 = __builtin_expect(req->i.size == 0U, 0L);
#line 1061
  if (tmp___2 != 0L) {
#line 1063
    if (((req->master_bio)->bi_rw & 4096UL) == 0UL) {
#line 1063
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( req->master_bio->bi_rw & REQ_FLUSH ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
              1063);
    } else {

    }
#line 1064
    if (remote != 0) {
#line 1065
      start_new_tl_epoch(mdev->tconn);
    } else {

    }
#line 1066
    return (0);
  } else {

  }
#line 1069
  if (remote == 0 && send_oos == 0) {
#line 1070
    return (0);
  } else {

  }
#line 1072
  if (remote != 0 && send_oos != 0) {
#line 1072
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !(remote && send_oos) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            1072);
  } else {

  }
#line 1074
  if (remote != 0) {
#line 1075
    _req_mod(req, TO_BE_SENT);
#line 1076
    _req_mod(req, QUEUE_FOR_NET_WRITE);
  } else {
#line 1077
    tmp___3 = __drbd_set_out_of_sync(mdev, req->i.sector, (int )req->i.size, "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                                     1077U);
#line 1077
    if (tmp___3 != 0) {
#line 1078
      _req_mod(req, QUEUE_FOR_SEND_OOS);
    } else {

    }
  }
#line 1080
  return (remote);
}
}
#line 1084 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
static void drbd_submit_req_private_bio(struct drbd_request *req ) 
{ 
  struct drbd_conf *mdev ;
  struct bio *bio ;
  int rw ;
  int tmp ;
  int tmp___0 ;

  {
#line 1086
  mdev = req->w.ldv_49807.mdev;
#line 1087
  bio = req->private_bio;
#line 1088
  rw = (int const   )bio->bi_rw & (int const   )8193;
#line 1090
  bio->bi_bdev = (mdev->ldev)->backing_bdev;
#line 1097
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1097
  if (tmp___0 != 0) {
#line 1098
    tmp = drbd_insert_fault(mdev, rw != 1 ? (rw == 0 ? 5U : 6U) : 4U);
#line 1098
    if (tmp != 0) {
#line 1102
      bio_endio(bio, -5);
    } else {
#line 1104
      generic_make_request(bio);
    }
#line 1105
    put_ldev(mdev);
  } else {
#line 1107
    bio_endio(bio, -5);
  }
#line 1108
  return;
}
}
#line 1110 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void __drbd_make_request(struct drbd_conf *mdev , struct bio *bio , unsigned long start_time ) 
{ 
  int rw ;
  struct bio_and_error m ;
  struct drbd_request *req ;
  bool no_remote ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  long tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;

  {
#line 1112
  rw = (int const   )bio->bi_rw & (int const   )8193;
#line 1113
  m.bio = 0;
#line 1113
  m.error = 0;
#line 1115
  no_remote = 0;
#line 1118
  req = drbd_req_new(mdev, bio);
#line 1119
  if ((unsigned long )req == (unsigned long )((struct drbd_request *)0)) {
#line 1120
    dec_ap_bio(mdev);
#line 1123
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "could not kmalloc() req\n");
#line 1124
    bio_endio(bio, -12);
#line 1125
    return;
  } else {

  }
#line 1127
  req->start_time = start_time;
#line 1129
  tmp = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1129
  if (tmp == 0) {
#line 1130
    bio_put(req->private_bio);
#line 1131
    req->private_bio = 0;
  } else {

  }
#line 1141
  if ((rw == 1 && (unsigned long )req->private_bio != (unsigned long )((struct bio *)0)) && req->i.size != 0U) {
#line 1141
    tmp___0 = constant_test_bit(18U, (unsigned long const volatile   *)(& mdev->flags));
#line 1141
    if (tmp___0 == 0) {
#line 1143
      req->rq_state = req->rq_state | 4096U;
#line 1144
      drbd_al_begin_io(mdev, & req->i);
    } else {

    }
  } else {

  }
#line 1147
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1148
  if (rw == 1) {
#line 1152
    complete_conflicting_writes(req);
  } else {

  }
#line 1157
  tmp___1 = drbd_suspended(mdev);
#line 1157
  if (tmp___1 != 0) {
#line 1159
    req->rq_state = req->rq_state | 8192U;
#line 1160
    if ((unsigned long )req->private_bio != (unsigned long )((struct bio *)0)) {
#line 1161
      bio_put(req->private_bio);
#line 1162
      req->private_bio = 0;
#line 1163
      put_ldev(mdev);
    } else {

    }
#line 1165
    goto out;
  } else {

  }
#line 1169
  _drbd_start_io_acct(mdev, req, bio);
#line 1174
  if (rw != 1) {
#line 1175
    tmp___2 = do_remote_read(req);
#line 1175
    if (tmp___2) {
#line 1175
      tmp___3 = 0;
    } else {
#line 1175
      tmp___3 = 1;
    }
#line 1175
    if (tmp___3 && (unsigned long )req->private_bio == (unsigned long )((struct bio *)0)) {
#line 1176
      goto nodata;
    } else {

    }
  } else {

  }
#line 1180
  tmp___4 = atomic_read((atomic_t const   *)(& (mdev->tconn)->current_tle_nr));
#line 1180
  req->epoch = (unsigned int )tmp___4;
#line 1184
  tmp___5 = __builtin_expect(req->i.size != 0U, 1L);
#line 1184
  if (tmp___5 != 0L) {
#line 1185
    if (rw == 1) {
#line 1186
      (mdev->tconn)->current_tle_writes = (mdev->tconn)->current_tle_writes + 1U;
    } else {

    }
#line 1188
    list_add_tail(& req->tl_requests, & (mdev->tconn)->transfer_log);
  } else {

  }
#line 1191
  if (rw == 1) {
#line 1192
    tmp___6 = drbd_process_write_request(req);
#line 1192
    if (tmp___6 == 0) {
#line 1193
      no_remote = 1;
    } else
#line 1197
    if ((unsigned long )req->private_bio == (unsigned long )((struct bio *)0)) {
#line 1198
      _req_mod(req, TO_BE_SENT);
#line 1199
      _req_mod(req, QUEUE_FOR_NET_READ);
    } else {
#line 1201
      no_remote = 1;
    }
  } else {

  }
#line 1204
  if ((unsigned long )req->private_bio != (unsigned long )((struct bio *)0)) {
#line 1206
    _req_mod(req, TO_BE_SUBMITTED);
#line 1208
    spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1209
    drbd_submit_req_private_bio(req);
#line 1210
    spin_lock_irq(& (mdev->tconn)->req_lock);
  } else
#line 1211
  if ((int )no_remote) {
    nodata: 
#line 1213
    tmp___7 = ___ratelimit(& drbd_ratelimit_state, "__drbd_make_request");
#line 1213
    if (tmp___7 != 0) {
#line 1214
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "IO ERROR: neither local nor remote data, sector %llu+%u\n",
              (unsigned long long )req->i.sector, req->i.size >> 9);
    } else {

    }
  } else {

  }
  out: 
#line 1221
  tmp___8 = drbd_req_put_completion_ref(req, & m, 1);
#line 1221
  if (tmp___8 != 0) {
#line 1222
    kref_put(& req->kref, & drbd_req_destroy);
  } else {

  }
#line 1223
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1225
  if ((unsigned long )m.bio != (unsigned long )((struct bio *)0)) {
#line 1226
    complete_master_bio(mdev, & m);
  } else {

  }
#line 1227
  return;
}
}
#line 1230 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void drbd_make_request(struct request_queue *q , struct bio *bio ) 
{ 
  struct drbd_conf *mdev ;
  unsigned long start_time ;

  {
#line 1232
  mdev = (struct drbd_conf *)q->queuedata;
#line 1235
  start_time = jiffies;
#line 1240
  if ((bio->bi_size & 511U) != 0U) {
#line 1240
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( IS_ALIGNED(bio->bi_size, 512) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
            1240);
  } else {

  }
#line 1242
  inc_ap_bio(mdev);
#line 1243
  __drbd_make_request(mdev, bio, start_time);
#line 1244
  return;
}
}
#line 1258 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
int drbd_merge_bvec(struct request_queue *q , struct bvec_merge_data *bvm , struct bio_vec *bvec ) 
{ 
  struct drbd_conf *mdev ;
  unsigned int bio_size ;
  int limit ;
  int backing_limit ;
  struct request_queue *b ;
  int _min1 ;
  int _min2 ;
  int tmp ;

  {
#line 1260
  mdev = (struct drbd_conf *)q->queuedata;
#line 1261
  bio_size = bvm->bi_size;
#line 1262
  limit = 1048576;
#line 1265
  if (bio_size != 0U) {
#line 1265
    tmp = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1265
    if (tmp != 0) {
#line 1266
      b = (((mdev->ldev)->backing_bdev)->bd_disk)->queue;
#line 1268
      if ((unsigned long )b->merge_bvec_fn != (unsigned long )((merge_bvec_fn *)0)) {
#line 1269
        backing_limit = (*(b->merge_bvec_fn))(b, bvm, bvec);
#line 1270
        _min1 = limit;
#line 1270
        _min2 = backing_limit;
#line 1270
        limit = _min1 < _min2 ? _min1 : _min2;
      } else {

      }
#line 1272
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 1274
  return (limit);
}
}
#line 1277 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
struct drbd_request *find_oldest_request(struct drbd_tconn *tconn ) 
{ 
  struct drbd_request *r ;
  struct list_head  const  *__mptr ;
  int tmp ;
  struct list_head  const  *__mptr___0 ;

  {
#line 1282
  __mptr = (struct list_head  const  *)tconn->transfer_log.next;
#line 1282
  r = (struct drbd_request *)__mptr + 0xffffffffffffff98UL;
#line 1282
  goto ldv_52338;
  ldv_52337: 
#line 1283
  tmp = atomic_read((atomic_t const   *)(& r->completion_ref));
#line 1283
  if (tmp != 0) {
#line 1284
    return (r);
  } else {

  }
#line 1282
  __mptr___0 = (struct list_head  const  *)r->tl_requests.next;
#line 1282
  r = (struct drbd_request *)__mptr___0 + 0xffffffffffffff98UL;
  ldv_52338: ;
#line 1282
  if ((unsigned long )(& r->tl_requests) != (unsigned long )(& tconn->transfer_log)) {
#line 1283
    goto ldv_52337;
  } else {

  }

#line 1286
  return (0);
}
}
#line 1289 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void request_timer_fn(unsigned long data ) 
{ 
  struct drbd_conf *mdev ;
  struct drbd_tconn *tconn ;
  struct drbd_request *req ;
  struct net_conf *nc ;
  unsigned long ent ;
  unsigned long dt ;
  unsigned long et ;
  unsigned long nt ;
  unsigned long now ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  struct disk_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  unsigned long __x ;
  unsigned long __y ;
  unsigned long _min1 ;
  unsigned long _min2 ;
  unsigned long tmp___4 ;
  unsigned long tmp___5 ;
  union drbd_state __ns ;

  {
#line 1291
  mdev = (struct drbd_conf *)data;
#line 1292
  tconn = mdev->tconn;
#line 1295
  ent = 0UL;
#line 1295
  dt = 0UL;
#line 1298
  rcu_read_lock___0();
#line 1299
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 1299
  tmp = debug_lockdep_rcu_enabled();
#line 1299
  if (tmp != 0 && ! __warned) {
#line 1299
    tmp___0 = rcu_read_lock_held();
#line 1299
    if (tmp___0 == 0 && 1) {
#line 1299
      __warned = 1;
#line 1299
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                             1299, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1299
  nc = _________p1;
#line 1300
  if ((unsigned long )nc != (unsigned long )((struct net_conf *)0) && (int )mdev->state.ldv_49522.conn > 8) {
#line 1301
    ent = (unsigned long )(((nc->timeout * 250U) / 10U) * nc->ko_count);
  } else {

  }
#line 1303
  tmp___3 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1303
  if (tmp___3 != 0) {
#line 1304
    _________p1___0 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1304
    tmp___1 = debug_lockdep_rcu_enabled();
#line 1304
    if (tmp___1 != 0 && ! __warned___0) {
#line 1304
      tmp___2 = rcu_read_lock_held();
#line 1304
      if (tmp___2 == 0 && 1) {
#line 1304
        __warned___0 = 1;
#line 1304
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared",
                               1304, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 1304
    dt = (unsigned long )((_________p1___0->disk_timeout * 250U) / 10U);
#line 1305
    put_ldev(mdev);
  } else {

  }
#line 1307
  rcu_read_unlock___0();
#line 1309
  __x = dt;
#line 1309
  __y = ent;
#line 1309
  if (__x != 0UL) {
#line 1309
    if (__y != 0UL) {
#line 1309
      _min1 = __x;
#line 1309
      _min2 = __y;
#line 1309
      tmp___4 = _min1 < _min2 ? _min1 : _min2;
    } else {
#line 1309
      tmp___4 = __x;
    }
#line 1309
    tmp___5 = tmp___4;
  } else {
#line 1309
    tmp___5 = __y;
  }
#line 1309
  et = tmp___5;
#line 1311
  if (et == 0UL) {
#line 1312
    return;
  } else {

  }
#line 1314
  now = jiffies;
#line 1316
  spin_lock_irq(& tconn->req_lock);
#line 1317
  req = find_oldest_request(tconn);
#line 1318
  if ((unsigned long )req == (unsigned long )((struct drbd_request *)0)) {
#line 1319
    spin_unlock_irq(& tconn->req_lock);
#line 1320
    mod_timer(& mdev->request_timer, now + et);
#line 1321
    return;
  } else {

  }
#line 1342
  if (((ent != 0UL && ((unsigned long )req->rq_state & 16UL) != 0UL) && ((1 != 0 && 1 != 0) && (long )(req->start_time + ent) - (long )now < 0L)) && (((1 == 0 || 1 == 0) || (long )now - (long )tconn->last_reconnect_jif < 0L) || ((1 == 0 || 1 == 0) || (long )(tconn->last_reconnect_jif + ent) - (long )now < 0L))) {
#line 1343
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Remote failed to finish a request within ko-count * timeout\n");
#line 1344
    __ns = drbd_read_state(mdev);
#line 1344
    __ns.ldv_40024.conn = 3U;
#line 1344
    _drbd_set_state(mdev, __ns, 3, 0);
  } else {

  }
#line 1348
  if ((((dt != 0UL && (int )req->rq_state & 1) && (unsigned long )req->w.ldv_49807.mdev == (unsigned long )mdev) && ((1 != 0 && 1 != 0) && (long )(req->start_time + dt) - (long )now < 0L)) && (((1 == 0 || 1 == 0) || (long )now - (long )mdev->last_reattach_jif < 0L) || ((1 == 0 || 1 == 0) || (long )(mdev->last_reattach_jif + dt) - (long )now < 0L))) {
#line 1349
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local backing device failed to meet the disk-timeout\n");
#line 1350
    __drbd_chk_io_error____1(mdev, DRBD_FORCE_DETACH, "request_timer_fn");
  } else {

  }
#line 1352
  nt = ((1 == 0 || 1 == 0) || (long )(req->start_time + et) - (long )now >= 0L ? req->start_time : now) + et;
#line 1353
  spin_unlock_irq(& tconn->req_lock);
#line 1354
  mod_timer(& mdev->request_timer, nt);
#line 1355
  return;
}
}
#line 1357 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_lock_153(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1362
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 1364
  mutex_lock(ldv_func_arg1);
#line 1365
  return;
}
}
#line 1367 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_unlock_154(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1372
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 1374
  mutex_unlock(ldv_func_arg1);
#line 1375
  return;
}
}
#line 1377 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_lock_155(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1382
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 1384
  mutex_lock(ldv_func_arg1);
#line 1385
  return;
}
}
#line 1387 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
int ldv_mutex_trylock_156(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 1392
  tmp = mutex_trylock(ldv_func_arg1);
#line 1392
  ldv_func_res = tmp;
#line 1394
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 1394
  return (tmp___0);
#line 1396
  return (ldv_func_res);
}
}
#line 1399 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_unlock_157(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1404
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 1406
  mutex_unlock(ldv_func_arg1);
#line 1407
  return;
}
}
#line 1409 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_lock_158(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1414
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1416
  mutex_lock(ldv_func_arg1);
#line 1417
  return;
}
}
#line 1419 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_unlock_159(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1424
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1426
  mutex_unlock(ldv_func_arg1);
#line 1427
  return;
}
}
#line 1429 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_lock_160(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1434
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1436
  mutex_lock(ldv_func_arg1);
#line 1437
  return;
}
}
#line 1439 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_unlock_161(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1444
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1446
  mutex_unlock(ldv_func_arg1);
#line 1447
  return;
}
}
#line 1449 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_lock_162(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1454
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1456
  mutex_lock(ldv_func_arg1);
#line 1457
  return;
}
}
#line 1459 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_req.c.prepared"
void ldv_mutex_unlock_163(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1464
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1466
  mutex_unlock(ldv_func_arg1);
#line 1467
  return;
}
}
#line 13 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/cmpxchg.h"
extern void __cmpxchg_wrong_size(void) ;
#line 209 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic.h"
__inline static int atomic_cmpxchg(atomic_t *v , int old , int new ) 
{ 
  int __ret ;
  int __old ;
  int __new ;
  u8 volatile   *__ptr ;
  u16 volatile   *__ptr___0 ;
  u32 volatile   *__ptr___1 ;
  u64 volatile   *__ptr___2 ;

  {
#line 211
  __old = old;
#line 211
  __new = new;
#line 211
  switch (4UL) {
  case 1UL: 
#line 211
  __ptr = (u8 volatile   *)(& v->counter);
#line 211
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgb %2,%1": "=a" (__ret),
                       "+m" (*__ptr): "q" (__new), "0" (__old): "memory");
#line 211
  goto ldv_5490;
  case 2UL: 
#line 211
  __ptr___0 = (u16 volatile   *)(& v->counter);
#line 211
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgw %2,%1": "=a" (__ret),
                       "+m" (*__ptr___0): "r" (__new), "0" (__old): "memory");
#line 211
  goto ldv_5490;
  case 4UL: 
#line 211
  __ptr___1 = (u32 volatile   *)(& v->counter);
#line 211
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgl %2,%1": "=a" (__ret),
                       "+m" (*__ptr___1): "r" (__new), "0" (__old): "memory");
#line 211
  goto ldv_5490;
  case 8UL: 
#line 211
  __ptr___2 = (u64 volatile   *)(& v->counter);
#line 211
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; cmpxchgq %2,%1": "=a" (__ret),
                       "+m" (*__ptr___2): "r" (__new), "0" (__old): "memory");
#line 211
  goto ldv_5490;
  default: 
#line 211
  __cmpxchg_wrong_size();
  }
  ldv_5490: ;
#line 211
  return (__ret);
}
}
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_178(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_176(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_179(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_181(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_183(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_185(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_lock_175(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_177(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_180(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_182(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_184(struct mutex *ldv_func_arg1 ) ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info___4(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6287;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6287;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6287;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6287;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6287: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock___4(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info___4();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock___4(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info___4();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock___4(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock___4();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock___4(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock___4();
#line 763
  return;
}
}
#line 6 "include/linux/crc32c.h"
extern u32 crc32c(u32  , void const   * , unsigned int  ) ;
#line 254 "include/linux/lru_cache.h"
extern void lc_reset(struct lru_cache * ) ;
#line 257
extern void lc_del(struct lru_cache * , struct lc_element * ) ;
#line 259
extern struct lc_element *lc_try_get(struct lru_cache * , unsigned int  ) ;
#line 261
extern struct lc_element *lc_get(struct lru_cache * , unsigned int  ) ;
#line 262
extern unsigned int lc_put(struct lru_cache * , struct lc_element * ) ;
#line 263
extern void lc_committed(struct lru_cache * ) ;
#line 279 "include/linux/lru_cache.h"
__inline static int lc_try_lock_for_transaction(struct lru_cache *lc ) 
{ 
  int tmp ;

  {
#line 281
  tmp = test_and_set_bit(2, (unsigned long volatile   *)(& lc->flags));
#line 281
  return (tmp == 0);
}
}
#line 299 "include/linux/lru_cache.h"
__inline static void lc_unlock(struct lru_cache *lc ) 
{ 


  {
#line 301
  clear_bit(1, (unsigned long volatile   *)(& lc->flags));
#line 302
  clear_bit_unlock(2U, (unsigned long volatile   *)(& lc->flags));
#line 303
  return;
}
}
#line 305
extern bool lc_is_used(struct lru_cache * , unsigned int  ) ;
#line 310
extern struct lc_element *lc_element_by_index(struct lru_cache * , unsigned int  ) ;
#line 1454 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
void *drbd_md_get_buffer(struct drbd_conf *mdev ) ;
#line 1456
int drbd_md_sync_page_io(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ,
                         sector_t sector , int rw ) ;
#line 1597
void drbd_al_shrink(struct drbd_conf *mdev ) ;
#line 1614
void drbd_bcast_event(struct drbd_conf *mdev , struct sib_info  const  *sib ) ;
#line 1675 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void __drbd_chk_io_error____2(struct drbd_conf *mdev , enum drbd_force_detach_flags df ,
                                              char const   *where ) 
{ 
  enum drbd_io_error_p ep ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  union drbd_state __ns ;
  union drbd_state __ns___0 ;

  {
#line 1681
  rcu_read_lock___4();
#line 1682
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1682
  tmp = debug_lockdep_rcu_enabled();
#line 1682
  if (tmp != 0 && ! __warned) {
#line 1682
    tmp___0 = rcu_read_lock_held();
#line 1682
    if (tmp___0 == 0 && 1) {
#line 1682
      __warned = 1;
#line 1682
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1682, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1682
  ep = (enum drbd_io_error_p )_________p1->on_io_error;
#line 1683
  rcu_read_unlock___4();
#line 1684
  switch ((unsigned int )ep) {
  case 0U: ;
#line 1686
  if ((unsigned int )df == 0U || (unsigned int )df == 1U) {
#line 1687
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "__drbd_chk_io_error_");
#line 1687
    if (tmp___1 != 0) {
#line 1688
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s.\n",
              where);
    } else {

    }
#line 1689
    if ((int )mdev->state.ldv_49522.disk > 4) {
#line 1690
      __ns = drbd_read_state(mdev);
#line 1690
      __ns.ldv_40024.disk = 4U;
#line 1690
      _drbd_set_state(mdev, __ns, CS_HARD, 0);
    } else {

    }
#line 1691
    goto ldv_50786;
  } else {

  }
  case 2U: ;
  case 1U: 
#line 1716
  set_bit(12U, (unsigned long volatile   *)(& mdev->flags));
#line 1717
  if ((unsigned int )df == 0U) {
#line 1718
    set_bit(13U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1719
  if ((unsigned int )df == 3U) {
#line 1720
    set_bit(14U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1721
  if ((int )mdev->state.ldv_49522.disk > 2) {
#line 1722
    __ns___0 = drbd_read_state(mdev);
#line 1722
    __ns___0.ldv_40024.disk = 2U;
#line 1722
    _drbd_set_state(mdev, __ns___0, CS_HARD, 0);
#line 1723
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s. Detaching...\n",
            where);
  } else {

  }
#line 1726
  goto ldv_50786;
  }
  ldv_50786: ;
#line 1729
  return;
}
}
#line 1739 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_chk_io_error____0(struct drbd_conf *mdev , int error , enum drbd_force_detach_flags forcedetach ,
                                            char const   *where ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 1742
  if (error != 0) {
#line 1744
    tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 1744
    flags = _raw_spin_lock_irqsave(tmp);
#line 1745
    __drbd_chk_io_error____2(mdev, forcedetach, where);
#line 1746
    spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
  } else {

  }
#line 1748
  return;
}
}
#line 1770 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_md_first_sector(struct drbd_backing_dev *bdev ) 
{ 
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  sector_t tmp___1 ;

  {
#line 1774
  rcu_read_lock___4();
#line 1775
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1775
  tmp = debug_lockdep_rcu_enabled();
#line 1775
  if (tmp != 0 && ! __warned) {
#line 1775
    tmp___0 = rcu_read_lock_held();
#line 1775
    if (tmp___0 == 0 && 1) {
#line 1775
      __warned = 1;
#line 1775
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1775, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1775
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1776
  rcu_read_unlock___4();
#line 1778
  tmp___1 = _drbd_md_first_sector(meta_dev_idx, bdev);
#line 1778
  return (tmp___1);
}
}
#line 1785 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_md_last_sector___0(struct drbd_backing_dev *bdev ) 
{ 
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 1789
  rcu_read_lock___4();
#line 1790
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1790
  tmp = debug_lockdep_rcu_enabled();
#line 1790
  if (tmp != 0 && ! __warned) {
#line 1790
    tmp___0 = rcu_read_lock_held();
#line 1790
    if (tmp___0 == 0 && 1) {
#line 1790
      __warned = 1;
#line 1790
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1790, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1790
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1791
  rcu_read_unlock___4();
#line 1793
  switch (meta_dev_idx) {
  case -1: ;
  case -3: ;
#line 1796
  return ((sector_t )(bdev->md.md_offset + 7ULL));
  case -2: ;
  default: ;
#line 1799
  return ((sector_t )(bdev->md.md_offset + (u64 )bdev->md.md_size_sect));
  }
}
}
#line 1887 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_queue_work_front(struct drbd_work_queue *q , struct drbd_work *w ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 1890
  tmp = spinlock_check(& q->q_lock);
#line 1890
  flags = _raw_spin_lock_irqsave(tmp);
#line 1891
  list_add(& w->list, & q->q);
#line 1892
  spin_unlock_irqrestore(& q->q_lock, flags);
#line 1893
  __wake_up(& q->q_wait, 3U, 1, 0);
#line 1894
  return;
}
}
#line 195 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int al_write_transaction(struct drbd_conf *mdev ) ;
#line 197 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void *drbd_md_get_buffer(struct drbd_conf *mdev ) 
{ 
  int r ;
  wait_queue_t __wait ;
  struct task_struct *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;

  {
#line 201
  r = atomic_cmpxchg(& mdev->md_io_in_use, 0, 1);
#line 201
  if (r == 0 || (int )mdev->state.ldv_49522.disk <= 2) {
#line 201
    goto ldv_51127;
  } else {

  }
#line 201
  tmp = get_current();
#line 201
  __wait.flags = 0U;
#line 201
  __wait.private = (void *)tmp;
#line 201
  __wait.func = & autoremove_wake_function;
#line 201
  __wait.task_list.next = & __wait.task_list;
#line 201
  __wait.task_list.prev = & __wait.task_list;
  ldv_51130: 
#line 201
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 201
  r = atomic_cmpxchg(& mdev->md_io_in_use, 0, 1);
#line 201
  if (r == 0 || (int )mdev->state.ldv_49522.disk <= 2) {
#line 201
    goto ldv_51129;
  } else {

  }
#line 201
  schedule();
#line 201
  goto ldv_51130;
  ldv_51129: 
#line 201
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_51127: ;
#line 205
  if (r == 0) {
#line 205
    tmp___0 = lowmem_page_address((struct page  const  *)mdev->md_io_page);
#line 205
    tmp___1 = tmp___0;
  } else {
#line 205
    tmp___1 = 0;
  }
#line 205
  return (tmp___1);
}
}
#line 208 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_md_put_buffer(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 210
  tmp = atomic_dec_and_test(& mdev->md_io_in_use);
#line 210
  if (tmp != 0) {
#line 211
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 212
  return;
}
}
#line 214 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void wait_until_done_or_force_detached(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ,
                                       unsigned int *done ) 
{ 
  long dt ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  long __ret ;
  wait_queue_t __wait ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 219
  rcu_read_lock___4();
#line 220
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 220
  tmp = debug_lockdep_rcu_enabled();
#line 220
  if (tmp != 0 && ! __warned) {
#line 220
    tmp___0 = rcu_read_lock_held();
#line 220
    if (tmp___0 == 0 && 1) {
#line 220
      __warned = 1;
#line 220
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                             220, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 220
  dt = (long )_________p1->disk_timeout;
#line 221
  rcu_read_unlock___4();
#line 222
  dt = (dt * 250L) / 10L;
#line 223
  if (dt == 0L) {
#line 224
    dt = 9223372036854775807L;
  } else {

  }
#line 226
  __ret = dt;
#line 226
  if (*done == 0U) {
#line 226
    tmp___3 = constant_test_bit(14U, (unsigned long const volatile   *)(& mdev->flags));
#line 226
    if (tmp___3 == 0) {
#line 226
      tmp___1 = get_current();
#line 226
      __wait.flags = 0U;
#line 226
      __wait.private = (void *)tmp___1;
#line 226
      __wait.func = & autoremove_wake_function;
#line 226
      __wait.task_list.next = & __wait.task_list;
#line 226
      __wait.task_list.prev = & __wait.task_list;
      ldv_51146: 
#line 226
      prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 226
      if (*done != 0U) {
#line 226
        goto ldv_51145;
      } else {
#line 226
        tmp___2 = constant_test_bit(14U, (unsigned long const volatile   *)(& mdev->flags));
#line 226
        if (tmp___2 != 0) {
#line 226
          goto ldv_51145;
        } else {

        }
      }
#line 226
      __ret = schedule_timeout(__ret);
#line 226
      if (__ret == 0L) {
#line 226
        goto ldv_51145;
      } else {

      }
#line 226
      goto ldv_51146;
      ldv_51145: 
#line 226
      finish_wait(& mdev->misc_wait, & __wait);
    } else {

    }
  } else {

  }
#line 226
  dt = __ret;
#line 228
  if (dt == 0L) {
#line 229
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "meta-data IO operation timed out\n");
#line 230
    drbd_chk_io_error____0(mdev, 1, DRBD_FORCE_DETACH, "wait_until_done_or_force_detached");
  } else {

  }
#line 232
  return;
}
}
#line 234 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int _drbd_md_sync_page_io(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ,
                                 struct page *page , sector_t sector , int rw , int size ) 
{ 
  struct bio *bio ;
  int err ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 242
  mdev->md_io.done = 0U;
#line 243
  mdev->md_io.error = -19;
#line 245
  if (rw & 1) {
#line 245
    tmp = constant_test_bit(7U, (unsigned long const volatile   *)(& mdev->flags));
#line 245
    if (tmp == 0) {
#line 246
      rw = rw | 6144;
    } else {

    }
  } else {

  }
#line 247
  rw = rw | 16;
#line 249
  bio = bio_alloc_drbd(16U);
#line 250
  bio->bi_bdev = bdev->md_bdev;
#line 251
  bio->bi_sector = sector;
#line 252
  err = -5;
#line 253
  tmp___0 = bio_add_page(bio, page, (unsigned int )size, 0U);
#line 253
  if (tmp___0 != size) {
#line 254
    goto out;
  } else {

  }
#line 255
  bio->bi_private = (void *)(& mdev->md_io);
#line 256
  bio->bi_end_io = & drbd_md_io_complete;
#line 257
  bio->bi_rw = (unsigned long )rw;
#line 259
  tmp___1 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 259
  if (tmp___1 == 0) {
#line 260
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED: get_ldev_if_state() == 1 in _drbd_md_sync_page_io()\n");
#line 261
    err = -19;
#line 262
    goto out;
  } else {

  }
#line 265
  atomic_inc(& bio->bi_cnt);
#line 266
  atomic_inc(& mdev->md_io_in_use);
#line 267
  tmp___2 = drbd_insert_fault(mdev, rw & 1 ? 0U : 1U);
#line 267
  if (tmp___2 != 0) {
#line 268
    bio_endio(bio, -5);
  } else {
#line 270
    submit_bio(rw, bio);
  }
#line 271
  wait_until_done_or_force_detached(mdev, bdev, & mdev->md_io.done);
#line 272
  if ((int )bio->bi_flags & 1) {
#line 273
    err = mdev->md_io.error;
  } else {

  }
  out: 
#line 276
  bio_put(bio);
#line 277
  return (err);
}
}
#line 280 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
int drbd_md_sync_page_io(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ,
                         sector_t sector , int rw ) 
{ 
  int err ;
  struct page *iop ;
  int tmp ;
  long tmp___0 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___1 ;
  struct task_struct *tmp___2 ;
  long tmp___3 ;
  struct task_struct *tmp___4 ;
  struct task_struct *tmp___5 ;
  sector_t tmp___6 ;
  sector_t tmp___7 ;

  {
#line 284
  iop = mdev->md_io_page;
#line 286
  tmp = atomic_read((atomic_t const   *)(& mdev->md_io_in_use));
#line 286
  if (tmp != 1) {
#line 286
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( atomic_read(&mdev->md_io_in_use) == 1 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
            286);
  } else {

  }
#line 288
  tmp___0 = __builtin_expect((unsigned long )bdev->md_bdev == (unsigned long )((struct block_device *)0),
                             0L);
#line 288
  if (tmp___0 != 0L) {
#line 288
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"),
                         "i" (288), "i" (12UL));
    ldv_51168: ;
#line 288
    goto ldv_51168;
  } else {

  }
#line 290
  descriptor.modname = "drbd";
#line 290
  descriptor.function = "drbd_md_sync_page_io";
#line 290
  descriptor.filename = "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared";
#line 290
  descriptor.format = "meta_data io: %s [%d]:%s(,%llus,%s)\n";
#line 290
  descriptor.lineno = 292U;
#line 290
  descriptor.flags = 0U;
#line 290
  tmp___3 = __builtin_expect((long )descriptor.flags & 1L, 0L);
#line 290
  if (tmp___3 != 0L) {
#line 290
    tmp___1 = get_current();
#line 290
    tmp___2 = get_current();
#line 290
    __dynamic_dev_dbg(& descriptor, (struct device  const  *)(& (mdev->vdisk)->part0.__dev),
                      "meta_data io: %s [%d]:%s(,%llus,%s)\n", (char *)(& tmp___2->comm),
                      tmp___1->pid, "drbd_md_sync_page_io", (unsigned long long )sector,
                      rw & 1 ? (char *)"WRITE" : (char *)"READ");
  } else {

  }
#line 294
  tmp___6 = drbd_md_first_sector(bdev);
#line 294
  if (tmp___6 > sector) {
#line 296
    tmp___4 = get_current();
#line 296
    tmp___5 = get_current();
#line 296
    dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s [%d]:%s(,%llus,%s) out of range md access!\n",
              (char *)(& tmp___5->comm), tmp___4->pid, "drbd_md_sync_page_io", (unsigned long long )sector,
              rw & 1 ? (char *)"WRITE" : (char *)"READ");
  } else {
#line 294
    tmp___7 = drbd_md_last_sector___0(bdev);
#line 294
    if (sector + 7UL > tmp___7) {
#line 296
      tmp___4 = get_current();
#line 296
      tmp___5 = get_current();
#line 296
      dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s [%d]:%s(,%llus,%s) out of range md access!\n",
                (char *)(& tmp___5->comm), tmp___4->pid, "drbd_md_sync_page_io", (unsigned long long )sector,
                rw & 1 ? (char *)"WRITE" : (char *)"READ");
    } else {

    }
  }
#line 300
  err = _drbd_md_sync_page_io(mdev, bdev, iop, sector, rw, 4096);
#line 301
  if (err != 0) {
#line 302
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_md_sync_page_io(,%llus,%s) failed with error %d\n",
            (unsigned long long )sector, rw & 1 ? (char *)"WRITE" : (char *)"READ",
            err);
  } else {

  }
#line 305
  return (err);
}
}
#line 308 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static struct lc_element *_al_get(struct drbd_conf *mdev , unsigned int enr ) 
{ 
  struct lc_element *al_ext ;
  struct lc_element *tmp ;
  int wake ;
  struct bm_extent *bm_ext ;
  struct lc_element  const  *__mptr ;
  int tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;

  {
#line 314
  spin_lock_irq(& mdev->al_lock);
#line 315
  tmp = lc_find(mdev->resync, enr / 4U);
#line 316
  tmp___2 = __builtin_expect((unsigned long )tmp != (unsigned long )((struct lc_element *)0),
                             0L);
#line 316
  if (tmp___2 != 0L) {
#line 317
    __mptr = (struct lc_element  const  *)tmp;
#line 317
    bm_ext = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
#line 318
    tmp___1 = constant_test_bit(0U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 318
    if (tmp___1 != 0) {
#line 319
      tmp___0 = test_and_set_bit(2, (unsigned long volatile   *)(& bm_ext->flags));
#line 319
      wake = tmp___0 == 0;
#line 320
      spin_unlock_irq(& mdev->al_lock);
#line 321
      if (wake != 0) {
#line 322
        __wake_up(& mdev->al_wait, 3U, 1, 0);
      } else {

      }
#line 323
      return (0);
    } else {

    }
  } else {

  }
#line 326
  al_ext = lc_get(mdev->act_log, enr);
#line 327
  spin_unlock_irq(& mdev->al_lock);
#line 328
  return (al_ext);
}
}
#line 331 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_al_begin_io(struct drbd_conf *mdev , struct drbd_interval *i ) 
{ 
  unsigned int first ;
  unsigned int last ;
  unsigned int enr ;
  bool locked ;
  int tmp ;
  struct lc_element *tmp___0 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___1 ;
  struct lc_element *tmp___2 ;
  int tmp___3 ;
  wait_queue_t __wait___0 ;
  struct task_struct *tmp___4 ;
  int tmp___5 ;
  bool write_al_updates ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___6 ;
  int tmp___7 ;

  {
#line 335
  first = (unsigned int )(i->sector >> 13);
#line 336
  last = i->size != 0U ? (unsigned int )(((i->sector + (sector_t )(i->size >> 9)) - 1UL) >> 13) : first;
#line 338
  locked = 0;
#line 341
  if (first > last) {
#line 341
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( first <= last ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
            341);
  } else {

  }
#line 342
  tmp = atomic_read((atomic_t const   *)(& mdev->local_cnt));
#line 342
  if (tmp <= 0) {
#line 342
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( atomic_read(&mdev->local_cnt) > 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
            342);
  } else {

  }
#line 344
  enr = first;
#line 344
  goto ldv_51194;
  ldv_51193: 
#line 345
  tmp___0 = _al_get(mdev, enr);
#line 345
  if ((unsigned long )tmp___0 != (unsigned long )((struct lc_element *)0)) {
#line 345
    goto ldv_51189;
  } else {

  }
#line 345
  tmp___1 = get_current();
#line 345
  __wait.flags = 0U;
#line 345
  __wait.private = (void *)tmp___1;
#line 345
  __wait.func = & autoremove_wake_function;
#line 345
  __wait.task_list.next = & __wait.task_list;
#line 345
  __wait.task_list.prev = & __wait.task_list;
  ldv_51192: 
#line 345
  prepare_to_wait(& mdev->al_wait, & __wait, 2);
#line 345
  tmp___2 = _al_get(mdev, enr);
#line 345
  if ((unsigned long )tmp___2 != (unsigned long )((struct lc_element *)0)) {
#line 345
    goto ldv_51191;
  } else {

  }
#line 345
  schedule();
#line 345
  goto ldv_51192;
  ldv_51191: 
#line 345
  finish_wait(& mdev->al_wait, & __wait);
  ldv_51189: 
#line 344
  enr = enr + 1U;
  ldv_51194: ;
#line 344
  if (enr <= last) {
#line 345
    goto ldv_51193;
  } else {

  }

#line 350
  if ((mdev->act_log)->pending_changes == 0U) {
#line 350
    goto ldv_51196;
  } else {
#line 350
    tmp___3 = lc_try_lock_for_transaction(mdev->act_log);
#line 350
    locked = tmp___3 != 0;
#line 350
    if ((int )locked) {
#line 350
      goto ldv_51196;
    } else {

    }
  }
#line 350
  tmp___4 = get_current();
#line 350
  __wait___0.flags = 0U;
#line 350
  __wait___0.private = (void *)tmp___4;
#line 350
  __wait___0.func = & autoremove_wake_function;
#line 350
  __wait___0.task_list.next = & __wait___0.task_list;
#line 350
  __wait___0.task_list.prev = & __wait___0.task_list;
  ldv_51199: 
#line 350
  prepare_to_wait(& mdev->al_wait, & __wait___0, 2);
#line 350
  if ((mdev->act_log)->pending_changes == 0U) {
#line 350
    goto ldv_51198;
  } else {
#line 350
    tmp___5 = lc_try_lock_for_transaction(mdev->act_log);
#line 350
    locked = tmp___5 != 0;
#line 350
    if ((int )locked) {
#line 350
      goto ldv_51198;
    } else {

    }
  }
#line 350
  schedule();
#line 350
  goto ldv_51199;
  ldv_51198: 
#line 350
  finish_wait(& mdev->al_wait, & __wait___0);
  ldv_51196: ;
#line 354
  if ((int )locked) {
#line 364
    if ((mdev->act_log)->pending_changes != 0U) {
#line 367
      rcu_read_lock___4();
#line 368
      _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 368
      tmp___6 = debug_lockdep_rcu_enabled();
#line 368
      if (tmp___6 != 0 && ! __warned) {
#line 368
        tmp___7 = rcu_read_lock_held();
#line 368
        if (tmp___7 == 0 && 1) {
#line 368
          __warned = 1;
#line 368
          lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                                 368, "suspicious rcu_dereference_check() usage");
        } else {

        }
      } else {

      }
#line 368
      write_al_updates = (int )((signed char )_________p1->al_updates) != 0;
#line 369
      rcu_read_unlock___4();
#line 371
      if ((int )write_al_updates) {
#line 372
        al_write_transaction(mdev);
#line 373
        mdev->al_writ_cnt = mdev->al_writ_cnt + 1U;
      } else {

      }
#line 376
      spin_lock_irq(& mdev->al_lock);
#line 381
      lc_committed(mdev->act_log);
#line 382
      spin_unlock_irq(& mdev->al_lock);
    } else {

    }
#line 384
    lc_unlock(mdev->act_log);
#line 385
    __wake_up(& mdev->al_wait, 3U, 1, 0);
  } else {

  }
#line 387
  return;
}
}
#line 389 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_al_complete_io(struct drbd_conf *mdev , struct drbd_interval *i ) 
{ 
  unsigned int first ;
  unsigned int last ;
  unsigned int enr ;
  struct lc_element *extent ;
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 393
  first = (unsigned int )(i->sector >> 13);
#line 394
  last = i->size != 0U ? (unsigned int )(((i->sector + (sector_t )(i->size >> 9)) - 1UL) >> 13) : first;
#line 399
  if (first > last) {
#line 399
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( first <= last ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
            399);
  } else {

  }
#line 400
  tmp = spinlock_check(& mdev->al_lock);
#line 400
  flags = _raw_spin_lock_irqsave(tmp);
#line 402
  enr = first;
#line 402
  goto ldv_51218;
  ldv_51217: 
#line 403
  extent = lc_find(mdev->act_log, enr);
#line 404
  if ((unsigned long )extent == (unsigned long )((struct lc_element *)0)) {
#line 405
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "al_complete_io() called on inactive extent %u\n",
            enr);
#line 406
    goto ldv_51216;
  } else {

  }
#line 408
  lc_put(mdev->act_log, extent);
  ldv_51216: 
#line 402
  enr = enr + 1U;
  ldv_51218: ;
#line 402
  if (enr <= last) {
#line 403
    goto ldv_51217;
  } else {

  }
#line 410
  spin_unlock_irqrestore(& mdev->al_lock, flags);
#line 411
  __wake_up(& mdev->al_wait, 3U, 1, 0);
#line 412
  return;
}
}
#line 423 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static unsigned int al_extent_to_bm_page(unsigned int al_enr ) 
{ 


  {
#line 425
  return (al_enr >> 5);
}
}
#line 432 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static unsigned int rs_extent_to_bm_page(unsigned int rs_enr ) 
{ 


  {
#line 434
  return (rs_enr >> 3);
}
}
#line 442 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int _al_write_transaction(struct drbd_conf *mdev ) 
{ 
  struct al_transaction_on_disk *buffer ;
  struct lc_element *e ;
  sector_t sector ;
  int i ;
  int mx ;
  unsigned int extent_nr ;
  unsigned int crc ;
  int err ;
  char const   *tmp ;
  int tmp___0 ;
  char const   *tmp___1 ;
  void *tmp___2 ;
  __u32 tmp___3 ;
  struct list_head  const  *__mptr ;
  __u16 tmp___4 ;
  __u32 tmp___5 ;
  unsigned int tmp___6 ;
  struct list_head  const  *__mptr___0 ;
  long tmp___7 ;
  __u16 tmp___8 ;
  __u16 tmp___9 ;
  __u16 tmp___10 ;
  int __min1 ;
  int __min2 ;
  unsigned int idx ;
  struct lc_element *tmp___11 ;
  __u32 tmp___12 ;
  __u32 tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;

  {
#line 449
  crc = 0U;
#line 450
  err = 0;
#line 452
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 452
  if (tmp___0 == 0) {
#line 453
    tmp = drbd_disk_str((enum drbd_disk_state )mdev->state.ldv_49522.disk);
#line 453
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "disk is %s, cannot start al transaction\n",
            tmp);
#line 455
    return (-5);
  } else {

  }
#line 459
  if ((int )mdev->state.ldv_49522.disk <= 3) {
#line 460
    tmp___1 = drbd_disk_str((enum drbd_disk_state )mdev->state.ldv_49522.disk);
#line 460
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "disk is %s, cannot write al transaction\n",
            tmp___1);
#line 463
    put_ldev(mdev);
#line 464
    return (-5);
  } else {

  }
#line 467
  tmp___2 = drbd_md_get_buffer(mdev);
#line 467
  buffer = (struct al_transaction_on_disk *)tmp___2;
#line 468
  if ((unsigned long )buffer == (unsigned long )((struct al_transaction_on_disk *)0)) {
#line 469
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "disk failed while waiting for md_io buffer\n");
#line 470
    put_ldev(mdev);
#line 471
    return (-19);
  } else {

  }
#line 474
  memset((void *)buffer, 0, 4096UL);
#line 475
  buffer->magic = 2724580201U;
#line 476
  tmp___3 = __fswab32(mdev->al_tr_number);
#line 476
  buffer->tr_number = tmp___3;
#line 478
  i = 0;
#line 484
  spin_lock_irq(& mdev->al_lock);
#line 485
  __mptr = (struct list_head  const  *)(mdev->act_log)->to_be_changed.next;
#line 485
  e = (struct lc_element *)__mptr + 0xfffffffffffffff0UL;
#line 485
  goto ldv_51243;
  ldv_51242: ;
#line 486
  if (i == 64) {
#line 487
    i = i + 1;
#line 488
    goto ldv_51241;
  } else {

  }
#line 490
  tmp___4 = __fswab16((int )((__u16 )e->lc_index));
#line 490
  buffer->update_slot_nr[i] = tmp___4;
#line 491
  tmp___5 = __fswab32(e->lc_new_number);
#line 491
  buffer->update_extent_nr[i] = tmp___5;
#line 492
  if (e->lc_number != 4294967295U) {
#line 493
    tmp___6 = al_extent_to_bm_page(e->lc_number);
#line 493
    drbd_bm_mark_for_writeout(mdev, (int )tmp___6);
  } else {

  }
#line 495
  i = i + 1;
#line 485
  __mptr___0 = (struct list_head  const  *)e->list.next;
#line 485
  e = (struct lc_element *)__mptr___0 + 0xfffffffffffffff0UL;
  ldv_51243: ;
#line 485
  if ((unsigned long )(& e->list) != (unsigned long )(& (mdev->act_log)->to_be_changed)) {
#line 486
    goto ldv_51242;
  } else {

  }
  ldv_51241: 
#line 497
  spin_unlock_irq(& mdev->al_lock);
#line 498
  tmp___7 = __builtin_expect(i > 64, 0L);
#line 498
  if (tmp___7 != 0L) {
#line 498
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"),
                         "i" (498), "i" (12UL));
    ldv_51244: ;
#line 498
    goto ldv_51244;
  } else {

  }
#line 500
  tmp___8 = __fswab16((int )((__u16 )i));
#line 500
  buffer->n_updates = tmp___8;
#line 501
  goto ldv_51246;
  ldv_51245: 
#line 502
  buffer->update_slot_nr[i] = 65535U;
#line 503
  buffer->update_extent_nr[i] = 4294967295U;
#line 501
  i = i + 1;
  ldv_51246: ;
#line 501
  if (i <= 63) {
#line 502
    goto ldv_51245;
  } else {

  }
#line 506
  tmp___9 = __fswab16((int )((__u16 )(mdev->act_log)->nr_elements));
#line 506
  buffer->context_size = tmp___9;
#line 507
  tmp___10 = __fswab16((int )((__u16 )mdev->al_tr_cycle));
#line 507
  buffer->context_start_slot_nr = tmp___10;
#line 509
  __min1 = 919;
#line 509
  __min2 = (int )((mdev->act_log)->nr_elements - (unsigned int )mdev->al_tr_cycle);
#line 509
  mx = __min1 < __min2 ? __min1 : __min2;
#line 511
  i = 0;
#line 511
  goto ldv_51253;
  ldv_51252: 
#line 512
  idx = (unsigned int )(mdev->al_tr_cycle + i);
#line 513
  tmp___11 = lc_element_by_index(mdev->act_log, idx);
#line 513
  extent_nr = tmp___11->lc_number;
#line 514
  tmp___12 = __fswab32(extent_nr);
#line 514
  buffer->context[i] = tmp___12;
#line 511
  i = i + 1;
  ldv_51253: ;
#line 511
  if (i < mx) {
#line 512
    goto ldv_51252;
  } else {

  }

#line 516
  goto ldv_51256;
  ldv_51255: 
#line 517
  buffer->context[i] = 4294967295U;
#line 516
  i = i + 1;
  ldv_51256: ;
#line 516
  if (i <= 918) {
#line 517
    goto ldv_51255;
  } else {

  }
#line 519
  mdev->al_tr_cycle = mdev->al_tr_cycle + 919;
#line 520
  if ((unsigned int )mdev->al_tr_cycle >= (mdev->act_log)->nr_elements) {
#line 521
    mdev->al_tr_cycle = 0;
  } else {

  }
#line 523
  sector = (sector_t )(((mdev->ldev)->md.md_offset + (u64 )(mdev->ldev)->md.al_offset) + (u64 )(mdev->al_tr_pos * 8));
#line 527
  crc = crc32c(0U, (void const   *)buffer, 4096U);
#line 528
  tmp___13 = __fswab32(crc);
#line 528
  buffer->crc32c = tmp___13;
#line 530
  tmp___15 = drbd_bm_write_hinted(mdev);
#line 530
  if (tmp___15 != 0) {
#line 531
    err = -5;
  } else {
#line 533
    tmp___14 = drbd_md_sync_page_io(mdev, mdev->ldev, sector, 1);
#line 533
    if (tmp___14 != 0) {
#line 534
      err = -5;
#line 535
      drbd_chk_io_error____0(mdev, 1, DRBD_META_IO_ERROR, "_al_write_transaction");
    } else {
#line 538
      mdev->al_tr_pos = (mdev->al_tr_pos + 1) % 8;
#line 539
      mdev->al_tr_number = mdev->al_tr_number + 1U;
    }
  }
#line 542
  drbd_md_put_buffer(mdev);
#line 543
  put_ldev(mdev);
#line 545
  return (err);
}
}
#line 549 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int w_al_write_transaction(struct drbd_work *w , int unused ) 
{ 
  struct update_al_work *aw ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  int err ;

  {
#line 551
  __mptr = (struct drbd_work  const  *)w;
#line 551
  aw = (struct update_al_work *)__mptr;
#line 552
  mdev = w->ldv_49807.mdev;
#line 555
  err = _al_write_transaction(mdev);
#line 556
  aw->err = err;
#line 557
  complete(& aw->event);
#line 559
  return (err != -5 ? err : 0);
}
}
#line 565 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int al_write_transaction(struct drbd_conf *mdev ) 
{ 
  struct update_al_work al_work ;
  int tmp ;
  struct task_struct *tmp___0 ;

  {
#line 569
  tmp___0 = get_current();
#line 569
  if ((unsigned long )tmp___0 == (unsigned long )(mdev->tconn)->worker.task) {
#line 570
    tmp = _al_write_transaction(mdev);
#line 570
    return (tmp);
  } else {

  }
#line 572
  init_completion(& al_work.event);
#line 573
  al_work.w.cb = & w_al_write_transaction;
#line 574
  al_work.w.ldv_49807.mdev = mdev;
#line 575
  drbd_queue_work_front(& (mdev->tconn)->sender_work, & al_work.w);
#line 576
  wait_for_completion(& al_work.event);
#line 578
  return (al_work.err);
}
}
#line 581 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int _try_lc_del(struct drbd_conf *mdev , struct lc_element *al_ext ) 
{ 
  int rv ;
  long tmp ;

  {
#line 585
  spin_lock_irq(& mdev->al_lock);
#line 586
  rv = al_ext->refcnt == 0U;
#line 587
  tmp = __builtin_expect(rv != 0, 1L);
#line 587
  if (tmp != 0L) {
#line 588
    lc_del(mdev->act_log, al_ext);
  } else {

  }
#line 589
  spin_unlock_irq(& mdev->al_lock);
#line 591
  return (rv);
}
}
#line 603 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_al_shrink(struct drbd_conf *mdev ) 
{ 
  struct lc_element *al_ext ;
  int i ;
  int tmp ;
  int tmp___0 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;

  {
#line 608
  tmp = constant_test_bit(2U, (unsigned long const volatile   *)(& (mdev->act_log)->flags));
#line 608
  if (tmp == 0) {
#line 608
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( test_bit(__LC_LOCKED, &mdev->act_log->flags) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
            608);
  } else {

  }
#line 610
  i = 0;
#line 610
  goto ldv_51288;
  ldv_51287: 
#line 611
  al_ext = lc_element_by_index(mdev->act_log, (unsigned int )i);
#line 612
  if (al_ext->lc_number == 4294967295U) {
#line 613
    goto ldv_51282;
  } else {

  }
#line 614
  tmp___0 = _try_lc_del(mdev, al_ext);
#line 614
  if (tmp___0 != 0) {
#line 614
    goto ldv_51283;
  } else {

  }
#line 614
  tmp___1 = get_current();
#line 614
  __wait.flags = 0U;
#line 614
  __wait.private = (void *)tmp___1;
#line 614
  __wait.func = & autoremove_wake_function;
#line 614
  __wait.task_list.next = & __wait.task_list;
#line 614
  __wait.task_list.prev = & __wait.task_list;
  ldv_51286: 
#line 614
  prepare_to_wait(& mdev->al_wait, & __wait, 2);
#line 614
  tmp___2 = _try_lc_del(mdev, al_ext);
#line 614
  if (tmp___2 != 0) {
#line 614
    goto ldv_51285;
  } else {

  }
#line 614
  schedule();
#line 614
  goto ldv_51286;
  ldv_51285: 
#line 614
  finish_wait(& mdev->al_wait, & __wait);
  ldv_51283: ;
  ldv_51282: 
#line 610
  i = i + 1;
  ldv_51288: ;
#line 610
  if ((unsigned int )i < (mdev->act_log)->nr_elements) {
#line 611
    goto ldv_51287;
  } else {

  }
#line 617
  __wake_up(& mdev->al_wait, 3U, 1, 0);
#line 618
  return;
}
}
#line 620 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int w_update_odbm(struct drbd_work *w , int unused ) 
{ 
  struct update_odbm_work *udw ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  struct sib_info sib ;
  int tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  unsigned long tmp___2 ;

  {
#line 622
  __mptr = (struct drbd_work  const  *)w;
#line 622
  udw = (struct update_odbm_work *)__mptr;
#line 623
  mdev = w->ldv_49807.mdev;
#line 624
  sib.sib_reason = SIB_SYNC_PROGRESS;
#line 624
  sib.ldv_50742.ldv_50737.helper_name = 0;
#line 624
  sib.ldv_50742.ldv_50737.helper_exit_code = 0U;
#line 626
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 626
  if (tmp___0 == 0) {
#line 627
    tmp = ___ratelimit(& drbd_ratelimit_state, "w_update_odbm");
#line 627
    if (tmp != 0) {
#line 628
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Can not update on disk bitmap, local IO disabled.\n");
    } else {

    }
#line 629
    kfree((void const   *)udw);
#line 630
    return (0);
  } else {

  }
#line 633
  tmp___1 = rs_extent_to_bm_page(udw->enr);
#line 633
  drbd_bm_write_page(mdev, tmp___1);
#line 634
  put_ldev(mdev);
#line 636
  kfree((void const   *)udw);
#line 638
  tmp___2 = drbd_bm_total_weight(mdev);
#line 638
  if (tmp___2 <= mdev->rs_failed) {
#line 639
    switch ((int )mdev->state.ldv_49522.conn) {
    case 16: ;
    case 17: ;
    case 20: ;
    case 21: 
#line 642
    drbd_resync_finished(mdev);
    default: ;
#line 645
    goto ldv_51305;
    }
    ldv_51305: ;
  } else {

  }
#line 648
  drbd_bcast_event(mdev, (struct sib_info  const  *)(& sib));
#line 650
  return (0);
}
}
#line 660 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static void drbd_try_clear_on_disk_bm(struct drbd_conf *mdev , sector_t sector , int count ,
                                      int success ) 
{ 
  struct lc_element *e ;
  struct update_odbm_work *udw ;
  unsigned int enr ;
  int tmp ;
  struct bm_extent *ext ;
  struct lc_element  const  *__mptr ;
  char const   *tmp___0 ;
  int rs_left ;
  int tmp___1 ;
  void *tmp___2 ;

  {
#line 668
  tmp = atomic_read((atomic_t const   *)(& mdev->local_cnt));
#line 668
  if (tmp == 0) {
#line 668
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( atomic_read(&mdev->local_cnt) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
            668);
  } else {

  }
#line 672
  enr = (unsigned int )(sector >> 15);
#line 674
  e = lc_get(mdev->resync, enr);
#line 675
  if ((unsigned long )e != (unsigned long )((struct lc_element *)0)) {
#line 676
    __mptr = (struct lc_element  const  *)e;
#line 676
    ext = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
#line 677
    if (ext->lce.lc_number == enr) {
#line 678
      if (success != 0) {
#line 679
        ext->rs_left = ext->rs_left - count;
      } else {
#line 681
        ext->rs_failed = ext->rs_failed + count;
      }
#line 682
      if (ext->rs_left < ext->rs_failed) {
#line 683
        tmp___0 = drbd_conn_str((enum drbd_conns )mdev->state.ldv_49522.conn);
#line 683
        dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "BAD! sector=%llus enr=%u rs_left=%d rs_failed=%d count=%d cstate=%s\n",
                 (unsigned long long )sector, ext->lce.lc_number, ext->rs_left, ext->rs_failed,
                 count, tmp___0);
#line 696
        ext->rs_left = drbd_bm_e_weight(mdev, (unsigned long )enr);
      } else {

      }
    } else {
#line 705
      tmp___1 = drbd_bm_e_weight(mdev, (unsigned long )enr);
#line 705
      rs_left = tmp___1;
#line 706
      if (ext->flags != 0UL) {
#line 707
        dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "changing resync lce: %d[%u;%02lx] -> %d[%u;00]\n",
                 ext->lce.lc_number, ext->rs_left, ext->flags, enr, rs_left);
#line 711
        ext->flags = 0UL;
      } else {

      }
#line 713
      if (ext->rs_failed != 0) {
#line 714
        dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Kicking resync_lru element enr=%u out with rs_failed=%d\n",
                 ext->lce.lc_number, ext->rs_failed);
      } else {

      }
#line 718
      ext->rs_left = rs_left;
#line 719
      ext->rs_failed = success == 0 ? count : 0;
#line 722
      lc_committed(mdev->resync);
    }
#line 724
    lc_put(mdev->resync, & ext->lce);
#line 727
    if (ext->rs_left == ext->rs_failed) {
#line 728
      ext->rs_failed = 0;
#line 730
      tmp___2 = kmalloc(40UL, 32U);
#line 730
      udw = (struct update_odbm_work *)tmp___2;
#line 731
      if ((unsigned long )udw != (unsigned long )((struct update_odbm_work *)0)) {
#line 732
        udw->enr = ext->lce.lc_number;
#line 733
        udw->w.cb = & w_update_odbm;
#line 734
        udw->w.ldv_49807.mdev = mdev;
#line 735
        drbd_queue_work_front(& (mdev->tconn)->sender_work, & udw->w);
      } else {
#line 737
        dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Could not kmalloc an udw\n");
      }
    } else {

    }
  } else {
#line 741
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "lc_get() failed! locked=%d/%d flags=%lu\n",
            mdev->resync_locked, (mdev->resync)->nr_elements, (mdev->resync)->flags);
  }
#line 745
  return;
}
}
#line 748 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_advance_rs_marks(struct drbd_conf *mdev , unsigned long still_to_go ) 
{ 
  unsigned long now ;
  unsigned long last ;
  int next ;

  {
#line 750
  now = jiffies;
#line 751
  last = mdev->rs_mark_time[mdev->rs_last_mark];
#line 752
  next = (mdev->rs_last_mark + 1) % 8;
#line 753
  if ((1 != 0 && 1 != 0) && (long )now - (long )(last + 750UL) >= 0L) {
#line 754
    if ((mdev->rs_mark_left[mdev->rs_last_mark] != still_to_go && (unsigned int )*((unsigned short *)mdev + 374UL) != 336U) && (unsigned int )*((unsigned short *)mdev + 374UL) != 320U) {
#line 757
      mdev->rs_mark_time[next] = now;
#line 758
      mdev->rs_mark_left[next] = still_to_go;
#line 759
      mdev->rs_last_mark = next;
    } else {

    }
  } else {

  }
#line 761
  return;
}
}
#line 771 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void __drbd_set_in_sync(struct drbd_conf *mdev , sector_t sector , int size , char const   *file ,
                        unsigned int const   line ) 
{ 
  unsigned long sbnr ;
  unsigned long ebnr ;
  unsigned long lbnr ;
  unsigned long count ;
  sector_t esector ;
  sector_t nr_sectors ;
  int wake_up ;
  unsigned long flags ;
  int tmp ;
  bool _bool ;
  int tmp___0 ;
  bool _bool___0 ;
  int tmp___1 ;
  long tmp___2 ;
  long tmp___3 ;
  int tmp___4 ;
  unsigned long tmp___5 ;
  raw_spinlock_t *tmp___6 ;

  {
#line 776
  count = 0UL;
#line 778
  wake_up = 0;
#line 781
  if ((size <= 0 || (size & 511) != 0) || (unsigned int )size > 1048576U) {
#line 782
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_set_in_sync: sector=%llus size=%d nonsense!\n",
            (unsigned long long )sector, size);
#line 784
    return;
  } else {

  }
#line 787
  tmp = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 787
  if (tmp == 0) {
#line 788
    return;
  } else {

  }
#line 790
  nr_sectors = drbd_get_capacity(mdev->this_bdev);
#line 791
  esector = ((sector_t )(size >> 9) + sector) - 1UL;
#line 793
  _bool = sector < nr_sectors;
#line 793
  if (! _bool) {
#line 793
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"sector < nr_sectors", "__drbd_set_in_sync");
  } else {

  }
#line 793
  if (_bool) {
#line 793
    tmp___0 = 0;
  } else {
#line 793
    tmp___0 = 1;
  }
#line 793
  if (tmp___0) {
#line 794
    goto out;
  } else {

  }
#line 795
  _bool___0 = esector < nr_sectors;
#line 795
  if (! _bool___0) {
#line 795
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"esector < nr_sectors", "__drbd_set_in_sync");
  } else {

  }
#line 795
  if (_bool___0) {
#line 795
    tmp___1 = 0;
  } else {
#line 795
    tmp___1 = 1;
  }
#line 795
  if (tmp___1) {
#line 796
    esector = nr_sectors - 1UL;
  } else {

  }
#line 798
  lbnr = (nr_sectors - 1UL) >> 3;
#line 803
  tmp___2 = __builtin_expect(esector <= 6UL, 0L);
#line 803
  if (tmp___2 != 0L) {
#line 804
    goto out;
  } else {

  }
#line 805
  tmp___3 = __builtin_expect(nr_sectors - 1UL == esector, 0L);
#line 805
  if (tmp___3 != 0L) {
#line 806
    ebnr = lbnr;
  } else {
#line 808
    ebnr = (esector - 7UL) >> 3;
  }
#line 809
  sbnr = (sector + 7UL) >> 3;
#line 811
  if (sbnr > ebnr) {
#line 812
    goto out;
  } else {

  }
#line 818
  tmp___4 = drbd_bm_clear_bits(mdev, sbnr, ebnr);
#line 818
  count = (unsigned long )tmp___4;
#line 819
  if (count != 0UL) {
#line 820
    tmp___5 = drbd_bm_total_weight(mdev);
#line 820
    drbd_advance_rs_marks(mdev, tmp___5);
#line 821
    tmp___6 = spinlock_check(& mdev->al_lock);
#line 821
    flags = _raw_spin_lock_irqsave(tmp___6);
#line 822
    drbd_try_clear_on_disk_bm(mdev, sector, (int )count, 1);
#line 823
    spin_unlock_irqrestore(& mdev->al_lock, flags);
#line 827
    wake_up = 1;
  } else {

  }
  out: 
#line 830
  put_ldev(mdev);
#line 831
  if (wake_up != 0) {
#line 832
    __wake_up(& mdev->al_wait, 3U, 1, 0);
  } else {

  }
#line 833
  return;
}
}
#line 843 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
int __drbd_set_out_of_sync(struct drbd_conf *mdev , sector_t sector , int size , char const   *file ,
                           unsigned int const   line ) 
{ 
  unsigned long sbnr ;
  unsigned long ebnr ;
  unsigned long flags ;
  sector_t esector ;
  sector_t nr_sectors ;
  unsigned int enr ;
  unsigned int count ;
  struct lc_element *e ;
  int tmp ;
  bool _bool ;
  int tmp___0 ;
  bool _bool___0 ;
  int tmp___1 ;
  raw_spinlock_t *tmp___2 ;
  int tmp___3 ;
  struct lc_element  const  *__mptr ;
  struct lc_element  const  *__mptr___0 ;

  {
#line 848
  count = 0U;
#line 852
  if (size == 0) {
#line 853
    return (0);
  } else {

  }
#line 855
  if ((size < 0 || (size & 511) != 0) || (unsigned int )size > 1048576U) {
#line 856
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "sector: %llus, size: %d\n",
            (unsigned long long )sector, size);
#line 858
    return (0);
  } else {

  }
#line 861
  tmp = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 861
  if (tmp == 0) {
#line 862
    return (0);
  } else {

  }
#line 864
  nr_sectors = drbd_get_capacity(mdev->this_bdev);
#line 865
  esector = ((sector_t )(size >> 9) + sector) - 1UL;
#line 867
  _bool = sector < nr_sectors;
#line 867
  if (! _bool) {
#line 867
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"sector < nr_sectors", "__drbd_set_out_of_sync");
  } else {

  }
#line 867
  if (_bool) {
#line 867
    tmp___0 = 0;
  } else {
#line 867
    tmp___0 = 1;
  }
#line 867
  if (tmp___0) {
#line 868
    goto out;
  } else {

  }
#line 869
  _bool___0 = esector < nr_sectors;
#line 869
  if (! _bool___0) {
#line 869
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"esector < nr_sectors", "__drbd_set_out_of_sync");
  } else {

  }
#line 869
  if (_bool___0) {
#line 869
    tmp___1 = 0;
  } else {
#line 869
    tmp___1 = 1;
  }
#line 869
  if (tmp___1) {
#line 870
    esector = nr_sectors - 1UL;
  } else {

  }
#line 874
  sbnr = sector >> 3;
#line 875
  ebnr = esector >> 3;
#line 879
  tmp___2 = spinlock_check(& mdev->al_lock);
#line 879
  flags = _raw_spin_lock_irqsave(tmp___2);
#line 880
  tmp___3 = drbd_bm_set_bits(mdev, sbnr, ebnr);
#line 880
  count = (unsigned int )tmp___3;
#line 882
  enr = (unsigned int )(sector >> 15);
#line 883
  e = lc_find(mdev->resync, enr);
#line 884
  if ((unsigned long )e != (unsigned long )((struct lc_element *)0)) {
#line 885
    __mptr = (struct lc_element  const  *)e;
#line 885
    __mptr___0 = (struct lc_element  const  *)e;
#line 885
    ((struct bm_extent *)__mptr + 0xfffffffffffffff0UL)->rs_left = (int )((unsigned int )((struct bm_extent *)__mptr___0 + 0xfffffffffffffff0UL)->rs_left + count);
  } else {

  }
#line 886
  spin_unlock_irqrestore(& mdev->al_lock, flags);
  out: 
#line 889
  put_ldev(mdev);
#line 891
  return ((int )count);
}
}
#line 895 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static struct bm_extent *_bme_get(struct drbd_conf *mdev , unsigned int enr ) 
{ 
  struct lc_element *e ;
  struct bm_extent *bm_ext ;
  int wakeup ;
  unsigned long rs_flags ;
  struct lc_element  const  *__mptr ;
  long tmp ;

  {
#line 899
  wakeup = 0;
#line 902
  spin_lock_irq(& mdev->al_lock);
#line 903
  if (mdev->resync_locked > (mdev->resync)->nr_elements / 2U) {
#line 904
    spin_unlock_irq(& mdev->al_lock);
#line 905
    return (0);
  } else {

  }
#line 907
  e = lc_get(mdev->resync, enr);
#line 908
  if ((unsigned long )e != (unsigned long )((struct lc_element *)0)) {
#line 908
    __mptr = (struct lc_element  const  *)e;
#line 908
    bm_ext = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
  } else {
#line 908
    bm_ext = 0;
  }
#line 909
  if ((unsigned long )bm_ext != (unsigned long )((struct bm_extent *)0)) {
#line 910
    if (bm_ext->lce.lc_number != enr) {
#line 911
      bm_ext->rs_left = drbd_bm_e_weight(mdev, (unsigned long )enr);
#line 912
      bm_ext->rs_failed = 0;
#line 913
      lc_committed(mdev->resync);
#line 914
      wakeup = 1;
    } else {

    }
#line 916
    if (bm_ext->lce.refcnt == 1U) {
#line 917
      mdev->resync_locked = mdev->resync_locked + 1U;
    } else {

    }
#line 918
    set_bit(0U, (unsigned long volatile   *)(& bm_ext->flags));
  } else {

  }
#line 920
  rs_flags = (mdev->resync)->flags;
#line 921
  spin_unlock_irq(& mdev->al_lock);
#line 922
  if (wakeup != 0) {
#line 923
    __wake_up(& mdev->al_wait, 3U, 1, 0);
  } else {

  }
#line 925
  if ((unsigned long )bm_ext == (unsigned long )((struct bm_extent *)0)) {
#line 926
    if ((rs_flags & 8UL) != 0UL) {
#line 927
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Have to wait for element (resync LRU too small?)\n");
    } else {

    }
#line 929
    tmp = __builtin_expect((rs_flags & 4UL) != 0UL, 0L);
#line 929
    if (tmp != 0L) {
#line 929
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"),
                           "i" (929), "i" (12UL));
      ldv_51392: ;
#line 929
      goto ldv_51392;
    } else {

    }
  } else {

  }
#line 932
  return (bm_ext);
}
}
#line 935 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
static int _is_in_al(struct drbd_conf *mdev , unsigned int enr ) 
{ 
  int rv ;
  bool tmp ;

  {
#line 939
  spin_lock_irq(& mdev->al_lock);
#line 940
  tmp = lc_is_used(mdev->act_log, enr);
#line 940
  rv = (int )tmp;
#line 941
  spin_unlock_irq(& mdev->al_lock);
#line 943
  return (rv);
}
}
#line 953 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
int drbd_rs_begin_io(struct drbd_conf *mdev , sector_t sector ) 
{ 
  unsigned int enr ;
  struct bm_extent *bm_ext ;
  int i ;
  int sig ;
  int sa ;
  int __ret ;
  wait_queue_t __wait ;
  struct task_struct *tmp ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int __ret___0 ;
  wait_queue_t __wait___0 ;
  struct task_struct *tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  struct task_struct *tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  unsigned int tmp___10 ;
  long tmp___11 ;
  int tmp___12 ;

  {
#line 955
  enr = (unsigned int )(sector >> 15);
#line 958
  sa = 200;
  retry: 
#line 962
  __ret = 0;
#line 962
  bm_ext = _bme_get(mdev, enr);
#line 962
  if ((unsigned long )bm_ext == (unsigned long )((struct bm_extent *)0)) {
#line 962
    tmp = get_current();
#line 962
    __wait.flags = 0U;
#line 962
    __wait.private = (void *)tmp;
#line 962
    __wait.func = & autoremove_wake_function;
#line 962
    __wait.task_list.next = & __wait.task_list;
#line 962
    __wait.task_list.prev = & __wait.task_list;
    ldv_51412: 
#line 962
    prepare_to_wait(& mdev->al_wait, & __wait, 1);
#line 962
    bm_ext = _bme_get(mdev, enr);
#line 962
    if ((unsigned long )bm_ext != (unsigned long )((struct bm_extent *)0)) {
#line 962
      goto ldv_51410;
    } else {

    }
#line 962
    tmp___0 = get_current();
#line 962
    tmp___1 = signal_pending(tmp___0);
#line 962
    if (tmp___1 == 0) {
#line 962
      schedule();
#line 962
      goto ldv_51411;
    } else {

    }
#line 962
    __ret = -512;
#line 962
    goto ldv_51410;
    ldv_51411: ;
#line 962
    goto ldv_51412;
    ldv_51410: 
#line 962
    finish_wait(& mdev->al_wait, & __wait);
  } else {

  }
#line 962
  sig = __ret;
#line 964
  if (sig != 0) {
#line 965
    return (-4);
  } else {

  }
#line 967
  tmp___2 = constant_test_bit(1U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 967
  if (tmp___2 != 0) {
#line 968
    return (0);
  } else {

  }
#line 970
  i = 0;
#line 970
  goto ldv_51421;
  ldv_51420: 
#line 971
  __ret___0 = 0;
#line 971
  tmp___8 = _is_in_al(mdev, enr * 4U + (unsigned int )i);
#line 971
  if (tmp___8 != 0) {
#line 971
    tmp___9 = constant_test_bit(2U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 971
    if (tmp___9 == 0) {
#line 971
      tmp___3 = get_current();
#line 971
      __wait___0.flags = 0U;
#line 971
      __wait___0.private = (void *)tmp___3;
#line 971
      __wait___0.func = & autoremove_wake_function;
#line 971
      __wait___0.task_list.next = & __wait___0.task_list;
#line 971
      __wait___0.task_list.prev = & __wait___0.task_list;
      ldv_51418: 
#line 971
      prepare_to_wait(& mdev->al_wait, & __wait___0, 1);
#line 971
      tmp___4 = _is_in_al(mdev, enr * 4U + (unsigned int )i);
#line 971
      if (tmp___4 == 0) {
#line 971
        goto ldv_51416;
      } else {
#line 971
        tmp___5 = constant_test_bit(2U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 971
        if (tmp___5 != 0) {
#line 971
          goto ldv_51416;
        } else {

        }
      }
#line 971
      tmp___6 = get_current();
#line 971
      tmp___7 = signal_pending(tmp___6);
#line 971
      if (tmp___7 == 0) {
#line 971
        schedule();
#line 971
        goto ldv_51417;
      } else {

      }
#line 971
      __ret___0 = -512;
#line 971
      goto ldv_51416;
      ldv_51417: ;
#line 971
      goto ldv_51418;
      ldv_51416: 
#line 971
      finish_wait(& mdev->al_wait, & __wait___0);
    } else {

    }
  } else {

  }
#line 971
  sig = __ret___0;
#line 975
  if (sig != 0) {
#line 975
    goto _L;
  } else {
#line 975
    tmp___12 = constant_test_bit(2U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 975
    if (tmp___12 != 0 && sa != 0) {
      _L: /* CIL Label */ 
#line 976
      spin_lock_irq(& mdev->al_lock);
#line 977
      tmp___10 = lc_put(mdev->resync, & bm_ext->lce);
#line 977
      if (tmp___10 == 0U) {
#line 978
        bm_ext->flags = 0UL;
#line 979
        mdev->resync_locked = mdev->resync_locked - 1U;
#line 980
        __wake_up(& mdev->al_wait, 3U, 1, 0);
      } else {

      }
#line 982
      spin_unlock_irq(& mdev->al_lock);
#line 983
      if (sig != 0) {
#line 984
        return (-4);
      } else {

      }
#line 985
      tmp___11 = schedule_timeout_interruptible(25L);
#line 985
      if (tmp___11 != 0L) {
#line 986
        return (-4);
      } else {

      }
#line 987
      if (sa != 0) {
#line 987
        sa = sa - 1;
#line 987
        if (sa == 0) {
#line 988
          dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_rs_begin_io() stepped aside for 20sec.Resync stalled?\n");
        } else {

        }
      } else {

      }
#line 990
      goto retry;
    } else {

    }
  }
#line 970
  i = i + 1;
  ldv_51421: ;
#line 970
  if (i <= 3) {
#line 971
    goto ldv_51420;
  } else {

  }
#line 993
  set_bit(1U, (unsigned long volatile   *)(& bm_ext->flags));
#line 994
  return (0);
}
}
#line 1006 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
int drbd_try_rs_begin_io(struct drbd_conf *mdev , sector_t sector ) 
{ 
  unsigned int enr ;
  unsigned int al_enr ;
  struct lc_element *e ;
  struct bm_extent *bm_ext ;
  int i ;
  struct lc_element  const  *__mptr ;
  int tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  struct lc_element  const  *__mptr___0 ;
  int tmp___2 ;
  int tmp___3 ;
  struct lc_element  const  *__mptr___1 ;
  unsigned long rs_flags ;
  long tmp___4 ;
  int tmp___5 ;
  bool tmp___6 ;

  {
#line 1008
  enr = (unsigned int )(sector >> 15);
#line 1009
  al_enr = enr * 4U;
#line 1014
  spin_lock_irq(& mdev->al_lock);
#line 1015
  if (mdev->resync_wenr != 4294967295U && mdev->resync_wenr != enr) {
#line 1029
    e = lc_find(mdev->resync, mdev->resync_wenr);
#line 1030
    if ((unsigned long )e != (unsigned long )((struct lc_element *)0)) {
#line 1030
      __mptr = (struct lc_element  const  *)e;
#line 1030
      bm_ext = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
    } else {
#line 1030
      bm_ext = 0;
    }
#line 1031
    if ((unsigned long )bm_ext != (unsigned long )((struct bm_extent *)0)) {
#line 1032
      tmp = constant_test_bit(1U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1032
      if (tmp != 0) {
#line 1032
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !test_bit(BME_LOCKED, &bm_ext->flags) ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                1032);
      } else {

      }
#line 1033
      tmp___0 = constant_test_bit(0U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1033
      if (tmp___0 == 0) {
#line 1033
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( test_bit(BME_NO_WRITES, &bm_ext->flags) ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                1033);
      } else {

      }
#line 1034
      clear_bit(0, (unsigned long volatile   *)(& bm_ext->flags));
#line 1035
      mdev->resync_wenr = 4294967295U;
#line 1036
      tmp___1 = lc_put(mdev->resync, & bm_ext->lce);
#line 1036
      if (tmp___1 == 0U) {
#line 1037
        mdev->resync_locked = mdev->resync_locked - 1U;
      } else {

      }
#line 1038
      __wake_up(& mdev->al_wait, 3U, 1, 0);
    } else {
#line 1040
      dev_alert((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "LOGIC BUG\n");
    }
  } else {

  }
#line 1044
  e = lc_try_get(mdev->resync, enr);
#line 1045
  if ((unsigned long )e != (unsigned long )((struct lc_element *)0)) {
#line 1045
    __mptr___0 = (struct lc_element  const  *)e;
#line 1045
    bm_ext = (struct bm_extent *)__mptr___0 + 0xfffffffffffffff0UL;
  } else {
#line 1045
    bm_ext = 0;
  }
#line 1046
  if ((unsigned long )bm_ext != (unsigned long )((struct bm_extent *)0)) {
#line 1047
    tmp___2 = constant_test_bit(1U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1047
    if (tmp___2 != 0) {
#line 1048
      goto proceed;
    } else {

    }
#line 1049
    tmp___3 = test_and_set_bit(0, (unsigned long volatile   *)(& bm_ext->flags));
#line 1049
    if (tmp___3 == 0) {
#line 1050
      mdev->resync_locked = mdev->resync_locked + 1U;
    } else {
#line 1056
      bm_ext->lce.refcnt = bm_ext->lce.refcnt - 1U;
#line 1057
      if (bm_ext->lce.refcnt == 0U) {
#line 1057
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( bm_ext->lce.refcnt > 0 ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                1057);
      } else {

      }
    }
#line 1059
    goto check_al;
  } else {
#line 1062
    if (mdev->resync_locked > (mdev->resync)->nr_elements - 3U) {
#line 1063
      goto try_again;
    } else {

    }
#line 1065
    e = lc_get(mdev->resync, enr);
#line 1066
    if ((unsigned long )e != (unsigned long )((struct lc_element *)0)) {
#line 1066
      __mptr___1 = (struct lc_element  const  *)e;
#line 1066
      bm_ext = (struct bm_extent *)__mptr___1 + 0xfffffffffffffff0UL;
    } else {
#line 1066
      bm_ext = 0;
    }
#line 1067
    if ((unsigned long )bm_ext == (unsigned long )((struct bm_extent *)0)) {
#line 1068
      rs_flags = (mdev->resync)->flags;
#line 1069
      if ((rs_flags & 8UL) != 0UL) {
#line 1070
        dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Have to wait for element (resync LRU too small?)\n");
      } else {

      }
#line 1072
      tmp___4 = __builtin_expect((rs_flags & 4UL) != 0UL, 0L);
#line 1072
      if (tmp___4 != 0L) {
#line 1072
        __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"),
                             "i" (1072), "i" (12UL));
        ldv_51442: ;
#line 1072
        goto ldv_51442;
      } else {

      }
#line 1073
      goto try_again;
    } else {

    }
#line 1075
    if (bm_ext->lce.lc_number != enr) {
#line 1076
      bm_ext->rs_left = drbd_bm_e_weight(mdev, (unsigned long )enr);
#line 1077
      bm_ext->rs_failed = 0;
#line 1078
      lc_committed(mdev->resync);
#line 1079
      __wake_up(& mdev->al_wait, 3U, 1, 0);
#line 1080
      tmp___5 = constant_test_bit(1U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1080
      if (tmp___5 != 0) {
#line 1080
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( test_bit(BME_LOCKED, &bm_ext->flags) == 0 ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                1080);
      } else {

      }
    } else {

    }
#line 1082
    set_bit(0U, (unsigned long volatile   *)(& bm_ext->flags));
#line 1083
    if (bm_ext->lce.refcnt != 1U) {
#line 1083
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( bm_ext->lce.refcnt == 1 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
              1083);
    } else {

    }
#line 1084
    mdev->resync_locked = mdev->resync_locked + 1U;
#line 1085
    goto check_al;
  }
  check_al: 
#line 1088
  i = 0;
#line 1088
  goto ldv_51444;
  ldv_51443: 
#line 1089
  tmp___6 = lc_is_used(mdev->act_log, al_enr + (unsigned int )i);
#line 1089
  if ((int )tmp___6) {
#line 1090
    goto try_again;
  } else {

  }
#line 1088
  i = i + 1;
  ldv_51444: ;
#line 1088
  if (i <= 3) {
#line 1089
    goto ldv_51443;
  } else {

  }
#line 1092
  set_bit(1U, (unsigned long volatile   *)(& bm_ext->flags));
  proceed: 
#line 1094
  mdev->resync_wenr = 4294967295U;
#line 1095
  spin_unlock_irq(& mdev->al_lock);
#line 1096
  return (0);
  try_again: ;
#line 1099
  if ((unsigned long )bm_ext != (unsigned long )((struct bm_extent *)0)) {
#line 1100
    mdev->resync_wenr = enr;
  } else {

  }
#line 1101
  spin_unlock_irq(& mdev->al_lock);
#line 1102
  return (-11);
}
}
#line 1105 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_rs_complete_io(struct drbd_conf *mdev , sector_t sector ) 
{ 
  unsigned int enr ;
  struct lc_element *e ;
  struct bm_extent *bm_ext ;
  unsigned long flags ;
  raw_spinlock_t *tmp ;
  struct lc_element  const  *__mptr ;
  int tmp___0 ;
  unsigned int tmp___1 ;

  {
#line 1107
  enr = (unsigned int )(sector >> 15);
#line 1112
  tmp = spinlock_check(& mdev->al_lock);
#line 1112
  flags = _raw_spin_lock_irqsave(tmp);
#line 1113
  e = lc_find(mdev->resync, enr);
#line 1114
  if ((unsigned long )e != (unsigned long )((struct lc_element *)0)) {
#line 1114
    __mptr = (struct lc_element  const  *)e;
#line 1114
    bm_ext = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
  } else {
#line 1114
    bm_ext = 0;
  }
#line 1115
  if ((unsigned long )bm_ext == (unsigned long )((struct bm_extent *)0)) {
#line 1116
    spin_unlock_irqrestore(& mdev->al_lock, flags);
#line 1117
    tmp___0 = ___ratelimit(& drbd_ratelimit_state, "drbd_rs_complete_io");
#line 1117
    if (tmp___0 != 0) {
#line 1118
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_rs_complete_io() called, but extent not found\n");
    } else {

    }
#line 1119
    return;
  } else {

  }
#line 1122
  if (bm_ext->lce.refcnt == 0U) {
#line 1123
    spin_unlock_irqrestore(& mdev->al_lock, flags);
#line 1124
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_rs_complete_io(,%llu [=%u]) called, but refcnt is 0!?\n",
            (unsigned long long )sector, enr);
#line 1127
    return;
  } else {

  }
#line 1130
  tmp___1 = lc_put(mdev->resync, & bm_ext->lce);
#line 1130
  if (tmp___1 == 0U) {
#line 1131
    bm_ext->flags = 0UL;
#line 1132
    mdev->resync_locked = mdev->resync_locked - 1U;
#line 1133
    __wake_up(& mdev->al_wait, 3U, 1, 0);
  } else {

  }
#line 1136
  spin_unlock_irqrestore(& mdev->al_lock, flags);
#line 1137
  return;
}
}
#line 1143 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_rs_cancel_all(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 1145
  spin_lock_irq(& mdev->al_lock);
#line 1147
  tmp = _get_ldev_if_state(mdev, D_FAILED);
#line 1147
  if (tmp != 0) {
#line 1148
    lc_reset(mdev->resync);
#line 1149
    put_ldev(mdev);
  } else {

  }
#line 1151
  mdev->resync_locked = 0U;
#line 1152
  mdev->resync_wenr = 4294967295U;
#line 1153
  spin_unlock_irq(& mdev->al_lock);
#line 1154
  __wake_up(& mdev->al_wait, 3U, 1, 0);
#line 1155
  return;
}
}
#line 1164 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
int drbd_rs_del_all(struct drbd_conf *mdev ) 
{ 
  struct lc_element *e ;
  struct bm_extent *bm_ext ;
  int i ;
  struct lc_element  const  *__mptr ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 1170
  spin_lock_irq(& mdev->al_lock);
#line 1172
  tmp___3 = _get_ldev_if_state(mdev, D_FAILED);
#line 1172
  if (tmp___3 != 0) {
#line 1174
    i = 0;
#line 1174
    goto ldv_51473;
    ldv_51472: 
#line 1175
    e = lc_element_by_index(mdev->resync, (unsigned int )i);
#line 1176
    __mptr = (struct lc_element  const  *)e;
#line 1176
    bm_ext = (struct bm_extent *)__mptr + 0xfffffffffffffff0UL;
#line 1177
    if (bm_ext->lce.lc_number == 4294967295U) {
#line 1178
      goto ldv_51471;
    } else {

    }
#line 1179
    if (bm_ext->lce.lc_number == mdev->resync_wenr) {
#line 1180
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "dropping %u in drbd_rs_del_all, apparently got \'synced\' by application io\n",
                mdev->resync_wenr);
#line 1183
      tmp = constant_test_bit(1U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1183
      if (tmp != 0) {
#line 1183
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !test_bit(BME_LOCKED, &bm_ext->flags) ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                1183);
      } else {

      }
#line 1184
      tmp___0 = constant_test_bit(0U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1184
      if (tmp___0 == 0) {
#line 1184
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( test_bit(BME_NO_WRITES, &bm_ext->flags) ) in %s:%d\n",
                (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
                1184);
      } else {

      }
#line 1185
      clear_bit(0, (unsigned long volatile   *)(& bm_ext->flags));
#line 1186
      mdev->resync_wenr = 4294967295U;
#line 1187
      lc_put(mdev->resync, & bm_ext->lce);
    } else {

    }
#line 1189
    if (bm_ext->lce.refcnt != 0U) {
#line 1190
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Retrying drbd_rs_del_all() later. refcnt=%d\n",
                bm_ext->lce.refcnt);
#line 1192
      put_ldev(mdev);
#line 1193
      spin_unlock_irq(& mdev->al_lock);
#line 1194
      return (-11);
    } else {

    }
#line 1196
    tmp___1 = constant_test_bit(1U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1196
    if (tmp___1 != 0) {
#line 1196
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !test_bit(BME_LOCKED, &bm_ext->flags) ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
              1196);
    } else {

    }
#line 1197
    tmp___2 = constant_test_bit(0U, (unsigned long const volatile   *)(& bm_ext->flags));
#line 1197
    if (tmp___2 != 0) {
#line 1197
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !test_bit(BME_NO_WRITES, &bm_ext->flags) ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
              1197);
    } else {

    }
#line 1198
    lc_del(mdev->resync, & bm_ext->lce);
    ldv_51471: 
#line 1174
    i = i + 1;
    ldv_51473: ;
#line 1174
    if ((unsigned int )i < (mdev->resync)->nr_elements) {
#line 1175
      goto ldv_51472;
    } else {

    }

#line 1200
    if ((mdev->resync)->used != 0U) {
#line 1200
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->resync->used == 0 ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared",
              1200);
    } else {

    }
#line 1201
    put_ldev(mdev);
  } else {

  }
#line 1203
  spin_unlock_irq(& mdev->al_lock);
#line 1204
  __wake_up(& mdev->al_wait, 3U, 1, 0);
#line 1206
  return (0);
}
}
#line 1215 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void drbd_rs_failed_io(struct drbd_conf *mdev , sector_t sector , int size ) 
{ 
  unsigned long sbnr ;
  unsigned long ebnr ;
  unsigned long lbnr ;
  unsigned long count ;
  sector_t esector ;
  sector_t nr_sectors ;
  int wake_up ;
  bool _bool ;
  int tmp ;
  bool _bool___0 ;
  int tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
#line 1221
  wake_up = 0;
#line 1223
  if ((size <= 0 || (size & 511) != 0) || (unsigned int )size > 1048576U) {
#line 1224
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "drbd_rs_failed_io: sector=%llus size=%d nonsense!\n",
            (unsigned long long )sector, size);
#line 1226
    return;
  } else {

  }
#line 1228
  nr_sectors = drbd_get_capacity(mdev->this_bdev);
#line 1229
  esector = ((sector_t )(size >> 9) + sector) - 1UL;
#line 1231
  _bool = sector < nr_sectors;
#line 1231
  if (! _bool) {
#line 1231
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"sector < nr_sectors", "drbd_rs_failed_io");
  } else {

  }
#line 1231
  if (_bool) {
#line 1231
    tmp = 0;
  } else {
#line 1231
    tmp = 1;
  }
#line 1231
  if (tmp) {
#line 1232
    return;
  } else {

  }
#line 1233
  _bool___0 = esector < nr_sectors;
#line 1233
  if (! _bool___0) {
#line 1233
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"esector < nr_sectors", "drbd_rs_failed_io");
  } else {

  }
#line 1233
  if (_bool___0) {
#line 1233
    tmp___0 = 0;
  } else {
#line 1233
    tmp___0 = 1;
  }
#line 1233
  if (tmp___0) {
#line 1234
    esector = nr_sectors - 1UL;
  } else {

  }
#line 1236
  lbnr = (nr_sectors - 1UL) >> 3;
#line 1241
  tmp___1 = __builtin_expect(esector <= 6UL, 0L);
#line 1241
  if (tmp___1 != 0L) {
#line 1242
    return;
  } else {

  }
#line 1243
  tmp___2 = __builtin_expect(nr_sectors - 1UL == esector, 0L);
#line 1243
  if (tmp___2 != 0L) {
#line 1244
    ebnr = lbnr;
  } else {
#line 1246
    ebnr = (esector - 7UL) >> 3;
  }
#line 1247
  sbnr = (sector + 7UL) >> 3;
#line 1249
  if (sbnr > ebnr) {
#line 1250
    return;
  } else {

  }
#line 1256
  spin_lock_irq(& mdev->al_lock);
#line 1257
  tmp___3 = drbd_bm_count_bits(mdev, sbnr, ebnr);
#line 1257
  count = (unsigned long )tmp___3;
#line 1258
  if (count != 0UL) {
#line 1259
    mdev->rs_failed = mdev->rs_failed + count;
#line 1261
    tmp___4 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1261
    if (tmp___4 != 0) {
#line 1262
      drbd_try_clear_on_disk_bm(mdev, sector, (int )count, 0);
#line 1263
      put_ldev(mdev);
    } else {

    }
#line 1268
    wake_up = 1;
  } else {

  }
#line 1270
  spin_unlock_irq(& mdev->al_lock);
#line 1271
  if (wake_up != 0) {
#line 1272
    __wake_up(& mdev->al_wait, 3U, 1, 0);
  } else {

  }
#line 1273
  return;
}
}
#line 1312 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_main5_sequence_infinite_withcheck_stateful(void) 
{ 
  int tmp ;
  int tmp___0 ;

  {
#line 1324
  LDV_IN_INTERRUPT = 1;
#line 1333
  ldv_initialize();
#line 1335
  goto ldv_51511;
  ldv_51510: 
#line 1338
  tmp = nondet_int();
#line 1338
  switch (tmp) {
  default: ;
#line 1340
  goto ldv_51509;
  }
  ldv_51509: ;
  ldv_51511: 
#line 1335
  tmp___0 = nondet_int();
#line 1335
  if (tmp___0 != 0) {
#line 1336
    goto ldv_51510;
  } else {

  }


#line 1349
  ldv_check_final_state();
#line 1352
  return;
}
}
#line 1356 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_lock_175(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1361
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 1363
  mutex_lock(ldv_func_arg1);
#line 1364
  return;
}
}
#line 1366 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_unlock_176(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1371
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 1373
  mutex_unlock(ldv_func_arg1);
#line 1374
  return;
}
}
#line 1376 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_lock_177(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1381
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 1383
  mutex_lock(ldv_func_arg1);
#line 1384
  return;
}
}
#line 1386 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
int ldv_mutex_trylock_178(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 1391
  tmp = mutex_trylock(ldv_func_arg1);
#line 1391
  ldv_func_res = tmp;
#line 1393
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 1393
  return (tmp___0);
#line 1395
  return (ldv_func_res);
}
}
#line 1398 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_unlock_179(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1403
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 1405
  mutex_unlock(ldv_func_arg1);
#line 1406
  return;
}
}
#line 1408 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_lock_180(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1413
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1415
  mutex_lock(ldv_func_arg1);
#line 1416
  return;
}
}
#line 1418 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_unlock_181(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1423
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1425
  mutex_unlock(ldv_func_arg1);
#line 1426
  return;
}
}
#line 1428 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_lock_182(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1433
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1435
  mutex_lock(ldv_func_arg1);
#line 1436
  return;
}
}
#line 1438 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_unlock_183(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1443
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 1445
  mutex_unlock(ldv_func_arg1);
#line 1446
  return;
}
}
#line 1448 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_lock_184(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1453
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1455
  mutex_lock(ldv_func_arg1);
#line 1456
  return;
}
}
#line 1458 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_actlog.c.prepared"
void ldv_mutex_unlock_185(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1463
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1465
  mutex_unlock(ldv_func_arg1);
#line 1466
  return;
}
}
#line 77 "include/uapi/linux/swab.h"
__inline static __u32 __fswahw32(__u32 val ) 
{ 


  {
#line 82
  return ((val << 16) | (val >> (8UL * sizeof(val) - 16UL)));
}
}
#line 323 "include/linux/kernel.h"
extern int sprintf(char * , char const   *  , ...) ;
#line 326
extern int snprintf(char * , size_t  , char const   *  , ...) ;
#line 23 "include/linux/string.h"
extern char *strncpy(char * , char const   * , __kernel_size_t  ) ;
#line 115
extern char *kstrdup(char const   * , gfp_t  ) ;
#line 93 "include/linux/bitmap.h"
extern int __bitmap_equal(unsigned long const   * , unsigned long const   * , int  ) ;
#line 113
extern int __bitmap_weight(unsigned long const   * , int  ) ;
#line 125
extern int __bitmap_parse(char const   * , unsigned int  , int  , unsigned long * ,
                          int  ) ;
#line 169 "include/linux/bitmap.h"
__inline static void bitmap_fill(unsigned long *dst , int nbits ) 
{ 
  size_t nlongs ;
  int len ;

  {
#line 171
  nlongs = ((unsigned long )nbits + 63UL) / 64UL;
#line 173
  len = (int )(((unsigned int )nlongs + 536870911U) * 8U);
#line 174
  memset((void *)dst, 255, (size_t )len);
#line 176
  *(dst + (nlongs + 0xffffffffffffffffUL)) = ((unsigned int )nbits & 63U) != 0U ? (1UL << nbits % 64) - 1UL : 0xffffffffffffffffUL;
#line 177
  return;
}
}
#line 179 "include/linux/bitmap.h"
__inline static void bitmap_copy(unsigned long *dst , unsigned long const   *src ,
                                 int nbits ) 
{ 
  int len ;
  size_t __len ;
  void *__ret ;

  {
#line 185
  len = (int )((unsigned int )(((unsigned long )nbits + 63UL) / 64UL) * 8U);
#line 186
  __len = (size_t )len;
#line 186
  __ret = __builtin_memcpy((void *)dst, (void const   *)src, __len);
#line 189
  return;
}
}
#line 233 "include/linux/bitmap.h"
__inline static int bitmap_equal(unsigned long const   *src1 , unsigned long const   *src2 ,
                                 int nbits ) 
{ 
  int tmp ;

  {
#line 239
  tmp = __bitmap_equal(src1, src2, nbits);
#line 239
  return (tmp);
}
}
#line 276 "include/linux/bitmap.h"
__inline static int bitmap_weight(unsigned long const   *src , int nbits ) 
{ 
  int tmp___0 ;

  {
#line 280
  tmp___0 = __bitmap_weight(src, nbits);
#line 280
  return (tmp___0);
}
}
#line 301 "include/linux/bitmap.h"
__inline static int bitmap_parse(char const   *buf , unsigned int buflen , unsigned long *maskp ,
                                 int nmaskbits ) 
{ 
  int tmp ;

  {
#line 304
  tmp = __bitmap_parse(buf, buflen, 0, maskp, nmaskbits);
#line 304
  return (tmp);
}
}
#line 80 "include/linux/cpumask.h"
extern struct cpumask  const  * const  cpu_online_mask ;
#line 255 "include/linux/cpumask.h"
__inline static void cpumask_set_cpu(unsigned int cpu , struct cpumask *dstp ) 
{ 
  unsigned int tmp ;

  {
#line 257
  tmp = cpumask_check(cpu);
#line 257
  set_bit(tmp, (unsigned long volatile   *)(& dstp->bits));
#line 258
  return;
}
}
#line 314 "include/linux/cpumask.h"
__inline static void cpumask_setall(struct cpumask *dstp ) 
{ 


  {
#line 316
  bitmap_fill((unsigned long *)(& dstp->bits), nr_cpu_ids);
#line 317
  return;
}
}
#line 404 "include/linux/cpumask.h"
__inline static bool cpumask_equal(struct cpumask  const  *src1p , struct cpumask  const  *src2p ) 
{ 
  int tmp ;

  {
#line 407
  tmp = bitmap_equal((unsigned long const   *)(& src1p->bits), (unsigned long const   *)(& src2p->bits),
                     nr_cpu_ids);
#line 407
  return (tmp != 0);
}
}
#line 459 "include/linux/cpumask.h"
__inline static unsigned int cpumask_weight(struct cpumask  const  *srcp ) 
{ 
  int tmp ;

  {
#line 461
  tmp = bitmap_weight((unsigned long const   *)(& srcp->bits), nr_cpu_ids);
#line 461
  return ((unsigned int )tmp);
}
}
#line 495 "include/linux/cpumask.h"
__inline static void cpumask_copy(struct cpumask *dstp , struct cpumask  const  *srcp ) 
{ 


  {
#line 498
  bitmap_copy((unsigned long *)(& dstp->bits), (unsigned long const   *)(& srcp->bits),
              nr_cpu_ids);
#line 499
  return;
}
}
#line 653
extern bool zalloc_cpumask_var(cpumask_var_t ** , gfp_t  ) ;
#line 655
extern void free_cpumask_var(cpumask_var_t  ) ;
#line 279 "include/linux/lockdep.h"
extern void lockdep_init_map(struct lockdep_map * , char const   * , struct lock_class_key * ,
                             int  ) ;
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_200(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_198(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_201(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_203(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_205(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_207(struct mutex *ldv_func_arg1 ) ;
#line 196
void ldv_mutex_unlock_209(struct mutex *ldv_func_arg1 ) ;
#line 200
void ldv_mutex_unlock_210(struct mutex *ldv_func_arg1 ) ;
#line 204
void ldv_mutex_unlock_211(struct mutex *ldv_func_arg1 ) ;
#line 208
void ldv_mutex_unlock_212(struct mutex *ldv_func_arg1 ) ;
#line 212
void ldv_mutex_unlock_214(struct mutex *ldv_func_arg1 ) ;
#line 216
void ldv_mutex_unlock_216(struct mutex *ldv_func_arg1 ) ;
#line 220
void ldv_mutex_unlock_217(struct mutex *ldv_func_arg1 ) ;
#line 224
void ldv_mutex_unlock_218(struct mutex *ldv_func_arg1 ) ;
#line 228
void ldv_mutex_unlock_220(struct mutex *ldv_func_arg1 ) ;
#line 232
void ldv_mutex_unlock_222(struct mutex *ldv_func_arg1 ) ;
#line 236
void ldv_mutex_unlock_224(struct mutex *ldv_func_arg1 ) ;
#line 240
void ldv_mutex_unlock_226(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_197(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_199(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_202(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_204(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_206(struct mutex *ldv_func_arg1 ) ;
#line 30
void ldv_mutex_lock_208(struct mutex *ldv_func_arg1 ) ;
#line 34
void ldv_mutex_lock_213(struct mutex *ldv_func_arg1 ) ;
#line 38
void ldv_mutex_lock_215(struct mutex *ldv_func_arg1 ) ;
#line 42
void ldv_mutex_lock_219(struct mutex *ldv_func_arg1 ) ;
#line 46
void ldv_mutex_lock_221(struct mutex *ldv_func_arg1 ) ;
#line 50
void ldv_mutex_lock_223(struct mutex *ldv_func_arg1 ) ;
#line 54
void ldv_mutex_lock_225(struct mutex *ldv_func_arg1 ) ;
#line 91
void ldv_mutex_lock_drbd_main_mutex(struct mutex *lock ) ;
#line 95
void ldv_mutex_unlock_drbd_main_mutex(struct mutex *lock ) ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info___5(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6394;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6394;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6394;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6394;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6394: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 18 "include/linux/rwlock.h"
extern void __rwlock_init(rwlock_t * , char const   * , struct lock_class_key * ) ;
#line 92 "include/linux/completion.h"
extern void complete_all(struct completion * ) ;
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock___5(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info___5();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock___5(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info___5();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock___5(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock___5();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock___5(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock___5();
#line 763
  return;
}
}
#line 94 "include/linux/timer.h"
extern void init_timer_key(struct timer_list * , unsigned int  , char const   * ,
                           struct lock_class_key * ) ;
#line 175
extern int del_timer(struct timer_list * ) ;
#line 164 "include/linux/workqueue.h"
extern void __init_work(struct work_struct * , int  ) ;
#line 328
extern struct workqueue_struct *__alloc_workqueue_key(char const   * , unsigned int  ,
                                                      int  , struct lock_class_key * ,
                                                      char const   *  , ...) ;
#line 390
extern void destroy_workqueue(struct workqueue_struct * ) ;
#line 394
extern bool queue_work(struct workqueue_struct * , struct work_struct * ) ;
#line 345 "include/linux/gfp.h"
extern unsigned long __get_free_pages(gfp_t  , unsigned int  ) ;
#line 360
extern void free_pages(unsigned long  , unsigned int  ) ;
#line 43 "include/linux/rculist.h"
extern void __list_add_rcu(struct list_head * , struct list_head * , struct list_head * ) ;
#line 84 "include/linux/rculist.h"
__inline static void list_add_tail_rcu(struct list_head *new , struct list_head *head ) 
{ 


  {
#line 87
  __list_add_rcu(new, head->prev, head);
#line 88
  return;
}
}
#line 205 "include/linux/page-flags.h"
__inline static int PageSlab(struct page  const  *page ) 
{ 
  int tmp ;

  {
#line 205
  tmp = constant_test_bit(7U, (unsigned long const volatile   *)(& page->flags));
#line 205
  return (tmp);
}
}
#line 2047 "include/linux/fs.h"
extern int register_blkdev(unsigned int  , char const   * ) ;
#line 2048
extern void unregister_blkdev(unsigned int  , char const   * ) ;
#line 2049
extern struct block_device *bdget(dev_t  ) ;
#line 2054
extern void bdput(struct block_device * ) ;
#line 2097
extern int blkdev_put(struct block_device * , fmode_t  ) ;
#line 1866 "include/linux/sched.h"
extern int set_cpus_allowed_ptr(struct task_struct * , struct cpumask  const  * ) ;
#line 2147
extern int wake_up_process(struct task_struct * ) ;
#line 246 "include/linux/net.h"
extern int kernel_sendmsg(struct socket * , struct msghdr * , struct kvec * , size_t  ,
                          size_t  ) ;
#line 270
extern int kernel_sock_shutdown(struct socket * , enum sock_shutdown_cmd  ) ;
#line 125 "include/linux/slab.h"
extern struct kmem_cache *kmem_cache_create(char const   * , size_t  , size_t  , unsigned long  ,
                                            void (*)(void * ) ) ;
#line 128
extern void kmem_cache_destroy(struct kmem_cache * ) ;
#line 111 "include/linux/proc_fs.h"
extern struct proc_dir_entry *proc_create_data(char const   * , umode_t  , struct proc_dir_entry * ,
                                               struct file_operations  const  * ,
                                               void * ) ;
#line 115
extern void remove_proc_entry(char const   * , struct proc_dir_entry * ) ;
#line 105 "include/linux/idr.h"
extern int idr_pre_get(struct idr * , gfp_t  ) ;
#line 107
extern int idr_get_new_above(struct idr * , void * , int  , int * ) ;
#line 112
extern void idr_remove(struct idr * , int  ) ;
#line 114
extern void idr_destroy(struct idr * ) ;
#line 115
extern void idr_init(struct idr * ) ;
#line 13 "include/linux/reboot.h"
extern int register_reboot_notifier(struct notifier_block * ) ;
#line 14
extern int unregister_reboot_notifier(struct notifier_block * ) ;
#line 8 "include/linux/kthread.h"
extern struct task_struct *kthread_create_on_node(int (*)(void * ) , void * , int  ,
                                                  char const   *  , ...) ;
#line 413 "include/linux/genhd.h"
extern void add_disk(struct gendisk * ) ;
#line 414
extern void del_gendisk(struct gendisk * ) ;
#line 419
extern void set_disk_ro(struct gendisk * , int  ) ;
#line 613
extern struct gendisk *alloc_disk(int  ) ;
#line 615
extern void put_disk(struct gendisk * ) ;
#line 26 "include/linux/mempool.h"
extern mempool_t *mempool_create(int  , mempool_alloc_t * , mempool_free_t * , void * ) ;
#line 33
extern void mempool_destroy(mempool_t * ) ;
#line 41
extern void *mempool_alloc_slab(gfp_t  , void * ) ;
#line 42
extern void mempool_free_slab(void * , void * ) ;
#line 66
extern void *mempool_alloc_pages(gfp_t  , void * ) ;
#line 67
extern void mempool_free_pages(void * , void * ) ;
#line 68 "include/linux/mempool.h"
__inline static mempool_t *mempool_create_page_pool(int min_nr , int order ) 
{ 
  mempool_t *tmp ;

  {
#line 70
  tmp = mempool_create(min_nr, & mempool_alloc_pages, & mempool_free_pages, (void *)((long )order));
#line 70
  return (tmp);
}
}
#line 212 "include/linux/bio.h"
extern struct bio_set *bioset_create(unsigned int  , unsigned int  ) ;
#line 213
extern void bioset_free(struct bio_set * ) ;
#line 787 "include/linux/blkdev.h"
__inline static struct request_queue *bdev_get_queue(struct block_device *bdev ) 
{ 


  {
#line 789
  return ((bdev->bd_disk)->queue);
}
}
#line 895
extern void blk_cleanup_queue(struct request_queue * ) ;
#line 896
extern void blk_queue_make_request(struct request_queue * , make_request_fn * ) ;
#line 897
extern void blk_queue_bounce_limit(struct request_queue * , u64  ) ;
#line 899
extern void blk_queue_max_hw_sectors(struct request_queue * , unsigned int  ) ;
#line 932
extern void blk_queue_merge_bvec(struct request_queue * , merge_bvec_fn * ) ;
#line 938
extern void blk_queue_flush(struct request_queue * , unsigned int  ) ;
#line 949
extern struct request_queue *blk_alloc_queue(gfp_t  ) ;
#line 255 "include/linux/lru_cache.h"
extern void lc_destroy(struct lru_cache * ) ;
#line 22 "include/linux/genl_magic_struct.h"
int drbd_genl_register(void) ;
#line 23
void drbd_genl_unregister(void) ;
#line 134 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_state.h"
void drbd_resume_al(struct drbd_conf *mdev ) ;
#line 66 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
bool disable_sendpage  ;
#line 67 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
bool allow_oos  ;
#line 70 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
int enable_faults  ;
#line 71 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
int fault_rate  ;
#line 72 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
int fault_devs  ;
#line 75
char usermode_helper[80U] ;
#line 167 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct idr minors  ;
#line 168 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct list_head drbd_tconns  ;
#line 1063
void drbd_init_set_defaults(struct drbd_conf *mdev ) ;
#line 1069
void drbd_calc_cpu_mask(struct drbd_tconn *tconn ) ;
#line 1078
int drbd_send(struct drbd_tconn *tconn , struct socket *sock , void *buf , size_t size ,
              unsigned int msg_flags ) ;
#line 1080
int drbd_send_all(struct drbd_tconn *tconn , struct socket *sock , void *buffer ,
                  size_t size , unsigned int msg_flags ) ;
#line 1083
int __drbd_send_protocol(struct drbd_tconn *tconn , enum drbd_packet cmd ) ;
#line 1086
int drbd_send_uuids_skip_initial_sync(struct drbd_conf *mdev ) ;
#line 1089
int drbd_send_state(struct drbd_conf *mdev , union drbd_state state ) ;
#line 1116
void drbd_free_bc(struct drbd_backing_dev *ldev ) ;
#line 1122
int drbd_md_read(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ) ;
#line 1129
void drbd_md_set_flag(struct drbd_conf *mdev , int flag ) ;
#line 1130
void drbd_md_clear_flag(struct drbd_conf *mdev , int flag ) ;
#line 1131
int drbd_md_test_flag(struct drbd_backing_dev *bdev , int flag ) ;
#line 1133
void drbd_md_mark_dirty(struct drbd_conf *mdev ) ;
#line 1139
void drbd_queue_bitmap_io(struct drbd_conf *mdev , int (*io_fn)(struct drbd_conf * ) ,
                          void (*done)(struct drbd_conf * , int  ) , char *why , enum bm_flag flags ) ;
#line 1146
int drbd_bitmap_io_from_worker(struct drbd_conf *mdev , int (*io_fn)(struct drbd_conf * ) ,
                               char *why , enum bm_flag flags ) ;
#line 1365 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct kmem_cache *drbd_request_cache  ;
#line 1366 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct kmem_cache *drbd_ee_cache  ;
#line 1367 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct kmem_cache *drbd_bm_ext_cache  ;
#line 1368 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct kmem_cache *drbd_al_ext_cache  ;
#line 1369 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
mempool_t *drbd_request_mempool  ;
#line 1370 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
mempool_t *drbd_ee_mempool  ;
#line 1385 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct page *drbd_pp_pool  ;
#line 1386 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
spinlock_t drbd_pp_lock  ;
#line 1387 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
int drbd_pp_vacant  ;
#line 1388 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
wait_queue_head_t drbd_pp_wait  ;
#line 1396 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
mempool_t *drbd_md_io_page_pool  ;
#line 1400 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
struct bio_set *drbd_md_io_bio_set  ;
#line 1406
int conn_lowest_minor(struct drbd_tconn *tconn ) ;
#line 1407
enum drbd_ret_code conn_new_minor(struct drbd_tconn *tconn , unsigned int minor ,
                                  int vnr ) ;
#line 1410
int set_resource_options(struct drbd_tconn *tconn , struct res_opts *res_opts ) ;
#line 1411
struct drbd_tconn *conn_create(char const   *name , struct res_opts *res_opts ) ;
#line 1412
void conn_destroy(struct kref *kref ) ;
#line 1413
struct drbd_tconn *conn_get_by_name(char const   *name ) ;
#line 1414
struct drbd_tconn *conn_get_by_addrs(void *my_addr , int my_addr_len , void *peer_addr ,
                                     int peer_addr_len ) ;
#line 1416
void conn_free_crypto(struct drbd_tconn *tconn ) ;
#line 1418 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
int proc_details  ;
#line 1429
int drbd_msg_put_info(char const   *info ) ;
#line 1430
void drbd_suspend_io(struct drbd_conf *mdev ) ;
#line 1431
void drbd_resume_io(struct drbd_conf *mdev ) ;
#line 1675 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void __drbd_chk_io_error____3(struct drbd_conf *mdev , enum drbd_force_detach_flags df ,
                                              char const   *where ) 
{ 
  enum drbd_io_error_p ep ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  union drbd_state __ns ;
  union drbd_state __ns___0 ;

  {
#line 1681
  rcu_read_lock___5();
#line 1682
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1682
  tmp = debug_lockdep_rcu_enabled();
#line 1682
  if (tmp != 0 && ! __warned) {
#line 1682
    tmp___0 = rcu_read_lock_held();
#line 1682
    if (tmp___0 == 0 && 1) {
#line 1682
      __warned = 1;
#line 1682
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1682, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1682
  ep = (enum drbd_io_error_p )_________p1->on_io_error;
#line 1683
  rcu_read_unlock___5();
#line 1684
  switch ((unsigned int )ep) {
  case 0U: ;
#line 1686
  if ((unsigned int )df == 0U || (unsigned int )df == 1U) {
#line 1687
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "__drbd_chk_io_error_");
#line 1687
    if (tmp___1 != 0) {
#line 1688
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s.\n",
              where);
    } else {

    }
#line 1689
    if ((int )mdev->state.ldv_49522.disk > 4) {
#line 1690
      __ns = drbd_read_state(mdev);
#line 1690
      __ns.ldv_40024.disk = 4U;
#line 1690
      _drbd_set_state(mdev, __ns, CS_HARD, 0);
    } else {

    }
#line 1691
    goto ldv_51849;
  } else {

  }
  case 2U: ;
  case 1U: 
#line 1716
  set_bit(12U, (unsigned long volatile   *)(& mdev->flags));
#line 1717
  if ((unsigned int )df == 0U) {
#line 1718
    set_bit(13U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1719
  if ((unsigned int )df == 3U) {
#line 1720
    set_bit(14U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1721
  if ((int )mdev->state.ldv_49522.disk > 2) {
#line 1722
    __ns___0 = drbd_read_state(mdev);
#line 1722
    __ns___0.ldv_40024.disk = 2U;
#line 1722
    _drbd_set_state(mdev, __ns___0, CS_HARD, 0);
#line 1723
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Local IO failed in %s. Detaching...\n",
            where);
  } else {

  }
#line 1726
  goto ldv_51849;
  }
  ldv_51849: ;
#line 1729
  return;
}
}
#line 1739 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_chk_io_error____1(struct drbd_conf *mdev , int error , enum drbd_force_detach_flags forcedetach ,
                                            char const   *where ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 1742
  if (error != 0) {
#line 1744
    tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 1744
    flags = _raw_spin_lock_irqsave(tmp);
#line 1745
    __drbd_chk_io_error____3(mdev, forcedetach, where);
#line 1746
    spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
  } else {

  }
#line 1748
  return;
}
}
#line 1818 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_get_max_capacity___0(struct drbd_backing_dev *bdev ) 
{ 
  sector_t s ;
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  sector_t __min1 ;
  sector_t __min2 ;
  sector_t tmp___2 ;
  sector_t tmp___3 ;
  sector_t __min1___0 ;
  sector_t __min2___0 ;
  sector_t tmp___4 ;
  sector_t __min1___1 ;
  sector_t __min2___1 ;
  sector_t __min1___2 ;
  sector_t __min2___2 ;
  sector_t tmp___5 ;

  {
#line 1823
  rcu_read_lock___5();
#line 1824
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1824
  tmp = debug_lockdep_rcu_enabled();
#line 1824
  if (tmp != 0 && ! __warned) {
#line 1824
    tmp___0 = rcu_read_lock_held();
#line 1824
    if (tmp___0 == 0 && 1) {
#line 1824
      __warned = 1;
#line 1824
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1824, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1824
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1825
  rcu_read_unlock___5();
#line 1827
  switch (meta_dev_idx) {
  case -1: ;
  case -3: 
#line 1831
  tmp___3 = drbd_get_capacity(bdev->backing_bdev);
#line 1831
  if (tmp___3 != 0UL) {
#line 1831
    __min1 = 2251799813685248UL;
#line 1831
    tmp___2 = _drbd_md_first_sector(meta_dev_idx, bdev);
#line 1831
    __min2 = tmp___2;
#line 1831
    s = __min1 < __min2 ? __min1 : __min2;
  } else {
#line 1831
    s = 0UL;
  }
#line 1834
  goto ldv_51906;
  case -2: 
#line 1836
  __min1___0 = 2251799813685248UL;
#line 1836
  tmp___4 = drbd_get_capacity(bdev->backing_bdev);
#line 1836
  __min2___0 = tmp___4;
#line 1836
  s = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
#line 1839
  __min1___1 = s;
#line 1839
  __min2___1 = (unsigned long )(bdev->md.md_size_sect - (u32 )bdev->md.bm_offset) << 15;
#line 1839
  s = __min1___1 < __min2___1 ? __min1___1 : __min2___1;
#line 1842
  goto ldv_51906;
  default: 
#line 1844
  __min1___2 = 8587575296UL;
#line 1844
  tmp___5 = drbd_get_capacity(bdev->backing_bdev);
#line 1844
  __min2___2 = tmp___5;
#line 1844
  s = __min1___2 < __min2___2 ? __min1___2 : __min2___2;
  }
  ldv_51906: ;
#line 1847
  return (s);
}
}
#line 1855 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_md_ss__(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ) 
{ 
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  sector_t tmp___2 ;

  {
#line 1860
  rcu_read_lock___5();
#line 1861
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1861
  tmp = debug_lockdep_rcu_enabled();
#line 1861
  if (tmp != 0 && ! __warned) {
#line 1861
    tmp___0 = rcu_read_lock_held();
#line 1861
    if (tmp___0 == 0 && 1) {
#line 1861
      __warned = 1;
#line 1861
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1861, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1861
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1862
  rcu_read_unlock___5();
#line 1864
  switch (meta_dev_idx) {
  default: ;
#line 1866
  return ((unsigned long )meta_dev_idx * 262144UL);
  case -1: ;
  case -3: ;
#line 1872
  if ((unsigned long )bdev->backing_bdev == (unsigned long )((struct block_device *)0)) {
#line 1873
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "drbd_md_ss__");
#line 1873
    if (tmp___1 != 0) {
#line 1874
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bdev->backing_bdev==NULL\n");
#line 1875
      dump_stack();
    } else {

    }
#line 1877
    return (0UL);
  } else {

  }
#line 1879
  tmp___2 = drbd_get_capacity(bdev->backing_bdev);
#line 1879
  return ((sector_t )(((unsigned long long )tmp___2 & 0xfffffffffffffff8ULL) - 8ULL));
  case -2: ;
#line 1882
  return (0UL);
  }
}
}
#line 1929
int drbd_send_state_req(struct drbd_conf *mdev , union drbd_state mask , union drbd_state val ) ;
#line 1930
int conn_send_state_req(struct drbd_tconn *tconn , union drbd_state mask , union drbd_state val ) ;
#line 2133 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_get_max_buffers___0(struct drbd_conf *mdev ) 
{ 
  struct net_conf *nc ;
  int mxb ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 2138
  rcu_read_lock___5();
#line 2139
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2139
  tmp = debug_lockdep_rcu_enabled();
#line 2139
  if (tmp != 0 && ! __warned) {
#line 2139
    tmp___0 = rcu_read_lock_held();
#line 2139
    if (tmp___0 == 0 && 1) {
#line 2139
      __warned = 1;
#line 2139
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             2139, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2139
  nc = _________p1;
#line 2140
  mxb = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (int )nc->max_buffers : 1000000;
#line 2141
  rcu_read_unlock___5();
#line 2143
  return (mxb);
}
}
#line 2146 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_state_is_stable___0(struct drbd_conf *mdev ) 
{ 
  union drbd_dev_state s ;

  {
#line 2148
  s = mdev->state;
#line 2153
  switch ((unsigned int )s.ldv_49522.conn) {
  case 0U: ;
  case 8U: ;
  case 10U: ;
  case 16U: ;
  case 17U: ;
  case 18U: ;
  case 19U: ;
  case 20U: ;
  case 21U: ;
  case 22U: ;
  case 23U: ;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 9U: ;
  case 11U: ;
  case 12U: ;
#line 2178
  goto ldv_52078;
  case 13U: ;
#line 2182
  if ((mdev->tconn)->agreed_pro_version <= 95) {
#line 2183
    return (0);
  } else {

  }
#line 2184
  goto ldv_52078;
  case 14U: ;
  case 15U: ;
  case 31U: ;
#line 2191
  return (0);
  }
  ldv_52078: ;
#line 2194
  switch ((unsigned int )s.ldv_49522.disk) {
  case 0U: ;
  case 4U: ;
  case 5U: ;
  case 7U: ;
  case 8U: ;
  case 2U: ;
#line 2202
  goto ldv_52089;
  case 1U: ;
  case 3U: ;
  case 6U: ;
  case 15U: ;
#line 2210
  return (0);
  }
  ldv_52089: ;
#line 2213
  return (1);
}
}
#line 2223 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static bool may_inc_ap_bio___0(struct drbd_conf *mdev ) 
{ 
  int mxb ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
#line 2225
  tmp = drbd_get_max_buffers___0(mdev);
#line 2225
  mxb = tmp;
#line 2227
  tmp___0 = drbd_suspended(mdev);
#line 2227
  if (tmp___0 != 0) {
#line 2228
    return (0);
  } else {

  }
#line 2229
  tmp___1 = constant_test_bit(8U, (unsigned long const volatile   *)(& mdev->flags));
#line 2229
  if (tmp___1 != 0) {
#line 2230
    return (0);
  } else {

  }
#line 2237
  tmp___2 = drbd_state_is_stable___0(mdev);
#line 2237
  if (tmp___2 == 0) {
#line 2238
    return (0);
  } else {

  }
#line 2242
  tmp___3 = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 2242
  if (tmp___3 > mxb) {
#line 2243
    return (0);
  } else {

  }
#line 2244
  tmp___4 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2244
  if (tmp___4 != 0) {
#line 2245
    return (0);
  } else {

  }
#line 2246
  return (1);
}
}
#line 2249 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static bool inc_ap_bio_cond___0(struct drbd_conf *mdev ) 
{ 
  bool rv ;

  {
#line 2251
  rv = 0;
#line 2253
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2254
  rv = may_inc_ap_bio___0(mdev);
#line 2255
  if ((int )rv) {
#line 2256
    atomic_inc(& mdev->ap_bio_cnt);
  } else {

  }
#line 2257
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2259
  return (rv);
}
}
#line 2262 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void inc_ap_bio___0(struct drbd_conf *mdev ) 
{ 
  bool tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  bool tmp___1 ;

  {
#line 2272
  tmp = inc_ap_bio_cond___0(mdev);
#line 2272
  if ((int )tmp) {
#line 2272
    goto ldv_52109;
  } else {

  }
#line 2272
  tmp___0 = get_current();
#line 2272
  __wait.flags = 0U;
#line 2272
  __wait.private = (void *)tmp___0;
#line 2272
  __wait.func = & autoremove_wake_function;
#line 2272
  __wait.task_list.next = & __wait.task_list;
#line 2272
  __wait.task_list.prev = & __wait.task_list;
  ldv_52112: 
#line 2272
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 2272
  tmp___1 = inc_ap_bio_cond___0(mdev);
#line 2272
  if ((int )tmp___1) {
#line 2272
    goto ldv_52111;
  } else {

  }
#line 2272
  schedule();
#line 2272
  goto ldv_52112;
  ldv_52111: 
#line 2272
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_52109: ;
#line 2275
  return;
}
}
#line 2275 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void dec_ap_bio___0(struct drbd_conf *mdev ) 
{ 
  int mxb ;
  int tmp ;
  int ap_bio ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 2277
  tmp = drbd_get_max_buffers___0(mdev);
#line 2277
  mxb = tmp;
#line 2278
  tmp___0 = atomic_sub_return(1, & mdev->ap_bio_cnt);
#line 2278
  ap_bio = tmp___0;
#line 2280
  if (ap_bio < 0) {
#line 2280
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( ap_bio >= 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
            2280);
  } else {

  }
#line 2282
  if (ap_bio == 0) {
#line 2282
    tmp___2 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2282
    if (tmp___2 != 0) {
#line 2283
      tmp___1 = test_and_set_bit(10, (unsigned long volatile   *)(& mdev->flags));
#line 2283
      if (tmp___1 == 0) {
#line 2284
        drbd_queue_work(& (mdev->tconn)->sender_work, & mdev->bm_io_work.w);
      } else {

      }
    } else {

    }
  } else {

  }
#line 2290
  if (ap_bio < mxb) {
#line 2291
    __wake_up(& mdev->misc_wait, 3U, 1, 0);
  } else {

  }
#line 2292
  return;
}
}
#line 2307 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static int drbd_queue_order_type(struct drbd_conf *mdev ) 
{ 


  {
#line 2314
  return (0);
}
}
#line 278 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_req.h"
void tl_restart(struct drbd_tconn *tconn , enum drbd_req_event what ) ;
#line 279
void _tl_restart(struct drbd_tconn *tconn , enum drbd_req_event what ) ;
#line 168 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static int __vli_encode_bits(u64 *out , u64 const   in ) 
{ 
  u64 max ;
  u64 adj ;

  {
#line 170
  max = 0ULL;
#line 171
  adj = 1ULL;
#line 173
  if ((unsigned long long )in == 0ULL) {
#line 174
    return (-22);
  } else {

  }
#line 186
  max = max + 2ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = ((unsigned long long )in - adj) << 1;
    } else {

    }
#line 186
    return (2);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 2ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 2) | 1ULL;
    } else {

    }
#line 186
    return (3);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 4ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 3) | 3ULL;
    } else {

    }
#line 186
    return (5);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 8ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 4) | 7ULL;
    } else {

    }
#line 186
    return (7);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 32ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 5) | 15ULL;
    } else {

    }
#line 186
    return (10);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 256ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 6) | 31ULL;
    } else {

    }
#line 186
    return (14);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 8192ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 8) | 63ULL;
    } else {

    }
#line 186
    return (21);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 2097152ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 8) | 127ULL;
    } else {

    }
#line 186
    return (29);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 17179869184ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 8) | 191ULL;
    } else {

    }
#line 186
    return (42);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 186
  max = max + 72057594037927936ULL;
#line 186
  if ((unsigned long long )in <= max) {
#line 186
    if ((unsigned long )out != (unsigned long )((u64 *)0)) {
#line 186
      *out = (((unsigned long long )in - adj) << 8) | 255ULL;
    } else {

    }
#line 186
    return (64);
  } else {

  }
#line 186
  adj = max + 1ULL;
#line 188
  return (-75);
}
}
#line 260 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static int bitstream_put_bits(struct bitstream *bs , u64 val , unsigned int const   bits ) 
{ 
  unsigned char *b ;
  unsigned int tmp ;
  unsigned char *tmp___0 ;
  unsigned char *tmp___1 ;

  {
#line 262
  b = bs->cur.b;
#line 265
  if ((unsigned int )bits == 0U) {
#line 266
    return (0);
  } else {

  }
#line 268
  if ((unsigned long )((long )(bs->cur.b + (unsigned long )(((bs->cur.bit + (unsigned int )bits) - 1U) >> 3)) - (long )bs->buf) >= bs->buf_len) {
#line 269
    return (-105);
  } else {

  }
#line 272
  if ((unsigned int )bits <= 63U) {
#line 273
    val = (0xffffffffffffffffULL >> (int )(64U - (unsigned int )bits)) & val;
  } else {

  }
#line 275
  tmp___0 = b;
#line 275
  b = b + 1;
#line 275
  *tmp___0 = (int )*tmp___0 | (int )((unsigned char )((val & 255ULL) << (int )bs->cur.bit));
#line 277
  tmp = 8U - bs->cur.bit;
#line 277
  goto ldv_52300;
  ldv_52299: 
#line 278
  tmp___1 = b;
#line 278
  b = b + 1;
#line 278
  *tmp___1 = (int )*tmp___1 | (int )((unsigned char )(val >> (int )tmp));
#line 277
  tmp = tmp + 8U;
  ldv_52300: ;
#line 277
  if (tmp < (unsigned int )bits) {
#line 278
    goto ldv_52299;
  } else {

  }
#line 280
  bitstream_cursor_advance(& bs->cur, bits);
#line 281
  return ((int )bits);
}
}
#line 340 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_vli.h"
__inline static int vli_encode_bits(struct bitstream *bs , u64 in ) 
{ 
  u64 code ;
  int bits ;
  int tmp ;
  int tmp___0 ;

  {
#line 342
  code = code;
#line 343
  tmp = __vli_encode_bits(& code, in);
#line 343
  bits = tmp;
#line 345
  if (bits <= 0) {
#line 346
    return (bits);
  } else {

  }
#line 348
  tmp___0 = bitstream_put_bits(bs, code, (unsigned int const   )bits);
#line 348
  return (tmp___0);
}
}
#line 147 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static struct mutex drbd_main_mutex  =    {{1}, {{{{{0U}}, 3735899821U, 4294967295U, 0xffffffffffffffffUL, {0, {0, 0}, "drbd_main_mutex.wait_lock",
                                                                     0, 0UL}}}}, {& drbd_main_mutex.wait_list,
                                                                                  & drbd_main_mutex.wait_list},
    0, 0, (void *)(& drbd_main_mutex), {0, {0, 0}, "drbd_main_mutex", 0, 0UL}};
#line 152
int drbd_init(void) ;
#line 153
static int drbd_open(struct block_device *bdev , fmode_t mode ) ;
#line 154
static int drbd_release(struct gendisk *gd , fmode_t mode ) ;
#line 155
static int w_md_sync(struct drbd_work *w , int unused ) ;
#line 156
static void md_sync_timer_fn(unsigned long data ) ;
#line 157
static int w_bitmap_io(struct drbd_work *w , int unused ) ;
#line 158
static int w_go_diskless(struct drbd_work *w , int unused ) ;
#line 182 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int fault_count  ;
#line 195 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
unsigned int minor_count  =    32U;
#line 202 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
char usermode_helper[80U]  = 
#line 202
  {      '/',      's',      'b',      'i', 
        'n',      '/',      'd',      'r', 
        'b',      'd',      'a',      'd', 
        'm',      '\000'};
#line 232 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct ratelimit_state drbd_ratelimit_state  =    {{{{0U}}, 3735899821U, 4294967295U, 0xffffffffffffffffUL, {0, {0, 0}, "drbd_ratelimit_state.lock",
                                                              0, 0UL}}, 1250, 5, 0,
    0, 0UL};
#line 234 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static struct block_device_operations  const  drbd_ops  = 
#line 234
     {& drbd_open, & drbd_release, 0, 0, 0, 0, 0, 0, 0, 0, 0, & __this_module};
#line 240 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct bio *bio_alloc_drbd(gfp_t gfp_mask ) 
{ 
  struct bio *bio ;
  struct bio *tmp ;

  {
#line 244
  if ((unsigned long )drbd_md_io_bio_set == (unsigned long )((struct bio_set *)0)) {
#line 245
    tmp = bio_alloc(gfp_mask, 1U);
#line 245
    return (tmp);
  } else {

  }
#line 247
  bio = bio_alloc_bioset(gfp_mask, 1, drbd_md_io_bio_set);
#line 248
  if ((unsigned long )bio == (unsigned long )((struct bio *)0)) {
#line 249
    return (0);
  } else {

  }
#line 250
  return (bio);
}
}
#line 282 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void tl_release(struct drbd_tconn *tconn , unsigned int barrier_nr , unsigned int set_size ) 
{ 
  struct drbd_request *r ;
  struct drbd_request *req ;
  int expect_epoch ;
  int expect_size ;
  struct list_head  const  *__mptr ;
  unsigned int s ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head  const  *__mptr___2 ;
  struct list_head  const  *__mptr___3 ;
  struct list_head  const  *__mptr___4 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 286
  req = 0;
#line 287
  expect_epoch = 0;
#line 288
  expect_size = 0;
#line 290
  spin_lock_irq(& tconn->req_lock);
#line 294
  __mptr = (struct list_head  const  *)tconn->transfer_log.next;
#line 294
  r = (struct drbd_request *)__mptr + 0xffffffffffffff98UL;
#line 294
  goto ldv_52496;
  ldv_52495: 
#line 295
  s = r->rq_state;
#line 296
  if ((unsigned long )req == (unsigned long )((struct drbd_request *)0)) {
#line 297
    if (((unsigned long )s & 2048UL) == 0UL) {
#line 298
      goto ldv_52493;
    } else {

    }
#line 299
    if (((unsigned long )s & 1008UL) == 0UL) {
#line 300
      goto ldv_52493;
    } else {

    }
#line 301
    if (((unsigned long )s & 128UL) != 0UL) {
#line 302
      goto ldv_52493;
    } else {

    }
#line 303
    req = r;
#line 304
    expect_epoch = (int )req->epoch;
#line 305
    expect_size = expect_size + 1;
  } else {
#line 307
    if (r->epoch != (unsigned int )expect_epoch) {
#line 308
      goto ldv_52494;
    } else {

    }
#line 309
    if (((unsigned long )s & 2048UL) == 0UL) {
#line 310
      goto ldv_52493;
    } else {

    }
#line 313
    expect_size = expect_size + 1;
  }
  ldv_52493: 
#line 294
  __mptr___0 = (struct list_head  const  *)r->tl_requests.next;
#line 294
  r = (struct drbd_request *)__mptr___0 + 0xffffffffffffff98UL;
  ldv_52496: ;
#line 294
  if ((unsigned long )(& r->tl_requests) != (unsigned long )(& tconn->transfer_log)) {
#line 295
    goto ldv_52495;
  } else {

  }
  ldv_52494: ;
#line 318
  if ((unsigned long )req == (unsigned long )((struct drbd_request *)0)) {
#line 319
    printk("\vd-con %s: BAD! BarrierAck #%u received, but no epoch in tl!?\n", tconn->name,
           barrier_nr);
#line 321
    goto bail;
  } else {

  }
#line 323
  if ((unsigned int )expect_epoch != barrier_nr) {
#line 324
    printk("\vd-con %s: BAD! BarrierAck #%u received, expected #%u!\n", tconn->name,
           barrier_nr, expect_epoch);
#line 326
    goto bail;
  } else {

  }
#line 329
  if ((unsigned int )expect_size != set_size) {
#line 330
    printk("\vd-con %s: BAD! BarrierAck #%u received with n_writes=%u, expected n_writes=%u!\n",
           tconn->name, barrier_nr, set_size, expect_size);
#line 332
    goto bail;
  } else {

  }
#line 339
  __mptr___1 = (struct list_head  const  *)tconn->transfer_log.next;
#line 339
  req = (struct drbd_request *)__mptr___1 + 0xffffffffffffff98UL;
#line 339
  goto ldv_52504;
  ldv_52503: ;
#line 340
  if (req->epoch == (unsigned int )expect_epoch) {
#line 341
    goto ldv_52502;
  } else {

  }
#line 339
  __mptr___2 = (struct list_head  const  *)req->tl_requests.next;
#line 339
  req = (struct drbd_request *)__mptr___2 + 0xffffffffffffff98UL;
  ldv_52504: ;
#line 339
  if ((unsigned long )(& req->tl_requests) != (unsigned long )(& tconn->transfer_log)) {
#line 340
    goto ldv_52503;
  } else {

  }
  ldv_52502: 
#line 342
  __mptr___3 = (struct list_head  const  *)req->tl_requests.next;
#line 342
  r = (struct drbd_request *)__mptr___3 + 0xffffffffffffff98UL;
#line 342
  goto ldv_52511;
  ldv_52510: ;
#line 343
  if (req->epoch != (unsigned int )expect_epoch) {
#line 344
    goto ldv_52509;
  } else {

  }
#line 345
  _req_mod(req, BARRIER_ACKED);
#line 342
  req = r;
#line 342
  __mptr___4 = (struct list_head  const  *)r->tl_requests.next;
#line 342
  r = (struct drbd_request *)__mptr___4 + 0xffffffffffffff98UL;
  ldv_52511: ;
#line 342
  if ((unsigned long )(& req->tl_requests) != (unsigned long )(& tconn->transfer_log)) {
#line 343
    goto ldv_52510;
  } else {

  }
  ldv_52509: 
#line 347
  spin_unlock_irq(& tconn->req_lock);
#line 349
  return;
  bail: 
#line 352
  spin_unlock_irq(& tconn->req_lock);
#line 353
  val.i = 0U;
#line 353
  val.ldv_40024.conn = 6U;
#line 353
  mask.i = 0U;
#line 353
  mask.ldv_40024.conn = 31U;
#line 353
  conn_request_state(tconn, mask, val, CS_HARD);
#line 355
  return;
}
}
#line 366 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void _tl_restart(struct drbd_tconn *tconn , enum drbd_req_event what ) 
{ 
  struct drbd_request *req ;
  struct drbd_request *r ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
#line 370
  __mptr = (struct list_head  const  *)tconn->transfer_log.next;
#line 370
  req = (struct drbd_request *)__mptr + 0xffffffffffffff98UL;
#line 370
  __mptr___0 = (struct list_head  const  *)req->tl_requests.next;
#line 370
  r = (struct drbd_request *)__mptr___0 + 0xffffffffffffff98UL;
#line 370
  goto ldv_52529;
  ldv_52528: 
#line 371
  _req_mod(req, what);
#line 370
  req = r;
#line 370
  __mptr___1 = (struct list_head  const  *)r->tl_requests.next;
#line 370
  r = (struct drbd_request *)__mptr___1 + 0xffffffffffffff98UL;
  ldv_52529: ;
#line 370
  if ((unsigned long )(& req->tl_requests) != (unsigned long )(& tconn->transfer_log)) {
#line 371
    goto ldv_52528;
  } else {

  }

#line 375
  return;
}
}
#line 374 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void tl_restart(struct drbd_tconn *tconn , enum drbd_req_event what ) 
{ 


  {
#line 376
  spin_lock_irq(& tconn->req_lock);
#line 377
  _tl_restart(tconn, what);
#line 378
  spin_unlock_irq(& tconn->req_lock);
#line 379
  return;
}
}
#line 389 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void tl_clear(struct drbd_tconn *tconn ) 
{ 


  {
#line 391
  tl_restart(tconn, CONNECTION_LOST_WHILE_PENDING);
#line 392
  return;
}
}
#line 398 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void tl_abort_disk_io(struct drbd_conf *mdev ) 
{ 
  struct drbd_tconn *tconn ;
  struct drbd_request *req ;
  struct drbd_request *r ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
#line 400
  tconn = mdev->tconn;
#line 403
  spin_lock_irq(& tconn->req_lock);
#line 404
  __mptr = (struct list_head  const  *)tconn->transfer_log.next;
#line 404
  req = (struct drbd_request *)__mptr + 0xffffffffffffff98UL;
#line 404
  __mptr___0 = (struct list_head  const  *)req->tl_requests.next;
#line 404
  r = (struct drbd_request *)__mptr___0 + 0xffffffffffffff98UL;
#line 404
  goto ldv_52552;
  ldv_52551: ;
#line 405
  if (((unsigned long )req->rq_state & 1UL) == 0UL) {
#line 406
    goto ldv_52550;
  } else {

  }
#line 407
  if ((unsigned long )req->w.ldv_49807.mdev != (unsigned long )mdev) {
#line 408
    goto ldv_52550;
  } else {

  }
#line 409
  _req_mod(req, ABORT_DISK_IO);
  ldv_52550: 
#line 404
  req = r;
#line 404
  __mptr___1 = (struct list_head  const  *)r->tl_requests.next;
#line 404
  r = (struct drbd_request *)__mptr___1 + 0xffffffffffffff98UL;
  ldv_52552: ;
#line 404
  if ((unsigned long )(& req->tl_requests) != (unsigned long )(& tconn->transfer_log)) {
#line 405
    goto ldv_52551;
  } else {

  }
#line 411
  spin_unlock_irq(& tconn->req_lock);
#line 412
  return;
}
}
#line 414 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int drbd_thread_setup(void *arg ) 
{ 
  struct drbd_thread *thi ;
  struct drbd_tconn *tconn ;
  unsigned long flags ;
  int retval ;
  struct task_struct *tmp ;
  raw_spinlock_t *tmp___0 ;
  struct task_struct *tmp___1 ;

  {
#line 416
  thi = (struct drbd_thread *)arg;
#line 417
  tconn = thi->tconn;
#line 421
  tmp = get_current();
#line 421
  snprintf((char *)(& tmp->comm), 16UL, "drbd_%c_%s", (int )thi->name[0], (thi->tconn)->name);
  restart: 
#line 425
  retval = (*(thi->function))(thi);
#line 427
  tmp___0 = spinlock_check(& thi->t_lock);
#line 427
  flags = _raw_spin_lock_irqsave(tmp___0);
#line 439
  if ((unsigned int )thi->t_state == 3U) {
#line 440
    printk("\016d-con %s: Restarting %s thread\n", tconn->name, (char *)(& thi->name));
#line 441
    thi->t_state = RUNNING;
#line 442
    spin_unlock_irqrestore(& thi->t_lock, flags);
#line 443
    goto restart;
  } else {

  }
#line 446
  thi->task = 0;
#line 447
  thi->t_state = NONE;
#line 448
  __asm__  volatile   ("mfence": : : "memory");
#line 449
  complete_all(& thi->stop);
#line 450
  spin_unlock_irqrestore(& thi->t_lock, flags);
#line 452
  tmp___1 = get_current();
#line 452
  printk("\016d-con %s: Terminating %s\n", tconn->name, (char *)(& tmp___1->comm));
#line 456
  kref_put(& tconn->kref, & conn_destroy);
#line 457
  module_put(& __this_module);
#line 458
  return (retval);
}
}
#line 461 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_thread_init(struct drbd_tconn *tconn , struct drbd_thread *thi ,
                             int (*func)(struct drbd_thread * ) , char *name ) 
{ 
  struct lock_class_key __key ;

  {
#line 464
  spinlock_check(& thi->t_lock);
#line 464
  __raw_spin_lock_init(& thi->t_lock.ldv_5957.rlock, "&(&thi->t_lock)->rlock", & __key);
#line 465
  thi->task = 0;
#line 466
  thi->t_state = NONE;
#line 467
  thi->function = func;
#line 468
  thi->tconn = tconn;
#line 469
  strncpy((char *)(& thi->name), (char const   *)name, 9UL);
#line 470
  return;
}
}
#line 472 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_thread_start(struct drbd_thread *thi ) 
{ 
  struct drbd_tconn *tconn ;
  struct task_struct *nt ;
  unsigned long flags ;
  raw_spinlock_t *tmp ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  struct task_struct *tmp___4 ;
  long tmp___5 ;
  raw_spinlock_t *tmp___6 ;
  struct task_struct *tmp___7 ;
  struct task_struct *tmp___8 ;

  {
#line 474
  tconn = thi->tconn;
#line 480
  tmp = spinlock_check(& thi->t_lock);
#line 480
  flags = _raw_spin_lock_irqsave(tmp);
#line 482
  switch ((unsigned int )thi->t_state) {
  case 0U: 
#line 484
  tmp___0 = get_current();
#line 484
  tmp___1 = get_current();
#line 484
  printk("\016d-con %s: Starting %s thread (from %s [%d])\n", tconn->name, (char *)(& thi->name),
         (char *)(& tmp___1->comm), tmp___0->pid);
#line 488
  tmp___2 = try_module_get(& __this_module);
#line 488
  if (tmp___2) {
#line 488
    tmp___3 = 0;
  } else {
#line 488
    tmp___3 = 1;
  }
#line 488
  if (tmp___3) {
#line 489
    printk("\vd-con %s: Failed to get module reference in drbd_thread_start\n", tconn->name);
#line 490
    spin_unlock_irqrestore(& thi->t_lock, flags);
#line 491
    return (0);
  } else {

  }
#line 494
  kref_get(& (thi->tconn)->kref);
#line 496
  init_completion(& thi->stop);
#line 497
  thi->reset_cpu_mask = 1;
#line 498
  thi->t_state = RUNNING;
#line 499
  spin_unlock_irqrestore(& thi->t_lock, flags);
#line 500
  tmp___4 = get_current();
#line 500
  flush_signals(tmp___4);
#line 502
  nt = kthread_create_on_node(& drbd_thread_setup, (void *)thi, -1, "drbd_%c_%s",
                              (int )thi->name[0], (thi->tconn)->name);
#line 505
  tmp___5 = IS_ERR((void const   *)nt);
#line 505
  if (tmp___5 != 0L) {
#line 506
    printk("\vd-con %s: Couldn\'t start thread\n", tconn->name);
#line 508
    kref_put(& tconn->kref, & conn_destroy);
#line 509
    module_put(& __this_module);
#line 510
    return (0);
  } else {

  }
#line 512
  tmp___6 = spinlock_check(& thi->t_lock);
#line 512
  flags = _raw_spin_lock_irqsave(tmp___6);
#line 513
  thi->task = nt;
#line 514
  thi->t_state = RUNNING;
#line 515
  spin_unlock_irqrestore(& thi->t_lock, flags);
#line 516
  wake_up_process(nt);
#line 517
  goto ldv_52588;
  case 2U: 
#line 519
  thi->t_state = RESTARTING;
#line 520
  tmp___7 = get_current();
#line 520
  tmp___8 = get_current();
#line 520
  printk("\016d-con %s: Restarting %s thread (from %s [%d])\n", tconn->name, (char *)(& thi->name),
         (char *)(& tmp___8->comm), tmp___7->pid);
  case 1U: ;
  case 3U: ;
  default: 
#line 526
  spin_unlock_irqrestore(& thi->t_lock, flags);
#line 527
  goto ldv_52588;
  }
  ldv_52588: ;
#line 530
  return (1);
}
}
#line 534 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void _drbd_thread_stop(struct drbd_thread *thi , int restart , int wait ) 
{ 
  unsigned long flags ;
  enum drbd_thread_state ns ;
  raw_spinlock_t *tmp ;
  struct task_struct *tmp___0 ;

  {
#line 538
  ns = restart != 0 ? RESTARTING : EXITING;
#line 541
  tmp = spinlock_check(& thi->t_lock);
#line 541
  flags = _raw_spin_lock_irqsave(tmp);
#line 543
  if ((unsigned int )thi->t_state == 0U) {
#line 544
    spin_unlock_irqrestore(& thi->t_lock, flags);
#line 545
    if (restart != 0) {
#line 546
      drbd_thread_start(thi);
    } else {

    }
#line 547
    return;
  } else {

  }
#line 550
  if ((unsigned int )thi->t_state != (unsigned int )ns) {
#line 551
    if ((unsigned long )thi->task == (unsigned long )((struct task_struct *)0)) {
#line 552
      spin_unlock_irqrestore(& thi->t_lock, flags);
#line 553
      return;
    } else {

    }
#line 556
    thi->t_state = ns;
#line 557
    __asm__  volatile   ("mfence": : : "memory");
#line 558
    init_completion(& thi->stop);
#line 559
    tmp___0 = get_current();
#line 559
    if ((unsigned long )thi->task != (unsigned long )tmp___0) {
#line 560
      force_sig(1, thi->task);
    } else {

    }
  } else {

  }
#line 563
  spin_unlock_irqrestore(& thi->t_lock, flags);
#line 565
  if (wait != 0) {
#line 566
    wait_for_completion(& thi->stop);
  } else {

  }
#line 567
  return;
}
}
#line 569 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static struct drbd_thread *drbd_task_to_thread(struct drbd_tconn *tconn , struct task_struct *task ) 
{ 
  struct drbd_thread *thi ;

  {
#line 571
  thi = (unsigned long )tconn->receiver.task == (unsigned long )task ? & tconn->receiver : ((unsigned long )tconn->asender.task == (unsigned long )task ? & tconn->asender : ((unsigned long )tconn->worker.task == (unsigned long )task ? & tconn->worker : 0));
#line 576
  return (thi);
}
}
#line 579 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
char *drbd_task_to_thread_name(struct drbd_tconn *tconn , struct task_struct *task ) 
{ 
  struct drbd_thread *thi ;
  struct drbd_thread *tmp ;

  {
#line 581
  tmp = drbd_task_to_thread(tconn, task);
#line 581
  thi = tmp;
#line 582
  return ((unsigned long )thi != (unsigned long )((struct drbd_thread *)0) ? (char *)(& thi->name) : (char *)(& task->comm));
}
}
#line 585 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int conn_lowest_minor(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  int vnr ;
  int m ;
  void *tmp ;
  unsigned int tmp___0 ;

  {
#line 588
  vnr = 0;
#line 590
  rcu_read_lock___5();
#line 591
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 591
  mdev = (struct drbd_conf *)tmp;
#line 592
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 592
    tmp___0 = mdev_to_minor(mdev);
#line 592
    m = (int )tmp___0;
  } else {
#line 592
    m = -1;
  }
#line 593
  rcu_read_unlock___5();
#line 595
  return (m);
}
}
#line 606 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_calc_cpu_mask(struct drbd_tconn *tconn ) 
{ 
  int ord ;
  int cpu ;
  unsigned int tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  int tmp___2 ;
  unsigned int tmp___3 ;

  {
#line 611
  tmp = cpumask_weight((struct cpumask  const  *)tconn->cpu_mask);
#line 611
  if (tmp != 0U) {
#line 612
    return;
  } else {

  }
#line 614
  tmp___0 = conn_lowest_minor(tconn);
#line 614
  tmp___1 = cpumask_weight(cpu_online_mask);
#line 614
  ord = (int )((unsigned int )tmp___0 % tmp___1);
#line 615
  cpu = -1;
#line 615
  goto ldv_52625;
  ldv_52624: 
#line 616
  tmp___2 = ord;
#line 616
  ord = ord - 1;
#line 616
  if (tmp___2 == 0) {
#line 617
    cpumask_set_cpu((unsigned int )cpu, tconn->cpu_mask);
#line 618
    return;
  } else {

  }
  ldv_52625: 
#line 615
  tmp___3 = cpumask_next(cpu, cpu_online_mask);
#line 615
  cpu = (int )tmp___3;
#line 615
  if (cpu < nr_cpu_ids) {
#line 616
    goto ldv_52624;
  } else {

  }
#line 622
  cpumask_setall(tconn->cpu_mask);
#line 623
  return;
}
}
#line 633 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_thread_current_set_cpu(struct drbd_thread *thi ) 
{ 
  struct task_struct *p ;
  struct task_struct *tmp ;

  {
#line 635
  tmp = get_current();
#line 635
  p = tmp;
#line 637
  if (thi->reset_cpu_mask == 0) {
#line 638
    return;
  } else {

  }
#line 639
  thi->reset_cpu_mask = 0;
#line 640
  set_cpus_allowed_ptr(p, (struct cpumask  const  *)(thi->tconn)->cpu_mask);
#line 641
  return;
}
}
#line 651 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
unsigned int drbd_header_size(struct drbd_tconn *tconn ) 
{ 


  {
#line 653
  if (tconn->agreed_pro_version > 99) {
#line 655
    return (16U);
  } else {
#line 660
    return (8U);
  }
}
}
#line 664 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static unsigned int prepare_header80(struct p_header80 *h , enum drbd_packet cmd ,
                                     int size ) 
{ 
  __u16 tmp ;
  __u16 tmp___0 ;

  {
#line 666
  h->magic = 1728214147U;
#line 667
  tmp = __fswab16((int )((__u16 )cmd));
#line 667
  h->command = tmp;
#line 668
  tmp___0 = __fswab16((int )((__u16 )size));
#line 668
  h->length = tmp___0;
#line 669
  return (8U);
}
}
#line 672 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static unsigned int prepare_header95(struct p_header95 *h , enum drbd_packet cmd ,
                                     int size ) 
{ 
  __u16 tmp ;
  __u32 tmp___0 ;

  {
#line 674
  h->magic = 23171U;
#line 675
  tmp = __fswab16((int )((__u16 )cmd));
#line 675
  h->command = tmp;
#line 676
  tmp___0 = __fswab32((__u32 )size);
#line 676
  h->length = tmp___0;
#line 677
  return (8U);
}
}
#line 680 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static unsigned int prepare_header100(struct p_header100 *h , enum drbd_packet cmd ,
                                      int size , int vnr ) 
{ 
  __u16 tmp ;
  __u16 tmp___0 ;
  __u32 tmp___1 ;

  {
#line 683
  h->magic = 552345734U;
#line 684
  tmp = __fswab16((int )((__u16 )vnr));
#line 684
  h->volume = tmp;
#line 685
  tmp___0 = __fswab16((int )((__u16 )cmd));
#line 685
  h->command = tmp___0;
#line 686
  tmp___1 = __fswab32((__u32 )size);
#line 686
  h->length = tmp___1;
#line 687
  h->pad = 0U;
#line 688
  return (16U);
}
}
#line 691 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static unsigned int prepare_header(struct drbd_tconn *tconn , int vnr , void *buffer ,
                                   enum drbd_packet cmd , int size ) 
{ 
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;

  {
#line 694
  if (tconn->agreed_pro_version > 99) {
#line 695
    tmp = prepare_header100((struct p_header100 *)buffer, cmd, size, vnr);
#line 695
    return (tmp);
  } else
#line 696
  if (tconn->agreed_pro_version > 94 && (unsigned int )size > 32768U) {
#line 698
    tmp___0 = prepare_header95((struct p_header95 *)buffer, cmd, size);
#line 698
    return (tmp___0);
  } else {
#line 700
    tmp___1 = prepare_header80((struct p_header80 *)buffer, cmd, size);
#line 700
    return (tmp___1);
  }
}
}
#line 703 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void *__conn_prepare_command(struct drbd_tconn *tconn , struct drbd_socket *sock ) 
{ 
  unsigned int tmp ;

  {
#line 706
  if ((unsigned long )sock->socket == (unsigned long )((struct socket *)0)) {
#line 707
    return (0);
  } else {

  }
#line 708
  tmp = drbd_header_size(tconn);
#line 708
  return (sock->sbuf + (unsigned long )tmp);
}
}
#line 711 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void *conn_prepare_command(struct drbd_tconn *tconn , struct drbd_socket *sock ) 
{ 
  void *p ;

  {
#line 715
  ldv_mutex_lock_208(& sock->mutex);
#line 716
  p = __conn_prepare_command(tconn, sock);
#line 717
  if ((unsigned long )p == (unsigned long )((void *)0)) {
#line 718
    ldv_mutex_unlock_209(& sock->mutex);
  } else {

  }
#line 720
  return (p);
}
}
#line 723 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void *drbd_prepare_command(struct drbd_conf *mdev , struct drbd_socket *sock ) 
{ 
  void *tmp ;

  {
#line 725
  tmp = conn_prepare_command(mdev->tconn, sock);
#line 725
  return (tmp);
}
}
#line 728 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int __send_command(struct drbd_tconn *tconn , int vnr , struct drbd_socket *sock ,
                          enum drbd_packet cmd , unsigned int header_size , void *data ,
                          unsigned int size ) 
{ 
  int msg_flags ;
  int err ;
  unsigned int tmp ;

  {
#line 743
  msg_flags = (unsigned long )data != (unsigned long )((void *)0) ? 32768 : 0;
#line 745
  tmp = prepare_header(tconn, vnr, sock->sbuf, cmd, (int )(header_size + size));
#line 745
  header_size = tmp + header_size;
#line 747
  err = drbd_send_all(tconn, sock->socket, sock->sbuf, (size_t )header_size, (unsigned int )msg_flags);
#line 749
  if ((unsigned long )data != (unsigned long )((void *)0) && err == 0) {
#line 750
    err = drbd_send_all(tconn, sock->socket, data, (size_t )size, 0U);
  } else {

  }
#line 751
  return (err);
}
}
#line 754 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int __conn_send_command(struct drbd_tconn *tconn , struct drbd_socket *sock ,
                               enum drbd_packet cmd , unsigned int header_size , void *data ,
                               unsigned int size ) 
{ 
  int tmp ;

  {
#line 758
  tmp = __send_command(tconn, 0, sock, cmd, header_size, data, size);
#line 758
  return (tmp);
}
}
#line 761 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int conn_send_command(struct drbd_tconn *tconn , struct drbd_socket *sock , enum drbd_packet cmd ,
                      unsigned int header_size , void *data , unsigned int size ) 
{ 
  int err ;

  {
#line 767
  err = __conn_send_command(tconn, sock, cmd, header_size, data, size);
#line 768
  ldv_mutex_unlock_210(& sock->mutex);
#line 769
  return (err);
}
}
#line 772 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_command(struct drbd_conf *mdev , struct drbd_socket *sock , enum drbd_packet cmd ,
                      unsigned int header_size , void *data , unsigned int size ) 
{ 
  int err ;

  {
#line 778
  err = __send_command(mdev->tconn, mdev->vnr, sock, cmd, header_size, data, size);
#line 780
  ldv_mutex_unlock_211(& sock->mutex);
#line 781
  return (err);
}
}
#line 784 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_ping(struct drbd_tconn *tconn ) 
{ 
  struct drbd_socket *sock ;
  void *tmp ;
  int tmp___0 ;

  {
#line 788
  sock = & tconn->meta;
#line 789
  tmp = conn_prepare_command(tconn, sock);
#line 789
  if ((unsigned long )tmp == (unsigned long )((void *)0)) {
#line 790
    return (-5);
  } else {

  }
#line 791
  tmp___0 = conn_send_command(tconn, sock, P_PING, 0U, 0, 0U);
#line 791
  return (tmp___0);
}
}
#line 794 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_ping_ack(struct drbd_tconn *tconn ) 
{ 
  struct drbd_socket *sock ;
  void *tmp ;
  int tmp___0 ;

  {
#line 798
  sock = & tconn->meta;
#line 799
  tmp = conn_prepare_command(tconn, sock);
#line 799
  if ((unsigned long )tmp == (unsigned long )((void *)0)) {
#line 800
    return (-5);
  } else {

  }
#line 801
  tmp___0 = conn_send_command(tconn, sock, P_PING_ACK, 0U, 0, 0U);
#line 801
  return (tmp___0);
}
}
#line 804 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_sync_param(struct drbd_conf *mdev ) 
{ 
  struct drbd_socket *sock ;
  struct p_rs_param_95 *p ;
  int size ;
  int apv ;
  enum drbd_packet cmd ;
  struct net_conf *nc ;
  struct disk_conf *dc ;
  void *tmp ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  size_t tmp___2 ;
  int tmp___3 ;
  struct disk_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;

  {
#line 809
  apv = (mdev->tconn)->agreed_pro_version;
#line 814
  sock = & (mdev->tconn)->data;
#line 815
  tmp = drbd_prepare_command(mdev, sock);
#line 815
  p = (struct p_rs_param_95 *)tmp;
#line 816
  if ((unsigned long )p == (unsigned long )((struct p_rs_param_95 *)0)) {
#line 817
    return (-5);
  } else {

  }
#line 819
  rcu_read_lock___5();
#line 820
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 820
  tmp___0 = debug_lockdep_rcu_enabled();
#line 820
  if (tmp___0 != 0 && ! __warned) {
#line 820
    tmp___1 = rcu_read_lock_held();
#line 820
    if (tmp___1 == 0 && 1) {
#line 820
      __warned = 1;
#line 820
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                             820, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 820
  nc = _________p1;
#line 822
  if (apv > 87) {
#line 822
    if (apv == 88) {
#line 822
      tmp___2 = strlen((char const   *)(& nc->verify_alg));
#line 822
      tmp___3 = (int )((unsigned int )tmp___2 + 5U);
    } else {
#line 822
      tmp___3 = apv <= 94 ? 132 : 148;
    }
#line 822
    size = tmp___3;
  } else {
#line 822
    size = 4;
  }
#line 828
  cmd = apv > 88 ? P_SYNC_PARAM89 : P_SYNC_PARAM;
#line 831
  memset((void *)(& p->verify_alg), 0, 128UL);
#line 833
  tmp___6 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 833
  if (tmp___6 != 0) {
#line 834
    _________p1___0 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 834
    tmp___4 = debug_lockdep_rcu_enabled();
#line 834
    if (tmp___4 != 0 && ! __warned___0) {
#line 834
      tmp___5 = rcu_read_lock_held();
#line 834
      if (tmp___5 == 0 && 1) {
#line 834
        __warned___0 = 1;
#line 834
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                               834, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 834
    dc = _________p1___0;
#line 835
    p->resync_rate = __fswab32(dc->resync_rate);
#line 836
    p->c_plan_ahead = __fswab32(dc->c_plan_ahead);
#line 837
    p->c_delay_target = __fswab32(dc->c_delay_target);
#line 838
    p->c_fill_target = __fswab32(dc->c_fill_target);
#line 839
    p->c_max_rate = __fswab32(dc->c_max_rate);
#line 840
    put_ldev(mdev);
  } else {
#line 842
    p->resync_rate = 4194304000U;
#line 843
    p->c_plan_ahead = 335544320U;
#line 844
    p->c_delay_target = 167772160U;
#line 845
    p->c_fill_target = 1677721600U;
#line 846
    p->c_max_rate = 9437440U;
  }
#line 849
  if (apv > 87) {
#line 850
    strcpy((char *)(& p->verify_alg), (char const   *)(& nc->verify_alg));
  } else {

  }
#line 851
  if (apv > 88) {
#line 852
    strcpy((char *)(& p->csums_alg), (char const   *)(& nc->csums_alg));
  } else {

  }
#line 853
  rcu_read_unlock___5();
#line 855
  tmp___7 = drbd_send_command(mdev, sock, cmd, (unsigned int )size, 0, 0U);
#line 855
  return (tmp___7);
}
}
#line 858 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int __drbd_send_protocol(struct drbd_tconn *tconn , enum drbd_packet cmd ) 
{ 
  struct drbd_socket *sock ;
  struct p_protocol *p ;
  struct net_conf *nc ;
  int size ;
  int cf ;
  void *tmp ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  size_t tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  int tmp___5 ;

  {
#line 865
  sock = & tconn->data;
#line 866
  tmp = __conn_prepare_command(tconn, sock);
#line 866
  p = (struct p_protocol *)tmp;
#line 867
  if ((unsigned long )p == (unsigned long )((struct p_protocol *)0)) {
#line 868
    return (-5);
  } else {

  }
#line 870
  rcu_read_lock___5();
#line 871
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 871
  tmp___0 = debug_lockdep_rcu_enabled();
#line 871
  if (tmp___0 != 0 && ! __warned) {
#line 871
    tmp___1 = rcu_read_lock_held();
#line 871
    if (tmp___1 == 0 && 1) {
#line 871
      __warned = 1;
#line 871
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                             871, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 871
  nc = _________p1;
#line 873
  if ((int )((signed char )nc->tentative) != 0 && tconn->agreed_pro_version <= 91) {
#line 874
    rcu_read_unlock___5();
#line 875
    ldv_mutex_unlock_212(& sock->mutex);
#line 876
    printk("\vd-con %s: --dry-run is not supported by peer", tconn->name);
#line 877
    return (-95);
  } else {

  }
#line 880
  size = 24;
#line 881
  if (tconn->agreed_pro_version > 86) {
#line 882
    tmp___2 = strlen((char const   *)(& nc->integrity_alg));
#line 882
    size = (int )(((unsigned int )tmp___2 + (unsigned int )size) + 1U);
  } else {

  }
#line 884
  p->protocol = __fswab32(nc->wire_protocol);
#line 885
  p->after_sb_0p = __fswab32(nc->after_sb_0p);
#line 886
  p->after_sb_1p = __fswab32(nc->after_sb_1p);
#line 887
  p->after_sb_2p = __fswab32(nc->after_sb_2p);
#line 888
  tmp___3 = __fswab32((__u32 )nc->two_primaries);
#line 888
  p->two_primaries = tmp___3;
#line 889
  cf = 0;
#line 890
  if ((int )((signed char )nc->discard_my_data) != 0) {
#line 891
    cf = cf | 1;
  } else {

  }
#line 892
  if ((int )((signed char )nc->tentative) != 0) {
#line 893
    cf = cf | 2;
  } else {

  }
#line 894
  tmp___4 = __fswab32((__u32 )cf);
#line 894
  p->conn_flags = tmp___4;
#line 896
  if (tconn->agreed_pro_version > 86) {
#line 897
    strcpy((char *)(& p->integrity_alg), (char const   *)(& nc->integrity_alg));
  } else {

  }
#line 898
  rcu_read_unlock___5();
#line 900
  tmp___5 = __conn_send_command(tconn, sock, cmd, (unsigned int )size, 0, 0U);
#line 900
  return (tmp___5);
}
}
#line 903 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_protocol(struct drbd_tconn *tconn ) 
{ 
  int err ;

  {
#line 907
  ldv_mutex_lock_213(& tconn->data.mutex);
#line 908
  err = __drbd_send_protocol(tconn, P_PROTOCOL);
#line 909
  ldv_mutex_unlock_214(& tconn->data.mutex);
#line 911
  return (err);
}
}
#line 914 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int _drbd_send_uuids(struct drbd_conf *mdev , u64 uuid_flags ) 
{ 
  struct drbd_socket *sock ;
  struct p_uuids *p ;
  int i ;
  int tmp ;
  void *tmp___0 ;
  __u64 tmp___1 ;
  __u64 tmp___2 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  __u64 tmp___6 ;
  int tmp___7 ;

  {
#line 920
  tmp = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 920
  if (tmp == 0) {
#line 921
    return (0);
  } else {

  }
#line 923
  sock = & (mdev->tconn)->data;
#line 924
  tmp___0 = drbd_prepare_command(mdev, sock);
#line 924
  p = (struct p_uuids *)tmp___0;
#line 925
  if ((unsigned long )p == (unsigned long )((struct p_uuids *)0)) {
#line 926
    put_ldev(mdev);
#line 927
    return (-5);
  } else {

  }
#line 929
  spin_lock_irq(& (mdev->ldev)->md.uuid_lock);
#line 930
  i = 0;
#line 930
  goto ldv_52755;
  ldv_52754: 
#line 931
  tmp___1 = __fswab64((mdev->ldev)->md.uuid[i]);
#line 931
  p->uuid[i] = tmp___1;
#line 930
  i = i + 1;
  ldv_52755: ;
#line 930
  if (i <= 3) {
#line 931
    goto ldv_52754;
  } else {

  }
#line 932
  spin_unlock_irq(& (mdev->ldev)->md.uuid_lock);
#line 934
  mdev->comm_bm_set = drbd_bm_total_weight(mdev);
#line 935
  tmp___2 = __fswab64((__u64 )mdev->comm_bm_set);
#line 935
  p->uuid[4] = tmp___2;
#line 936
  rcu_read_lock___5();
#line 937
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 937
  tmp___3 = debug_lockdep_rcu_enabled();
#line 937
  if (tmp___3 != 0 && ! __warned) {
#line 937
    tmp___4 = rcu_read_lock_held();
#line 937
    if (tmp___4 == 0 && 1) {
#line 937
      __warned = 1;
#line 937
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                             937, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 937
  uuid_flags = ((int )((signed char )_________p1->discard_my_data) != 0 ? 1ULL : 0ULL) | uuid_flags;
#line 938
  rcu_read_unlock___5();
#line 939
  tmp___5 = constant_test_bit(5U, (unsigned long const volatile   *)(& mdev->flags));
#line 939
  uuid_flags = (tmp___5 != 0 ? 2ULL : 0ULL) | uuid_flags;
#line 940
  uuid_flags = ((unsigned int )*((unsigned char *)mdev + 745UL) == 8U ? 4ULL : 0ULL) | uuid_flags;
#line 941
  tmp___6 = __fswab64(uuid_flags);
#line 941
  p->uuid[5] = tmp___6;
#line 943
  put_ldev(mdev);
#line 944
  tmp___7 = drbd_send_command(mdev, sock, P_UUIDS, 48U, 0, 0U);
#line 944
  return (tmp___7);
}
}
#line 947 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_uuids(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 949
  tmp = _drbd_send_uuids(mdev, 0ULL);
#line 949
  return (tmp);
}
}
#line 952 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_uuids_skip_initial_sync(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 954
  tmp = _drbd_send_uuids(mdev, 8ULL);
#line 954
  return (tmp);
}
}
#line 957 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_print_uuids(struct drbd_conf *mdev , char const   *text ) 
{ 
  u64 *uuid ;
  int tmp ;

  {
#line 959
  tmp = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 959
  if (tmp != 0) {
#line 960
    uuid = (u64 *)(& (mdev->ldev)->md.uuid);
#line 961
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s %016llX:%016llX:%016llX:%016llX\n",
              text, *uuid, *(uuid + 1UL), *(uuid + 2UL), *(uuid + 3UL));
#line 967
    put_ldev(mdev);
  } else {
#line 969
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s effective data uuid: %016llX\n",
              text, mdev->ed_uuid);
  }
#line 970
  return;
}
}
#line 975 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_gen_and_send_sync_uuid(struct drbd_conf *mdev ) 
{ 
  struct drbd_socket *sock ;
  struct p_rs_uuid *p ;
  u64 uuid ;
  void *tmp ;
  __u64 tmp___0 ;

  {
#line 981
  if ((unsigned int )*((unsigned char *)mdev + 749UL) != 16U) {
#line 981
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->state.disk == D_UP_TO_DATE ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            981);
  } else {

  }
#line 983
  uuid = (mdev->ldev)->md.uuid[1];
#line 984
  if (uuid != 0ULL && uuid != 4ULL) {
#line 985
    uuid = uuid + 281474976710656ULL;
  } else {
#line 987
    get_random_bytes((void *)(& uuid), 8);
  }
#line 988
  drbd_uuid_set(mdev, 1, uuid);
#line 989
  drbd_print_uuids(mdev, "updated sync UUID");
#line 990
  drbd_md_sync(mdev);
#line 992
  sock = & (mdev->tconn)->data;
#line 993
  tmp = drbd_prepare_command(mdev, sock);
#line 993
  p = (struct p_rs_uuid *)tmp;
#line 994
  if ((unsigned long )p != (unsigned long )((struct p_rs_uuid *)0)) {
#line 995
    tmp___0 = __fswab64(uuid);
#line 995
    p->uuid = tmp___0;
#line 996
    drbd_send_command(mdev, sock, P_SYNC_UUID, 8U, 0, 0U);
  } else {

  }
#line 998
  return;
}
}
#line 1000 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_sizes(struct drbd_conf *mdev , int trigger_reply , enum dds_flags flags ) 
{ 
  struct drbd_socket *sock ;
  struct p_sizes *p ;
  sector_t d_size ;
  sector_t u_size ;
  int q_order_type ;
  unsigned int max_bio_size ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  unsigned int _min1 ;
  unsigned int _min2 ;
  int tmp___2 ;
  void *tmp___3 ;
  unsigned int _min1___0 ;
  unsigned int _min2___0 ;
  unsigned int _min1___1 ;
  unsigned int _min2___1 ;
  __u64 tmp___4 ;
  __u64 tmp___5 ;
  sector_t tmp___6 ;
  __u64 tmp___7 ;
  __u64 tmp___8 ;
  __u32 tmp___9 ;
  __u16 tmp___10 ;
  __u16 tmp___11 ;
  int tmp___12 ;

  {
#line 1008
  tmp___2 = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 1008
  if (tmp___2 != 0) {
#line 1009
    if ((unsigned long )(mdev->ldev)->backing_bdev == (unsigned long )((struct block_device *)0)) {
#line 1009
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->ldev->backing_bdev ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
              1009);
    } else {

    }
#line 1010
    d_size = drbd_get_max_capacity___0(mdev->ldev);
#line 1011
    rcu_read_lock___5();
#line 1012
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1012
    tmp = debug_lockdep_rcu_enabled();
#line 1012
    if (tmp != 0 && ! __warned) {
#line 1012
      tmp___0 = rcu_read_lock_held();
#line 1012
      if (tmp___0 == 0 && 1) {
#line 1012
        __warned = 1;
#line 1012
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                               1012, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 1012
    u_size = (sector_t )_________p1->disk_size;
#line 1013
    rcu_read_unlock___5();
#line 1014
    q_order_type = drbd_queue_order_type(mdev);
#line 1015
    tmp___1 = queue_max_hw_sectors((((mdev->ldev)->backing_bdev)->bd_disk)->queue);
#line 1015
    max_bio_size = tmp___1 << 9;
#line 1016
    _min1 = max_bio_size;
#line 1016
    _min2 = 1048576U;
#line 1016
    max_bio_size = _min1 < _min2 ? _min1 : _min2;
#line 1017
    put_ldev(mdev);
  } else {
#line 1019
    d_size = 0UL;
#line 1020
    u_size = 0UL;
#line 1021
    q_order_type = 0;
#line 1022
    max_bio_size = 1048576U;
  }
#line 1025
  sock = & (mdev->tconn)->data;
#line 1026
  tmp___3 = drbd_prepare_command(mdev, sock);
#line 1026
  p = (struct p_sizes *)tmp___3;
#line 1027
  if ((unsigned long )p == (unsigned long )((struct p_sizes *)0)) {
#line 1028
    return (-5);
  } else {

  }
#line 1030
  if ((mdev->tconn)->agreed_pro_version <= 94) {
#line 1031
    _min1___0 = max_bio_size;
#line 1031
    _min2___0 = 32768U;
#line 1031
    max_bio_size = _min1___0 < _min2___0 ? _min1___0 : _min2___0;
  } else
#line 1032
  if ((mdev->tconn)->agreed_pro_version <= 99) {
#line 1033
    _min1___1 = max_bio_size;
#line 1033
    _min2___1 = 131072U;
#line 1033
    max_bio_size = _min1___1 < _min2___1 ? _min1___1 : _min2___1;
  } else {

  }
#line 1035
  tmp___4 = __fswab64((__u64 )d_size);
#line 1035
  p->d_size = tmp___4;
#line 1036
  tmp___5 = __fswab64((__u64 )u_size);
#line 1036
  p->u_size = tmp___5;
#line 1037
  if (trigger_reply == 0) {
#line 1037
    tmp___6 = drbd_get_capacity(mdev->this_bdev);
#line 1037
    tmp___7 = (__u64 )tmp___6;
  } else {
#line 1037
    tmp___7 = 0ULL;
  }
#line 1037
  tmp___8 = __fswab64(tmp___7);
#line 1037
  p->c_size = tmp___8;
#line 1038
  tmp___9 = __fswab32(max_bio_size);
#line 1038
  p->max_bio_size = tmp___9;
#line 1039
  tmp___10 = __fswab16((int )((__u16 )q_order_type));
#line 1039
  p->queue_order_type = tmp___10;
#line 1040
  tmp___11 = __fswab16((int )((__u16 )flags));
#line 1040
  p->dds_flags = tmp___11;
#line 1041
  tmp___12 = drbd_send_command(mdev, sock, P_SIZES, 32U, 0, 0U);
#line 1041
  return (tmp___12);
}
}
#line 1048 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_current_state(struct drbd_conf *mdev ) 
{ 
  struct drbd_socket *sock ;
  struct p_state *p ;
  void *tmp ;
  __u32 tmp___0 ;
  int tmp___1 ;

  {
#line 1053
  sock = & (mdev->tconn)->data;
#line 1054
  tmp = drbd_prepare_command(mdev, sock);
#line 1054
  p = (struct p_state *)tmp;
#line 1055
  if ((unsigned long )p == (unsigned long )((struct p_state *)0)) {
#line 1056
    return (-5);
  } else {

  }
#line 1057
  tmp___0 = __fswab32(mdev->state.i);
#line 1057
  p->state = tmp___0;
#line 1058
  tmp___1 = drbd_send_command(mdev, sock, P_STATE, 4U, 0, 0U);
#line 1058
  return (tmp___1);
}
}
#line 1071 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_state(struct drbd_conf *mdev , union drbd_state state ) 
{ 
  struct drbd_socket *sock ;
  struct p_state *p ;
  void *tmp ;
  __u32 tmp___0 ;
  int tmp___1 ;

  {
#line 1076
  sock = & (mdev->tconn)->data;
#line 1077
  tmp = drbd_prepare_command(mdev, sock);
#line 1077
  p = (struct p_state *)tmp;
#line 1078
  if ((unsigned long )p == (unsigned long )((struct p_state *)0)) {
#line 1079
    return (-5);
  } else {

  }
#line 1080
  tmp___0 = __fswab32(state.i);
#line 1080
  p->state = tmp___0;
#line 1081
  tmp___1 = drbd_send_command(mdev, sock, P_STATE, 4U, 0, 0U);
#line 1081
  return (tmp___1);
}
}
#line 1084 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_state_req(struct drbd_conf *mdev , union drbd_state mask , union drbd_state val ) 
{ 
  struct drbd_socket *sock ;
  struct p_req_state *p ;
  void *tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 1089
  sock = & (mdev->tconn)->data;
#line 1090
  tmp = drbd_prepare_command(mdev, sock);
#line 1090
  p = (struct p_req_state *)tmp;
#line 1091
  if ((unsigned long )p == (unsigned long )((struct p_req_state *)0)) {
#line 1092
    return (-5);
  } else {

  }
#line 1093
  tmp___0 = __fswab32(mask.i);
#line 1093
  p->mask = tmp___0;
#line 1094
  tmp___1 = __fswab32(val.i);
#line 1094
  p->val = tmp___1;
#line 1095
  tmp___2 = drbd_send_command(mdev, sock, P_STATE_CHG_REQ, 8U, 0, 0U);
#line 1095
  return (tmp___2);
}
}
#line 1098 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int conn_send_state_req(struct drbd_tconn *tconn , union drbd_state mask , union drbd_state val ) 
{ 
  enum drbd_packet cmd ;
  struct drbd_socket *sock ;
  struct p_req_state *p ;
  void *tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 1104
  cmd = tconn->agreed_pro_version <= 99 ? P_STATE_CHG_REQ : P_CONN_ST_CHG_REQ;
#line 1105
  sock = & tconn->data;
#line 1106
  tmp = conn_prepare_command(tconn, sock);
#line 1106
  p = (struct p_req_state *)tmp;
#line 1107
  if ((unsigned long )p == (unsigned long )((struct p_req_state *)0)) {
#line 1108
    return (-5);
  } else {

  }
#line 1109
  tmp___0 = __fswab32(mask.i);
#line 1109
  p->mask = tmp___0;
#line 1110
  tmp___1 = __fswab32(val.i);
#line 1110
  p->val = tmp___1;
#line 1111
  tmp___2 = conn_send_command(tconn, sock, cmd, 8U, 0, 0U);
#line 1111
  return (tmp___2);
}
}
#line 1114 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_send_sr_reply(struct drbd_conf *mdev , enum drbd_state_rv retcode ) 
{ 
  struct drbd_socket *sock ;
  struct p_req_state_reply *p ;
  void *tmp ;
  __u32 tmp___0 ;

  {
#line 1119
  sock = & (mdev->tconn)->meta;
#line 1120
  tmp = drbd_prepare_command(mdev, sock);
#line 1120
  p = (struct p_req_state_reply *)tmp;
#line 1121
  if ((unsigned long )p != (unsigned long )((struct p_req_state_reply *)0)) {
#line 1122
    tmp___0 = __fswab32((__u32 )retcode);
#line 1122
    p->retcode = tmp___0;
#line 1123
    drbd_send_command(mdev, sock, P_STATE_CHG_REPLY, 4U, 0, 0U);
  } else {

  }
#line 1125
  return;
}
}
#line 1127 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void conn_send_sr_reply(struct drbd_tconn *tconn , enum drbd_state_rv retcode ) 
{ 
  struct drbd_socket *sock ;
  struct p_req_state_reply *p ;
  enum drbd_packet cmd ;
  void *tmp ;
  __u32 tmp___0 ;

  {
#line 1131
  cmd = tconn->agreed_pro_version <= 99 ? P_STATE_CHG_REPLY : P_CONN_ST_CHG_REPLY;
#line 1133
  sock = & tconn->meta;
#line 1134
  tmp = conn_prepare_command(tconn, sock);
#line 1134
  p = (struct p_req_state_reply *)tmp;
#line 1135
  if ((unsigned long )p != (unsigned long )((struct p_req_state_reply *)0)) {
#line 1136
    tmp___0 = __fswab32((__u32 )retcode);
#line 1136
    p->retcode = tmp___0;
#line 1137
    conn_send_command(tconn, sock, cmd, 4U, 0, 0U);
  } else {

  }
#line 1139
  return;
}
}
#line 1141 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void dcbp_set_code(struct p_compressed_bm *p , enum drbd_bitmap_code code ) 
{ 
  long tmp ;

  {
#line 1143
  tmp = __builtin_expect(((unsigned int )code & 4294967280U) != 0U, 0L);
#line 1143
  if (tmp != 0L) {
#line 1143
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"),
                         "i" (1143), "i" (12UL));
    ldv_52843: ;
#line 1143
    goto ldv_52843;
  } else {

  }
#line 1144
  p->encoding = ((unsigned int )p->encoding & 240U) | (unsigned int )((u8 )code);
#line 1145
  return;
}
}
#line 1147 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void dcbp_set_start(struct p_compressed_bm *p , int set ) 
{ 


  {
#line 1149
  p->encoding = (u8 )(((int )((signed char )p->encoding) & 127) | (set != 0 ? -128 : 0));
#line 1150
  return;
}
}
#line 1152 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void dcbp_set_pad_bits(struct p_compressed_bm *p , int n ) 
{ 
  long tmp ;

  {
#line 1154
  tmp = __builtin_expect((n & -8) != 0, 0L);
#line 1154
  if (tmp != 0L) {
#line 1154
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"),
                         "i" (1154), "i" (12UL));
    ldv_52852: ;
#line 1154
    goto ldv_52852;
  } else {

  }
#line 1155
  p->encoding = (u8 )(((int )((signed char )p->encoding) & -128) | (int )((signed char )(n << 4)));
#line 1156
  return;
}
}
#line 1158 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int fill_bitmap_rle_bits(struct drbd_conf *mdev , struct p_compressed_bm *p , unsigned int size ,
                         struct bm_xfer_ctx *c ) 
{ 
  struct bitstream bs ;
  unsigned long plain_bits ;
  unsigned long tmp ;
  unsigned long rl ;
  unsigned int len ;
  unsigned int toggle ;
  int bits ;
  int use_rle ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;

  {
#line 1172
  rcu_read_lock___5();
#line 1173
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 1173
  tmp___0 = debug_lockdep_rcu_enabled();
#line 1173
  if (tmp___0 != 0 && ! __warned) {
#line 1173
    tmp___1 = rcu_read_lock_held();
#line 1173
    if (tmp___1 == 0 && 1) {
#line 1173
      __warned = 1;
#line 1173
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                             1173, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1173
  use_rle = (int )_________p1->use_rle;
#line 1174
  rcu_read_unlock___5();
#line 1175
  if (use_rle == 0 || (mdev->tconn)->agreed_pro_version <= 89) {
#line 1176
    return (0);
  } else {

  }
#line 1178
  if (c->bit_offset >= c->bm_bits) {
#line 1179
    return (0);
  } else {

  }
#line 1182
  bitstream_init(& bs, (void *)(& p->code), (size_t )size, 0U);
#line 1183
  memset((void *)(& p->code), 0, (size_t )size);
#line 1185
  plain_bits = 0UL;
#line 1190
  toggle = 2U;
  ldv_52872: ;
#line 1195
  if (toggle == 0U) {
#line 1195
    tmp___2 = _drbd_bm_find_next_zero(mdev, c->bit_offset);
#line 1195
    tmp = tmp___2;
  } else {
#line 1195
    tmp___3 = _drbd_bm_find_next(mdev, c->bit_offset);
#line 1195
    tmp = tmp___3;
  }
#line 1197
  if (tmp == 0xffffffffffffffffUL) {
#line 1198
    tmp = c->bm_bits;
  } else {

  }
#line 1199
  rl = tmp - c->bit_offset;
#line 1201
  if (toggle == 2U) {
#line 1202
    if (rl == 0UL) {
#line 1205
      dcbp_set_start(p, 1);
#line 1207
      toggle = toggle == 0U;
#line 1208
      goto ldv_52870;
    } else {

    }
#line 1210
    dcbp_set_start(p, 0);
  } else {

  }
#line 1215
  if (rl == 0UL) {
#line 1216
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "unexpected zero runlength while encoding bitmap t:%u bo:%lu\n",
            toggle, c->bit_offset);
#line 1218
    return (-1);
  } else {

  }
#line 1221
  bits = vli_encode_bits(& bs, (u64 )rl);
#line 1222
  if (bits == -105) {
#line 1223
    goto ldv_52871;
  } else {

  }
#line 1224
  if (bits <= 0) {
#line 1225
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "error while encoding bitmap: %d\n",
            bits);
#line 1226
    return (0);
  } else {

  }
#line 1229
  toggle = toggle == 0U;
#line 1230
  plain_bits = plain_bits + rl;
#line 1231
  c->bit_offset = tmp;
  ldv_52870: ;
#line 1232
  if (c->bit_offset < c->bm_bits) {
#line 1233
    goto ldv_52872;
  } else {

  }
  ldv_52871: 
#line 1234
  len = ((unsigned int )((long )bs.cur.b) - (unsigned int )((long )(& p->code))) + (unsigned int )(bs.cur.bit != 0U);
#line 1236
  if ((unsigned long )(len << 3) > plain_bits) {
#line 1239
    c->bit_offset = c->bit_offset - plain_bits;
#line 1240
    bm_xfer_ctx_bit_to_word_offset(c);
#line 1241
    c->bit_offset = c->word_offset * 64UL;
#line 1242
    return (0);
  } else {

  }
#line 1247
  bm_xfer_ctx_bit_to_word_offset(c);
#line 1250
  dcbp_set_pad_bits(p, (int )(- bs.cur.bit) & 7);
#line 1252
  return ((int )len);
}
}
#line 1262 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int send_bitmap_rle_or_plain(struct drbd_conf *mdev , struct bm_xfer_ctx *c ) 
{ 
  struct drbd_socket *sock ;
  unsigned int header_size ;
  unsigned int tmp ;
  struct p_compressed_bm *p ;
  int len ;
  int err ;
  unsigned int data_size ;
  unsigned long num_words ;
  unsigned long *p___0 ;
  size_t __min1 ;
  size_t __min2 ;

  {
#line 1264
  sock = & (mdev->tconn)->data;
#line 1265
  tmp = drbd_header_size(mdev->tconn);
#line 1265
  header_size = tmp;
#line 1266
  p = (struct p_compressed_bm *)sock->sbuf + (unsigned long )header_size;
#line 1269
  len = fill_bitmap_rle_bits(mdev, p, 4095U - header_size, c);
#line 1271
  if (len < 0) {
#line 1272
    return (-5);
  } else {

  }
#line 1274
  if (len != 0) {
#line 1275
    dcbp_set_code(p, RLE_VLI_Bits);
#line 1276
    err = __send_command(mdev->tconn, mdev->vnr, sock, P_COMPRESSED_BITMAP, (unsigned int )len + 1U,
                         0, 0U);
#line 1279
    c->packets[0] = c->packets[0] + 1U;
#line 1280
    c->bytes[0] = (c->bytes[0] + (header_size + (unsigned int )len)) + 1U;
#line 1282
    if (c->bit_offset >= c->bm_bits) {
#line 1283
      len = 0;
    } else {

    }
  } else {
#line 1289
    p___0 = (unsigned long *)sock->sbuf + (unsigned long )header_size;
#line 1291
    data_size = 4096U - header_size;
#line 1292
    __min1 = (unsigned long )(data_size / 8U);
#line 1292
    __min2 = c->bm_words - c->word_offset;
#line 1292
    num_words = __min1 < __min2 ? __min1 : __min2;
#line 1294
    len = (int )((unsigned int )num_words * 8U);
#line 1295
    if (len != 0) {
#line 1296
      drbd_bm_get_lel(mdev, c->word_offset, num_words, p___0);
    } else {

    }
#line 1297
    err = __send_command(mdev->tconn, mdev->vnr, sock, P_BITMAP, (unsigned int )len,
                         0, 0U);
#line 1298
    c->word_offset = c->word_offset + num_words;
#line 1299
    c->bit_offset = c->word_offset * 64UL;
#line 1301
    c->packets[1] = c->packets[1] + 1U;
#line 1302
    c->bytes[1] = c->bytes[1] + (header_size + (unsigned int )len);
#line 1304
    if (c->bit_offset > c->bm_bits) {
#line 1305
      c->bit_offset = c->bm_bits;
    } else {

    }
  }
#line 1307
  if (err == 0) {
#line 1308
    if (len == 0) {
#line 1309
      INFO_bm_xfer_stats(mdev, "send", c);
#line 1310
      return (0);
    } else {
#line 1312
      return (1);
    }
  } else {

  }
#line 1314
  return (-5);
}
}
#line 1318 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int _drbd_send_bitmap(struct drbd_conf *mdev ) 
{ 
  struct bm_xfer_ctx c ;
  int err ;
  bool _bool ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  struct bm_xfer_ctx __constr_expr_0 ;
  unsigned long tmp___3 ;
  size_t tmp___4 ;

  {
#line 1323
  _bool = (unsigned long )mdev->bitmap != (unsigned long )((struct drbd_bitmap *)0);
#line 1323
  if (! _bool) {
#line 1323
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"mdev->bitmap", "_drbd_send_bitmap");
  } else {

  }
#line 1323
  if (_bool) {
#line 1323
    tmp = 0;
  } else {
#line 1323
    tmp = 1;
  }
#line 1323
  if (tmp) {
#line 1324
    return (0);
  } else {

  }
#line 1326
  tmp___2 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1326
  if (tmp___2 != 0) {
#line 1327
    tmp___1 = drbd_md_test_flag(mdev->ldev, 8);
#line 1327
    if (tmp___1 != 0) {
#line 1328
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Writing the whole bitmap, MDF_FullSync was set.\n");
#line 1329
      drbd_bm_set_all(mdev);
#line 1330
      tmp___0 = drbd_bm_write(mdev);
#line 1330
      if (tmp___0 != 0) {
#line 1334
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Failed to write bitmap to disk!\n");
      } else {
#line 1336
        drbd_md_clear_flag(mdev, 8);
#line 1337
        drbd_md_sync(mdev);
      }
    } else {

    }
#line 1340
    put_ldev(mdev);
  } else {

  }
#line 1343
  tmp___3 = drbd_bm_bits(mdev);
#line 1343
  tmp___4 = drbd_bm_words(mdev);
#line 1343
  __constr_expr_0.bm_bits = tmp___3;
#line 1343
  __constr_expr_0.bm_words = tmp___4;
#line 1343
  __constr_expr_0.bit_offset = 0UL;
#line 1343
  __constr_expr_0.word_offset = 0UL;
#line 1343
  __constr_expr_0.packets[0] = 0U;
#line 1343
  __constr_expr_0.packets[1] = 0U;
#line 1343
  __constr_expr_0.bytes[0] = 0U;
#line 1343
  __constr_expr_0.bytes[1] = 0U;
#line 1343
  c = __constr_expr_0;
  ldv_52897: 
#line 1349
  err = send_bitmap_rle_or_plain(mdev, & c);
#line 1350
  if (err > 0) {
#line 1351
    goto ldv_52897;
  } else {

  }

#line 1352
  return (err == 0);
}
}
#line 1355 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_bitmap(struct drbd_conf *mdev ) 
{ 
  struct drbd_socket *sock ;
  int err ;
  int tmp ;

  {
#line 1357
  sock = & (mdev->tconn)->data;
#line 1358
  err = -1;
#line 1360
  ldv_mutex_lock_215(& sock->mutex);
#line 1361
  if ((unsigned long )sock->socket != (unsigned long )((struct socket *)0)) {
#line 1362
    tmp = _drbd_send_bitmap(mdev);
#line 1362
    err = tmp == 0;
  } else {

  }
#line 1363
  ldv_mutex_unlock_216(& sock->mutex);
#line 1364
  return (err);
}
}
#line 1367 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_send_b_ack(struct drbd_tconn *tconn , u32 barrier_nr , u32 set_size ) 
{ 
  struct drbd_socket *sock ;
  struct p_barrier_ack *p ;
  void *tmp ;
  __u32 tmp___0 ;

  {
#line 1372
  if ((unsigned int )tconn->cstate <= 8U) {
#line 1373
    return;
  } else {

  }
#line 1375
  sock = & tconn->meta;
#line 1376
  tmp = conn_prepare_command(tconn, sock);
#line 1376
  p = (struct p_barrier_ack *)tmp;
#line 1377
  if ((unsigned long )p == (unsigned long )((struct p_barrier_ack *)0)) {
#line 1378
    return;
  } else {

  }
#line 1379
  p->barrier = barrier_nr;
#line 1380
  tmp___0 = __fswab32(set_size);
#line 1380
  p->set_size = tmp___0;
#line 1381
  conn_send_command(tconn, sock, P_BARRIER_ACK, 8U, 0, 0U);
#line 1382
  return;
}
}
#line 1392 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int _drbd_send_ack(struct drbd_conf *mdev , enum drbd_packet cmd , u64 sector ,
                          u32 blksize , u64 block_id ) 
{ 
  struct drbd_socket *sock ;
  struct p_block_ack *p ;
  void *tmp ;
  int tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 1398
  if ((int )mdev->state.ldv_49522.conn <= 9) {
#line 1399
    return (-5);
  } else {

  }
#line 1401
  sock = & (mdev->tconn)->meta;
#line 1402
  tmp = drbd_prepare_command(mdev, sock);
#line 1402
  p = (struct p_block_ack *)tmp;
#line 1403
  if ((unsigned long )p == (unsigned long )((struct p_block_ack *)0)) {
#line 1404
    return (-5);
  } else {

  }
#line 1405
  p->sector = sector;
#line 1406
  p->block_id = block_id;
#line 1407
  p->blksize = blksize;
#line 1408
  tmp___0 = atomic_add_return(1, & mdev->packet_seq);
#line 1408
  tmp___1 = __fswab32((__u32 )tmp___0);
#line 1408
  p->seq_num = tmp___1;
#line 1409
  tmp___2 = drbd_send_command(mdev, sock, cmd, 24U, 0, 0U);
#line 1409
  return (tmp___2);
}
}
#line 1415 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_send_ack_dp(struct drbd_conf *mdev , enum drbd_packet cmd , struct p_data *dp ,
                      int data_size ) 
{ 
  unsigned int tmp ;
  __u32 tmp___0 ;

  {
#line 1418
  if ((unsigned long )(mdev->tconn)->peer_integrity_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 1419
    tmp = crypto_hash_digestsize((mdev->tconn)->peer_integrity_tfm);
#line 1419
    data_size = (int )((unsigned int )data_size - tmp);
  } else {

  }
#line 1420
  tmp___0 = __fswab32((__u32 )data_size);
#line 1420
  _drbd_send_ack(mdev, cmd, dp->sector, tmp___0, dp->block_id);
#line 1422
  return;
}
}
#line 1424 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_send_ack_rp(struct drbd_conf *mdev , enum drbd_packet cmd , struct p_block_req *rp ) 
{ 


  {
#line 1427
  _drbd_send_ack(mdev, cmd, rp->sector, rp->blksize, rp->block_id);
#line 1428
  return;
}
}
#line 1436 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_ack(struct drbd_conf *mdev , enum drbd_packet cmd , struct drbd_peer_request *peer_req ) 
{ 
  __u32 tmp ;
  __u64 tmp___0 ;
  int tmp___1 ;

  {
#line 1439
  tmp = __fswab32(peer_req->i.size);
#line 1439
  tmp___0 = __fswab64((__u64 )peer_req->i.sector);
#line 1439
  tmp___1 = _drbd_send_ack(mdev, cmd, tmp___0, tmp, peer_req->ldv_50726.block_id);
#line 1439
  return (tmp___1);
}
}
#line 1447 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_ack_ex(struct drbd_conf *mdev , enum drbd_packet cmd , sector_t sector ,
                     int blksize , u64 block_id ) 
{ 
  __u64 tmp ;
  __u32 tmp___0 ;
  __u64 tmp___1 ;
  int tmp___2 ;

  {
#line 1450
  tmp = __fswab64(block_id);
#line 1450
  tmp___0 = __fswab32((__u32 )blksize);
#line 1450
  tmp___1 = __fswab64((__u64 )sector);
#line 1450
  tmp___2 = _drbd_send_ack(mdev, cmd, tmp___1, tmp___0, tmp);
#line 1450
  return (tmp___2);
}
}
#line 1456 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_drequest(struct drbd_conf *mdev , int cmd , sector_t sector , int size ,
                       u64 block_id ) 
{ 
  struct drbd_socket *sock ;
  struct p_block_req *p ;
  void *tmp ;
  __u64 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 1462
  sock = & (mdev->tconn)->data;
#line 1463
  tmp = drbd_prepare_command(mdev, sock);
#line 1463
  p = (struct p_block_req *)tmp;
#line 1464
  if ((unsigned long )p == (unsigned long )((struct p_block_req *)0)) {
#line 1465
    return (-5);
  } else {

  }
#line 1466
  tmp___0 = __fswab64((__u64 )sector);
#line 1466
  p->sector = tmp___0;
#line 1467
  p->block_id = block_id;
#line 1468
  tmp___1 = __fswab32((__u32 )size);
#line 1468
  p->blksize = tmp___1;
#line 1469
  tmp___2 = drbd_send_command(mdev, sock, (enum drbd_packet )cmd, 24U, 0, 0U);
#line 1469
  return (tmp___2);
}
}
#line 1472 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_drequest_csum(struct drbd_conf *mdev , sector_t sector , int size ,
                            void *digest , int digest_size , enum drbd_packet cmd ) 
{ 
  struct drbd_socket *sock ;
  struct p_block_req *p ;
  void *tmp ;
  __u64 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 1480
  sock = & (mdev->tconn)->data;
#line 1481
  tmp = drbd_prepare_command(mdev, sock);
#line 1481
  p = (struct p_block_req *)tmp;
#line 1482
  if ((unsigned long )p == (unsigned long )((struct p_block_req *)0)) {
#line 1483
    return (-5);
  } else {

  }
#line 1484
  tmp___0 = __fswab64((__u64 )sector);
#line 1484
  p->sector = tmp___0;
#line 1485
  p->block_id = 0xffffffffffffffffULL;
#line 1486
  tmp___1 = __fswab32((__u32 )size);
#line 1486
  p->blksize = tmp___1;
#line 1487
  tmp___2 = drbd_send_command(mdev, sock, cmd, 24U, digest, (unsigned int )digest_size);
#line 1487
  return (tmp___2);
}
}
#line 1491 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_ov_request(struct drbd_conf *mdev , sector_t sector , int size ) 
{ 
  struct drbd_socket *sock ;
  struct p_block_req *p ;
  void *tmp ;
  __u64 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 1496
  sock = & (mdev->tconn)->data;
#line 1497
  tmp = drbd_prepare_command(mdev, sock);
#line 1497
  p = (struct p_block_req *)tmp;
#line 1498
  if ((unsigned long )p == (unsigned long )((struct p_block_req *)0)) {
#line 1499
    return (-5);
  } else {

  }
#line 1500
  tmp___0 = __fswab64((__u64 )sector);
#line 1500
  p->sector = tmp___0;
#line 1501
  p->block_id = 0xffffffffffffffffULL;
#line 1502
  tmp___1 = __fswab32((__u32 )size);
#line 1502
  p->blksize = tmp___1;
#line 1503
  tmp___2 = drbd_send_command(mdev, sock, P_OV_REQUEST, 24U, 0, 0U);
#line 1503
  return (tmp___2);
}
}
#line 1510 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int we_should_drop_the_connection(struct drbd_tconn *tconn , struct socket *sock ) 
{ 
  int drop_it ;
  enum drbd_thread_state tmp ;
  int tmp___0 ;
  struct task_struct *tmp___1 ;
  struct task_struct *tmp___2 ;

  {
#line 1515
  if ((unsigned long )tconn->meta.socket == (unsigned long )sock || (unsigned long )tconn->asender.task == (unsigned long )((struct task_struct *)0)) {
#line 1515
    tmp___0 = 1;
  } else {
#line 1515
    tmp = get_t_state(& tconn->asender);
#line 1515
    if ((unsigned int )tmp != 1U) {
#line 1515
      tmp___0 = 1;
    } else
#line 1515
    if ((unsigned int )tconn->cstate <= 8U) {
#line 1515
      tmp___0 = 1;
    } else {
#line 1515
      tmp___0 = 0;
    }
  }
#line 1515
  drop_it = tmp___0;
#line 1520
  if (drop_it != 0) {
#line 1521
    return (1);
  } else {

  }
#line 1523
  tconn->ko_count = tconn->ko_count - 1U;
#line 1523
  drop_it = tconn->ko_count == 0U;
#line 1524
  if (drop_it == 0) {
#line 1525
    tmp___1 = get_current();
#line 1525
    tmp___2 = get_current();
#line 1525
    printk("\vd-con %s: [%s/%d] sock_sendmsg time expired, ko = %u\n", tconn->name,
           (char *)(& tmp___2->comm), tmp___1->pid, tconn->ko_count);
#line 1527
    request_ping(tconn);
  } else {

  }
#line 1530
  return (drop_it);
}
}
#line 1533 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_update_congested(struct drbd_tconn *tconn ) 
{ 
  struct sock *sk ;

  {
#line 1535
  sk = (tconn->data.socket)->sk;
#line 1536
  if (sk->sk_wmem_queued > (sk->sk_sndbuf * 4) / 5) {
#line 1537
    set_bit(0U, (unsigned long volatile   *)(& tconn->flags));
  } else {

  }
#line 1538
  return;
}
}
#line 1561 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int _drbd_no_send_page(struct drbd_conf *mdev , struct page *page , int offset ,
                              size_t size , unsigned int msg_flags ) 
{ 
  struct socket *socket ;
  void *addr ;
  int err ;
  void *tmp ;

  {
#line 1568
  socket = (mdev->tconn)->data.socket;
#line 1569
  tmp = kmap(page);
#line 1569
  addr = tmp + (unsigned long )offset;
#line 1570
  err = drbd_send_all(mdev->tconn, socket, addr, size, msg_flags);
#line 1571
  kunmap(page);
#line 1572
  if (err == 0) {
#line 1573
    mdev->send_cnt = mdev->send_cnt + (unsigned int )(size >> 9);
  } else {

  }
#line 1574
  return (err);
}
}
#line 1577 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int _drbd_send_page(struct drbd_conf *mdev , struct page *page , int offset ,
                           size_t size , unsigned int msg_flags ) 
{ 
  struct socket *socket ;
  mm_segment_t oldfs ;
  struct thread_info *tmp ;
  int len ;
  int err ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  struct thread_info *tmp___3 ;
  mm_segment_t __constr_expr_0 ;
  int sent ;
  ssize_t tmp___4 ;
  int tmp___5 ;
  struct thread_info *tmp___6 ;

  {
#line 1580
  socket = (mdev->tconn)->data.socket;
#line 1581
  tmp = current_thread_info___5();
#line 1581
  oldfs = tmp->addr_limit;
#line 1582
  len = (int )size;
#line 1583
  err = -5;
#line 1591
  if ((int )disable_sendpage) {
#line 1592
    tmp___0 = _drbd_no_send_page(mdev, page, offset, size, msg_flags);
#line 1592
    return (tmp___0);
  } else {
#line 1591
    tmp___1 = page_count(page);
#line 1591
    if (tmp___1 <= 0) {
#line 1592
      tmp___0 = _drbd_no_send_page(mdev, page, offset, size, msg_flags);
#line 1592
      return (tmp___0);
    } else {
#line 1591
      tmp___2 = PageSlab((struct page  const  *)page);
#line 1591
      if (tmp___2 != 0) {
#line 1592
        tmp___0 = _drbd_no_send_page(mdev, page, offset, size, msg_flags);
#line 1592
        return (tmp___0);
      } else {

      }
    }
  }
#line 1594
  msg_flags = msg_flags | 16384U;
#line 1595
  drbd_update_congested(mdev->tconn);
#line 1596
  tmp___3 = current_thread_info___5();
#line 1596
  __constr_expr_0.seg = 0xffffffffffffffffUL;
#line 1596
  tmp___3->addr_limit = __constr_expr_0;
  ldv_53004: 
#line 1600
  tmp___4 = (*((socket->ops)->sendpage))(socket, page, offset, (size_t )len, (int )msg_flags);
#line 1600
  sent = (int )tmp___4;
#line 1601
  if (sent <= 0) {
#line 1602
    if (sent == -11) {
#line 1603
      tmp___5 = we_should_drop_the_connection(mdev->tconn, socket);
#line 1603
      if (tmp___5 != 0) {
#line 1604
        goto ldv_53001;
      } else {

      }
#line 1605
      goto ldv_53002;
    } else {

    }
#line 1607
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s: size=%d len=%d sent=%d\n",
             "_drbd_send_page", (int )size, len, sent);
#line 1609
    if (sent < 0) {
#line 1610
      err = sent;
    } else {

    }
#line 1611
    goto ldv_53001;
  } else {

  }
#line 1613
  len = len - sent;
#line 1614
  offset = offset + sent;
  ldv_53002: ;
#line 1615
  if (len > 0) {
#line 1616
    goto ldv_53004;
  } else {

  }
  ldv_53001: 
#line 1616
  tmp___6 = current_thread_info___5();
#line 1616
  tmp___6->addr_limit = oldfs;
#line 1617
  clear_bit(0, (unsigned long volatile   *)(& (mdev->tconn)->flags));
#line 1619
  if (len == 0) {
#line 1620
    err = 0;
#line 1621
    mdev->send_cnt = mdev->send_cnt + (unsigned int )(size >> 9);
  } else {

  }
#line 1623
  return (err);
}
}
#line 1626 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int _drbd_send_bio(struct drbd_conf *mdev , struct bio *bio ) 
{ 
  struct bio_vec *bvec ;
  int i ;
  int err ;

  {
#line 1631
  bvec = bio->bi_io_vec + (unsigned long )bio->bi_idx;
#line 1631
  i = (int )bio->bi_idx;
#line 1631
  goto ldv_53013;
  ldv_53012: 
#line 1634
  err = _drbd_no_send_page(mdev, bvec->bv_page, (int )bvec->bv_offset, (size_t )bvec->bv_len,
                           (int )bio->bi_vcnt + -1 == i ? 0U : 32768U);
#line 1637
  if (err != 0) {
#line 1638
    return (err);
  } else {

  }
#line 1631
  bvec = bvec + 1;
#line 1631
  i = i + 1;
  ldv_53013: ;
#line 1631
  if ((int )bio->bi_vcnt > i) {
#line 1632
    goto ldv_53012;
  } else {

  }

#line 1640
  return (0);
}
}
#line 1643 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int _drbd_send_zc_bio(struct drbd_conf *mdev , struct bio *bio ) 
{ 
  struct bio_vec *bvec ;
  int i ;
  int err ;

  {
#line 1648
  bvec = bio->bi_io_vec + (unsigned long )bio->bi_idx;
#line 1648
  i = (int )bio->bi_idx;
#line 1648
  goto ldv_53023;
  ldv_53022: 
#line 1651
  err = _drbd_send_page(mdev, bvec->bv_page, (int )bvec->bv_offset, (size_t )bvec->bv_len,
                        (int )bio->bi_vcnt + -1 == i ? 0U : 32768U);
#line 1654
  if (err != 0) {
#line 1655
    return (err);
  } else {

  }
#line 1648
  bvec = bvec + 1;
#line 1648
  i = i + 1;
  ldv_53023: ;
#line 1648
  if ((int )bio->bi_vcnt > i) {
#line 1649
    goto ldv_53022;
  } else {

  }

#line 1657
  return (0);
}
}
#line 1660 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int _drbd_send_zc_ee(struct drbd_conf *mdev , struct drbd_peer_request *peer_req ) 
{ 
  struct page *page ;
  unsigned int len ;
  int err ;
  unsigned int l ;
  unsigned int __min1 ;
  unsigned int __min2 ;
  struct page *tmp ;
  struct page *tmp___0 ;

  {
#line 1663
  page = peer_req->pages;
#line 1664
  len = peer_req->i.size;
#line 1668
  goto ldv_53038;
  ldv_53037: 
#line 1669
  __min1 = len;
#line 1669
  __min2 = 4096U;
#line 1669
  l = __min1 < __min2 ? __min1 : __min2;
#line 1671
  tmp = page_chain_next(page);
#line 1671
  err = _drbd_send_page(mdev, page, 0, (size_t )l, (unsigned long )tmp != (unsigned long )((struct page *)0) ? 32768U : 0U);
#line 1673
  if (err != 0) {
#line 1674
    return (err);
  } else {

  }
#line 1675
  len = len - l;
#line 1668
  page = page_chain_next(page);
  ldv_53038: ;
#line 1668
  if ((unsigned long )page != (unsigned long )((struct page *)0)) {
#line 1668
    tmp___0 = page_chain_next(page);
#line 1668
    __builtin_prefetch((void const   *)tmp___0);
#line 1668
    if (1 != 0) {
#line 1669
      goto ldv_53037;
    } else {
#line 1671
      goto ldv_53039;
    }
  } else {

  }
  ldv_53039: ;
#line 1677
  return (0);
}
}
#line 1680 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static u32 bio_flags_to_wire(struct drbd_conf *mdev , unsigned long bi_rw ) 
{ 


  {
#line 1682
  if ((mdev->tconn)->agreed_pro_version > 94) {
#line 1683
    return ((u32 )(((((bi_rw & 16UL) != 0UL ? 2 : 0) | ((bi_rw & 2048UL) != 0UL ? 16 : 0)) | ((bi_rw & 4096UL) != 0UL ? 32 : 0)) | ((bi_rw & 128UL) != 0UL ? 64 : 0)));
  } else {
#line 1688
    return ((bi_rw & 16UL) != 0UL ? 2U : 0U);
  }
}
}
#line 1694 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_dblock(struct drbd_conf *mdev , struct drbd_request *req ) 
{ 
  struct drbd_socket *sock ;
  struct p_data *p ;
  unsigned int dp_flags ;
  int dgs ;
  int err ;
  void *tmp ;
  unsigned int tmp___0 ;
  __u64 tmp___1 ;
  int tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  unsigned char digest[64U] ;
  int tmp___5 ;

  {
#line 1698
  dp_flags = 0U;
#line 1702
  sock = & (mdev->tconn)->data;
#line 1703
  tmp = drbd_prepare_command(mdev, sock);
#line 1703
  p = (struct p_data *)tmp;
#line 1704
  if ((unsigned long )(mdev->tconn)->integrity_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 1704
    tmp___0 = crypto_hash_digestsize((mdev->tconn)->integrity_tfm);
#line 1704
    dgs = (int )tmp___0;
  } else {
#line 1704
    dgs = 0;
  }
#line 1706
  if ((unsigned long )p == (unsigned long )((struct p_data *)0)) {
#line 1707
    return (-5);
  } else {

  }
#line 1708
  tmp___1 = __fswab64((__u64 )req->i.sector);
#line 1708
  p->sector = tmp___1;
#line 1709
  p->block_id = (u64 )req;
#line 1710
  tmp___2 = atomic_add_return(1, & mdev->packet_seq);
#line 1710
  tmp___3 = __fswab32((__u32 )tmp___2);
#line 1710
  p->seq_num = tmp___3;
#line 1711
  dp_flags = bio_flags_to_wire(mdev, (req->master_bio)->bi_rw);
#line 1712
  if ((int )mdev->state.ldv_49522.conn > 15 && (int )mdev->state.ldv_49522.conn <= 21) {
#line 1714
    dp_flags = dp_flags | 4U;
  } else {

  }
#line 1715
  if ((mdev->tconn)->agreed_pro_version > 99) {
#line 1716
    if (((unsigned long )req->rq_state & 32768UL) != 0UL) {
#line 1717
      dp_flags = dp_flags | 128U;
    } else {

    }
#line 1718
    if (((unsigned long )req->rq_state & 65536UL) != 0UL) {
#line 1719
      dp_flags = dp_flags | 256U;
    } else {

    }
  } else {

  }
#line 1721
  tmp___4 = __fswab32(dp_flags);
#line 1721
  p->dp_flags = tmp___4;
#line 1722
  if (dgs != 0) {
#line 1723
    drbd_csum_bio(mdev, (mdev->tconn)->integrity_tfm, req->master_bio, (void *)p + 1U);
  } else {

  }
#line 1724
  err = __send_command(mdev->tconn, mdev->vnr, sock, P_DATA, (unsigned int )dgs + 24U,
                       0, req->i.size);
#line 1725
  if (err == 0) {
#line 1737
    if (((unsigned long )req->rq_state & 98304UL) == 0UL || dgs != 0) {
#line 1738
      err = _drbd_send_bio(mdev, req->master_bio);
    } else {
#line 1740
      err = _drbd_send_zc_bio(mdev, req->master_bio);
    }
#line 1743
    if (dgs > 0 && dgs <= 64) {
#line 1747
      drbd_csum_bio(mdev, (mdev->tconn)->integrity_tfm, req->master_bio, (void *)(& digest));
#line 1748
      tmp___5 = memcmp((void const   *)p + 1U, (void const   *)(& digest), (size_t )dgs);
#line 1748
      if (tmp___5 != 0) {
#line 1749
        dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Digest mismatch, buffer modified by upper layers during write: %llus +%u\n",
                 (unsigned long long )req->i.sector, req->i.size);
      } else {

      }
    } else {

    }
  } else {

  }
#line 1757
  ldv_mutex_unlock_217(& sock->mutex);
#line 1759
  return (err);
}
}
#line 1766 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_block(struct drbd_conf *mdev , enum drbd_packet cmd , struct drbd_peer_request *peer_req ) 
{ 
  struct drbd_socket *sock ;
  struct p_data *p ;
  int err ;
  int dgs ;
  void *tmp ;
  unsigned int tmp___0 ;
  __u64 tmp___1 ;

  {
#line 1774
  sock = & (mdev->tconn)->data;
#line 1775
  tmp = drbd_prepare_command(mdev, sock);
#line 1775
  p = (struct p_data *)tmp;
#line 1777
  if ((unsigned long )(mdev->tconn)->integrity_tfm != (unsigned long )((struct crypto_hash *)0)) {
#line 1777
    tmp___0 = crypto_hash_digestsize((mdev->tconn)->integrity_tfm);
#line 1777
    dgs = (int )tmp___0;
  } else {
#line 1777
    dgs = 0;
  }
#line 1779
  if ((unsigned long )p == (unsigned long )((struct p_data *)0)) {
#line 1780
    return (-5);
  } else {

  }
#line 1781
  tmp___1 = __fswab64((__u64 )peer_req->i.sector);
#line 1781
  p->sector = tmp___1;
#line 1782
  p->block_id = peer_req->ldv_50726.block_id;
#line 1783
  p->seq_num = 0U;
#line 1784
  p->dp_flags = 0U;
#line 1785
  if (dgs != 0) {
#line 1786
    drbd_csum_ee(mdev, (mdev->tconn)->integrity_tfm, peer_req, (void *)p + 1U);
  } else {

  }
#line 1787
  err = __send_command(mdev->tconn, mdev->vnr, sock, cmd, (unsigned int )dgs + 24U,
                       0, peer_req->i.size);
#line 1788
  if (err == 0) {
#line 1789
    err = _drbd_send_zc_ee(mdev, peer_req);
  } else {

  }
#line 1790
  ldv_mutex_unlock_218(& sock->mutex);
#line 1792
  return (err);
}
}
#line 1795 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_out_of_sync(struct drbd_conf *mdev , struct drbd_request *req ) 
{ 
  struct drbd_socket *sock ;
  struct p_block_desc *p ;
  void *tmp ;
  __u64 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 1800
  sock = & (mdev->tconn)->data;
#line 1801
  tmp = drbd_prepare_command(mdev, sock);
#line 1801
  p = (struct p_block_desc *)tmp;
#line 1802
  if ((unsigned long )p == (unsigned long )((struct p_block_desc *)0)) {
#line 1803
    return (-5);
  } else {

  }
#line 1804
  tmp___0 = __fswab64((__u64 )req->i.sector);
#line 1804
  p->sector = tmp___0;
#line 1805
  tmp___1 = __fswab32(req->i.size);
#line 1805
  p->blksize = tmp___1;
#line 1806
  tmp___2 = drbd_send_command(mdev, sock, P_OUT_OF_SYNC, 16U, 0, 0U);
#line 1806
  return (tmp___2);
}
}
#line 1825 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send(struct drbd_tconn *tconn , struct socket *sock , void *buf , size_t size ,
              unsigned int msg_flags ) 
{ 
  struct kvec iov ;
  struct msghdr msg ;
  int rv ;
  int sent ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  struct task_struct *tmp___2 ;
  union drbd_state val ;
  union drbd_state mask ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;

  {
#line 1830
  sent = 0;
#line 1832
  if ((unsigned long )sock == (unsigned long )((struct socket *)0)) {
#line 1833
    return (-53);
  } else {

  }
#line 1837
  iov.iov_base = buf;
#line 1838
  iov.iov_len = size;
#line 1840
  msg.msg_name = 0;
#line 1841
  msg.msg_namelen = 0;
#line 1842
  msg.msg_control = 0;
#line 1843
  msg.msg_controllen = 0UL;
#line 1844
  msg.msg_flags = msg_flags | 16384U;
#line 1846
  if ((unsigned long )tconn->data.socket == (unsigned long )sock) {
#line 1847
    rcu_read_lock___5();
#line 1848
    _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 1848
    tmp = debug_lockdep_rcu_enabled();
#line 1848
    if (tmp != 0 && ! __warned) {
#line 1848
      tmp___0 = rcu_read_lock_held();
#line 1848
      if (tmp___0 == 0 && 1) {
#line 1848
        __warned = 1;
#line 1848
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                               1848, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 1848
    tconn->ko_count = _________p1->ko_count;
#line 1849
    rcu_read_unlock___5();
#line 1850
    drbd_update_congested(tconn);
  } else {

  }
  ldv_53085: 
#line 1862
  rv = kernel_sendmsg(sock, & msg, & iov, 1UL, size);
#line 1863
  if (rv == -11) {
#line 1864
    tmp___1 = we_should_drop_the_connection(tconn, sock);
#line 1864
    if (tmp___1 != 0) {
#line 1865
      goto ldv_53083;
    } else {
#line 1867
      goto ldv_53084;
    }
  } else {

  }
#line 1869
  if (rv == -4) {
#line 1870
    tmp___2 = get_current();
#line 1870
    flush_signals(tmp___2);
#line 1871
    rv = 0;
  } else {

  }
#line 1873
  if (rv < 0) {
#line 1874
    goto ldv_53083;
  } else {

  }
#line 1875
  sent = sent + rv;
#line 1876
  iov.iov_base = iov.iov_base + (unsigned long )rv;
#line 1877
  iov.iov_len = iov.iov_len - (size_t )rv;
  ldv_53084: ;
#line 1878
  if ((size_t )sent < size) {
#line 1879
    goto ldv_53085;
  } else {

  }
  ldv_53083: ;
#line 1880
  if ((unsigned long )tconn->data.socket == (unsigned long )sock) {
#line 1881
    clear_bit(0, (unsigned long volatile   *)(& tconn->flags));
  } else {

  }
#line 1883
  if (rv <= 0) {
#line 1884
    if (rv != -11) {
#line 1885
      printk("\vd-con %s: %s_sendmsg returned %d\n", tconn->name, (unsigned long )tconn->meta.socket == (unsigned long )sock ? (char *)"msock" : (char *)"sock",
             rv);
#line 1888
      val.i = 0U;
#line 1888
      val.ldv_40024.conn = 4U;
#line 1888
      mask.i = 0U;
#line 1888
      mask.ldv_40024.conn = 31U;
#line 1888
      conn_request_state(tconn, mask, val, CS_HARD);
    } else {
#line 1890
      val___0.i = 0U;
#line 1890
      val___0.ldv_40024.conn = 3U;
#line 1890
      mask___0.i = 0U;
#line 1890
      mask___0.ldv_40024.conn = 31U;
#line 1890
      conn_request_state(tconn, mask___0, val___0, CS_HARD);
    }
  } else {

  }
#line 1893
  return (sent);
}
}
#line 1901 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_send_all(struct drbd_tconn *tconn , struct socket *sock , void *buffer ,
                  size_t size , unsigned int msg_flags ) 
{ 
  int err ;

  {
#line 1906
  err = drbd_send(tconn, sock, buffer, size, msg_flags);
#line 1907
  if (err < 0) {
#line 1908
    return (err);
  } else {

  }
#line 1909
  if ((size_t )err != size) {
#line 1910
    return (-5);
  } else {

  }
#line 1911
  return (0);
}
}
#line 1914 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int drbd_open(struct block_device *bdev , fmode_t mode ) 
{ 
  struct drbd_conf *mdev ;
  unsigned long flags ;
  int rv ;
  raw_spinlock_t *tmp ;

  {
#line 1916
  mdev = (struct drbd_conf *)(bdev->bd_disk)->private_data;
#line 1918
  rv = 0;
#line 1920
  ldv_mutex_lock_219(& drbd_main_mutex);
#line 1921
  tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 1921
  flags = _raw_spin_lock_irqsave(tmp);
#line 1925
  if ((unsigned int )*((unsigned char *)mdev + 748UL) != 1U) {
#line 1926
    if ((mode & 2U) != 0U) {
#line 1927
      rv = -30;
    } else
#line 1928
    if (! allow_oos) {
#line 1929
      rv = -124;
    } else {

    }
  } else {

  }
#line 1932
  if (rv == 0) {
#line 1933
    mdev->open_cnt = mdev->open_cnt + 1;
  } else {

  }
#line 1934
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 1935
  ldv_mutex_unlock_220(& drbd_main_mutex);
#line 1937
  return (rv);
}
}
#line 1940 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int drbd_release(struct gendisk *gd , fmode_t mode ) 
{ 
  struct drbd_conf *mdev ;

  {
#line 1942
  mdev = (struct drbd_conf *)gd->private_data;
#line 1943
  ldv_mutex_lock_221(& drbd_main_mutex);
#line 1944
  mdev->open_cnt = mdev->open_cnt - 1;
#line 1945
  ldv_mutex_unlock_222(& drbd_main_mutex);
#line 1946
  return (0);
}
}
#line 1949 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_set_defaults(struct drbd_conf *mdev ) 
{ 
  union drbd_dev_state __constr_expr_0 ;

  {
#line 1953
  __constr_expr_0.ldv_49522.role = 2U;
#line 1953
  __constr_expr_0.ldv_49522.peer = 0U;
#line 1953
  __constr_expr_0.ldv_49522.conn = 0U;
#line 1953
  __constr_expr_0.ldv_49522.disk = 0U;
#line 1953
  __constr_expr_0.ldv_49522.pdsk = 6U;
#line 1953
  __constr_expr_0.ldv_49522._unused = (unsigned char)0;
#line 1953
  __constr_expr_0.ldv_49522.aftr_isp = (unsigned char)0;
#line 1953
  __constr_expr_0.ldv_49522.peer_isp = (unsigned char)0;
#line 1953
  __constr_expr_0.ldv_49522.user_isp = (unsigned char)0;
#line 1953
  __constr_expr_0.ldv_49522._pad = (unsigned short)0;
#line 1953
  mdev->state = __constr_expr_0;
#line 1954
  return;
}
}
#line 1962 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_init_set_defaults(struct drbd_conf *mdev ) 
{ 
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;
  struct lock_class_key __key___2 ;
  struct lock_class_key __key___3 ;
  struct lock_class_key __key___4 ;
  struct lock_class_key __key___5 ;
  struct lock_class_key __key___6 ;
  struct lock_class_key __key___7 ;
  struct lock_class_key __key___8 ;
  struct lock_class_key __key___9 ;
  struct lock_class_key __key___10 ;

  {
#line 1967
  drbd_set_defaults(mdev);
#line 1969
  atomic_set(& mdev->ap_bio_cnt, 0);
#line 1970
  atomic_set(& mdev->ap_pending_cnt, 0);
#line 1971
  atomic_set(& mdev->rs_pending_cnt, 0);
#line 1972
  atomic_set(& mdev->unacked_cnt, 0);
#line 1973
  atomic_set(& mdev->local_cnt, 0);
#line 1974
  atomic_set(& mdev->pp_in_use_by_net, 0);
#line 1975
  atomic_set(& mdev->rs_sect_in, 0);
#line 1976
  atomic_set(& mdev->rs_sect_ev, 0);
#line 1977
  atomic_set(& mdev->ap_in_flight, 0);
#line 1978
  atomic_set(& mdev->md_io_in_use, 0);
#line 1980
  __mutex_init(& mdev->own_state_mutex, "&mdev->own_state_mutex", & __key);
#line 1981
  mdev->state_mutex = & mdev->own_state_mutex;
#line 1983
  spinlock_check(& mdev->al_lock);
#line 1983
  __raw_spin_lock_init(& mdev->al_lock.ldv_5957.rlock, "&(&mdev->al_lock)->rlock",
                       & __key___0);
#line 1984
  spinlock_check(& mdev->peer_seq_lock);
#line 1984
  __raw_spin_lock_init(& mdev->peer_seq_lock.ldv_5957.rlock, "&(&mdev->peer_seq_lock)->rlock",
                       & __key___1);
#line 1986
  INIT_LIST_HEAD(& mdev->active_ee);
#line 1987
  INIT_LIST_HEAD(& mdev->sync_ee);
#line 1988
  INIT_LIST_HEAD(& mdev->done_ee);
#line 1989
  INIT_LIST_HEAD(& mdev->read_ee);
#line 1990
  INIT_LIST_HEAD(& mdev->net_ee);
#line 1991
  INIT_LIST_HEAD(& mdev->resync_reads);
#line 1992
  INIT_LIST_HEAD(& mdev->resync_work.list);
#line 1993
  INIT_LIST_HEAD(& mdev->unplug_work.list);
#line 1994
  INIT_LIST_HEAD(& mdev->go_diskless.list);
#line 1995
  INIT_LIST_HEAD(& mdev->md_sync_work.list);
#line 1996
  INIT_LIST_HEAD(& mdev->start_resync_work.list);
#line 1997
  INIT_LIST_HEAD(& mdev->bm_io_work.w.list);
#line 1999
  mdev->resync_work.cb = & w_resync_timer;
#line 2000
  mdev->unplug_work.cb = & w_send_write_hint;
#line 2001
  mdev->go_diskless.cb = & w_go_diskless;
#line 2002
  mdev->md_sync_work.cb = & w_md_sync;
#line 2003
  mdev->bm_io_work.w.cb = & w_bitmap_io;
#line 2004
  mdev->start_resync_work.cb = & w_start_resync;
#line 2006
  mdev->resync_work.ldv_49807.mdev = mdev;
#line 2007
  mdev->unplug_work.ldv_49807.mdev = mdev;
#line 2008
  mdev->go_diskless.ldv_49807.mdev = mdev;
#line 2009
  mdev->md_sync_work.ldv_49807.mdev = mdev;
#line 2010
  mdev->bm_io_work.w.ldv_49807.mdev = mdev;
#line 2011
  mdev->start_resync_work.ldv_49807.mdev = mdev;
#line 2013
  init_timer_key(& mdev->resync_timer, 0U, "(&mdev->resync_timer)", & __key___2);
#line 2014
  init_timer_key(& mdev->md_sync_timer, 0U, "(&mdev->md_sync_timer)", & __key___3);
#line 2015
  init_timer_key(& mdev->start_resync_timer, 0U, "(&mdev->start_resync_timer)", & __key___4);
#line 2016
  init_timer_key(& mdev->request_timer, 0U, "(&mdev->request_timer)", & __key___5);
#line 2017
  mdev->resync_timer.function = & resync_timer_fn;
#line 2018
  mdev->resync_timer.data = (unsigned long )mdev;
#line 2019
  mdev->md_sync_timer.function = & md_sync_timer_fn;
#line 2020
  mdev->md_sync_timer.data = (unsigned long )mdev;
#line 2021
  mdev->start_resync_timer.function = & start_resync_timer_fn;
#line 2022
  mdev->start_resync_timer.data = (unsigned long )mdev;
#line 2023
  mdev->request_timer.function = & request_timer_fn;
#line 2024
  mdev->request_timer.data = (unsigned long )mdev;
#line 2026
  __init_waitqueue_head(& mdev->misc_wait, "&mdev->misc_wait", & __key___6);
#line 2027
  __init_waitqueue_head(& mdev->state_wait, "&mdev->state_wait", & __key___7);
#line 2028
  __init_waitqueue_head(& mdev->ee_wait, "&mdev->ee_wait", & __key___8);
#line 2029
  __init_waitqueue_head(& mdev->al_wait, "&mdev->al_wait", & __key___9);
#line 2030
  __init_waitqueue_head(& mdev->seq_wait, "&mdev->seq_wait", & __key___10);
#line 2032
  mdev->resync_wenr = 4294967295U;
#line 2033
  mdev->peer_max_bio_size = 4096U;
#line 2034
  mdev->local_max_bio_size = 4096U;
#line 2035
  return;
}
}
#line 2037 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_mdev_cleanup(struct drbd_conf *mdev ) 
{ 
  int i ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;
  unsigned int tmp___2 ;
  unsigned int tmp___3 ;
  sector_t tmp___4 ;
  unsigned long tmp___5 ;
  unsigned long tmp___6 ;
  unsigned long tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;
  int tmp___16 ;
  int tmp___17 ;

  {
#line 2040
  if ((unsigned int )(mdev->tconn)->receiver.t_state != 0U) {
#line 2041
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED: receiver t_state == %d expected 0.\n",
            (unsigned int )(mdev->tconn)->receiver.t_state);
  } else {

  }
#line 2044
  tmp___7 = 0UL;
#line 2044
  mdev->rs_failed = tmp___7;
#line 2044
  tmp___6 = tmp___7;
#line 2044
  mdev->rs_total = tmp___6;
#line 2044
  tmp___5 = tmp___6;
#line 2044
  mdev->rs_start = tmp___5;
#line 2044
  tmp___4 = tmp___5;
#line 2044
  mdev->p_size = tmp___4;
#line 2044
  tmp___3 = (unsigned int )tmp___4;
#line 2044
  mdev->writ_cnt = tmp___3;
#line 2044
  tmp___2 = tmp___3;
#line 2044
  mdev->send_cnt = tmp___2;
#line 2044
  tmp___1 = tmp___2;
#line 2044
  mdev->recv_cnt = tmp___1;
#line 2044
  tmp___0 = tmp___1;
#line 2044
  mdev->read_cnt = tmp___0;
#line 2044
  tmp = tmp___0;
#line 2044
  mdev->bm_writ_cnt = tmp;
#line 2044
  mdev->al_writ_cnt = tmp;
#line 2054
  mdev->rs_last_events = 0;
#line 2055
  mdev->rs_last_sect_ev = 0;
#line 2056
  i = 0;
#line 2056
  goto ldv_53141;
  ldv_53140: 
#line 2057
  mdev->rs_mark_left[i] = 0UL;
#line 2058
  mdev->rs_mark_time[i] = 0UL;
#line 2056
  i = i + 1;
  ldv_53141: ;
#line 2056
  if (i <= 7) {
#line 2057
    goto ldv_53140;
  } else {

  }

#line 2060
  if ((unsigned long )(mdev->tconn)->net_conf != (unsigned long )((struct net_conf *)0)) {
#line 2060
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->tconn->net_conf == NULL ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2060);
  } else {

  }
#line 2062
  drbd_set_my_capacity(mdev, 0UL);
#line 2063
  if ((unsigned long )mdev->bitmap != (unsigned long )((struct drbd_bitmap *)0)) {
#line 2065
    drbd_bm_resize(mdev, 0UL, 1);
#line 2066
    drbd_bm_cleanup(mdev);
  } else {

  }
#line 2069
  drbd_free_bc(mdev->ldev);
#line 2070
  mdev->ldev = 0;
#line 2072
  clear_bit(18, (unsigned long volatile   *)(& mdev->flags));
#line 2074
  tmp___8 = list_empty((struct list_head  const  *)(& mdev->active_ee));
#line 2074
  if (tmp___8 == 0) {
#line 2074
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->active_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2074);
  } else {

  }
#line 2075
  tmp___9 = list_empty((struct list_head  const  *)(& mdev->sync_ee));
#line 2075
  if (tmp___9 == 0) {
#line 2075
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->sync_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2075);
  } else {

  }
#line 2076
  tmp___10 = list_empty((struct list_head  const  *)(& mdev->done_ee));
#line 2076
  if (tmp___10 == 0) {
#line 2076
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->done_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2076);
  } else {

  }
#line 2077
  tmp___11 = list_empty((struct list_head  const  *)(& mdev->read_ee));
#line 2077
  if (tmp___11 == 0) {
#line 2077
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->read_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2077);
  } else {

  }
#line 2078
  tmp___12 = list_empty((struct list_head  const  *)(& mdev->net_ee));
#line 2078
  if (tmp___12 == 0) {
#line 2078
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->net_ee) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2078);
  } else {

  }
#line 2079
  tmp___13 = list_empty((struct list_head  const  *)(& mdev->resync_reads));
#line 2079
  if (tmp___13 == 0) {
#line 2079
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->resync_reads) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2079);
  } else {

  }
#line 2080
  tmp___14 = list_empty((struct list_head  const  *)(& (mdev->tconn)->sender_work.q));
#line 2080
  if (tmp___14 == 0) {
#line 2080
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->tconn->sender_work.q) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2080);
  } else {

  }
#line 2081
  tmp___15 = list_empty((struct list_head  const  *)(& mdev->resync_work.list));
#line 2081
  if (tmp___15 == 0) {
#line 2081
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->resync_work.list) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2081);
  } else {

  }
#line 2082
  tmp___16 = list_empty((struct list_head  const  *)(& mdev->unplug_work.list));
#line 2082
  if (tmp___16 == 0) {
#line 2082
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->unplug_work.list) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2082);
  } else {

  }
#line 2083
  tmp___17 = list_empty((struct list_head  const  *)(& mdev->go_diskless.list));
#line 2083
  if (tmp___17 == 0) {
#line 2083
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->go_diskless.list) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2083);
  } else {

  }
#line 2085
  drbd_set_defaults(mdev);
#line 2086
  return;
}
}
#line 2089 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_destroy_mempools(void) 
{ 
  struct page *page ;

  {
#line 2093
  goto ldv_53148;
  ldv_53147: 
#line 2094
  page = drbd_pp_pool;
#line 2095
  drbd_pp_pool = (struct page *)page->ldv_14746.private;
#line 2096
  __free_pages(page, 0U);
#line 2097
  drbd_pp_vacant = drbd_pp_vacant - 1;
  ldv_53148: ;
#line 2093
  if ((unsigned long )drbd_pp_pool != (unsigned long )((struct page *)0)) {
#line 2094
    goto ldv_53147;
  } else {

  }

#line 2102
  if ((unsigned long )drbd_md_io_bio_set != (unsigned long )((struct bio_set *)0)) {
#line 2103
    bioset_free(drbd_md_io_bio_set);
  } else {

  }
#line 2104
  if ((unsigned long )drbd_md_io_page_pool != (unsigned long )((mempool_t *)0)) {
#line 2105
    mempool_destroy(drbd_md_io_page_pool);
  } else {

  }
#line 2106
  if ((unsigned long )drbd_ee_mempool != (unsigned long )((mempool_t *)0)) {
#line 2107
    mempool_destroy(drbd_ee_mempool);
  } else {

  }
#line 2108
  if ((unsigned long )drbd_request_mempool != (unsigned long )((mempool_t *)0)) {
#line 2109
    mempool_destroy(drbd_request_mempool);
  } else {

  }
#line 2110
  if ((unsigned long )drbd_ee_cache != (unsigned long )((struct kmem_cache *)0)) {
#line 2111
    kmem_cache_destroy(drbd_ee_cache);
  } else {

  }
#line 2112
  if ((unsigned long )drbd_request_cache != (unsigned long )((struct kmem_cache *)0)) {
#line 2113
    kmem_cache_destroy(drbd_request_cache);
  } else {

  }
#line 2114
  if ((unsigned long )drbd_bm_ext_cache != (unsigned long )((struct kmem_cache *)0)) {
#line 2115
    kmem_cache_destroy(drbd_bm_ext_cache);
  } else {

  }
#line 2116
  if ((unsigned long )drbd_al_ext_cache != (unsigned long )((struct kmem_cache *)0)) {
#line 2117
    kmem_cache_destroy(drbd_al_ext_cache);
  } else {

  }
#line 2119
  drbd_md_io_bio_set = 0;
#line 2120
  drbd_md_io_page_pool = 0;
#line 2121
  drbd_ee_mempool = 0;
#line 2122
  drbd_request_mempool = 0;
#line 2123
  drbd_ee_cache = 0;
#line 2124
  drbd_request_cache = 0;
#line 2125
  drbd_bm_ext_cache = 0;
#line 2126
  drbd_al_ext_cache = 0;
#line 2128
  return;
}
}
#line 2131 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int drbd_create_mempools(void) 
{ 
  struct page *page ;
  int number ;
  int i ;
  struct lock_class_key __key ;

  {
#line 2134
  number = (int const   )(minor_count * 256U);
#line 2138
  drbd_request_mempool = 0;
#line 2139
  drbd_ee_cache = 0;
#line 2140
  drbd_request_cache = 0;
#line 2141
  drbd_bm_ext_cache = 0;
#line 2142
  drbd_al_ext_cache = 0;
#line 2143
  drbd_pp_pool = 0;
#line 2144
  drbd_md_io_page_pool = 0;
#line 2145
  drbd_md_io_bio_set = 0;
#line 2148
  drbd_request_cache = kmem_cache_create("drbd_req", 152UL, 0UL, 0UL, 0);
#line 2150
  if ((unsigned long )drbd_request_cache == (unsigned long )((struct kmem_cache *)0)) {
#line 2151
    goto Enomem;
  } else {

  }
#line 2153
  drbd_ee_cache = kmem_cache_create("drbd_ee", 128UL, 0UL, 0UL, 0);
#line 2155
  if ((unsigned long )drbd_ee_cache == (unsigned long )((struct kmem_cache *)0)) {
#line 2156
    goto Enomem;
  } else {

  }
#line 2158
  drbd_bm_ext_cache = kmem_cache_create("drbd_bm", 64UL, 0UL, 0UL, 0);
#line 2160
  if ((unsigned long )drbd_bm_ext_cache == (unsigned long )((struct kmem_cache *)0)) {
#line 2161
    goto Enomem;
  } else {

  }
#line 2163
  drbd_al_ext_cache = kmem_cache_create("drbd_al", 48UL, 0UL, 0UL, 0);
#line 2165
  if ((unsigned long )drbd_al_ext_cache == (unsigned long )((struct kmem_cache *)0)) {
#line 2166
    goto Enomem;
  } else {

  }
#line 2169
  drbd_md_io_bio_set = bioset_create(128U, 0U);
#line 2170
  if ((unsigned long )drbd_md_io_bio_set == (unsigned long )((struct bio_set *)0)) {
#line 2171
    goto Enomem;
  } else {

  }
#line 2173
  drbd_md_io_page_pool = mempool_create_page_pool(128, 0);
#line 2174
  if ((unsigned long )drbd_md_io_page_pool == (unsigned long )((mempool_t *)0)) {
#line 2175
    goto Enomem;
  } else {

  }
#line 2177
  drbd_request_mempool = mempool_create(number, & mempool_alloc_slab, & mempool_free_slab,
                                        (void *)drbd_request_cache);
#line 2179
  if ((unsigned long )drbd_request_mempool == (unsigned long )((mempool_t *)0)) {
#line 2180
    goto Enomem;
  } else {

  }
#line 2182
  drbd_ee_mempool = mempool_create(number, & mempool_alloc_slab, & mempool_free_slab,
                                   (void *)drbd_ee_cache);
#line 2184
  if ((unsigned long )drbd_ee_mempool == (unsigned long )((mempool_t *)0)) {
#line 2185
    goto Enomem;
  } else {

  }
#line 2188
  spinlock_check(& drbd_pp_lock);
#line 2188
  __raw_spin_lock_init(& drbd_pp_lock.ldv_5957.rlock, "&(&drbd_pp_lock)->rlock", & __key);
#line 2190
  i = 0;
#line 2190
  goto ldv_53159;
  ldv_53158: 
#line 2191
  page = alloc_pages(131282U, 0U);
#line 2192
  if ((unsigned long )page == (unsigned long )((struct page *)0)) {
#line 2193
    goto Enomem;
  } else {

  }
#line 2194
  page->ldv_14746.private = (unsigned long )drbd_pp_pool;
#line 2195
  drbd_pp_pool = page;
#line 2190
  i = i + 1;
  ldv_53159: ;
#line 2190
  if (i < number) {
#line 2191
    goto ldv_53158;
  } else {

  }
#line 2197
  drbd_pp_vacant = number;
#line 2199
  return (0);
  Enomem: 
#line 2202
  drbd_destroy_mempools();
#line 2203
  return (-12);
}
}
#line 2206 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int drbd_notify_sys(struct notifier_block *this , unsigned long code , void *unused ) 
{ 


  {
#line 2213
  return (0);
}
}
#line 2216 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static struct notifier_block drbd_notifier  =    {& drbd_notify_sys, 0, 0};
#line 2220 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_release_all_peer_reqs(struct drbd_conf *mdev ) 
{ 
  int rr ;

  {
#line 2224
  rr = drbd_free_peer_reqs(mdev, & mdev->active_ee);
#line 2225
  if (rr != 0) {
#line 2226
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%d EEs in active list found!\n",
            rr);
  } else {

  }
#line 2228
  rr = drbd_free_peer_reqs(mdev, & mdev->sync_ee);
#line 2229
  if (rr != 0) {
#line 2230
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%d EEs in sync list found!\n",
            rr);
  } else {

  }
#line 2232
  rr = drbd_free_peer_reqs(mdev, & mdev->read_ee);
#line 2233
  if (rr != 0) {
#line 2234
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%d EEs in read list found!\n",
            rr);
  } else {

  }
#line 2236
  rr = drbd_free_peer_reqs(mdev, & mdev->done_ee);
#line 2237
  if (rr != 0) {
#line 2238
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%d EEs in done list found!\n",
            rr);
  } else {

  }
#line 2240
  rr = drbd_free_peer_reqs(mdev, & mdev->net_ee);
#line 2241
  if (rr != 0) {
#line 2242
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%d EEs in net list found!\n",
            rr);
  } else {

  }
#line 2243
  return;
}
}
#line 2246 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_minor_destroy(struct kref *kref ) 
{ 
  struct drbd_conf *mdev ;
  struct kref  const  *__mptr ;
  struct drbd_tconn *tconn ;

  {
#line 2248
  __mptr = (struct kref  const  *)kref;
#line 2248
  mdev = (struct drbd_conf *)__mptr + 0xfffffffffffffff4UL;
#line 2249
  tconn = mdev->tconn;
#line 2251
  del_timer_sync(& mdev->request_timer);
#line 2254
  if (mdev->open_cnt != 0) {
#line 2254
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->open_cnt == 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2254);
  } else {

  }
#line 2260
  if ((unsigned long )mdev->this_bdev != (unsigned long )((struct block_device *)0)) {
#line 2261
    bdput(mdev->this_bdev);
  } else {

  }
#line 2263
  drbd_free_bc(mdev->ldev);
#line 2264
  mdev->ldev = 0;
#line 2266
  drbd_release_all_peer_reqs(mdev);
#line 2268
  lc_destroy(mdev->act_log);
#line 2269
  lc_destroy(mdev->resync);
#line 2271
  kfree((void const   *)mdev->p_uuid);
#line 2274
  if ((unsigned long )mdev->bitmap != (unsigned long )((struct drbd_bitmap *)0)) {
#line 2275
    drbd_bm_cleanup(mdev);
  } else {

  }
#line 2276
  __free_pages(mdev->md_io_page, 0U);
#line 2277
  put_disk(mdev->vdisk);
#line 2278
  blk_cleanup_queue(mdev->rq_queue);
#line 2279
  kfree((void const   *)mdev->rs_plan_s);
#line 2280
  kfree((void const   *)mdev);
#line 2282
  kref_put(& tconn->kref, & conn_destroy);
#line 2283
  return;
}
}
#line 2294 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static struct retry_worker retry  ;
#line 2296 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void do_retry(struct work_struct *ws ) 
{ 
  struct retry_worker *retry___0 ;
  struct work_struct  const  *__mptr ;
  struct list_head writes ;
  struct drbd_request *req ;
  struct drbd_request *tmp ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;
  struct drbd_conf *mdev ;
  struct bio *bio ;
  unsigned long start_time ;
  bool expected ;
  bool _bool ;
  int tmp___0 ;
  bool _bool___0 ;
  bool _bool___1 ;
  int tmp___1 ;
  int tmp___2 ;
  struct list_head  const  *__mptr___2 ;

  {
#line 2298
  __mptr = (struct work_struct  const  *)ws;
#line 2298
  retry___0 = (struct retry_worker *)__mptr + 0xfffffffffffffff8UL;
#line 2299
  writes.next = & writes;
#line 2299
  writes.prev = & writes;
#line 2302
  spin_lock_irq(& retry___0->lock);
#line 2303
  list_splice_init(& retry___0->writes, & writes);
#line 2304
  spin_unlock_irq(& retry___0->lock);
#line 2306
  __mptr___0 = (struct list_head  const  *)writes.next;
#line 2306
  req = (struct drbd_request *)__mptr___0 + 0xffffffffffffff98UL;
#line 2306
  __mptr___1 = (struct list_head  const  *)req->tl_requests.next;
#line 2306
  tmp = (struct drbd_request *)__mptr___1 + 0xffffffffffffff98UL;
#line 2306
  goto ldv_53211;
  ldv_53210: 
#line 2307
  mdev = req->w.ldv_49807.mdev;
#line 2308
  bio = req->master_bio;
#line 2309
  start_time = req->start_time;
#line 2313
  tmp___0 = atomic_read((atomic_t const   *)(& req->completion_ref));
#line 2313
  _bool = tmp___0 == 0;
#line 2313
  if (! _bool) {
#line 2313
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"atomic_read(&req->completion_ref) == 0", "do_retry");
  } else {

  }
#line 2315
  if ((int )_bool) {
#line 2314
    _bool___0 = ((unsigned long )req->rq_state & 8192UL) != 0UL;
#line 2314
    if (! _bool___0) {
#line 2314
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
              (char *)"req->rq_state & RQ_POSTPONED", "do_retry");
    } else {

    }
#line 2315
    if ((int )_bool___0) {
#line 2315
      _bool___1 = (bool )(((unsigned long )req->rq_state & 1UL) == 0UL || ((unsigned long )req->rq_state & 8UL) != 0UL);
#line 2315
      if (! _bool___1) {
#line 2315
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
                (char *)"(req->rq_state & RQ_LOCAL_PENDING) == 0 || (req->rq_state & RQ_LOCAL_ABORTED) != 0",
                "do_retry");
      } else {

      }
#line 2315
      if ((int )_bool___1) {
#line 2315
        tmp___1 = 1;
      } else {
#line 2315
        tmp___1 = 0;
      }
    } else {
#line 2315
      tmp___1 = 0;
    }
  } else {
#line 2315
    tmp___1 = 0;
  }
#line 2315
  expected = (bool )tmp___1;
#line 2318
  if (! expected) {
#line 2319
    tmp___2 = atomic_read((atomic_t const   *)(& req->completion_ref));
#line 2319
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "req=%p completion_ref=%d rq_state=%x\n",
            req, tmp___2, req->rq_state);
  } else {

  }
#line 2328
  kref_put(& req->kref, & drbd_req_destroy);
#line 2343
  inc_ap_bio___0(mdev);
#line 2344
  __drbd_make_request(mdev, bio, start_time);
#line 2306
  req = tmp;
#line 2306
  __mptr___2 = (struct list_head  const  *)tmp->tl_requests.next;
#line 2306
  tmp = (struct drbd_request *)__mptr___2 + 0xffffffffffffff98UL;
  ldv_53211: ;
#line 2306
  if ((unsigned long )(& req->tl_requests) != (unsigned long )(& writes)) {
#line 2307
    goto ldv_53210;
  } else {

  }

#line 2311
  return;
}
}
#line 2348 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_restart_request(struct drbd_request *req ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 2351
  tmp = spinlock_check(& retry.lock);
#line 2351
  flags = _raw_spin_lock_irqsave(tmp);
#line 2352
  list_move_tail(& req->tl_requests, & retry.writes);
#line 2353
  spin_unlock_irqrestore(& retry.lock, flags);
#line 2358
  dec_ap_bio___0(req->w.ldv_49807.mdev);
#line 2360
  queue_work(retry.wq, & retry.worker);
#line 2361
  return;
}
}
#line 2364 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_cleanup(void) 
{ 
  unsigned int i ;
  struct drbd_conf *mdev ;
  struct drbd_tconn *tconn ;
  struct drbd_tconn *tmp ;
  void *tmp___0 ;
  unsigned int tmp___1 ;
  void *tmp___2 ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct list_head  const  *__mptr___1 ;

  {
#line 2370
  unregister_reboot_notifier(& drbd_notifier);
#line 2380
  if ((unsigned long )drbd_proc != (unsigned long )((struct proc_dir_entry *)0)) {
#line 2381
    remove_proc_entry("drbd", 0);
  } else {

  }
#line 2383
  if ((unsigned long )retry.wq != (unsigned long )((struct workqueue_struct *)0)) {
#line 2384
    destroy_workqueue(retry.wq);
  } else {

  }
#line 2386
  drbd_genl_unregister();
#line 2388
  i = 0U;
#line 2388
  tmp___0 = idr_get_next(& minors, (int *)(& i));
#line 2388
  mdev = (struct drbd_conf *)tmp___0;
#line 2388
  goto ldv_53228;
  ldv_53227: 
#line 2389
  tmp___1 = mdev_to_minor(mdev);
#line 2389
  idr_remove(& minors, (int )tmp___1);
#line 2390
  idr_remove(& (mdev->tconn)->volumes, mdev->vnr);
#line 2391
  del_gendisk(mdev->vdisk);
#line 2393
  kref_put(& mdev->kref, & drbd_minor_destroy);
#line 2388
  i = i + 1U;
#line 2388
  tmp___2 = idr_get_next(& minors, (int *)(& i));
#line 2388
  mdev = (struct drbd_conf *)tmp___2;
  ldv_53228: ;
#line 2388
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 2389
    goto ldv_53227;
  } else {

  }
#line 2397
  __mptr = (struct list_head  const  *)drbd_tconns.next;
#line 2397
  tconn = (struct drbd_tconn *)__mptr + 0xfffffffffffffff8UL;
#line 2397
  __mptr___0 = (struct list_head  const  *)tconn->all_tconn.next;
#line 2397
  tmp = (struct drbd_tconn *)__mptr___0 + 0xfffffffffffffff8UL;
#line 2397
  goto ldv_53237;
  ldv_53236: 
#line 2398
  list_del(& tconn->all_tconn);
#line 2400
  kref_put(& tconn->kref, & conn_destroy);
#line 2397
  tconn = tmp;
#line 2397
  __mptr___1 = (struct list_head  const  *)tmp->all_tconn.next;
#line 2397
  tmp = (struct drbd_tconn *)__mptr___1 + 0xfffffffffffffff8UL;
  ldv_53237: ;
#line 2397
  if ((unsigned long )(& tconn->all_tconn) != (unsigned long )(& drbd_tconns)) {
#line 2398
    goto ldv_53236;
  } else {

  }
#line 2403
  drbd_destroy_mempools();
#line 2404
  unregister_blkdev(147U, "drbd");
#line 2406
  idr_destroy(& minors);
#line 2408
  printk("\016drbd: module cleanup done.\n");
#line 2409
  return;
}
}
#line 2418 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int drbd_congested(void *congested_data , int bdi_bits ) 
{ 
  struct drbd_conf *mdev ;
  struct request_queue *q ;
  char reason ;
  int r ;
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
#line 2420
  mdev = (struct drbd_conf *)congested_data;
#line 2422
  reason = 45;
#line 2423
  r = 0;
#line 2425
  tmp = may_inc_ap_bio___0(mdev);
#line 2425
  if (tmp) {
#line 2425
    tmp___0 = 0;
  } else {
#line 2425
    tmp___0 = 1;
  }
#line 2425
  if (tmp___0) {
#line 2427
    r = bdi_bits;
#line 2428
    reason = 100;
#line 2429
    goto out;
  } else {

  }
#line 2432
  tmp___2 = constant_test_bit(11U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
#line 2432
  if (tmp___2 != 0) {
#line 2433
    r = r | 4;
#line 2439
    tmp___1 = _get_ldev_if_state(mdev, D_UP_TO_DATE);
#line 2439
    if (tmp___1 == 0) {
#line 2440
      r = r | 8;
    } else {
#line 2442
      put_ldev(mdev);
    }
#line 2443
    r = r & bdi_bits;
#line 2444
    reason = 99;
#line 2445
    goto out;
  } else {

  }
#line 2448
  tmp___3 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 2448
  if (tmp___3 != 0) {
#line 2449
    q = bdev_get_queue((mdev->ldev)->backing_bdev);
#line 2450
    r = bdi_congested(& q->backing_dev_info, bdi_bits);
#line 2451
    put_ldev(mdev);
#line 2452
    if (r != 0) {
#line 2453
      reason = 98;
    } else {

    }
  } else {

  }
#line 2456
  if ((bdi_bits & 4) != 0) {
#line 2456
    tmp___4 = constant_test_bit(0U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
#line 2456
    if (tmp___4 != 0) {
#line 2457
      r = r | 4;
#line 2458
      reason = (int )((signed char )reason) == 98 ? 97 : 110;
    } else {

    }
  } else {

  }
  out: 
#line 2462
  mdev->congestion_reason = reason;
#line 2463
  return (r);
}
}
#line 2466 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_init_workqueue(struct drbd_work_queue *wq ) 
{ 
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;

  {
#line 2468
  spinlock_check(& wq->q_lock);
#line 2468
  __raw_spin_lock_init(& wq->q_lock.ldv_5957.rlock, "&(&wq->q_lock)->rlock", & __key);
#line 2469
  INIT_LIST_HEAD(& wq->q);
#line 2470
  __init_waitqueue_head(& wq->q_wait, "&wq->q_wait", & __key___0);
#line 2472
  return;
}
}
#line 2473 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct drbd_tconn *conn_get_by_name(char const   *name ) 
{ 
  struct drbd_tconn *tconn ;
  struct list_head *__ptr ;
  struct list_head  const  *__mptr ;
  struct list_head *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  struct list_head *__ptr___0 ;
  struct list_head  const  *__mptr___0 ;
  struct list_head *_________p1___0 ;
  bool __warned___0 ;
  int tmp___1 ;

  {
#line 2477
  if ((unsigned long )name == (unsigned long )((char const   *)0) || (int )((signed char )*name) == 0) {
#line 2478
    return (0);
  } else {

  }
#line 2480
  rcu_read_lock___5();
#line 2481
  __ptr = drbd_tconns.next;
#line 2481
  _________p1 = *((struct list_head * volatile  *)(& __ptr));
#line 2481
  tmp = debug_lockdep_rcu_enabled();
#line 2481
  if (tmp != 0 && ! __warned) {
#line 2481
    rcu_read_lock_held();
  } else {

  }
#line 2481
  __mptr = (struct list_head  const  *)_________p1;
#line 2481
  tconn = (struct drbd_tconn *)__mptr + 0xfffffffffffffff8UL;
#line 2481
  goto ldv_53273;
  ldv_53272: 
#line 2482
  tmp___0 = strcmp((char const   *)tconn->name, name);
#line 2482
  if (tmp___0 == 0) {
#line 2483
    kref_get(& tconn->kref);
#line 2484
    goto found;
  } else {

  }
#line 2481
  __ptr___0 = tconn->all_tconn.next;
#line 2481
  _________p1___0 = *((struct list_head * volatile  *)(& __ptr___0));
#line 2481
  tmp___1 = debug_lockdep_rcu_enabled();
#line 2481
  if (tmp___1 != 0 && ! __warned___0) {
#line 2481
    rcu_read_lock_held();
  } else {

  }
#line 2481
  __mptr___0 = (struct list_head  const  *)_________p1___0;
#line 2481
  tconn = (struct drbd_tconn *)__mptr___0 + 0xfffffffffffffff8UL;
  ldv_53273: ;
#line 2481
  if ((unsigned long )(& tconn->all_tconn) != (unsigned long )(& drbd_tconns)) {
#line 2482
    goto ldv_53272;
  } else {

  }
#line 2487
  tconn = 0;
  found: 
#line 2489
  rcu_read_unlock___5();
#line 2490
  return (tconn);
}
}
#line 2493 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct drbd_tconn *conn_get_by_addrs(void *my_addr , int my_addr_len , void *peer_addr ,
                                     int peer_addr_len ) 
{ 
  struct drbd_tconn *tconn ;
  struct list_head *__ptr ;
  struct list_head  const  *__mptr ;
  struct list_head *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  struct list_head *__ptr___0 ;
  struct list_head  const  *__mptr___0 ;
  struct list_head *_________p1___0 ;
  bool __warned___0 ;
  int tmp___2 ;

  {
#line 2498
  rcu_read_lock___5();
#line 2499
  __ptr = drbd_tconns.next;
#line 2499
  _________p1 = *((struct list_head * volatile  *)(& __ptr));
#line 2499
  tmp = debug_lockdep_rcu_enabled();
#line 2499
  if (tmp != 0 && ! __warned) {
#line 2499
    rcu_read_lock_held();
  } else {

  }
#line 2499
  __mptr = (struct list_head  const  *)_________p1;
#line 2499
  tconn = (struct drbd_tconn *)__mptr + 0xfffffffffffffff8UL;
#line 2499
  goto ldv_53298;
  ldv_53297: ;
#line 2500
  if (tconn->my_addr_len == my_addr_len && tconn->peer_addr_len == peer_addr_len) {
#line 2500
    tmp___0 = memcmp((void const   *)(& tconn->my_addr), (void const   *)my_addr,
                     (size_t )my_addr_len);
#line 2500
    if (tmp___0 == 0) {
#line 2500
      tmp___1 = memcmp((void const   *)(& tconn->peer_addr), (void const   *)peer_addr,
                       (size_t )peer_addr_len);
#line 2500
      if (tmp___1 == 0) {
#line 2504
        kref_get(& tconn->kref);
#line 2505
        goto found;
      } else {

      }
    } else {

    }
  } else {

  }
#line 2499
  __ptr___0 = tconn->all_tconn.next;
#line 2499
  _________p1___0 = *((struct list_head * volatile  *)(& __ptr___0));
#line 2499
  tmp___2 = debug_lockdep_rcu_enabled();
#line 2499
  if (tmp___2 != 0 && ! __warned___0) {
#line 2499
    rcu_read_lock_held();
  } else {

  }
#line 2499
  __mptr___0 = (struct list_head  const  *)_________p1___0;
#line 2499
  tconn = (struct drbd_tconn *)__mptr___0 + 0xfffffffffffffff8UL;
  ldv_53298: ;
#line 2499
  if ((unsigned long )(& tconn->all_tconn) != (unsigned long )(& drbd_tconns)) {
#line 2500
    goto ldv_53297;
  } else {

  }
#line 2508
  tconn = 0;
  found: 
#line 2510
  rcu_read_unlock___5();
#line 2511
  return (tconn);
}
}
#line 2514 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int drbd_alloc_socket(struct drbd_socket *socket ) 
{ 
  unsigned long tmp ;
  unsigned long tmp___0 ;

  {
#line 2516
  tmp = __get_free_pages(208U, 0U);
#line 2516
  socket->rbuf = (void *)tmp;
#line 2517
  if ((unsigned long )socket->rbuf == (unsigned long )((void *)0)) {
#line 2518
    return (-12);
  } else {

  }
#line 2519
  tmp___0 = __get_free_pages(208U, 0U);
#line 2519
  socket->sbuf = (void *)tmp___0;
#line 2520
  if ((unsigned long )socket->sbuf == (unsigned long )((void *)0)) {
#line 2521
    return (-12);
  } else {

  }
#line 2522
  return (0);
}
}
#line 2525 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void drbd_free_socket(struct drbd_socket *socket ) 
{ 


  {
#line 2527
  free_pages((unsigned long )socket->sbuf, 0U);
#line 2528
  free_pages((unsigned long )socket->rbuf, 0U);
#line 2529
  return;
}
}
#line 2531 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void conn_free_crypto(struct drbd_tconn *tconn ) 
{ 


  {
#line 2533
  drbd_free_sock(tconn);
#line 2535
  crypto_free_hash(tconn->csums_tfm);
#line 2536
  crypto_free_hash(tconn->verify_tfm);
#line 2537
  crypto_free_hash(tconn->cram_hmac_tfm);
#line 2538
  crypto_free_hash(tconn->integrity_tfm);
#line 2539
  crypto_free_hash(tconn->peer_integrity_tfm);
#line 2540
  kfree((void const   *)tconn->int_dig_in);
#line 2541
  kfree((void const   *)tconn->int_dig_vv);
#line 2543
  tconn->csums_tfm = 0;
#line 2544
  tconn->verify_tfm = 0;
#line 2545
  tconn->cram_hmac_tfm = 0;
#line 2546
  tconn->integrity_tfm = 0;
#line 2547
  tconn->peer_integrity_tfm = 0;
#line 2548
  tconn->int_dig_in = 0;
#line 2549
  tconn->int_dig_vv = 0;
#line 2550
  return;
}
}
#line 2552 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int set_resource_options(struct drbd_tconn *tconn , struct res_opts *res_opts ) 
{ 
  cpumask_var_t new_cpu_mask ;
  int err ;
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;

  {
#line 2557
  tmp = zalloc_cpumask_var(& new_cpu_mask, 208U);
#line 2557
  if (tmp) {
#line 2557
    tmp___0 = 0;
  } else {
#line 2557
    tmp___0 = 1;
  }
#line 2557
  if (tmp___0) {
#line 2558
    return (-12);
  } else {

  }
#line 2565
  if (nr_cpu_ids > 1 && (int )((signed char )res_opts->cpu_mask[0]) != 0) {
#line 2567
    err = bitmap_parse((char const   *)(& res_opts->cpu_mask), 32U, (unsigned long *)(& new_cpu_mask->bits),
                       nr_cpu_ids);
#line 2569
    if (err != 0) {
#line 2570
      printk("\fd-con %s: bitmap_parse() failed with %d\n", tconn->name, err);
#line 2572
      goto fail;
    } else {

    }
  } else {

  }
#line 2575
  tconn->res_opts = *res_opts;
#line 2576
  tmp___1 = cpumask_equal((struct cpumask  const  *)tconn->cpu_mask, (struct cpumask  const  *)new_cpu_mask);
#line 2576
  if (tmp___1) {
#line 2576
    tmp___2 = 0;
  } else {
#line 2576
    tmp___2 = 1;
  }
#line 2576
  if (tmp___2) {
#line 2577
    cpumask_copy(tconn->cpu_mask, (struct cpumask  const  *)new_cpu_mask);
#line 2578
    drbd_calc_cpu_mask(tconn);
#line 2579
    tconn->receiver.reset_cpu_mask = 1;
#line 2580
    tconn->asender.reset_cpu_mask = 1;
#line 2581
    tconn->worker.reset_cpu_mask = 1;
  } else {

  }
#line 2583
  err = 0;
  fail: 
#line 2586
  free_cpumask_var(new_cpu_mask);
#line 2587
  return (err);
}
}
#line 2592 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
struct drbd_tconn *conn_create(char const   *name , struct res_opts *res_opts ) 
{ 
  struct drbd_tconn *tconn ;
  void *tmp ;
  int tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  void *tmp___5 ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;
  struct lock_class_key __key___2 ;
  struct lock_class_key __key___3 ;
  struct lock_class_key __key___4 ;
  struct lock_class_key __key___5 ;

  {
#line 2596
  tmp = kzalloc(2392UL, 208U);
#line 2596
  tconn = (struct drbd_tconn *)tmp;
#line 2597
  if ((unsigned long )tconn == (unsigned long )((struct drbd_tconn *)0)) {
#line 2598
    return (0);
  } else {

  }
#line 2600
  tconn->name = kstrdup(name, 208U);
#line 2601
  if ((unsigned long )tconn->name == (unsigned long )((char *)0)) {
#line 2602
    goto fail;
  } else {

  }
#line 2604
  tmp___0 = drbd_alloc_socket(& tconn->data);
#line 2604
  if (tmp___0 != 0) {
#line 2605
    goto fail;
  } else {

  }
#line 2606
  tmp___1 = drbd_alloc_socket(& tconn->meta);
#line 2606
  if (tmp___1 != 0) {
#line 2607
    goto fail;
  } else {

  }
#line 2609
  tmp___2 = zalloc_cpumask_var(& tconn->cpu_mask, 208U);
#line 2609
  if (tmp___2) {
#line 2609
    tmp___3 = 0;
  } else {
#line 2609
    tmp___3 = 1;
  }
#line 2609
  if (tmp___3) {
#line 2610
    goto fail;
  } else {

  }
#line 2612
  tmp___4 = set_resource_options(tconn, res_opts);
#line 2612
  if (tmp___4 != 0) {
#line 2613
    goto fail;
  } else {

  }
#line 2615
  tmp___5 = kzalloc(48UL, 208U);
#line 2615
  tconn->current_epoch = (struct drbd_epoch *)tmp___5;
#line 2616
  if ((unsigned long )tconn->current_epoch == (unsigned long )((struct drbd_epoch *)0)) {
#line 2617
    goto fail;
  } else {

  }
#line 2619
  INIT_LIST_HEAD(& tconn->transfer_log);
#line 2621
  INIT_LIST_HEAD(& (tconn->current_epoch)->list);
#line 2622
  tconn->epochs = 1U;
#line 2623
  spinlock_check(& tconn->epoch_lock);
#line 2623
  __raw_spin_lock_init(& tconn->epoch_lock.ldv_5957.rlock, "&(&tconn->epoch_lock)->rlock",
                       & __key);
#line 2624
  tconn->write_ordering = WO_bdev_flush;
#line 2626
  tconn->send.seen_any_write_yet = 0;
#line 2627
  tconn->send.current_epoch_nr = 0;
#line 2628
  tconn->send.current_epoch_writes = 0U;
#line 2630
  tconn->cstate = C_STANDALONE;
#line 2631
  __mutex_init(& tconn->cstate_mutex, "&tconn->cstate_mutex", & __key___0);
#line 2632
  spinlock_check(& tconn->req_lock);
#line 2632
  __raw_spin_lock_init(& tconn->req_lock.ldv_5957.rlock, "&(&tconn->req_lock)->rlock",
                       & __key___1);
#line 2633
  __mutex_init(& tconn->conf_update, "&tconn->conf_update", & __key___2);
#line 2634
  __init_waitqueue_head(& tconn->ping_wait, "&tconn->ping_wait", & __key___3);
#line 2635
  idr_init(& tconn->volumes);
#line 2637
  drbd_init_workqueue(& tconn->sender_work);
#line 2638
  __mutex_init(& tconn->data.mutex, "&tconn->data.mutex", & __key___4);
#line 2639
  __mutex_init(& tconn->meta.mutex, "&tconn->meta.mutex", & __key___5);
#line 2641
  drbd_thread_init(tconn, & tconn->receiver, & drbdd_init, (char *)"receiver");
#line 2642
  drbd_thread_init(tconn, & tconn->worker, & drbd_worker, (char *)"worker");
#line 2643
  drbd_thread_init(tconn, & tconn->asender, & drbd_asender, (char *)"asender");
#line 2645
  kref_init(& tconn->kref);
#line 2646
  list_add_tail_rcu(& tconn->all_tconn, & drbd_tconns);
#line 2648
  return (tconn);
  fail: 
#line 2651
  kfree((void const   *)tconn->current_epoch);
#line 2652
  free_cpumask_var(tconn->cpu_mask);
#line 2653
  drbd_free_socket(& tconn->meta);
#line 2654
  drbd_free_socket(& tconn->data);
#line 2655
  kfree((void const   *)tconn->name);
#line 2656
  kfree((void const   *)tconn);
#line 2658
  return (0);
}
}
#line 2661 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void conn_destroy(struct kref *kref ) 
{ 
  struct drbd_tconn *tconn ;
  struct kref  const  *__mptr ;
  int tmp ;
  int tmp___0 ;

  {
#line 2663
  __mptr = (struct kref  const  *)kref;
#line 2663
  tconn = (struct drbd_tconn *)__mptr + 0xffffffffffffffe8UL;
#line 2665
  tmp___0 = atomic_read((atomic_t const   *)(& (tconn->current_epoch)->epoch_size));
#line 2665
  if (tmp___0 != 0) {
#line 2666
    tmp = atomic_read((atomic_t const   *)(& (tconn->current_epoch)->epoch_size));
#line 2666
    printk("\vd-con %s: epoch_size:%d\n", tconn->name, tmp);
  } else {

  }
#line 2667
  kfree((void const   *)tconn->current_epoch);
#line 2669
  idr_destroy(& tconn->volumes);
#line 2671
  free_cpumask_var(tconn->cpu_mask);
#line 2672
  drbd_free_socket(& tconn->meta);
#line 2673
  drbd_free_socket(& tconn->data);
#line 2674
  kfree((void const   *)tconn->name);
#line 2675
  kfree((void const   *)tconn->int_dig_in);
#line 2676
  kfree((void const   *)tconn->int_dig_vv);
#line 2677
  kfree((void const   *)tconn);
#line 2678
  return;
}
}
#line 2680 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
enum drbd_ret_code conn_new_minor(struct drbd_tconn *tconn , unsigned int minor ,
                                  int vnr ) 
{ 
  struct drbd_conf *mdev ;
  struct gendisk *disk ;
  struct request_queue *q ;
  int vnr_got ;
  int minor_got ;
  enum drbd_ret_code err ;
  void *tmp ;
  int tmp___0 ;
  struct rb_root __constr_expr_0 ;
  struct rb_root __constr_expr_1 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
#line 2685
  vnr_got = vnr;
#line 2686
  minor_got = (int )minor;
#line 2687
  err = ERR_NOMEM;
#line 2689
  mdev = minor_to_mdev(minor);
#line 2690
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 2691
    return (ERR_MINOR_EXISTS);
  } else {

  }
#line 2694
  tmp = kzalloc(2160UL, 208U);
#line 2694
  mdev = (struct drbd_conf *)tmp;
#line 2695
  if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 2696
    return (ERR_NOMEM);
  } else {

  }
#line 2698
  kref_get(& tconn->kref);
#line 2699
  mdev->tconn = tconn;
#line 2701
  mdev->minor = minor;
#line 2702
  mdev->vnr = vnr;
#line 2704
  drbd_init_set_defaults(mdev);
#line 2706
  q = blk_alloc_queue(208U);
#line 2707
  if ((unsigned long )q == (unsigned long )((struct request_queue *)0)) {
#line 2708
    goto out_no_q;
  } else {

  }
#line 2709
  mdev->rq_queue = q;
#line 2710
  q->queuedata = (void *)mdev;
#line 2712
  disk = alloc_disk(1);
#line 2713
  if ((unsigned long )disk == (unsigned long )((struct gendisk *)0)) {
#line 2714
    goto out_no_disk;
  } else {

  }
#line 2715
  mdev->vdisk = disk;
#line 2717
  set_disk_ro(disk, 1);
#line 2719
  disk->queue = q;
#line 2720
  disk->major = 147;
#line 2721
  disk->first_minor = (int )minor;
#line 2722
  disk->fops = & drbd_ops;
#line 2723
  sprintf((char *)(& disk->disk_name), "drbd%d", minor);
#line 2724
  disk->private_data = (void *)mdev;
#line 2726
  mdev->this_bdev = bdget(minor | 154140672U);
#line 2728
  (mdev->this_bdev)->bd_contains = mdev->this_bdev;
#line 2730
  q->backing_dev_info.congested_fn = & drbd_congested;
#line 2731
  q->backing_dev_info.congested_data = (void *)mdev;
#line 2733
  blk_queue_make_request(q, & drbd_make_request);
#line 2734
  blk_queue_flush(q, 6144U);
#line 2737
  blk_queue_max_hw_sectors(q, 16U);
#line 2738
  blk_queue_bounce_limit(q, 0xffffffffffffffffULL);
#line 2739
  blk_queue_merge_bvec(q, & drbd_merge_bvec);
#line 2740
  q->queue_lock = & (mdev->tconn)->req_lock;
#line 2742
  mdev->md_io_page = alloc_pages(208U, 0U);
#line 2743
  if ((unsigned long )mdev->md_io_page == (unsigned long )((struct page *)0)) {
#line 2744
    goto out_no_io_page;
  } else {

  }
#line 2746
  tmp___0 = drbd_bm_init(mdev);
#line 2746
  if (tmp___0 != 0) {
#line 2747
    goto out_no_bitmap;
  } else {

  }
#line 2748
  __constr_expr_0.rb_node = 0;
#line 2748
  mdev->read_requests = __constr_expr_0;
#line 2749
  __constr_expr_1.rb_node = 0;
#line 2749
  mdev->write_requests = __constr_expr_1;
#line 2751
  tmp___1 = idr_pre_get(& minors, 208U);
#line 2751
  if (tmp___1 == 0) {
#line 2752
    goto out_no_minor_idr;
  } else {

  }
#line 2753
  tmp___2 = idr_get_new_above(& minors, (void *)mdev, (int )minor, & minor_got);
#line 2753
  if (tmp___2 != 0) {
#line 2754
    goto out_no_minor_idr;
  } else {

  }
#line 2755
  if ((unsigned int )minor_got != minor) {
#line 2756
    err = ERR_MINOR_EXISTS;
#line 2757
    drbd_msg_put_info("requested minor exists already");
#line 2758
    goto out_idr_remove_minor;
  } else {

  }
#line 2761
  tmp___3 = idr_pre_get(& tconn->volumes, 208U);
#line 2761
  if (tmp___3 == 0) {
#line 2762
    goto out_idr_remove_minor;
  } else {

  }
#line 2763
  tmp___4 = idr_get_new_above(& tconn->volumes, (void *)mdev, vnr, & vnr_got);
#line 2763
  if (tmp___4 != 0) {
#line 2764
    goto out_idr_remove_minor;
  } else {

  }
#line 2765
  if (vnr_got != vnr) {
#line 2766
    err = ERR_INVALID_REQUEST;
#line 2767
    drbd_msg_put_info("requested volume exists already");
#line 2768
    goto out_idr_remove_vol;
  } else {

  }
#line 2770
  add_disk(disk);
#line 2771
  kref_init(& mdev->kref);
#line 2774
  mdev->state.ldv_49522.conn = (unsigned char )tconn->cstate;
#line 2775
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 144U) {
#line 2776
    drbd_connected(mdev);
  } else {

  }
#line 2778
  return (NO_ERROR);
  out_idr_remove_vol: 
#line 2781
  idr_remove(& tconn->volumes, vnr_got);
  out_idr_remove_minor: 
#line 2783
  idr_remove(& minors, minor_got);
#line 2784
  synchronize_rcu();
  out_no_minor_idr: 
#line 2786
  drbd_bm_cleanup(mdev);
  out_no_bitmap: 
#line 2788
  __free_pages(mdev->md_io_page, 0U);
  out_no_io_page: 
#line 2790
  put_disk(disk);
  out_no_disk: 
#line 2792
  blk_cleanup_queue(q);
  out_no_q: 
#line 2794
  kfree((void const   *)mdev);
#line 2795
  kref_put(& tconn->kref, & conn_destroy);
#line 2796
  return (err);
}
}
#line 2799 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_init(void) 
{ 
  int err ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp ;
  struct lock_class_key __key___2 ;
  atomic_long_t __constr_expr_0 ;
  struct lock_class_key __key___3 ;
  char const   *tmp___0 ;

  {
#line 2803
  if (minor_count == 0U || minor_count > 255U) {
#line 2804
    printk("\vdrbd: invalid minor_count (%d)\n", minor_count);
#line 2807
    return (-22);
  } else {

  }
#line 2813
  err = register_blkdev(147U, "drbd");
#line 2814
  if (err != 0) {
#line 2815
    printk("\vdrbd: unable to register block device major %d\n", 147);
#line 2818
    return (err);
  } else {

  }
#line 2821
  err = drbd_genl_register();
#line 2822
  if (err != 0) {
#line 2823
    printk("\vdrbd: unable to register generic netlink family\n");
#line 2824
    goto fail;
  } else {

  }
#line 2828
  register_reboot_notifier(& drbd_notifier);
#line 2833
  err = -12;
#line 2835
  __init_waitqueue_head(& drbd_pp_wait, "&drbd_pp_wait", & __key);
#line 2837
  drbd_proc = 0;
#line 2838
  idr_init(& minors);
#line 2840
  err = drbd_create_mempools();
#line 2841
  if (err != 0) {
#line 2842
    goto fail;
  } else {

  }
#line 2844
  drbd_proc = proc_create_data("drbd", 33060, 0, & drbd_proc_fops, 0);
#line 2845
  if ((unsigned long )drbd_proc == (unsigned long )((struct proc_dir_entry *)0)) {
#line 2846
    printk("\vdrbd: unable to register proc file\n");
#line 2847
    goto fail;
  } else {

  }
#line 2850
  __rwlock_init(& global_state_lock, "&global_state_lock", & __key___0);
#line 2851
  INIT_LIST_HEAD(& drbd_tconns);
#line 2853
  __lock_name = "drbd-reissue";
#line 2853
  tmp = __alloc_workqueue_key("drbd-reissue", 10U, 1, & __key___1, __lock_name);
#line 2853
  retry.wq = tmp;
#line 2854
  if ((unsigned long )retry.wq == (unsigned long )((struct workqueue_struct *)0)) {
#line 2855
    printk("\vdrbd: unable to create retry workqueue\n");
#line 2856
    goto fail;
  } else {

  }
#line 2858
  __init_work(& retry.worker, 0);
#line 2858
  __constr_expr_0.counter = 4195328L;
#line 2858
  retry.worker.data = __constr_expr_0;
#line 2858
  lockdep_init_map(& retry.worker.lockdep_map, "(&retry.worker)", & __key___2, 0);
#line 2858
  INIT_LIST_HEAD(& retry.worker.entry);
#line 2858
  retry.worker.func = & do_retry;
#line 2859
  spinlock_check(& retry.lock);
#line 2859
  __raw_spin_lock_init(& retry.lock.ldv_5957.rlock, "&(&retry.lock)->rlock", & __key___3);
#line 2860
  INIT_LIST_HEAD(& retry.writes);
#line 2862
  printk("\016drbd: initialized. Version: 8.4.2 (api:%d/proto:%d-%d)\n", 1, 86, 101);
#line 2865
  tmp___0 = drbd_buildtag();
#line 2865
  printk("\016drbd: %s\n", tmp___0);
#line 2866
  printk("\016drbd: registered as block device major %d\n", 147);
#line 2869
  return (0);
  fail: 
#line 2872
  drbd_cleanup();
#line 2873
  if (err == -12) {
#line 2875
    printk("\vdrbd: ran out of memory\n");
  } else {
#line 2877
    printk("\vdrbd: initialization failure\n");
  }
#line 2878
  return (err);
}
}
#line 2881 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_free_bc(struct drbd_backing_dev *ldev ) 
{ 


  {
#line 2883
  if ((unsigned long )ldev == (unsigned long )((struct drbd_backing_dev *)0)) {
#line 2884
    return;
  } else {

  }
#line 2886
  blkdev_put(ldev->backing_bdev, 131U);
#line 2887
  blkdev_put(ldev->md_bdev, 131U);
#line 2889
  kfree((void const   *)ldev);
#line 2890
  return;
}
}
#line 2892 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_free_sock(struct drbd_tconn *tconn ) 
{ 


  {
#line 2894
  if ((unsigned long )tconn->data.socket != (unsigned long )((struct socket *)0)) {
#line 2895
    ldv_mutex_lock_223(& tconn->data.mutex);
#line 2896
    kernel_sock_shutdown(tconn->data.socket, SHUT_RDWR);
#line 2897
    sock_release(tconn->data.socket);
#line 2898
    tconn->data.socket = 0;
#line 2899
    ldv_mutex_unlock_224(& tconn->data.mutex);
  } else {

  }
#line 2901
  if ((unsigned long )tconn->meta.socket != (unsigned long )((struct socket *)0)) {
#line 2902
    ldv_mutex_lock_225(& tconn->meta.mutex);
#line 2903
    kernel_sock_shutdown(tconn->meta.socket, SHUT_RDWR);
#line 2904
    sock_release(tconn->meta.socket);
#line 2905
    tconn->meta.socket = 0;
#line 2906
    ldv_mutex_unlock_226(& tconn->meta.mutex);
  } else {

  }
#line 2908
  return;
}
}
#line 2912 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void conn_md_sync(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 2917
  rcu_read_lock___5();
#line 2918
  vnr = 0;
#line 2918
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 2918
  mdev = (struct drbd_conf *)tmp;
#line 2918
  goto ldv_53380;
  ldv_53379: 
#line 2919
  kref_get(& mdev->kref);
#line 2920
  rcu_read_unlock___5();
#line 2921
  drbd_md_sync(mdev);
#line 2922
  kref_put(& mdev->kref, & drbd_minor_destroy);
#line 2923
  rcu_read_lock___5();
#line 2918
  vnr = vnr + 1;
#line 2918
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 2918
  mdev = (struct drbd_conf *)tmp___0;
  ldv_53380: ;
#line 2918
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 2919
    goto ldv_53379;
  } else {

  }
#line 2925
  rcu_read_unlock___5();
#line 2926
  return;
}
}
#line 2950 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_md_sync(struct drbd_conf *mdev ) 
{ 
  struct meta_data_on_disk *buffer ;
  sector_t sector ;
  int i ;
  int tmp ;
  int tmp___0 ;
  void *tmp___1 ;
  sector_t tmp___2 ;
  __u64 tmp___3 ;
  __u64 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u64 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  sector_t tmp___12 ;
  int tmp___13 ;
  sector_t tmp___14 ;

  {
#line 2956
  del_timer(& mdev->md_sync_timer);
#line 2958
  tmp = test_and_clear_bit(1, (unsigned long volatile   *)(& mdev->flags));
#line 2958
  if (tmp == 0) {
#line 2959
    return;
  } else {

  }
#line 2963
  tmp___0 = _get_ldev_if_state(mdev, D_FAILED);
#line 2963
  if (tmp___0 == 0) {
#line 2964
    return;
  } else {

  }
#line 2966
  tmp___1 = drbd_md_get_buffer(mdev);
#line 2966
  buffer = (struct meta_data_on_disk *)tmp___1;
#line 2967
  if ((unsigned long )buffer == (unsigned long )((struct meta_data_on_disk *)0)) {
#line 2968
    goto out;
  } else {

  }
#line 2970
  memset((void *)buffer, 0, 512UL);
#line 2972
  tmp___2 = drbd_get_capacity(mdev->this_bdev);
#line 2972
  tmp___3 = __fswab64((__u64 )tmp___2);
#line 2972
  buffer->la_size = tmp___3;
#line 2973
  i = 0;
#line 2973
  goto ldv_53404;
  ldv_53403: 
#line 2974
  tmp___4 = __fswab64((mdev->ldev)->md.uuid[i]);
#line 2974
  buffer->uuid[i] = tmp___4;
#line 2973
  i = i + 1;
  ldv_53404: ;
#line 2973
  if (i <= 3) {
#line 2974
    goto ldv_53403;
  } else {

  }
#line 2975
  tmp___5 = __fswab32((mdev->ldev)->md.flags);
#line 2975
  buffer->flags = tmp___5;
#line 2976
  buffer->magic = 1812100227U;
#line 2978
  tmp___6 = __fswab32((mdev->ldev)->md.md_size_sect);
#line 2978
  buffer->md_size_sect = tmp___6;
#line 2979
  tmp___7 = __fswab32((__u32 )(mdev->ldev)->md.al_offset);
#line 2979
  buffer->al_offset = tmp___7;
#line 2980
  tmp___8 = __fswab32((mdev->act_log)->nr_elements);
#line 2980
  buffer->al_nr_extents = tmp___8;
#line 2981
  buffer->bm_bytes_per_bit = 1048576U;
#line 2982
  tmp___9 = __fswab64((mdev->ldev)->md.device_uuid);
#line 2982
  buffer->device_uuid = tmp___9;
#line 2984
  tmp___10 = __fswab32((__u32 )(mdev->ldev)->md.bm_offset);
#line 2984
  buffer->bm_offset = tmp___10;
#line 2985
  tmp___11 = __fswab32(mdev->peer_max_bio_size);
#line 2985
  buffer->la_peer_max_bio_size = tmp___11;
#line 2987
  tmp___12 = drbd_md_ss__(mdev, mdev->ldev);
#line 2987
  if ((unsigned long long )tmp___12 != (mdev->ldev)->md.md_offset) {
#line 2987
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( drbd_md_ss__(mdev, mdev->ldev) == mdev->ldev->md.md_offset ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            2987);
  } else {

  }
#line 2988
  sector = (sector_t )(mdev->ldev)->md.md_offset;
#line 2990
  tmp___13 = drbd_md_sync_page_io(mdev, mdev->ldev, sector, 1);
#line 2990
  if (tmp___13 != 0) {
#line 2992
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "meta data update failed!\n");
#line 2993
    drbd_chk_io_error____1(mdev, 1, DRBD_META_IO_ERROR, "drbd_md_sync");
  } else {

  }
#line 2998
  tmp___14 = drbd_get_capacity(mdev->this_bdev);
#line 2998
  (mdev->ldev)->md.la_size_sect = (u64 )tmp___14;
#line 3000
  drbd_md_put_buffer(mdev);
  out: 
#line 3002
  put_ldev(mdev);
#line 3003
  return;
}
}
#line 3013 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_md_read(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ) 
{ 
  struct meta_data_on_disk *buffer ;
  u32 magic ;
  u32 flags ;
  int i ;
  int rv ;
  int tmp ;
  void *tmp___0 ;
  int tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  __u64 tmp___12 ;
  __u64 tmp___13 ;
  __u32 tmp___14 ;
  __u64 tmp___15 ;
  unsigned int peer ;
  __u32 tmp___16 ;
  unsigned int _max1 ;
  unsigned int _max2 ;

  {
#line 3017
  rv = 101;
#line 3019
  tmp = _get_ldev_if_state(mdev, D_ATTACHING);
#line 3019
  if (tmp == 0) {
#line 3020
    return (118);
  } else {

  }
#line 3022
  tmp___0 = drbd_md_get_buffer(mdev);
#line 3022
  buffer = (struct meta_data_on_disk *)tmp___0;
#line 3023
  if ((unsigned long )buffer == (unsigned long )((struct meta_data_on_disk *)0)) {
#line 3024
    goto out;
  } else {

  }
#line 3026
  tmp___1 = drbd_md_sync_page_io(mdev, bdev, (sector_t )bdev->md.md_offset, 0);
#line 3026
  if (tmp___1 != 0) {
#line 3029
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Error while reading metadata.\n");
#line 3030
    rv = 118;
#line 3031
    goto err;
  } else {

  }
#line 3034
  tmp___2 = __fswab32(buffer->magic);
#line 3034
  magic = tmp___2;
#line 3035
  tmp___3 = __fswab32(buffer->flags);
#line 3035
  flags = tmp___3;
#line 3036
  if (magic == 2205418092U || (magic == 2205418091U && (flags & 128U) == 0U)) {
#line 3039
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Found unclean meta data. Did you \"drbdadm apply-al\"?\n");
#line 3040
    rv = 165;
#line 3041
    goto err;
  } else {

  }
#line 3043
  if (magic != 2205418091U) {
#line 3044
    if (magic == 2205418090U) {
#line 3045
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Found old (0.7) meta data magic. Did you \"drbdadm create-md\"?\n");
    } else {
#line 3047
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Meta data magic not found. Did you \"drbdadm create-md\"?\n");
    }
#line 3048
    rv = 119;
#line 3049
    goto err;
  } else {

  }
#line 3051
  tmp___5 = __fswab32(buffer->al_offset);
#line 3051
  if (tmp___5 != (unsigned int )bdev->md.al_offset) {
#line 3052
    tmp___4 = __fswab32(buffer->al_offset);
#line 3052
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "unexpected al_offset: %d (expected %d)\n",
            tmp___4, bdev->md.al_offset);
#line 3054
    rv = 119;
#line 3055
    goto err;
  } else {

  }
#line 3057
  tmp___7 = __fswab32(buffer->bm_offset);
#line 3057
  if (tmp___7 != (unsigned int )bdev->md.bm_offset) {
#line 3058
    tmp___6 = __fswab32(buffer->bm_offset);
#line 3058
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "unexpected bm_offset: %d (expected %d)\n",
            tmp___6, bdev->md.bm_offset);
#line 3060
    rv = 119;
#line 3061
    goto err;
  } else {

  }
#line 3063
  tmp___9 = __fswab32(buffer->md_size_sect);
#line 3063
  if (tmp___9 != bdev->md.md_size_sect) {
#line 3064
    tmp___8 = __fswab32(buffer->md_size_sect);
#line 3064
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "unexpected md_size: %u (expected %u)\n",
            tmp___8, bdev->md.md_size_sect);
#line 3066
    rv = 119;
#line 3067
    goto err;
  } else {

  }
#line 3070
  tmp___11 = __fswab32(buffer->bm_bytes_per_bit);
#line 3070
  if (tmp___11 != 4096U) {
#line 3071
    tmp___10 = __fswab32(buffer->bm_bytes_per_bit);
#line 3071
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "unexpected bm_bytes_per_bit: %u (expected %u)\n",
            tmp___10, 4096);
#line 3073
    rv = 119;
#line 3074
    goto err;
  } else {

  }
#line 3077
  tmp___12 = __fswab64(buffer->la_size);
#line 3077
  bdev->md.la_size_sect = tmp___12;
#line 3078
  i = 0;
#line 3078
  goto ldv_53419;
  ldv_53418: 
#line 3079
  tmp___13 = __fswab64(buffer->uuid[i]);
#line 3079
  bdev->md.uuid[i] = tmp___13;
#line 3078
  i = i + 1;
  ldv_53419: ;
#line 3078
  if (i <= 3) {
#line 3079
    goto ldv_53418;
  } else {

  }
#line 3080
  tmp___14 = __fswab32(buffer->flags);
#line 3080
  bdev->md.flags = tmp___14;
#line 3081
  tmp___15 = __fswab64(buffer->device_uuid);
#line 3081
  bdev->md.device_uuid = tmp___15;
#line 3083
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 3084
  if ((int )mdev->state.ldv_49522.conn <= 9) {
#line 3086
    tmp___16 = __fswab32(buffer->la_peer_max_bio_size);
#line 3086
    peer = tmp___16;
#line 3087
    _max1 = peer;
#line 3087
    _max2 = 4096U;
#line 3087
    peer = _max1 > _max2 ? _max1 : _max2;
#line 3088
    mdev->peer_max_bio_size = peer;
  } else {

  }
#line 3090
  spin_unlock_irq(& (mdev->tconn)->req_lock);
  err: 
#line 3093
  drbd_md_put_buffer(mdev);
  out: 
#line 3095
  put_ldev(mdev);
#line 3097
  return (rv);
}
}
#line 3118 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_md_mark_dirty(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 3120
  tmp = test_and_set_bit(1, (unsigned long volatile   *)(& mdev->flags));
#line 3120
  if (tmp == 0) {
#line 3121
    mod_timer(& mdev->md_sync_timer, (unsigned long )jiffies + 1250UL);
  } else {

  }
#line 3122
  return;
}
}
#line 3125 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_uuid_move_history(struct drbd_conf *mdev ) 
{ 
  int i ;

  {
#line 3129
  i = 2;
#line 3129
  goto ldv_53433;
  ldv_53432: 
#line 3130
  (mdev->ldev)->md.uuid[i + 1] = (mdev->ldev)->md.uuid[i];
#line 3129
  i = i + 1;
  ldv_53433: ;
#line 3129
  if (i <= 2) {
#line 3130
    goto ldv_53432;
  } else {

  }

#line 3134
  return;
}
}
#line 3133 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void __drbd_uuid_set(struct drbd_conf *mdev , int idx , u64 val ) 
{ 


  {
#line 3135
  if (idx == 0) {
#line 3136
    if ((unsigned int )*((unsigned char *)mdev + 748UL) == 1U) {
#line 3137
      val = val | 1ULL;
    } else {
#line 3139
      val = val & 0xfffffffffffffffeULL;
    }
#line 3141
    drbd_set_ed_uuid(mdev, val);
  } else {

  }
#line 3144
  (mdev->ldev)->md.uuid[idx] = val;
#line 3145
  drbd_md_mark_dirty(mdev);
#line 3146
  return;
}
}
#line 3148 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void _drbd_uuid_set(struct drbd_conf *mdev , int idx , u64 val ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 3151
  tmp = spinlock_check(& (mdev->ldev)->md.uuid_lock);
#line 3151
  flags = _raw_spin_lock_irqsave(tmp);
#line 3152
  __drbd_uuid_set(mdev, idx, val);
#line 3153
  spin_unlock_irqrestore(& (mdev->ldev)->md.uuid_lock, flags);
#line 3154
  return;
}
}
#line 3156 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_uuid_set(struct drbd_conf *mdev , int idx , u64 val ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 3159
  tmp = spinlock_check(& (mdev->ldev)->md.uuid_lock);
#line 3159
  flags = _raw_spin_lock_irqsave(tmp);
#line 3160
  if ((mdev->ldev)->md.uuid[idx] != 0ULL) {
#line 3161
    drbd_uuid_move_history(mdev);
#line 3162
    (mdev->ldev)->md.uuid[2] = (mdev->ldev)->md.uuid[idx];
  } else {

  }
#line 3164
  __drbd_uuid_set(mdev, idx, val);
#line 3165
  spin_unlock_irqrestore(& (mdev->ldev)->md.uuid_lock, flags);
#line 3166
  return;
}
}
#line 3175 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_uuid_new_current(struct drbd_conf *mdev ) 
{ 
  u64 val ;
  unsigned long long bm_uuid ;

  {
#line 3180
  get_random_bytes((void *)(& val), 8);
#line 3182
  spin_lock_irq(& (mdev->ldev)->md.uuid_lock);
#line 3183
  bm_uuid = (mdev->ldev)->md.uuid[1];
#line 3185
  if (bm_uuid != 0ULL) {
#line 3186
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bm UUID was already set: %llX\n",
             bm_uuid);
  } else {

  }
#line 3188
  (mdev->ldev)->md.uuid[1] = (mdev->ldev)->md.uuid[0];
#line 3189
  __drbd_uuid_set(mdev, 0, val);
#line 3190
  spin_unlock_irq(& (mdev->ldev)->md.uuid_lock);
#line 3192
  drbd_print_uuids(mdev, "new current UUID");
#line 3194
  drbd_md_sync(mdev);
#line 3195
  return;
}
}
#line 3197 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_uuid_set_bm(struct drbd_conf *mdev , u64 val ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;
  unsigned long long bm_uuid ;

  {
#line 3200
  if ((mdev->ldev)->md.uuid[1] == 0ULL && val == 0ULL) {
#line 3201
    return;
  } else {

  }
#line 3203
  tmp = spinlock_check(& (mdev->ldev)->md.uuid_lock);
#line 3203
  flags = _raw_spin_lock_irqsave(tmp);
#line 3204
  if (val == 0ULL) {
#line 3205
    drbd_uuid_move_history(mdev);
#line 3206
    (mdev->ldev)->md.uuid[2] = (mdev->ldev)->md.uuid[1];
#line 3207
    (mdev->ldev)->md.uuid[1] = 0ULL;
  } else {
#line 3209
    bm_uuid = (mdev->ldev)->md.uuid[1];
#line 3210
    if (bm_uuid != 0ULL) {
#line 3211
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bm UUID was already set: %llX\n",
               bm_uuid);
    } else {

    }
#line 3213
    (mdev->ldev)->md.uuid[1] = val & 0xfffffffffffffffeULL;
  }
#line 3215
  spin_unlock_irqrestore(& (mdev->ldev)->md.uuid_lock, flags);
#line 3217
  drbd_md_mark_dirty(mdev);
#line 3218
  return;
}
}
#line 3226 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_bmio_set_n_write(struct drbd_conf *mdev ) 
{ 
  int rv ;
  int tmp ;

  {
#line 3228
  rv = -5;
#line 3230
  tmp = _get_ldev_if_state(mdev, D_ATTACHING);
#line 3230
  if (tmp != 0) {
#line 3231
    drbd_md_set_flag(mdev, 8);
#line 3232
    drbd_md_sync(mdev);
#line 3233
    drbd_bm_set_all(mdev);
#line 3235
    rv = drbd_bm_write(mdev);
#line 3237
    if (rv == 0) {
#line 3238
      drbd_md_clear_flag(mdev, 8);
#line 3239
      drbd_md_sync(mdev);
    } else {

    }
#line 3242
    put_ldev(mdev);
  } else {

  }
#line 3245
  return (rv);
}
}
#line 3254 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_bmio_clear_n_write(struct drbd_conf *mdev ) 
{ 
  int rv ;
  int tmp ;

  {
#line 3256
  rv = -5;
#line 3258
  drbd_resume_al(mdev);
#line 3259
  tmp = _get_ldev_if_state(mdev, D_ATTACHING);
#line 3259
  if (tmp != 0) {
#line 3260
    drbd_bm_clear_all(mdev);
#line 3261
    rv = drbd_bm_write(mdev);
#line 3262
    put_ldev(mdev);
  } else {

  }
#line 3265
  return (rv);
}
}
#line 3268 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int w_bitmap_io(struct drbd_work *w , int unused ) 
{ 
  struct bm_io_work *work ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;
  int rv ;
  int tmp ;
  int tmp___0 ;

  {
#line 3270
  __mptr = (struct drbd_work  const  *)w;
#line 3270
  work = (struct bm_io_work *)__mptr;
#line 3271
  mdev = w->ldv_49807.mdev;
#line 3272
  rv = -5;
#line 3274
  tmp = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 3274
  if (tmp != 0) {
#line 3274
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( atomic_read(&mdev->ap_bio_cnt) == 0 ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3274);
  } else {

  }
#line 3276
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 3276
  if (tmp___0 != 0) {
#line 3277
    drbd_bm_lock(mdev, work->why, work->flags);
#line 3278
    rv = (*(work->io_fn))(mdev);
#line 3279
    drbd_bm_unlock(mdev);
#line 3280
    put_ldev(mdev);
  } else {

  }
#line 3283
  clear_bit_unlock(9U, (unsigned long volatile   *)(& mdev->flags));
#line 3284
  __wake_up(& mdev->misc_wait, 3U, 1, 0);
#line 3286
  if ((unsigned long )work->done != (unsigned long )((void (*)(struct drbd_conf * ,
                                                               int  ))0)) {
#line 3287
    (*(work->done))(mdev, rv);
  } else {

  }
#line 3289
  clear_bit(10, (unsigned long volatile   *)(& mdev->flags));
#line 3290
  work->why = 0;
#line 3291
  work->flags = 0;
#line 3293
  return (0);
}
}
#line 3296 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_ldev_destroy(struct drbd_conf *mdev ) 
{ 


  {
#line 3298
  lc_destroy(mdev->resync);
#line 3299
  mdev->resync = 0;
#line 3300
  lc_destroy(mdev->act_log);
#line 3301
  mdev->act_log = 0;
#line 3302
  drbd_free_bc(mdev->ldev);
#line 3302
  mdev->ldev = 0;
#line 3306
  clear_bit(11, (unsigned long volatile   *)(& mdev->flags));
#line 3307
  return;
}
}
#line 3309 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int w_go_diskless(struct drbd_work *w , int unused ) 
{ 
  struct drbd_conf *mdev ;
  int tmp ;
  int tmp___0 ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 3311
  mdev = w->ldv_49807.mdev;
#line 3313
  if ((unsigned int )*((unsigned char *)mdev + 749UL) != 4U) {
#line 3313
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->state.disk == D_FAILED ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3313);
  } else {

  }
#line 3332
  if ((unsigned long )mdev->bitmap != (unsigned long )((struct drbd_bitmap *)0) && (unsigned long )mdev->ldev != (unsigned long )((struct drbd_backing_dev *)0)) {
#line 3333
    tmp___0 = drbd_bitmap_io_from_worker(mdev, & drbd_bm_write, (char *)"detach",
                                         BM_LOCKED_MASK);
#line 3333
    if (tmp___0 != 0) {
#line 3335
      tmp = constant_test_bit(13U, (unsigned long const volatile   *)(& mdev->flags));
#line 3335
      if (tmp != 0) {
#line 3336
        drbd_md_set_flag(mdev, 8);
#line 3337
        drbd_md_sync(mdev);
      } else {

      }
    } else {

    }
  } else {

  }
#line 3342
  val.i = 0U;
#line 3342
  val.ldv_40024.disk = 0U;
#line 3342
  mask.i = 0U;
#line 3342
  mask.ldv_40024.disk = 15U;
#line 3342
  drbd_force_state(mdev, mask, val);
#line 3343
  return (0);
}
}
#line 3346 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_go_diskless(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 3348
  if ((unsigned int )*((unsigned char *)mdev + 749UL) != 4U) {
#line 3348
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->state.disk == D_FAILED ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3348);
  } else {

  }
#line 3349
  tmp = test_and_set_bit(11, (unsigned long volatile   *)(& mdev->flags));
#line 3349
  if (tmp == 0) {
#line 3350
    drbd_queue_work(& (mdev->tconn)->sender_work, & mdev->go_diskless);
  } else {

  }
#line 3351
  return;
}
}
#line 3365 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_queue_bitmap_io(struct drbd_conf *mdev , int (*io_fn)(struct drbd_conf * ) ,
                          void (*done)(struct drbd_conf * , int  ) , char *why , enum bm_flag flags ) 
{ 
  struct task_struct *tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;

  {
#line 3370
  tmp = get_current();
#line 3370
  if ((unsigned long )tmp != (unsigned long )(mdev->tconn)->worker.task) {
#line 3370
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( current == mdev->tconn->worker.task ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3370);
  } else {

  }
#line 3372
  tmp___0 = constant_test_bit(10U, (unsigned long const volatile   *)(& mdev->flags));
#line 3372
  if (tmp___0 != 0) {
#line 3372
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !test_bit(BITMAP_IO_QUEUED, &mdev->flags) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3372);
  } else {

  }
#line 3373
  tmp___1 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 3373
  if (tmp___1 != 0) {
#line 3373
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( !test_bit(BITMAP_IO, &mdev->flags) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3373);
  } else {

  }
#line 3374
  tmp___2 = list_empty((struct list_head  const  *)(& mdev->bm_io_work.w.list));
#line 3374
  if (tmp___2 == 0) {
#line 3374
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( list_empty(&mdev->bm_io_work.w.list) ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3374);
  } else {

  }
#line 3375
  if ((unsigned long )mdev->bm_io_work.why != (unsigned long )((char *)0)) {
#line 3376
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "FIXME going to queue \'%s\' but \'%s\' still pending?\n",
            why, mdev->bm_io_work.why);
  } else {

  }
#line 3379
  mdev->bm_io_work.io_fn = io_fn;
#line 3380
  mdev->bm_io_work.done = done;
#line 3381
  mdev->bm_io_work.why = why;
#line 3382
  mdev->bm_io_work.flags = flags;
#line 3384
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 3385
  set_bit(9U, (unsigned long volatile   *)(& mdev->flags));
#line 3386
  tmp___4 = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 3386
  if (tmp___4 == 0) {
#line 3387
    tmp___3 = test_and_set_bit(10, (unsigned long volatile   *)(& mdev->flags));
#line 3387
    if (tmp___3 == 0) {
#line 3388
      drbd_queue_work(& (mdev->tconn)->sender_work, & mdev->bm_io_work.w);
    } else {

    }
  } else {

  }
#line 3390
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 3391
  return;
}
}
#line 3402 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_bitmap_io(struct drbd_conf *mdev , int (*io_fn)(struct drbd_conf * ) , char *why ,
                   enum bm_flag flags ) 
{ 
  int rv ;
  struct task_struct *tmp ;

  {
#line 3407
  tmp = get_current();
#line 3407
  if ((unsigned long )tmp == (unsigned long )(mdev->tconn)->worker.task) {
#line 3407
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( current != mdev->tconn->worker.task ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
            3407);
  } else {

  }
#line 3409
  if (((unsigned int )flags & 9U) == 0U) {
#line 3410
    drbd_suspend_io(mdev);
  } else {

  }
#line 3412
  drbd_bm_lock(mdev, why, flags);
#line 3413
  rv = (*io_fn)(mdev);
#line 3414
  drbd_bm_unlock(mdev);
#line 3416
  if (((unsigned int )flags & 9U) == 0U) {
#line 3417
    drbd_resume_io(mdev);
  } else {

  }
#line 3419
  return (rv);
}
}
#line 3422 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_md_set_flag(struct drbd_conf *mdev , int flag ) 
{ 


  {
#line 3424
  if (((mdev->ldev)->md.flags & (u32 )flag) != (u32 )flag) {
#line 3425
    drbd_md_mark_dirty(mdev);
#line 3426
    (mdev->ldev)->md.flags = (mdev->ldev)->md.flags | (u32 )flag;
  } else {

  }
#line 3428
  return;
}
}
#line 3430 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void drbd_md_clear_flag(struct drbd_conf *mdev , int flag ) 
{ 


  {
#line 3432
  if (((mdev->ldev)->md.flags & (u32 )flag) != 0U) {
#line 3433
    drbd_md_mark_dirty(mdev);
#line 3434
    (mdev->ldev)->md.flags = (mdev->ldev)->md.flags & (u32 )(~ flag);
  } else {

  }
#line 3436
  return;
}
}
#line 3437 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_md_test_flag(struct drbd_backing_dev *bdev , int flag ) 
{ 


  {
#line 3439
  return ((bdev->md.flags & (u32 )flag) != 0U);
}
}
#line 3442 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static void md_sync_timer_fn(unsigned long data ) 
{ 
  struct drbd_conf *mdev ;
  int tmp ;

  {
#line 3444
  mdev = (struct drbd_conf *)data;
#line 3447
  tmp = list_empty((struct list_head  const  *)(& mdev->md_sync_work.list));
#line 3447
  if (tmp != 0) {
#line 3448
    drbd_queue_work_front(& (mdev->tconn)->sender_work, & mdev->md_sync_work);
  } else {

  }
#line 3449
  return;
}
}
#line 3451 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static int w_md_sync(struct drbd_work *w , int unused ) 
{ 
  struct drbd_conf *mdev ;

  {
#line 3453
  mdev = w->ldv_49807.mdev;
#line 3455
  dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "md_sync_timer expired! Worker calls drbd_md_sync().\n");
#line 3460
  drbd_md_sync(mdev);
#line 3461
  return (0);
}
}
#line 3464 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
char const   *cmdname(enum drbd_packet cmd ) 
{ 
  char const   *cmdnames[46U] ;

  {
#line 3469
  cmdnames[0] = "Data";
#line 3469
  cmdnames[1] = "DataReply";
#line 3469
  cmdnames[2] = "RSDataReply";
#line 3469
  cmdnames[3] = "Barrier";
#line 3469
  cmdnames[4] = "ReportBitMap";
#line 3469
  cmdnames[5] = "BecomeSyncTarget";
#line 3469
  cmdnames[6] = "BecomeSyncSource";
#line 3469
  cmdnames[7] = "UnplugRemote";
#line 3469
  cmdnames[8] = "DataRequest";
#line 3469
  cmdnames[9] = "RSDataRequest";
#line 3469
  cmdnames[10] = "SyncParam";
#line 3469
  cmdnames[11] = "ReportProtocol";
#line 3469
  cmdnames[12] = "ReportUUIDs";
#line 3469
  cmdnames[13] = "ReportSizes";
#line 3469
  cmdnames[14] = "ReportState";
#line 3469
  cmdnames[15] = "ReportSyncUUID";
#line 3469
  cmdnames[16] = "AuthChallenge";
#line 3469
  cmdnames[17] = "AuthResponse";
#line 3469
  cmdnames[18] = "StateChgRequest";
#line 3469
  cmdnames[19] = "Ping";
#line 3469
  cmdnames[20] = "PingAck";
#line 3469
  cmdnames[21] = "RecvAck";
#line 3469
  cmdnames[22] = "WriteAck";
#line 3469
  cmdnames[23] = "RSWriteAck";
#line 3469
  cmdnames[24] = "Superseded";
#line 3469
  cmdnames[25] = "NegAck";
#line 3469
  cmdnames[26] = "NegDReply";
#line 3469
  cmdnames[27] = "NegRSDReply";
#line 3469
  cmdnames[28] = "BarrierAck";
#line 3469
  cmdnames[29] = "StateChgReply";
#line 3469
  cmdnames[30] = "OVRequest";
#line 3469
  cmdnames[31] = "OVReply";
#line 3469
  cmdnames[32] = "OVResult";
#line 3469
  cmdnames[33] = "CsumRSRequest";
#line 3469
  cmdnames[34] = "CsumRSIsInSync";
#line 3469
  cmdnames[35] = "SyncParam89";
#line 3469
  cmdnames[36] = "CBitmap";
#line 3469
  cmdnames[37] = 0;
#line 3469
  cmdnames[38] = 0;
#line 3469
  cmdnames[39] = "DelayProbe";
#line 3469
  cmdnames[40] = "OutOfSync";
#line 3469
  cmdnames[41] = "RSCancel";
#line 3469
  cmdnames[42] = "conn_st_chg_req";
#line 3469
  cmdnames[43] = "conn_st_chg_reply";
#line 3469
  cmdnames[44] = "retry_write";
#line 3469
  cmdnames[45] = "protocol_update";
#line 3523
  if ((unsigned int )cmd == 65521U) {
#line 3524
    return ("InitialMeta");
  } else {

  }
#line 3525
  if ((unsigned int )cmd == 65522U) {
#line 3526
    return ("InitialData");
  } else {

  }
#line 3527
  if ((unsigned int )cmd == 65534U) {
#line 3528
    return ("ConnectionFeatures");
  } else {

  }
#line 3529
  if ((unsigned int )cmd > (unsigned int )P_PROTOCOL_UPDATE) {
#line 3530
    return ("Unknown");
  } else {

  }
#line 3531
  return (cmdnames[(unsigned int )cmd]);
}
}
#line 3540 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int drbd_wait_misc(struct drbd_conf *mdev , struct drbd_interval *i ) 
{ 
  struct net_conf *nc ;
  wait_queue_t wait ;
  struct task_struct *tmp ;
  long timeout ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  struct task_struct *tmp___2 ;
  int tmp___3 ;

  {
#line 3543
  tmp = get_current();
#line 3543
  wait.flags = 0U;
#line 3543
  wait.private = (void *)tmp;
#line 3543
  wait.func = & autoremove_wake_function;
#line 3543
  wait.task_list.next = & wait.task_list;
#line 3543
  wait.task_list.prev = & wait.task_list;
#line 3546
  rcu_read_lock___5();
#line 3547
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 3547
  tmp___0 = debug_lockdep_rcu_enabled();
#line 3547
  if (tmp___0 != 0 && ! __warned) {
#line 3547
    tmp___1 = rcu_read_lock_held();
#line 3547
    if (tmp___1 == 0 && 1) {
#line 3547
      __warned = 1;
#line 3547
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared",
                             3547, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 3547
  nc = _________p1;
#line 3548
  if ((unsigned long )nc == (unsigned long )((struct net_conf *)0)) {
#line 3549
    rcu_read_unlock___5();
#line 3550
    return (-110);
  } else {

  }
#line 3552
  timeout = nc->ko_count != 0U ? (long )(((nc->timeout * 250U) / 10U) * nc->ko_count) : 9223372036854775807L;
#line 3553
  rcu_read_unlock___5();
#line 3556
  i->waiting = -1;
#line 3557
  prepare_to_wait(& mdev->misc_wait, & wait, 1);
#line 3558
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 3559
  timeout = schedule_timeout(timeout);
#line 3560
  finish_wait(& mdev->misc_wait, & wait);
#line 3561
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 3562
  if (timeout == 0L || (int )mdev->state.ldv_49522.conn <= 9) {
#line 3563
    return (-110);
  } else {

  }
#line 3564
  tmp___2 = get_current();
#line 3564
  tmp___3 = signal_pending(tmp___2);
#line 3564
  if (tmp___3 != 0) {
#line 3565
    return (-512);
  } else {

  }
#line 3566
  return (0);
}
}
#line 3586 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static unsigned long _drbd_fault_random(struct fault_random_state *rsp ) 
{ 
  long refresh ;
  unsigned long tmp ;
  __u32 tmp___0 ;

  {
#line 3590
  tmp = rsp->count;
#line 3590
  rsp->count = rsp->count - 1UL;
#line 3590
  if (tmp == 0UL) {
#line 3591
    get_random_bytes((void *)(& refresh), 8);
#line 3592
    rsp->state = rsp->state + (unsigned long )refresh;
#line 3593
    rsp->count = 10000UL;
  } else {

  }
#line 3595
  rsp->state = rsp->state * 39916801UL + 479001701UL;
#line 3596
  tmp___0 = __fswahw32((__u32 )rsp->state);
#line 3596
  return ((unsigned long )tmp___0);
}
}
#line 3600 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
static char *_drbd_fault_str(unsigned int type ) 
{ 
  char *_faults[10U] ;

  {
#line 3601
  _faults[0] = (char *)"Meta-data write";
#line 3601
  _faults[1] = (char *)"Meta-data read";
#line 3601
  _faults[2] = (char *)"Resync write";
#line 3601
  _faults[3] = (char *)"Resync read";
#line 3601
  _faults[4] = (char *)"Data write";
#line 3601
  _faults[5] = (char *)"Data read";
#line 3601
  _faults[6] = (char *)"Data read ahead";
#line 3601
  _faults[7] = (char *)"BM allocation";
#line 3601
  _faults[8] = (char *)"EE allocation";
#line 3601
  _faults[9] = (char *)"receive data corruption";
#line 3614
  return (type <= 9U ? _faults[type] : (char *)"**Unknown**");
}
}
#line 3618 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
unsigned int _drbd_insert_fault(struct drbd_conf *mdev , unsigned int type ) 
{ 
  struct fault_random_state rrs ;
  unsigned int ret ;
  unsigned int tmp ;
  unsigned long tmp___0 ;
  int tmp___1 ;
  char *tmp___2 ;
  int tmp___3 ;

  {
#line 3620
  rrs.state = 0UL;
#line 3620
  rrs.count = 0UL;
#line 3622
  if (fault_devs == 0) {
#line 3622
    goto _L;
  } else {
#line 3622
    tmp = mdev_to_minor(mdev);
#line 3622
    if ((fault_devs >> (int )tmp) & 1) {
      _L: /* CIL Label */ 
#line 3622
      tmp___0 = _drbd_fault_random(& rrs);
#line 3622
      if (tmp___0 % 100UL + 1UL <= (unsigned long )fault_rate) {
#line 3622
        tmp___1 = 1;
      } else {
#line 3622
        tmp___1 = 0;
      }
    } else {
#line 3622
      tmp___1 = 0;
    }
  }
#line 3622
  ret = (unsigned int )tmp___1;
#line 3627
  if (ret != 0U) {
#line 3628
    fault_count = fault_count + 1;
#line 3630
    tmp___3 = ___ratelimit(& drbd_ratelimit_state, "_drbd_insert_fault");
#line 3630
    if (tmp___3 != 0) {
#line 3631
      tmp___2 = _drbd_fault_str(type);
#line 3631
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "***Simulating %s failure\n",
               tmp___2);
    } else {

    }
  } else {

  }
#line 3635
  return (ret);
}
}
#line 3639 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
char const   *drbd_buildtag(void) 
{ 
  char buildtag[38U] ;
  unsigned int tmp ;

  {
#line 3644
  buildtag[0] = '\000';
#line 3644
  tmp = 1U;
#line 3644
  while (1) {
#line 3644
    if (tmp >= 38U) {
#line 3644
      break;
    } else {

    }
#line 3644
    buildtag[tmp] = (char)0;
#line 3644
    tmp = tmp + 1U;
  }
#line 3646
  if ((int )((signed char )buildtag[0]) == 0) {
#line 3648
    sprintf((char *)(& buildtag), "srcversion: %-24s", __this_module.srcversion);
  } else {

  }
#line 3654
  return ((char const   *)(& buildtag));
}
}
#line 3702 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_main6_sequence_infinite_withcheck_stateful(void) 
{ 
  struct block_device *var_group1 ;
  fmode_t var_drbd_open_73_p1 ;
  int res_drbd_open_73 ;
  struct gendisk *var_group2 ;
  fmode_t var_drbd_release_74_p1 ;
  struct notifier_block *var_group3 ;
  unsigned long var_drbd_notify_sys_80_p1 ;
  void *var_drbd_notify_sys_80_p2 ;
  unsigned long var_md_sync_timer_fn_120_p0 ;
  int ldv_s_drbd_ops_block_device_operations ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 3891
  ldv_s_drbd_ops_block_device_operations = 0;
#line 3850
  LDV_IN_INTERRUPT = 1;
#line 3859
  ldv_initialize();
#line 3873
  ldv_handler_precall();
#line 3874
  tmp = drbd_init();
#line 3874
  if (tmp != 0) {
#line 3875
    goto ldv_final;
  } else {

  }
#line 3898
  goto ldv_53646;
  ldv_53645: 
#line 3902
  tmp___0 = nondet_int();
#line 3902
  switch (tmp___0) {
  case 0: ;
#line 3907
  if (ldv_s_drbd_ops_block_device_operations == 0) {
#line 3920
    ldv_handler_precall();
#line 3921
    res_drbd_open_73 = drbd_open(var_group1, var_drbd_open_73_p1);
#line 3922
    ldv_check_return_value(res_drbd_open_73);
#line 3923
    if (res_drbd_open_73 != 0) {
#line 3924
      goto ldv_module_exit;
    } else {

    }
#line 3943
    ldv_s_drbd_ops_block_device_operations = ldv_s_drbd_ops_block_device_operations + 1;
  } else {

  }
#line 3949
  goto ldv_53640;
  case 1: ;
#line 3953
  if (ldv_s_drbd_ops_block_device_operations == 1) {
#line 3966
    ldv_handler_precall();
#line 3967
    drbd_release(var_group2, var_drbd_release_74_p1);
#line 3986
    ldv_s_drbd_ops_block_device_operations = 0;
  } else {

  }
#line 3992
  goto ldv_53640;
  case 2: 
#line 4009
  ldv_handler_precall();
#line 4010
  drbd_notify_sys(var_group3, var_drbd_notify_sys_80_p1, var_drbd_notify_sys_80_p2);
#line 4035
  goto ldv_53640;
  case 3: 
#line 4058
  ldv_handler_precall();
#line 4059
  md_sync_timer_fn(var_md_sync_timer_fn_120_p0);
#line 4078
  goto ldv_53640;
  default: ;
#line 4079
  goto ldv_53640;
  }
  ldv_53640: ;
  ldv_53646: 
#line 3898
  tmp___1 = nondet_int();
#line 3898
  if (tmp___1 != 0 || ldv_s_drbd_ops_block_device_operations != 0) {
#line 3900
    goto ldv_53645;
  } else {

  }

  ldv_module_exit: 
#line 4099
  ldv_handler_precall();
#line 4100
  drbd_cleanup();
  ldv_final: 
#line 4121
  ldv_check_final_state();
#line 4124
  return;
}
}
#line 4128 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_197(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4133
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 4135
  mutex_lock(ldv_func_arg1);
#line 4136
  return;
}
}
#line 4138 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_198(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4143
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 4145
  mutex_unlock(ldv_func_arg1);
#line 4146
  return;
}
}
#line 4148 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_199(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4153
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 4155
  mutex_lock(ldv_func_arg1);
#line 4156
  return;
}
}
#line 4158 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
int ldv_mutex_trylock_200(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 4163
  tmp = mutex_trylock(ldv_func_arg1);
#line 4163
  ldv_func_res = tmp;
#line 4165
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 4165
  return (tmp___0);
#line 4167
  return (ldv_func_res);
}
}
#line 4170 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_201(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4175
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 4177
  mutex_unlock(ldv_func_arg1);
#line 4178
  return;
}
}
#line 4180 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_202(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4185
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 4187
  mutex_lock(ldv_func_arg1);
#line 4188
  return;
}
}
#line 4190 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_203(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4195
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 4197
  mutex_unlock(ldv_func_arg1);
#line 4198
  return;
}
}
#line 4200 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_204(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4205
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 4207
  mutex_lock(ldv_func_arg1);
#line 4208
  return;
}
}
#line 4210 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_205(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4215
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 4217
  mutex_unlock(ldv_func_arg1);
#line 4218
  return;
}
}
#line 4220 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_206(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4225
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 4227
  mutex_lock(ldv_func_arg1);
#line 4228
  return;
}
}
#line 4230 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_207(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4235
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 4237
  mutex_unlock(ldv_func_arg1);
#line 4238
  return;
}
}
#line 4240 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_208(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4245
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4247
  mutex_lock(ldv_func_arg1);
#line 4248
  return;
}
}
#line 4250 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_209(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4255
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4257
  mutex_unlock(ldv_func_arg1);
#line 4258
  return;
}
}
#line 4260 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_210(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4265
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4267
  mutex_unlock(ldv_func_arg1);
#line 4268
  return;
}
}
#line 4270 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_211(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4275
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4277
  mutex_unlock(ldv_func_arg1);
#line 4278
  return;
}
}
#line 4280 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_212(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4285
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4287
  mutex_unlock(ldv_func_arg1);
#line 4288
  return;
}
}
#line 4290 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_213(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4295
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4297
  mutex_lock(ldv_func_arg1);
#line 4298
  return;
}
}
#line 4300 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_214(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4305
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4307
  mutex_unlock(ldv_func_arg1);
#line 4308
  return;
}
}
#line 4310 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_215(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4315
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4317
  mutex_lock(ldv_func_arg1);
#line 4318
  return;
}
}
#line 4320 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_216(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4325
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4327
  mutex_unlock(ldv_func_arg1);
#line 4328
  return;
}
}
#line 4330 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_217(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4335
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4337
  mutex_unlock(ldv_func_arg1);
#line 4338
  return;
}
}
#line 4340 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_218(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4345
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4347
  mutex_unlock(ldv_func_arg1);
#line 4348
  return;
}
}
#line 4350 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_219(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4355
  ldv_mutex_lock_drbd_main_mutex(ldv_func_arg1);
#line 4357
  mutex_lock(ldv_func_arg1);
#line 4358
  return;
}
}
#line 4360 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_220(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4365
  ldv_mutex_unlock_drbd_main_mutex(ldv_func_arg1);
#line 4367
  mutex_unlock(ldv_func_arg1);
#line 4368
  return;
}
}
#line 4370 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_221(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4375
  ldv_mutex_lock_drbd_main_mutex(ldv_func_arg1);
#line 4377
  mutex_lock(ldv_func_arg1);
#line 4378
  return;
}
}
#line 4380 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_222(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4385
  ldv_mutex_unlock_drbd_main_mutex(ldv_func_arg1);
#line 4387
  mutex_unlock(ldv_func_arg1);
#line 4388
  return;
}
}
#line 4390 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_223(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4395
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4397
  mutex_lock(ldv_func_arg1);
#line 4398
  return;
}
}
#line 4400 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_224(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4405
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4407
  mutex_unlock(ldv_func_arg1);
#line 4408
  return;
}
}
#line 4410 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_lock_225(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4415
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4417
  mutex_lock(ldv_func_arg1);
#line 4418
  return;
}
}
#line 4420 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_main.c.prepared"
void ldv_mutex_unlock_226(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 4425
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 4427
  mutex_unlock(ldv_func_arg1);
#line 4428
  return;
}
}
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_260(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_258(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_261(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_263(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_265(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_267(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_lock_257(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_259(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_262(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_264(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_266(struct mutex *ldv_func_arg1 ) ;
#line 115 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
static char const   *drbd_conn_s_names[24U]  = 
#line 115
  {      "StandAlone",      "Disconnecting",      "Unconnected",      "Timeout", 
        "BrokenPipe",      "NetworkFailure",      "ProtocolError",      "TearDown", 
        "WFConnection",      "WFReportParams",      "Connected",      "StartingSyncS", 
        "StartingSyncT",      "WFBitMapS",      "WFBitMapT",      "WFSyncUUID", 
        "SyncSource",      "SyncTarget",      "VerifyS",      "VerifyT", 
        "PausedSyncS",      "PausedSyncT",      "Ahead",      "Behind"};
#line 142 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
static char const   *drbd_role_s_names[3U]  = {      "Unknown",      "Primary",      "Secondary"};
#line 148 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
static char const   *drbd_disk_s_names[9U]  = 
#line 148
  {      "Diskless",      "Attaching",      "Failed",      "Negotiating", 
        "Inconsistent",      "Outdated",      "DUnknown",      "Consistent", 
        "UpToDate"};
#line 160 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
static char const   *drbd_state_sw_errors[21U]  = 
#line 160
  {      0,      "Multiple primaries not allowed by config",      "Need access to UpToDate data",      0, 
        "Can not resync without local disk",      "Can not resync without remote disk",      "Refusing to be Outdated while Connected",      "Refusing to be Primary while peer is not outdated", 
        "Can not start OV/resync since it is already active",      "Can not disconnect a StandAlone device",      "State change was refused by peer node",      "Device is diskless, the requested operation requires a disk", 
        "Device is held open by someone",      "Have no net/connection configuration",      "Need a verify algorithm to start online verify",      "Need a connection to start verify or resync", 
        "Disk state is lower than outdated",      "Peer does not support protocol",      "In transient state, retry after next state change",      "Concurrent state changes detected and aborted", 
        "Other vol primary on peer not allowed by config"};
#line 182 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
char const   *drbd_conn_str(enum drbd_conns s ) 
{ 


  {
#line 185
  return ((unsigned int )s <= 23U ? drbd_conn_s_names[(unsigned int )s] : "TOO_LARGE");
}
}
#line 188 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
char const   *drbd_role_str(enum drbd_role s ) 
{ 


  {
#line 190
  return ((unsigned int )s <= 2U ? drbd_role_s_names[(unsigned int )s] : "TOO_LARGE");
}
}
#line 193 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
char const   *drbd_disk_str(enum drbd_disk_state s ) 
{ 


  {
#line 195
  return ((unsigned int )s <= 8U ? drbd_disk_s_names[(unsigned int )s] : "TOO_LARGE");
}
}
#line 198 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
char const   *drbd_set_st_err_str(enum drbd_state_rv err ) 
{ 


  {
#line 200
  return ((int )err >= -20 ? ((int )err < 0 ? drbd_state_sw_errors[- ((int )err)] : "TOO_LARGE") : "TOO_SMALL");
}
}
#line 205 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_lock_257(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 210
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 212
  mutex_lock(ldv_func_arg1);
#line 213
  return;
}
}
#line 215 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_unlock_258(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 220
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 222
  mutex_unlock(ldv_func_arg1);
#line 223
  return;
}
}
#line 225 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_lock_259(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 230
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 232
  mutex_lock(ldv_func_arg1);
#line 233
  return;
}
}
#line 235 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
int ldv_mutex_trylock_260(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 240
  tmp = mutex_trylock(ldv_func_arg1);
#line 240
  ldv_func_res = tmp;
#line 242
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 242
  return (tmp___0);
#line 244
  return (ldv_func_res);
}
}
#line 247 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_unlock_261(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 252
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 254
  mutex_unlock(ldv_func_arg1);
#line 255
  return;
}
}
#line 257 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_lock_262(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 262
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 264
  mutex_lock(ldv_func_arg1);
#line 265
  return;
}
}
#line 267 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_unlock_263(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 272
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 274
  mutex_unlock(ldv_func_arg1);
#line 275
  return;
}
}
#line 277 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_lock_264(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 282
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 284
  mutex_lock(ldv_func_arg1);
#line 285
  return;
}
}
#line 287 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_unlock_265(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 292
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 294
  mutex_unlock(ldv_func_arg1);
#line 295
  return;
}
}
#line 297 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_lock_266(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 302
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 304
  mutex_lock(ldv_func_arg1);
#line 305
  return;
}
}
#line 307 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_strings.c.prepared"
void ldv_mutex_unlock_267(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 312
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 314
  mutex_unlock(ldv_func_arg1);
#line 315
  return;
}
}
#line 53 "include/linux/string.h"
extern char *strchr(char const   * , int  ) ;
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_282(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_280(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_283(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_285(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_287(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_289(struct mutex *ldv_func_arg1 ) ;
#line 196
void ldv_mutex_unlock_292(struct mutex *ldv_func_arg1 ) ;
#line 200
void ldv_mutex_unlock_293(struct mutex *ldv_func_arg1 ) ;
#line 204
void ldv_mutex_unlock_295(struct mutex *ldv_func_arg1 ) ;
#line 208
void ldv_mutex_unlock_296(struct mutex *ldv_func_arg1 ) ;
#line 212
void ldv_mutex_unlock_299(struct mutex *ldv_func_arg1 ) ;
#line 216
void ldv_mutex_unlock_300(struct mutex *ldv_func_arg1 ) ;
#line 220
void ldv_mutex_unlock_301(struct mutex *ldv_func_arg1 ) ;
#line 224
void ldv_mutex_unlock_302(struct mutex *ldv_func_arg1 ) ;
#line 228
void ldv_mutex_unlock_304(struct mutex *ldv_func_arg1 ) ;
#line 232
void ldv_mutex_unlock_305(struct mutex *ldv_func_arg1 ) ;
#line 236
void ldv_mutex_unlock_307(struct mutex *ldv_func_arg1 ) ;
#line 240
void ldv_mutex_unlock_309(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_279(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_281(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_284(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_286(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_288(struct mutex *ldv_func_arg1 ) ;
#line 30
void ldv_mutex_lock_290(struct mutex *ldv_func_arg1 ) ;
#line 34
void ldv_mutex_lock_291(struct mutex *ldv_func_arg1 ) ;
#line 38
void ldv_mutex_lock_294(struct mutex *ldv_func_arg1 ) ;
#line 42
void ldv_mutex_lock_297(struct mutex *ldv_func_arg1 ) ;
#line 46
void ldv_mutex_lock_298(struct mutex *ldv_func_arg1 ) ;
#line 50
void ldv_mutex_lock_303(struct mutex *ldv_func_arg1 ) ;
#line 54
void ldv_mutex_lock_306(struct mutex *ldv_func_arg1 ) ;
#line 58
void ldv_mutex_lock_308(struct mutex *ldv_func_arg1 ) ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info___6(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6398;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6398;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6398;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6398;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6398: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock___6(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info___6();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock___6(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info___6();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock___6(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock___6();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock___6(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock___6();
#line 763
  return;
}
}
#line 70 "include/linux/kmod.h"
extern int call_usermodehelper_fns(char * , char ** , char ** , int  , int (*)(struct subprocess_info * ,
                                                                               struct cred * ) ,
                                   void (*)(struct subprocess_info * ) , void * ) ;
#line 75 "include/linux/kmod.h"
__inline static int call_usermodehelper(char *path , char **argv , char **envp , int wait ) 
{ 
  int tmp ;

  {
#line 77
  tmp = call_usermodehelper_fns(path, argv, envp, wait, 0, 0, 0);
#line 77
  return (tmp);
}
}
#line 207 "include/linux/kobject.h"
extern int kobject_uevent(struct kobject * , enum kobject_action  ) ;
#line 114 "include/linux/rculist.h"
__inline static void list_del_rcu(struct list_head *entry ) 
{ 


  {
#line 116
  __list_del_entry(entry);
#line 117
  entry->prev = 0xdead000000200200UL;
#line 118
  return;
}
}
#line 210 "include/linux/capability.h"
extern bool capable(int  ) ;
#line 2093 "include/linux/fs.h"
extern struct block_device *blkdev_get_by_path(char const   * , fmode_t  , void * ) ;
#line 568 "include/linux/skbuff.h"
extern void kfree_skb(struct sk_buff * ) ;
#line 577
extern struct sk_buff *__alloc_skb(unsigned int  , gfp_t  , int  , int  ) ;
#line 580 "include/linux/skbuff.h"
__inline static struct sk_buff *alloc_skb(unsigned int size , gfp_t priority ) 
{ 
  struct sk_buff *tmp ;

  {
#line 583
  tmp = __alloc_skb(size, priority, 0, -1);
#line 583
  return (tmp);
}
}
#line 1295 "include/linux/skbuff.h"
__inline static unsigned char *skb_tail_pointer(struct sk_buff  const  *skb ) 
{ 


  {
#line 1297
  return ((unsigned char *)skb->head + (unsigned long )skb->tail);
}
}
#line 1644
extern void skb_trim(struct sk_buff * , unsigned int  ) ;
#line 7 "include/linux/seq_file_net.h"
extern struct net init_net ;
#line 238 "include/net/net_namespace.h"
__inline static struct net *read_pnet(struct net * const  *pnet ) 
{ 


  {
#line 240
  return ((struct net *)*pnet);
}
}
#line 13 "include/linux/netlink.h"
__inline static struct nlmsghdr *nlmsg_hdr(struct sk_buff  const  *skb ) 
{ 


  {
#line 15
  return ((struct nlmsghdr *)skb->data);
}
}
#line 60
extern int netlink_unicast(struct sock * , struct sk_buff * , __u32  , int  ) ;
#line 61
extern int netlink_broadcast(struct sock * , struct sk_buff * , __u32  , __u32  ,
                             gfp_t  ) ;
#line 242 "include/net/netlink.h"
extern struct nlattr *nla_find(struct nlattr  const  * , int  , int  ) ;
#line 244
extern size_t nla_strlcpy(char * , struct nlattr  const  * , size_t  ) ;
#line 246
extern int nla_memcpy(void * , struct nlattr  const  * , int  ) ;
#line 260
extern int nla_put(struct sk_buff * , int  , int  , void const   * ) ;
#line 262
extern int nla_put_nohdr(struct sk_buff * , int  , void const   * ) ;
#line 275 "include/net/netlink.h"
__inline static int nlmsg_msg_size(int payload ) 
{ 


  {
#line 277
  return (payload + 16);
}
}
#line 284 "include/net/netlink.h"
__inline static int nlmsg_total_size(int payload ) 
{ 
  int tmp ;

  {
#line 286
  tmp = nlmsg_msg_size(payload);
#line 286
  return ((int )((unsigned int )tmp + 3U) & -4);
}
}
#line 302 "include/net/netlink.h"
__inline static void *nlmsg_data(struct nlmsghdr  const  *nlh ) 
{ 


  {
#line 304
  return ((void *)nlh + 16U);
}
}
#line 311 "include/net/netlink.h"
__inline static int nlmsg_len(struct nlmsghdr  const  *nlh ) 
{ 


  {
#line 313
  return ((int )((unsigned int )nlh->nlmsg_len - 16U));
}
}
#line 321 "include/net/netlink.h"
__inline static struct nlattr *nlmsg_attrdata(struct nlmsghdr  const  *nlh , int hdrlen ) 
{ 
  unsigned char *data ;
  void *tmp ;

  {
#line 324
  tmp = nlmsg_data(nlh);
#line 324
  data = (unsigned char *)tmp;
#line 325
  return ((struct nlattr *)(data + ((unsigned long )((unsigned int )hdrlen + 3U) & 4294967292UL)));
}
}
#line 333 "include/net/netlink.h"
__inline static int nlmsg_attrlen(struct nlmsghdr  const  *nlh , int hdrlen ) 
{ 
  int tmp ;

  {
#line 335
  tmp = nlmsg_len(nlh);
#line 335
  return ((int )((unsigned int )tmp - (((unsigned int )hdrlen + 3U) & 4294967292U)));
}
}
#line 493 "include/net/netlink.h"
__inline static struct sk_buff *nlmsg_new(size_t payload , gfp_t flags ) 
{ 
  int tmp ;
  struct sk_buff *tmp___0 ;

  {
#line 495
  tmp = nlmsg_total_size((int )payload);
#line 495
  tmp___0 = alloc_skb((unsigned int )tmp, flags);
#line 495
  return (tmp___0);
}
}
#line 509 "include/net/netlink.h"
__inline static int nlmsg_end(struct sk_buff *skb , struct nlmsghdr *nlh ) 
{ 
  unsigned char *tmp ;

  {
#line 511
  tmp = skb_tail_pointer((struct sk_buff  const  *)skb);
#line 511
  nlh->nlmsg_len = (__u32 )((long )tmp) - (__u32 )((long )nlh);
#line 513
  return ((int )skb->len);
}
}
#line 534 "include/net/netlink.h"
__inline static void nlmsg_trim(struct sk_buff *skb , void const   *mark ) 
{ 


  {
#line 536
  if ((unsigned long )mark != (unsigned long )((void const   *)0)) {
#line 537
    skb_trim(skb, (unsigned int )((long )mark) - (unsigned int )((long )skb->data));
  } else {

  }
#line 538
  return;
}
}
#line 548 "include/net/netlink.h"
__inline static void nlmsg_cancel(struct sk_buff *skb , struct nlmsghdr *nlh ) 
{ 


  {
#line 550
  nlmsg_trim(skb, (void const   *)nlh);
#line 551
  return;
}
}
#line 557 "include/net/netlink.h"
__inline static void nlmsg_free(struct sk_buff *skb ) 
{ 


  {
#line 559
  kfree_skb(skb);
#line 560
  return;
}
}
#line 570 "include/net/netlink.h"
__inline static int nlmsg_multicast(struct sock *sk , struct sk_buff *skb , u32 portid ,
                                    unsigned int group , gfp_t flags ) 
{ 
  int err ;

  {
#line 575
  ((struct netlink_skb_parms *)(& skb->cb))->dst_group = group;
#line 577
  err = netlink_broadcast(sk, skb, portid, group, flags);
#line 578
  if (err > 0) {
#line 579
    err = 0;
  } else {

  }
#line 581
  return (err);
}
}
#line 590 "include/net/netlink.h"
__inline static int nlmsg_unicast(struct sock *sk , struct sk_buff *skb , u32 portid ) 
{ 
  int err ;

  {
#line 594
  err = netlink_unicast(sk, skb, portid, 64);
#line 595
  if (err > 0) {
#line 596
    err = 0;
  } else {

  }
#line 598
  return (err);
}
}
#line 681 "include/net/netlink.h"
__inline static void *nla_data(struct nlattr  const  *nla ) 
{ 


  {
#line 683
  return ((void *)nla + 4U);
}
}
#line 690 "include/net/netlink.h"
__inline static int nla_len(struct nlattr  const  *nla ) 
{ 


  {
#line 692
  return ((int )nla->nla_len + -4);
}
}
#line 758 "include/net/netlink.h"
__inline static int nla_put_u8(struct sk_buff *skb , int attrtype , u8 value ) 
{ 
  int tmp ;

  {
#line 760
  tmp = nla_put(skb, attrtype, 1, (void const   *)(& value));
#line 760
  return (tmp);
}
}
#line 813 "include/net/netlink.h"
__inline static int nla_put_u32(struct sk_buff *skb , int attrtype , u32 value ) 
{ 
  int tmp ;

  {
#line 815
  tmp = nla_put(skb, attrtype, 4, (void const   *)(& value));
#line 815
  return (tmp);
}
}
#line 857 "include/net/netlink.h"
__inline static int nla_put_u64(struct sk_buff *skb , int attrtype , u64 value ) 
{ 
  int tmp ;

  {
#line 859
  tmp = nla_put(skb, attrtype, 8, (void const   *)(& value));
#line 859
  return (tmp);
}
}
#line 945 "include/net/netlink.h"
__inline static int nla_put_string(struct sk_buff *skb , int attrtype , char const   *str ) 
{ 
  size_t tmp ;
  int tmp___0 ;

  {
#line 948
  tmp = strlen(str);
#line 948
  tmp___0 = nla_put(skb, attrtype, (int )((unsigned int )tmp + 1U), (void const   *)str);
#line 948
  return (tmp___0);
}
}
#line 978 "include/net/netlink.h"
__inline static u32 nla_get_u32(struct nlattr  const  *nla ) 
{ 
  void *tmp ;

  {
#line 980
  tmp = nla_data(nla);
#line 980
  return (*((u32 *)tmp));
}
}
#line 1023 "include/net/netlink.h"
__inline static u8 nla_get_u8(struct nlattr  const  *nla ) 
{ 
  void *tmp ;

  {
#line 1025
  tmp = nla_data(nla);
#line 1025
  return (*((u8 *)tmp));
}
}
#line 1032 "include/net/netlink.h"
__inline static u64 nla_get_u64(struct nlattr  const  *nla ) 
{ 
  u64 tmp ;

  {
#line 1036
  nla_memcpy((void *)(& tmp), nla, 8);
#line 1038
  return (tmp);
}
}
#line 1123 "include/net/netlink.h"
__inline static struct nlattr *nla_nest_start(struct sk_buff *skb , int attrtype ) 
{ 
  struct nlattr *start ;
  unsigned char *tmp ;
  int tmp___0 ;

  {
#line 1125
  tmp = skb_tail_pointer((struct sk_buff  const  *)skb);
#line 1125
  start = (struct nlattr *)tmp;
#line 1127
  tmp___0 = nla_put(skb, attrtype, 0, 0);
#line 1127
  if (tmp___0 < 0) {
#line 1128
    return (0);
  } else {

  }
#line 1130
  return (start);
}
}
#line 1143 "include/net/netlink.h"
__inline static int nla_nest_end(struct sk_buff *skb , struct nlattr *start ) 
{ 
  unsigned char *tmp ;

  {
#line 1145
  tmp = skb_tail_pointer((struct sk_buff  const  *)skb);
#line 1145
  start->nla_len = (int )((__u16 )((long )tmp)) - (int )((__u16 )((long )start));
#line 1146
  return ((int )skb->len);
}
}
#line 1157 "include/net/netlink.h"
__inline static void nla_nest_cancel(struct sk_buff *skb , struct nlattr *start ) 
{ 


  {
#line 1159
  nlmsg_trim(skb, (void const   *)start);
#line 1160
  return;
}
}
#line 900 "include/linux/blkdev.h"
extern void blk_queue_max_segments(struct request_queue * , unsigned short  ) ;
#line 906
extern void blk_queue_logical_block_size(struct request_queue * , unsigned short  ) ;
#line 922
extern void blk_queue_stack_limits(struct request_queue * , struct request_queue * ) ;
#line 929
extern void blk_queue_segment_boundary(struct request_queue * , unsigned long  ) ;
#line 251 "include/linux/lru_cache.h"
extern struct lru_cache *lc_create(char const   * , struct kmem_cache * , unsigned int  ,
                                   unsigned int  , size_t  , size_t  ) ;
#line 293
extern int lc_try_lock(struct lru_cache * ) ;
#line 135 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_state.h"
bool conn_all_vols_unconf(struct drbd_tconn *tconn ) ;
#line 147 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_state.h"
__inline static int drbd_request_state(struct drbd_conf *mdev , union drbd_state mask ,
                                       union drbd_state val ) 
{ 
  enum drbd_state_rv tmp ;

  {
#line 151
  tmp = _drbd_request_state(mdev, mask, val, 14);
#line 151
  return ((int )tmp);
}
}
#line 155
enum drbd_role conn_highest_peer(struct drbd_tconn *tconn ) ;
#line 156
enum drbd_disk_state conn_highest_disk(struct drbd_tconn *tconn ) ;
#line 1441 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
bool conn_try_outdate_peer(struct drbd_tconn *tconn ) ;
#line 1770 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_md_first_sector___0(struct drbd_backing_dev *bdev ) 
{ 
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  sector_t tmp___1 ;

  {
#line 1774
  rcu_read_lock___6();
#line 1775
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1775
  tmp = debug_lockdep_rcu_enabled();
#line 1775
  if (tmp != 0 && ! __warned) {
#line 1775
    tmp___0 = rcu_read_lock_held();
#line 1775
    if (tmp___0 == 0 && 1) {
#line 1775
      __warned = 1;
#line 1775
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1775, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1775
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1776
  rcu_read_unlock___6();
#line 1778
  tmp___1 = _drbd_md_first_sector(meta_dev_idx, bdev);
#line 1778
  return (tmp___1);
}
}
#line 1818 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_get_max_capacity___1(struct drbd_backing_dev *bdev ) 
{ 
  sector_t s ;
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  sector_t __min1 ;
  sector_t __min2 ;
  sector_t tmp___2 ;
  sector_t tmp___3 ;
  sector_t __min1___0 ;
  sector_t __min2___0 ;
  sector_t tmp___4 ;
  sector_t __min1___1 ;
  sector_t __min2___1 ;
  sector_t __min1___2 ;
  sector_t __min2___2 ;
  sector_t tmp___5 ;

  {
#line 1823
  rcu_read_lock___6();
#line 1824
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1824
  tmp = debug_lockdep_rcu_enabled();
#line 1824
  if (tmp != 0 && ! __warned) {
#line 1824
    tmp___0 = rcu_read_lock_held();
#line 1824
    if (tmp___0 == 0 && 1) {
#line 1824
      __warned = 1;
#line 1824
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1824, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1824
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1825
  rcu_read_unlock___6();
#line 1827
  switch (meta_dev_idx) {
  case -1: ;
  case -3: 
#line 1831
  tmp___3 = drbd_get_capacity(bdev->backing_bdev);
#line 1831
  if (tmp___3 != 0UL) {
#line 1831
    __min1 = 2251799813685248UL;
#line 1831
    tmp___2 = _drbd_md_first_sector(meta_dev_idx, bdev);
#line 1831
    __min2 = tmp___2;
#line 1831
    s = __min1 < __min2 ? __min1 : __min2;
  } else {
#line 1831
    s = 0UL;
  }
#line 1834
  goto ldv_51783;
  case -2: 
#line 1836
  __min1___0 = 2251799813685248UL;
#line 1836
  tmp___4 = drbd_get_capacity(bdev->backing_bdev);
#line 1836
  __min2___0 = tmp___4;
#line 1836
  s = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
#line 1839
  __min1___1 = s;
#line 1839
  __min2___1 = (unsigned long )(bdev->md.md_size_sect - (u32 )bdev->md.bm_offset) << 15;
#line 1839
  s = __min1___1 < __min2___1 ? __min1___1 : __min2___1;
#line 1842
  goto ldv_51783;
  default: 
#line 1844
  __min1___2 = 8587575296UL;
#line 1844
  tmp___5 = drbd_get_capacity(bdev->backing_bdev);
#line 1844
  __min2___2 = tmp___5;
#line 1844
  s = __min1___2 < __min2___2 ? __min1___2 : __min2___2;
  }
  ldv_51783: ;
#line 1847
  return (s);
}
}
#line 1855 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static sector_t drbd_md_ss_____0(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ) 
{ 
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  sector_t tmp___2 ;

  {
#line 1860
  rcu_read_lock___6();
#line 1861
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 1861
  tmp = debug_lockdep_rcu_enabled();
#line 1861
  if (tmp != 0 && ! __warned) {
#line 1861
    tmp___0 = rcu_read_lock_held();
#line 1861
    if (tmp___0 == 0 && 1) {
#line 1861
      __warned = 1;
#line 1861
      lockdep_rcu_suspicious("/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h",
                             1861, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1861
  meta_dev_idx = _________p1->meta_dev_idx;
#line 1862
  rcu_read_unlock___6();
#line 1864
  switch (meta_dev_idx) {
  default: ;
#line 1866
  return ((unsigned long )meta_dev_idx * 262144UL);
  case -1: ;
  case -3: ;
#line 1872
  if ((unsigned long )bdev->backing_bdev == (unsigned long )((struct block_device *)0)) {
#line 1873
    tmp___1 = ___ratelimit(& drbd_ratelimit_state, "drbd_md_ss__");
#line 1873
    if (tmp___1 != 0) {
#line 1874
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "bdev->backing_bdev==NULL\n");
#line 1875
      dump_stack();
    } else {

    }
#line 1877
    return (0UL);
  } else {

  }
#line 1879
  tmp___2 = drbd_get_capacity(bdev->backing_bdev);
#line 1879
  return ((sector_t )(((unsigned long long )tmp___2 & 0xfffffffffffffff8ULL) - 8ULL));
  case -2: ;
#line 1882
  return (0UL);
  }
}
}
#line 89 "include/net/genetlink.h"
__inline static struct net *genl_info_net(struct genl_info *info ) 
{ 
  struct net *tmp ;

  {
#line 91
  tmp = read_pnet((struct net * const  *)(& info->_net));
#line 91
  return (tmp);
}
}
#line 124
extern int genl_register_family_with_ops(struct genl_family * , struct genl_ops * ,
                                         size_t  ) ;
#line 126
extern int genl_unregister_family(struct genl_family * ) ;
#line 129
extern int genl_register_mc_group(struct genl_family * , struct genl_multicast_group * ) ;
#line 136
extern void *genlmsg_put(struct sk_buff * , u32  , u32  , struct genl_family * , int  ,
                         u8  ) ;
#line 181 "include/net/genetlink.h"
__inline static void *genlmsg_put_reply(struct sk_buff *skb , struct genl_info *info ,
                                        struct genl_family *family , int flags , u8 cmd ) 
{ 
  void *tmp ;

  {
#line 186
  tmp = genlmsg_put(skb, info->snd_portid, info->snd_seq, family, flags, (int )cmd);
#line 186
  return (tmp);
}
}
#line 195 "include/net/genetlink.h"
__inline static int genlmsg_end(struct sk_buff *skb , void *hdr ) 
{ 
  int tmp ;

  {
#line 197
  tmp = nlmsg_end(skb, (struct nlmsghdr *)hdr + 0xffffffffffffffecUL);
#line 197
  return (tmp);
}
}
#line 205 "include/net/genetlink.h"
__inline static void genlmsg_cancel(struct sk_buff *skb , void *hdr ) 
{ 


  {
#line 207
  if ((unsigned long )hdr != (unsigned long )((void *)0)) {
#line 208
    nlmsg_cancel(skb, (struct nlmsghdr *)hdr + 0xffffffffffffffecUL);
  } else {

  }
#line 209
  return;
}
}
#line 219 "include/net/genetlink.h"
__inline static int genlmsg_multicast_netns(struct net *net , struct sk_buff *skb ,
                                            u32 portid , unsigned int group , gfp_t flags ) 
{ 
  int tmp ;

  {
#line 222
  tmp = nlmsg_multicast(net->genl_sock, skb, portid, group, flags);
#line 222
  return (tmp);
}
}
#line 232 "include/net/genetlink.h"
__inline static int genlmsg_multicast(struct sk_buff *skb , u32 portid , unsigned int group ,
                                      gfp_t flags ) 
{ 
  int tmp ;

  {
#line 235
  tmp = genlmsg_multicast_netns(& init_net, skb, portid, group, flags);
#line 235
  return (tmp);
}
}
#line 255 "include/net/genetlink.h"
__inline static int genlmsg_unicast(struct net *net , struct sk_buff *skb , u32 portid ) 
{ 
  int tmp ;

  {
#line 257
  tmp = nlmsg_unicast(net->genl_sock, skb, portid);
#line 257
  return (tmp);
}
}
#line 265 "include/net/genetlink.h"
__inline static int genlmsg_reply(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct net *tmp ;
  int tmp___0 ;

  {
#line 267
  tmp = genl_info_net(info);
#line 267
  tmp___0 = genlmsg_unicast(tmp, skb, info->snd_portid);
#line 267
  return (tmp___0);
}
}
#line 274 "include/net/genetlink.h"
__inline static void *genlmsg_data(struct genlmsghdr  const  *gnlh ) 
{ 


  {
#line 276
  return ((void *)gnlh + 4U);
}
}
#line 294 "include/net/genetlink.h"
__inline static int genlmsg_msg_size(int payload ) 
{ 


  {
#line 296
  return ((int )((unsigned int )payload + 4U));
}
}
#line 303 "include/net/genetlink.h"
__inline static int genlmsg_total_size(int payload ) 
{ 
  int tmp ;

  {
#line 305
  tmp = genlmsg_msg_size(payload);
#line 305
  return ((int )((unsigned int )tmp + 3U) & -4);
}
}
#line 313 "include/net/genetlink.h"
__inline static struct sk_buff *genlmsg_new(size_t payload , gfp_t flags ) 
{ 
  int tmp ;
  struct sk_buff *tmp___0 ;

  {
#line 315
  tmp = genlmsg_total_size((int )payload);
#line 315
  tmp___0 = nlmsg_new((size_t )tmp, flags);
#line 315
  return (tmp___0);
}
}
#line 134 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_add_minor(struct sk_buff *skb , struct genl_info *info ) ;
#line 135
int drbd_adm_delete_minor(struct sk_buff *skb , struct genl_info *info ) ;
#line 137
int drbd_adm_new_resource(struct sk_buff *skb , struct genl_info *info ) ;
#line 138
int drbd_adm_del_resource(struct sk_buff *skb , struct genl_info *info ) ;
#line 139
int drbd_adm_down(struct sk_buff *skb , struct genl_info *info ) ;
#line 141
int drbd_adm_set_role(struct sk_buff *skb , struct genl_info *info ) ;
#line 142
int drbd_adm_attach(struct sk_buff *skb , struct genl_info *info ) ;
#line 143
int drbd_adm_disk_opts(struct sk_buff *skb , struct genl_info *info ) ;
#line 144
int drbd_adm_detach(struct sk_buff *skb , struct genl_info *info ) ;
#line 145
int drbd_adm_connect(struct sk_buff *skb , struct genl_info *info ) ;
#line 146
int drbd_adm_net_opts(struct sk_buff *skb , struct genl_info *info ) ;
#line 147
int drbd_adm_resize(struct sk_buff *skb , struct genl_info *info ) ;
#line 148
int drbd_adm_start_ov(struct sk_buff *skb , struct genl_info *info ) ;
#line 149
int drbd_adm_new_c_uuid(struct sk_buff *skb , struct genl_info *info ) ;
#line 150
int drbd_adm_disconnect(struct sk_buff *skb , struct genl_info *info ) ;
#line 151
int drbd_adm_invalidate(struct sk_buff *skb , struct genl_info *info ) ;
#line 152
int drbd_adm_invalidate_peer(struct sk_buff *skb , struct genl_info *info ) ;
#line 153
int drbd_adm_pause_sync(struct sk_buff *skb , struct genl_info *info ) ;
#line 154
int drbd_adm_resume_sync(struct sk_buff *skb , struct genl_info *info ) ;
#line 155
int drbd_adm_suspend_io(struct sk_buff *skb , struct genl_info *info ) ;
#line 156
int drbd_adm_resume_io(struct sk_buff *skb , struct genl_info *info ) ;
#line 157
int drbd_adm_outdate(struct sk_buff *skb , struct genl_info *info ) ;
#line 158
int drbd_adm_resource_opts(struct sk_buff *skb , struct genl_info *info ) ;
#line 159
int drbd_adm_get_status(struct sk_buff *skb , struct genl_info *info ) ;
#line 160
int drbd_adm_get_timeout_type(struct sk_buff *skb , struct genl_info *info ) ;
#line 162
int drbd_adm_get_status_all(struct sk_buff *skb , struct netlink_callback *cb ) ;
#line 4 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_nla.h"
int drbd_nla_parse_nested(struct nlattr **tb , int maxtype , struct nlattr *nla ,
                          struct nla_policy  const  *policy ) ;
#line 6
struct nlattr *drbd_nla_find_nested(int maxtype , struct nlattr *nla , int attrtype ) ;
#line 24 "include/linux/genl_magic_func.h"
static struct nla_policy drbd_tla_nl_policy[14U]  = 
#line 24 "include/linux/genl_magic_func.h"
  {      {(unsigned short)0, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}, 
        {8U, (unsigned short)0}};
#line 102 "include/linux/drbd_genl.h"
static struct nla_policy drbd_cfg_context_nl_policy[5U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {10U, 127U}, 
        {11U, 128U}, 
        {11U, 128U}};
#line 135 "include/linux/drbd_genl.h"
static struct nla_policy disk_conf_nl_policy[24U]  = 
#line 135
  {      {(unsigned short)0, (unsigned short)0}, 
        {10U, 127U}, 
        {10U, 127U}, 
        {3U, (unsigned short)0}, 
        {4U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {(unsigned short)0, (unsigned short)0}, 
        {1U, (unsigned short)0}};
#line 140 "include/linux/drbd_genl.h"
static struct nla_policy res_opts_nl_policy[3U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {10U, 31U}, 
        {3U, (unsigned short)0}};
#line 174 "include/linux/drbd_genl.h"
static struct nla_policy net_conf_nl_policy[30U]  = 
#line 174
  {      {(unsigned short)0, (unsigned short)0}, 
        {10U, 63U}, 
        {10U, 63U}, 
        {10U, 63U}, 
        {10U, 63U}, 
        {10U, 63U}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {3U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}};
#line 178 "include/linux/drbd_genl.h"
static struct nla_policy set_role_parms_nl_policy[2U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {1U, (unsigned short)0}};
#line 184 "include/linux/drbd_genl.h"
static struct nla_policy resize_parms_nl_policy[4U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {4U, (unsigned short)0}, 
        {1U, (unsigned short)0}, 
        {1U, (unsigned short)0}};
#line 229 "include/linux/drbd_genl.h"
static struct nla_policy start_ov_parms_nl_policy[3U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {4U, (unsigned short)0}, 
        {4U, (unsigned short)0}};
#line 233 "include/linux/drbd_genl.h"
static struct nla_policy new_c_uuid_parms_nl_policy[2U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {1U, (unsigned short)0}};
#line 241 "include/linux/drbd_genl.h"
static struct nla_policy disconnect_parms_nl_policy[2U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {1U, (unsigned short)0}};
#line 245 "include/linux/drbd_genl.h"
static struct nla_policy detach_parms_nl_policy[2U]  = {      {(unsigned short)0, (unsigned short)0}, 
        {1U, (unsigned short)0}};
#line 132 "include/linux/genl_magic_func.h"
static struct nlattr *nested_attr_tb[128U]  ;
#line 102 "include/linux/drbd_genl.h"
static int __drbd_cfg_context_from_attrs(struct drbd_cfg_context *s , struct genl_info *info ,
                                         bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  size_t tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 97
  maxtype = 4;
#line 97
  tla = *(info->attrs + 2UL);
#line 97
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 97
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 97
    return (-42);
  } else {

  }
#line 97
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& drbd_cfg_context_nl_policy));
#line 97
  if (err != 0) {
#line 97
    return (err);
  } else {

  }
#line 97
  nla = *(ntb + 1UL);
#line 97
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 97
    if ((unsigned long )s != (unsigned long )((struct drbd_cfg_context *)0)) {
#line 97
      s->ctx_volume = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 97
  nla = *(ntb + 2UL);
#line 97
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 97
    if ((unsigned long )s != (unsigned long )((struct drbd_cfg_context *)0)) {
#line 97
      tmp = nla_strlcpy((char *)(& s->ctx_resource_name), (struct nlattr  const  *)nla,
                        128UL);
#line 97
      s->ctx_resource_name_len = (__u32 )tmp;
    } else {

    }
  } else {

  }
#line 97
  nla = *(ntb + 3UL);
#line 97
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 97
    if ((unsigned long )s != (unsigned long )((struct drbd_cfg_context *)0)) {
#line 97
      tmp___0 = nla_memcpy((void *)(& s->ctx_my_addr), (struct nlattr  const  *)nla,
                           128);
#line 97
      s->ctx_my_addr_len = (__u32 )tmp___0;
    } else {

    }
  } else {

  }
#line 97
  nla = *(ntb + 4UL);
#line 97
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 97
    if ((unsigned long )s != (unsigned long )((struct drbd_cfg_context *)0)) {
#line 97
      tmp___1 = nla_memcpy((void *)(& s->ctx_peer_addr), (struct nlattr  const  *)nla,
                           128);
#line 97
      s->ctx_peer_addr_len = (__u32 )tmp___1;
    } else {

    }
  } else {

  }
#line 97
  return (0);
}
}
#line 102 "include/linux/drbd_genl.h"
static int drbd_cfg_context_from_attrs(struct drbd_cfg_context *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 97
  tmp = __drbd_cfg_context_from_attrs(s, info, 0);
#line 97
  return (tmp);
}
}
#line 135 "include/linux/drbd_genl.h"
static int __disk_conf_from_attrs(struct disk_conf *s , struct genl_info *info , bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  size_t tmp ;
  size_t tmp___0 ;
  u32 tmp___1 ;
  u32 tmp___2 ;
  u8 tmp___3 ;
  u8 tmp___4 ;
  u8 tmp___5 ;
  u8 tmp___6 ;
  u8 tmp___7 ;

  {
#line 104
  maxtype = 23;
#line 104
  tla = *(info->attrs + 3UL);
#line 104
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 104
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 104
    return (-42);
  } else {

  }
#line 104
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& disk_conf_nl_policy));
#line 104
  if (err != 0) {
#line 104
    return (err);
  } else {

  }
#line 104
  nla = *(ntb + 1UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((int )exclude_invariants) {
#line 104
      printk("\016<< must not change invariant attr: %s\n", (char *)"backing_dev");
#line 104
      return (-17);
    } else {

    }
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp = nla_strlcpy((char *)(& s->backing_dev), (struct nlattr  const  *)nla,
                        128UL);
#line 104
      s->backing_dev_len = (__u32 )tmp;
    } else {

    }
  } else
#line 104
  if ((int )exclude_invariants) {

  } else {
#line 104
    printk("\016<< missing attr: %s\n", (char *)"backing_dev");
#line 104
    return (-42);
  }
#line 104
  nla = *(ntb + 2UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((int )exclude_invariants) {
#line 104
      printk("\016<< must not change invariant attr: %s\n", (char *)"meta_dev");
#line 104
      return (-17);
    } else {

    }
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___0 = nla_strlcpy((char *)(& s->meta_dev), (struct nlattr  const  *)nla,
                            128UL);
#line 104
      s->meta_dev_len = (__u32 )tmp___0;
    } else {

    }
  } else
#line 104
  if ((int )exclude_invariants) {

  } else {
#line 104
    printk("\016<< missing attr: %s\n", (char *)"meta_dev");
#line 104
    return (-42);
  }
#line 104
  nla = *(ntb + 3UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((int )exclude_invariants) {
#line 104
      printk("\016<< must not change invariant attr: %s\n", (char *)"meta_dev_idx");
#line 104
      return (-17);
    } else {

    }
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___1 = nla_get_u32((struct nlattr  const  *)nla);
#line 104
      s->meta_dev_idx = (__s32 )tmp___1;
    } else {

    }
  } else
#line 104
  if ((int )exclude_invariants) {

  } else {
#line 104
    printk("\016<< missing attr: %s\n", (char *)"meta_dev_idx");
#line 104
    return (-42);
  }
#line 104
  nla = *(ntb + 4UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((int )exclude_invariants) {
#line 104
      printk("\016<< must not change invariant attr: %s\n", (char *)"disk_size");
#line 104
      return (-17);
    } else {

    }
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->disk_size = nla_get_u64((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 5UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((int )exclude_invariants) {
#line 104
      printk("\016<< must not change invariant attr: %s\n", (char *)"max_bio_bvecs");
#line 104
      return (-17);
    } else {

    }
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->max_bio_bvecs = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 6UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->on_io_error = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 7UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->fencing = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 8UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->resync_rate = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 9UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___2 = nla_get_u32((struct nlattr  const  *)nla);
#line 104
      s->resync_after = (__s32 )tmp___2;
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 10UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->al_extents = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 11UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->c_plan_ahead = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 12UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->c_delay_target = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 13UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->c_fill_target = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 14UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->c_max_rate = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 15UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->c_min_rate = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 16UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___3 = nla_get_u8((struct nlattr  const  *)nla);
#line 104
      s->disk_barrier = (char )tmp___3;
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 17UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___4 = nla_get_u8((struct nlattr  const  *)nla);
#line 104
      s->disk_flushes = (char )tmp___4;
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 18UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___5 = nla_get_u8((struct nlattr  const  *)nla);
#line 104
      s->disk_drain = (char )tmp___5;
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 19UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___6 = nla_get_u8((struct nlattr  const  *)nla);
#line 104
      s->md_flushes = (char )tmp___6;
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 20UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->disk_timeout = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 21UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      s->read_balancing = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 104
  nla = *(ntb + 23UL);
#line 104
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 104
    if ((unsigned long )s != (unsigned long )((struct disk_conf *)0)) {
#line 104
      tmp___7 = nla_get_u8((struct nlattr  const  *)nla);
#line 104
      s->al_updates = (char )tmp___7;
    } else {

    }
  } else {

  }
#line 104
  return (0);
}
}
#line 135 "include/linux/drbd_genl.h"
static int disk_conf_from_attrs(struct disk_conf *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 104
  tmp = __disk_conf_from_attrs(s, info, 0);
#line 104
  return (tmp);
}
}
#line 135 "include/linux/drbd_genl.h"
static int disk_conf_from_attrs_for_change(struct disk_conf *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 104
  tmp = __disk_conf_from_attrs(s, info, 1);
#line 104
  return (tmp);
}
}
#line 140 "include/linux/drbd_genl.h"
static int __res_opts_from_attrs(struct res_opts *s , struct genl_info *info , bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  size_t tmp ;

  {
#line 137
  maxtype = 2;
#line 137
  tla = *(info->attrs + 4UL);
#line 137
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 137
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 137
    return (-42);
  } else {

  }
#line 137
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& res_opts_nl_policy));
#line 137
  if (err != 0) {
#line 137
    return (err);
  } else {

  }
#line 137
  nla = *(ntb + 1UL);
#line 137
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 137
    if ((unsigned long )s != (unsigned long )((struct res_opts *)0)) {
#line 137
      tmp = nla_strlcpy((char *)(& s->cpu_mask), (struct nlattr  const  *)nla, 32UL);
#line 137
      s->cpu_mask_len = (__u32 )tmp;
    } else {

    }
  } else {

  }
#line 137
  nla = *(ntb + 2UL);
#line 137
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 137
    if ((unsigned long )s != (unsigned long )((struct res_opts *)0)) {
#line 137
      s->on_no_data = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 137
  return (0);
}
}
#line 140 "include/linux/drbd_genl.h"
static int res_opts_from_attrs(struct res_opts *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 137
  tmp = __res_opts_from_attrs(s, info, 0);
#line 137
  return (tmp);
}
}
#line 174 "include/linux/drbd_genl.h"
static int __net_conf_from_attrs(struct net_conf *s , struct genl_info *info , bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  size_t tmp ;
  size_t tmp___0 ;
  size_t tmp___1 ;
  size_t tmp___2 ;
  size_t tmp___3 ;
  u8 tmp___4 ;
  u8 tmp___5 ;
  u8 tmp___6 ;
  u8 tmp___7 ;
  u8 tmp___8 ;
  u8 tmp___9 ;

  {
#line 142
  maxtype = 29;
#line 142
  tla = *(info->attrs + 5UL);
#line 142
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 142
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 142
    return (-42);
  } else {

  }
#line 142
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& net_conf_nl_policy));
#line 142
  if (err != 0) {
#line 142
    return (err);
  } else {

  }
#line 142
  nla = *(ntb + 1UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp = nla_strlcpy((char *)(& s->shared_secret), (struct nlattr  const  *)nla,
                        64UL);
#line 142
      s->shared_secret_len = (__u32 )tmp;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 2UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___0 = nla_strlcpy((char *)(& s->cram_hmac_alg), (struct nlattr  const  *)nla,
                            64UL);
#line 142
      s->cram_hmac_alg_len = (__u32 )tmp___0;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 3UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___1 = nla_strlcpy((char *)(& s->integrity_alg), (struct nlattr  const  *)nla,
                            64UL);
#line 142
      s->integrity_alg_len = (__u32 )tmp___1;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 4UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___2 = nla_strlcpy((char *)(& s->verify_alg), (struct nlattr  const  *)nla,
                            64UL);
#line 142
      s->verify_alg_len = (__u32 )tmp___2;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 5UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___3 = nla_strlcpy((char *)(& s->csums_alg), (struct nlattr  const  *)nla,
                            64UL);
#line 142
      s->csums_alg_len = (__u32 )tmp___3;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 6UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->wire_protocol = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 7UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->connect_int = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 8UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->timeout = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 9UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->ping_int = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 10UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->ping_timeo = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 11UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->sndbuf_size = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 12UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->rcvbuf_size = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 13UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->ko_count = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 14UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->max_buffers = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 15UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->max_epoch_size = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 16UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->unplug_watermark = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 17UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->after_sb_0p = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 18UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->after_sb_1p = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 19UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->after_sb_2p = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 20UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->rr_conflict = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 21UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->on_congestion = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 22UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->cong_fill = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 23UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      s->cong_extents = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 24UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___4 = nla_get_u8((struct nlattr  const  *)nla);
#line 142
      s->two_primaries = (char )tmp___4;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 25UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((int )exclude_invariants) {
#line 142
      printk("\016<< must not change invariant attr: %s\n", (char *)"discard_my_data");
#line 142
      return (-17);
    } else {

    }
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___5 = nla_get_u8((struct nlattr  const  *)nla);
#line 142
      s->discard_my_data = (char )tmp___5;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 26UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___6 = nla_get_u8((struct nlattr  const  *)nla);
#line 142
      s->tcp_cork = (char )tmp___6;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 27UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___7 = nla_get_u8((struct nlattr  const  *)nla);
#line 142
      s->always_asbp = (char )tmp___7;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 28UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((int )exclude_invariants) {
#line 142
      printk("\016<< must not change invariant attr: %s\n", (char *)"tentative");
#line 142
      return (-17);
    } else {

    }
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___8 = nla_get_u8((struct nlattr  const  *)nla);
#line 142
      s->tentative = (char )tmp___8;
    } else {

    }
  } else {

  }
#line 142
  nla = *(ntb + 29UL);
#line 142
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 142
    if ((unsigned long )s != (unsigned long )((struct net_conf *)0)) {
#line 142
      tmp___9 = nla_get_u8((struct nlattr  const  *)nla);
#line 142
      s->use_rle = (char )tmp___9;
    } else {

    }
  } else {

  }
#line 142
  return (0);
}
}
#line 174 "include/linux/drbd_genl.h"
static int net_conf_from_attrs(struct net_conf *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 142
  tmp = __net_conf_from_attrs(s, info, 0);
#line 142
  return (tmp);
}
}
#line 174 "include/linux/drbd_genl.h"
static int net_conf_from_attrs_for_change(struct net_conf *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 142
  tmp = __net_conf_from_attrs(s, info, 1);
#line 142
  return (tmp);
}
}
#line 178 "include/linux/drbd_genl.h"
static int __set_role_parms_from_attrs(struct set_role_parms *s , struct genl_info *info ,
                                       bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  u8 tmp ;

  {
#line 176
  maxtype = 1;
#line 176
  tla = *(info->attrs + 6UL);
#line 176
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 176
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 176
    return (-42);
  } else {

  }
#line 176
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& set_role_parms_nl_policy));
#line 176
  if (err != 0) {
#line 176
    return (err);
  } else {

  }
#line 176
  nla = *(ntb + 1UL);
#line 176
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 176
    if ((unsigned long )s != (unsigned long )((struct set_role_parms *)0)) {
#line 176
      tmp = nla_get_u8((struct nlattr  const  *)nla);
#line 176
      s->assume_uptodate = (char )tmp;
    } else {

    }
  } else {

  }
#line 176
  return (0);
}
}
#line 178 "include/linux/drbd_genl.h"
static int set_role_parms_from_attrs(struct set_role_parms *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 176
  tmp = __set_role_parms_from_attrs(s, info, 0);
#line 176
  return (tmp);
}
}
#line 184 "include/linux/drbd_genl.h"
static int __resize_parms_from_attrs(struct resize_parms *s , struct genl_info *info ,
                                     bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  u8 tmp ;
  u8 tmp___0 ;

  {
#line 180
  maxtype = 3;
#line 180
  tla = *(info->attrs + 7UL);
#line 180
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 180
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 180
    return (-42);
  } else {

  }
#line 180
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& resize_parms_nl_policy));
#line 180
  if (err != 0) {
#line 180
    return (err);
  } else {

  }
#line 180
  nla = *(ntb + 1UL);
#line 180
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 180
    if ((unsigned long )s != (unsigned long )((struct resize_parms *)0)) {
#line 180
      s->resize_size = nla_get_u64((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 180
  nla = *(ntb + 2UL);
#line 180
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 180
    if ((unsigned long )s != (unsigned long )((struct resize_parms *)0)) {
#line 180
      tmp = nla_get_u8((struct nlattr  const  *)nla);
#line 180
      s->resize_force = (char )tmp;
    } else {

    }
  } else {

  }
#line 180
  nla = *(ntb + 3UL);
#line 180
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 180
    if ((unsigned long )s != (unsigned long )((struct resize_parms *)0)) {
#line 180
      tmp___0 = nla_get_u8((struct nlattr  const  *)nla);
#line 180
      s->no_resync = (char )tmp___0;
    } else {

    }
  } else {

  }
#line 180
  return (0);
}
}
#line 184 "include/linux/drbd_genl.h"
static int resize_parms_from_attrs(struct resize_parms *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 180
  tmp = __resize_parms_from_attrs(s, info, 0);
#line 180
  return (tmp);
}
}
#line 229 "include/linux/drbd_genl.h"
static int __start_ov_parms_from_attrs(struct start_ov_parms *s , struct genl_info *info ,
                                       bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;

  {
#line 226
  maxtype = 2;
#line 226
  tla = *(info->attrs + 9UL);
#line 226
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 226
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 226
    return (-42);
  } else {

  }
#line 226
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& start_ov_parms_nl_policy));
#line 226
  if (err != 0) {
#line 226
    return (err);
  } else {

  }
#line 226
  nla = *(ntb + 1UL);
#line 226
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 226
    if ((unsigned long )s != (unsigned long )((struct start_ov_parms *)0)) {
#line 226
      s->ov_start_sector = nla_get_u64((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 226
  nla = *(ntb + 2UL);
#line 226
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 226
    if ((unsigned long )s != (unsigned long )((struct start_ov_parms *)0)) {
#line 226
      s->ov_stop_sector = nla_get_u64((struct nlattr  const  *)nla);
    } else {

    }
  } else {

  }
#line 226
  return (0);
}
}
#line 229 "include/linux/drbd_genl.h"
static int start_ov_parms_from_attrs(struct start_ov_parms *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 226
  tmp = __start_ov_parms_from_attrs(s, info, 0);
#line 226
  return (tmp);
}
}
#line 233 "include/linux/drbd_genl.h"
static int __new_c_uuid_parms_from_attrs(struct new_c_uuid_parms *s , struct genl_info *info ,
                                         bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  u8 tmp ;

  {
#line 231
  maxtype = 1;
#line 231
  tla = *(info->attrs + 10UL);
#line 231
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 231
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 231
    return (-42);
  } else {

  }
#line 231
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& new_c_uuid_parms_nl_policy));
#line 231
  if (err != 0) {
#line 231
    return (err);
  } else {

  }
#line 231
  nla = *(ntb + 1UL);
#line 231
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 231
    if ((unsigned long )s != (unsigned long )((struct new_c_uuid_parms *)0)) {
#line 231
      tmp = nla_get_u8((struct nlattr  const  *)nla);
#line 231
      s->clear_bm = (char )tmp;
    } else {

    }
  } else {

  }
#line 231
  return (0);
}
}
#line 233 "include/linux/drbd_genl.h"
static int new_c_uuid_parms_from_attrs(struct new_c_uuid_parms *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 231
  tmp = __new_c_uuid_parms_from_attrs(s, info, 0);
#line 231
  return (tmp);
}
}
#line 241 "include/linux/drbd_genl.h"
static int __disconnect_parms_from_attrs(struct disconnect_parms *s , struct genl_info *info ,
                                         bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  u8 tmp ;

  {
#line 239
  maxtype = 1;
#line 239
  tla = *(info->attrs + 12UL);
#line 239
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 239
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 239
    return (-42);
  } else {

  }
#line 239
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& disconnect_parms_nl_policy));
#line 239
  if (err != 0) {
#line 239
    return (err);
  } else {

  }
#line 239
  nla = *(ntb + 1UL);
#line 239
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 239
    if ((unsigned long )s != (unsigned long )((struct disconnect_parms *)0)) {
#line 239
      tmp = nla_get_u8((struct nlattr  const  *)nla);
#line 239
      s->force_disconnect = (char )tmp;
    } else {

    }
  } else {

  }
#line 239
  return (0);
}
}
#line 241 "include/linux/drbd_genl.h"
static int disconnect_parms_from_attrs(struct disconnect_parms *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 239
  tmp = __disconnect_parms_from_attrs(s, info, 0);
#line 239
  return (tmp);
}
}
#line 245 "include/linux/drbd_genl.h"
static int __detach_parms_from_attrs(struct detach_parms *s , struct genl_info *info ,
                                     bool exclude_invariants ) 
{ 
  int maxtype ;
  struct nlattr *tla ;
  struct nlattr **ntb ;
  struct nlattr *nla ;
  int err ;
  u8 tmp ;

  {
#line 243
  maxtype = 1;
#line 243
  tla = *(info->attrs + 13UL);
#line 243
  ntb = (struct nlattr **)(& nested_attr_tb);
#line 243
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 243
    return (-42);
  } else {

  }
#line 243
  err = drbd_nla_parse_nested(ntb, maxtype, tla, (struct nla_policy  const  *)(& detach_parms_nl_policy));
#line 243
  if (err != 0) {
#line 243
    return (err);
  } else {

  }
#line 243
  nla = *(ntb + 1UL);
#line 243
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 243
    if ((unsigned long )s != (unsigned long )((struct detach_parms *)0)) {
#line 243
      tmp = nla_get_u8((struct nlattr  const  *)nla);
#line 243
      s->force_detach = (char )tmp;
    } else {

    }
  } else {

  }
#line 243
  return (0);
}
}
#line 245 "include/linux/drbd_genl.h"
static int detach_parms_from_attrs(struct detach_parms *s , struct genl_info *info ) 
{ 
  int tmp ;

  {
#line 243
  tmp = __detach_parms_from_attrs(s, info, 0);
#line 243
  return (tmp);
}
}
#line 221 "include/linux/genl_magic_func.h"
char const   *drbd_genl_cmd_to_str(__u8 cmd ) 
{ 


  {
#line 223
  switch ((int )cmd) {
  case 2: ;
#line 263 "include/linux/drbd_genl.h"
  return ("DRBD_ADM_GET_STATUS");
  case 5: ;
#line 277
  return ("DRBD_ADM_NEW_MINOR");
  case 6: ;
#line 279
  return ("DRBD_ADM_DEL_MINOR");
  case 7: ;
#line 283
  return ("DRBD_ADM_NEW_RESOURCE");
  case 8: ;
#line 285
  return ("DRBD_ADM_DEL_RESOURCE");
  case 9: ;
#line 288
  return ("DRBD_ADM_RESOURCE_OPTS");
  case 10: ;
#line 294
  return ("DRBD_ADM_CONNECT");
  case 29: ;
#line 301
  return ("DRBD_ADM_CHG_NET_OPTS");
  case 11: ;
#line 308
  return ("DRBD_ADM_DISCONNECT");
  case 12: ;
#line 311
  return ("DRBD_ADM_ATTACH");
  case 28: ;
#line 317
  return ("DRBD_ADM_CHG_DISK_OPTS");
  case 13: ;
#line 323
  return ("DRBD_ADM_RESIZE");
  case 14: ;
#line 330
  return ("DRBD_ADM_PRIMARY");
  case 15: ;
#line 337
  return ("DRBD_ADM_SECONDARY");
  case 16: ;
#line 344
  return ("DRBD_ADM_NEW_C_UUID");
  case 17: ;
#line 351
  return ("DRBD_ADM_START_OV");
  case 18: ;
#line 357
  return ("DRBD_ADM_DETACH");
  case 19: ;
#line 361
  return ("DRBD_ADM_INVALIDATE");
  case 20: ;
#line 363
  return ("DRBD_ADM_INVAL_PEER");
  case 21: ;
#line 365
  return ("DRBD_ADM_PAUSE_SYNC");
  case 22: ;
#line 367
  return ("DRBD_ADM_RESUME_SYNC");
  case 23: ;
#line 369
  return ("DRBD_ADM_SUSPEND_IO");
  case 24: ;
#line 371
  return ("DRBD_ADM_RESUME_IO");
  case 25: ;
#line 373
  return ("DRBD_ADM_OUTDATE");
  case 26: ;
#line 375
  return ("DRBD_ADM_GET_TIMEOUT_TYPE");
  case 27: ;
#line 377
  return ("DRBD_ADM_DOWN");
  default: ;
#line 229 "include/linux/genl_magic_func.h"
  return ("unknown");
  }
}
}
#line 249 "include/linux/genl_magic_func.h"
static struct genl_ops drbd_genl_ops[26U]  = 
#line 249
  {      {2U, (unsigned char)0, 0U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_get_status, & drbd_adm_get_status_all, 0, {0, 0}}, 
        {5U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_add_minor, 0, 0, {0, 0}}, 
        {6U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_delete_minor, 0, 0, {0, 0}}, 
        {7U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_new_resource, 0, 0, {0, 0}}, 
        {8U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_del_resource, 0, 0, {0, 0}}, 
        {9U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_resource_opts, 0, 0, {0, 0}}, 
        {10U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_connect, 0, 0, {0, 0}}, 
        {29U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_net_opts, 0, 0, {0, 0}}, 
        {11U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_disconnect, 0, 0, {0, 0}}, 
        {12U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_attach, 0, 0, {0, 0}}, 
        {28U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_disk_opts, 0, 0, {0, 0}}, 
        {13U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_resize, 0, 0, {0, 0}}, 
        {14U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_set_role, 0, 0, {0, 0}}, 
        {15U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_set_role, 0, 0, {0, 0}}, 
        {16U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_new_c_uuid, 0, 0, {0, 0}}, 
        {17U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_start_ov, 0, 0, {0, 0}}, 
        {18U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_detach, 0, 0, {0, 0}}, 
        {19U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_invalidate, 0, 0, {0, 0}}, 
        {20U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_invalidate_peer, 0, 0, {0, 0}}, 
        {21U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_pause_sync, 0, 0, {0, 0}}, 
        {22U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_resume_sync, 0, 0, {0, 0}}, 
        {23U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_suspend_io, 0, 0, {0, 0}}, 
        {24U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_resume_io, 0, 0, {0, 0}}, 
        {25U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_outdate, 0, 0, {0, 0}}, 
        {26U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_get_timeout_type, 0, 0, {0, 0}}, 
        {27U, (unsigned char)0, 1U, (struct nla_policy  const  *)(& drbd_tla_nl_policy),
      & drbd_adm_down, 0, 0, {0, 0}}};
#line 262 "include/linux/genl_magic_func.h"
static struct genl_family drbd_genl_family  = 
#line 262
     {0U, 8U, {'d', 'r', 'b', 'd', '\000'}, 1U, 13U, (_Bool)0, 0, 0, 0, {0, 0}, {0,
                                                                               0},
    {0, 0}};
#line 250 "include/linux/drbd_genl.h"
static struct genl_multicast_group drbd_mcg_events  =    {0, {0, 0}, {'e', 'v', 'e', 'n', 't', 's', '\000'}, 0U};
#line 250 "include/linux/drbd_genl.h"
static int drbd_genl_multicast_events(struct sk_buff *skb , gfp_t flags ) 
{ 
  unsigned int group_id ;
  int tmp ;

  {
#line 250
  group_id = drbd_mcg_events.id;
#line 250
  if (group_id == 0U) {
#line 250
    return (-22);
  } else {

  }
#line 250
  tmp = genlmsg_multicast(skb, 0U, group_id, flags);
#line 250
  return (tmp);
}
}
#line 294 "include/linux/genl_magic_func.h"
int drbd_genl_register(void) 
{ 
  int err ;
  int tmp ;

  {
#line 296
  tmp = genl_register_family_with_ops(& drbd_genl_family, (struct genl_ops *)(& drbd_genl_ops),
                                      26UL);
#line 296
  err = tmp;
#line 298
  if (err != 0) {
#line 299
    return (err);
  } else {

  }
#line 250 "include/linux/drbd_genl.h"
  err = genl_register_mc_group(& drbd_genl_family, & drbd_mcg_events);
#line 250
  if (err != 0) {
#line 250
    goto fail;
  } else {
#line 250
    printk("\016%s: mcg %s: %u\n", (char *)"events", (char *)"drbd", drbd_mcg_events.id);
  }
#line 315 "include/linux/genl_magic_func.h"
  return (0);
  fail: 
#line 317
  genl_unregister_family(& drbd_genl_family);
#line 318
  return (err);
}
}
#line 321 "include/linux/genl_magic_func.h"
void drbd_genl_unregister(void) 
{ 


  {
#line 323
  genl_unregister_family(& drbd_genl_family);
#line 324
  return;
}
}
#line 135 "include/linux/drbd_genl.h"
static int disk_conf_to_skb(struct sk_buff *skb , struct disk_conf *s , bool const   exclude_sensitive ) 
{ 
  struct nlattr *tla ;
  struct nlattr *tmp ;
  int __min1 ;
  int __min2 ;
  int tmp___0 ;
  int __min1___0 ;
  int __min2___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;
  int tmp___16 ;
  int tmp___17 ;
  int tmp___18 ;
  int tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;

  {
#line 104
  tmp = nla_nest_start(skb, 3);
#line 104
  tla = tmp;
#line 104
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  __min1 = 128;
#line 104
  __min2 = (int )(s->backing_dev_len + 1U);
#line 104
  tmp___0 = nla_put(skb, 1, __min1 < __min2 ? __min1 : __min2, (void const   *)(& s->backing_dev));
#line 104
  if (tmp___0 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  __min1___0 = 128;
#line 104
  __min2___0 = (int )(s->meta_dev_len + 1U);
#line 104
  tmp___1 = nla_put(skb, 2, __min1___0 < __min2___0 ? __min1___0 : __min2___0, (void const   *)(& s->meta_dev));
#line 104
  if (tmp___1 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___2 = nla_put_u32(skb, 3, (u32 )s->meta_dev_idx);
#line 104
  if (tmp___2 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___3 = nla_put_u64(skb, 4, s->disk_size);
#line 104
  if (tmp___3 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___4 = nla_put_u32(skb, 5, s->max_bio_bvecs);
#line 104
  if (tmp___4 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___5 = nla_put_u32(skb, 6, s->on_io_error);
#line 104
  if (tmp___5 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___6 = nla_put_u32(skb, 7, s->fencing);
#line 104
  if (tmp___6 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___7 = nla_put_u32(skb, 8, s->resync_rate);
#line 104
  if (tmp___7 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___8 = nla_put_u32(skb, 9, (u32 )s->resync_after);
#line 104
  if (tmp___8 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___9 = nla_put_u32(skb, 10, s->al_extents);
#line 104
  if (tmp___9 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___10 = nla_put_u32(skb, 11, s->c_plan_ahead);
#line 104
  if (tmp___10 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___11 = nla_put_u32(skb, 12, s->c_delay_target);
#line 104
  if (tmp___11 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___12 = nla_put_u32(skb, 13, s->c_fill_target);
#line 104
  if (tmp___12 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___13 = nla_put_u32(skb, 14, s->c_max_rate);
#line 104
  if (tmp___13 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___14 = nla_put_u32(skb, 15, s->c_min_rate);
#line 104
  if (tmp___14 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___15 = nla_put_u8(skb, 16, (int )((u8 )s->disk_barrier));
#line 104
  if (tmp___15 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___16 = nla_put_u8(skb, 17, (int )((u8 )s->disk_flushes));
#line 104
  if (tmp___16 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___17 = nla_put_u8(skb, 18, (int )((u8 )s->disk_drain));
#line 104
  if (tmp___17 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___18 = nla_put_u8(skb, 19, (int )((u8 )s->md_flushes));
#line 104
  if (tmp___18 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___19 = nla_put_u32(skb, 20, s->disk_timeout);
#line 104
  if (tmp___19 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___20 = nla_put_u32(skb, 21, s->read_balancing);
#line 104
  if (tmp___20 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  tmp___21 = nla_put_u8(skb, 23, (int )((u8 )s->al_updates));
#line 104
  if (tmp___21 != 0) {
#line 104
    goto nla_put_failure;
  } else {

  }
#line 104
  nla_nest_end(skb, tla);
#line 104
  return (0);
  nla_put_failure: ;
#line 104
  if ((unsigned long )tla != (unsigned long )((struct nlattr *)0)) {
#line 104
    nla_nest_cancel(skb, tla);
  } else {

  }
#line 104
  return (-90);
}
}
#line 140 "include/linux/drbd_genl.h"
static int res_opts_to_skb(struct sk_buff *skb , struct res_opts *s , bool const   exclude_sensitive ) 
{ 
  struct nlattr *tla ;
  struct nlattr *tmp ;
  int __min1 ;
  int __min2 ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 137
  tmp = nla_nest_start(skb, 4);
#line 137
  tla = tmp;
#line 137
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 137
    goto nla_put_failure;
  } else {

  }
#line 137
  __min1 = 32;
#line 137
  __min2 = (int )(s->cpu_mask_len + 1U);
#line 137
  tmp___0 = nla_put(skb, 1, __min1 < __min2 ? __min1 : __min2, (void const   *)(& s->cpu_mask));
#line 137
  if (tmp___0 != 0) {
#line 137
    goto nla_put_failure;
  } else {

  }
#line 137
  tmp___1 = nla_put_u32(skb, 2, s->on_no_data);
#line 137
  if (tmp___1 != 0) {
#line 137
    goto nla_put_failure;
  } else {

  }
#line 137
  nla_nest_end(skb, tla);
#line 137
  return (0);
  nla_put_failure: ;
#line 137
  if ((unsigned long )tla != (unsigned long )((struct nlattr *)0)) {
#line 137
    nla_nest_cancel(skb, tla);
  } else {

  }
#line 137
  return (-90);
}
}
#line 174 "include/linux/drbd_genl.h"
static int net_conf_to_skb(struct sk_buff *skb , struct net_conf *s , bool const   exclude_sensitive ) 
{ 
  struct nlattr *tla ;
  struct nlattr *tmp ;
  int __min1 ;
  int __min2 ;
  int tmp___0 ;
  int __min1___0 ;
  int __min2___0 ;
  int tmp___1 ;
  int __min1___1 ;
  int __min2___1 ;
  int tmp___2 ;
  int __min1___2 ;
  int __min2___2 ;
  int tmp___3 ;
  int __min1___3 ;
  int __min2___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;
  int tmp___16 ;
  int tmp___17 ;
  int tmp___18 ;
  int tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  int tmp___22 ;
  int tmp___23 ;
  int tmp___24 ;
  int tmp___25 ;
  int tmp___26 ;
  int tmp___27 ;
  int tmp___28 ;

  {
#line 142
  tmp = nla_nest_start(skb, 5);
#line 142
  tla = tmp;
#line 142
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  if (! ((_Bool )exclude_sensitive)) {
#line 142
    __min1 = 64;
#line 142
    __min2 = (int )(s->shared_secret_len + 1U);
#line 142
    tmp___0 = nla_put(skb, 1, __min1 < __min2 ? __min1 : __min2, (void const   *)(& s->shared_secret));
#line 142
    if (tmp___0 != 0) {
#line 142
      goto nla_put_failure;
    } else {

    }
  } else {

  }
#line 142
  __min1___0 = 64;
#line 142
  __min2___0 = (int )(s->cram_hmac_alg_len + 1U);
#line 142
  tmp___1 = nla_put(skb, 2, __min1___0 < __min2___0 ? __min1___0 : __min2___0, (void const   *)(& s->cram_hmac_alg));
#line 142
  if (tmp___1 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  __min1___1 = 64;
#line 142
  __min2___1 = (int )(s->integrity_alg_len + 1U);
#line 142
  tmp___2 = nla_put(skb, 3, __min1___1 < __min2___1 ? __min1___1 : __min2___1, (void const   *)(& s->integrity_alg));
#line 142
  if (tmp___2 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  __min1___2 = 64;
#line 142
  __min2___2 = (int )(s->verify_alg_len + 1U);
#line 142
  tmp___3 = nla_put(skb, 4, __min1___2 < __min2___2 ? __min1___2 : __min2___2, (void const   *)(& s->verify_alg));
#line 142
  if (tmp___3 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  __min1___3 = 64;
#line 142
  __min2___3 = (int )(s->csums_alg_len + 1U);
#line 142
  tmp___4 = nla_put(skb, 5, __min1___3 < __min2___3 ? __min1___3 : __min2___3, (void const   *)(& s->csums_alg));
#line 142
  if (tmp___4 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___5 = nla_put_u32(skb, 6, s->wire_protocol);
#line 142
  if (tmp___5 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___6 = nla_put_u32(skb, 7, s->connect_int);
#line 142
  if (tmp___6 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___7 = nla_put_u32(skb, 8, s->timeout);
#line 142
  if (tmp___7 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___8 = nla_put_u32(skb, 9, s->ping_int);
#line 142
  if (tmp___8 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___9 = nla_put_u32(skb, 10, s->ping_timeo);
#line 142
  if (tmp___9 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___10 = nla_put_u32(skb, 11, s->sndbuf_size);
#line 142
  if (tmp___10 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___11 = nla_put_u32(skb, 12, s->rcvbuf_size);
#line 142
  if (tmp___11 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___12 = nla_put_u32(skb, 13, s->ko_count);
#line 142
  if (tmp___12 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___13 = nla_put_u32(skb, 14, s->max_buffers);
#line 142
  if (tmp___13 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___14 = nla_put_u32(skb, 15, s->max_epoch_size);
#line 142
  if (tmp___14 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___15 = nla_put_u32(skb, 16, s->unplug_watermark);
#line 142
  if (tmp___15 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___16 = nla_put_u32(skb, 17, s->after_sb_0p);
#line 142
  if (tmp___16 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___17 = nla_put_u32(skb, 18, s->after_sb_1p);
#line 142
  if (tmp___17 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___18 = nla_put_u32(skb, 19, s->after_sb_2p);
#line 142
  if (tmp___18 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___19 = nla_put_u32(skb, 20, s->rr_conflict);
#line 142
  if (tmp___19 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___20 = nla_put_u32(skb, 21, s->on_congestion);
#line 142
  if (tmp___20 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___21 = nla_put_u32(skb, 22, s->cong_fill);
#line 142
  if (tmp___21 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___22 = nla_put_u32(skb, 23, s->cong_extents);
#line 142
  if (tmp___22 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___23 = nla_put_u8(skb, 24, (int )((u8 )s->two_primaries));
#line 142
  if (tmp___23 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___24 = nla_put_u8(skb, 25, (int )((u8 )s->discard_my_data));
#line 142
  if (tmp___24 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___25 = nla_put_u8(skb, 26, (int )((u8 )s->tcp_cork));
#line 142
  if (tmp___25 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___26 = nla_put_u8(skb, 27, (int )((u8 )s->always_asbp));
#line 142
  if (tmp___26 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___27 = nla_put_u8(skb, 28, (int )((u8 )s->tentative));
#line 142
  if (tmp___27 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  tmp___28 = nla_put_u8(skb, 29, (int )((u8 )s->use_rle));
#line 142
  if (tmp___28 != 0) {
#line 142
    goto nla_put_failure;
  } else {

  }
#line 142
  nla_nest_end(skb, tla);
#line 142
  return (0);
  nla_put_failure: ;
#line 142
  if ((unsigned long )tla != (unsigned long )((struct nlattr *)0)) {
#line 142
    nla_nest_cancel(skb, tla);
  } else {

  }
#line 142
  return (-90);
}
}
#line 237 "include/linux/drbd_genl.h"
static int timeout_parms_to_skb(struct sk_buff *skb , struct timeout_parms *s , bool const   exclude_sensitive ) 
{ 
  struct nlattr *tla ;
  struct nlattr *tmp ;
  int tmp___0 ;

  {
#line 235
  tmp = nla_nest_start(skb, 11);
#line 235
  tla = tmp;
#line 235
  if ((unsigned long )tla == (unsigned long )((struct nlattr *)0)) {
#line 235
    goto nla_put_failure;
  } else {

  }
#line 235
  tmp___0 = nla_put_u32(skb, 1, s->timeout_type);
#line 235
  if (tmp___0 != 0) {
#line 235
    goto nla_put_failure;
  } else {

  }
#line 235
  nla_nest_end(skb, tla);
#line 235
  return (0);
  nla_put_failure: ;
#line 235
  if ((unsigned long )tla != (unsigned long )((struct nlattr *)0)) {
#line 235
    nla_nest_cancel(skb, tla);
  } else {

  }
#line 235
  return (-90);
}
}
#line 237 "include/linux/drbd_genl.h"
__inline static int timeout_parms_to_priv_skb(struct sk_buff *skb , struct timeout_parms *s ) 
{ 
  int tmp ;

  {
#line 235
  tmp = timeout_parms_to_skb(skb, s, 0);
#line 235
  return (tmp);
}
}
#line 135
static void set_disk_conf_defaults(struct disk_conf *x ) ;
#line 135 "include/linux/drbd_genl.h"
static void set_disk_conf_defaults(struct disk_conf *x ) 
{ 


  {
#line 104
  x->on_io_error = 2U;
#line 104
  x->fencing = 0U;
#line 104
  x->resync_rate = 250U;
#line 104
  x->resync_after = -1;
#line 104
  x->al_extents = 1237U;
#line 104
  x->c_plan_ahead = 20U;
#line 104
  x->c_delay_target = 10U;
#line 104
  x->c_fill_target = 100U;
#line 104
  x->c_max_rate = 102400U;
#line 104
  x->c_min_rate = 250U;
#line 104
  x->disk_barrier = 0;
#line 104
  x->disk_flushes = 1;
#line 104
  x->disk_drain = 1;
#line 104
  x->md_flushes = 1;
#line 104
  x->disk_timeout = 0U;
#line 104
  x->read_balancing = 0U;
#line 104
  x->al_updates = 1;
#line 105
  return;
}
}
#line 140
static void set_res_opts_defaults(struct res_opts *x ) ;
#line 140 "include/linux/drbd_genl.h"
static void set_res_opts_defaults(struct res_opts *x ) 
{ 


  {
#line 137
  memset((void *)(& x->cpu_mask), 0, 32UL);
#line 137
  x->cpu_mask_len = 0U;
#line 137
  x->on_no_data = 0U;
#line 138
  return;
}
}
#line 174
static void set_net_conf_defaults(struct net_conf *x ) ;
#line 174 "include/linux/drbd_genl.h"
static void set_net_conf_defaults(struct net_conf *x ) 
{ 


  {
#line 142
  memset((void *)(& x->shared_secret), 0, 64UL);
#line 142
  x->shared_secret_len = 0U;
#line 142
  memset((void *)(& x->cram_hmac_alg), 0, 64UL);
#line 142
  x->cram_hmac_alg_len = 0U;
#line 142
  memset((void *)(& x->integrity_alg), 0, 64UL);
#line 142
  x->integrity_alg_len = 0U;
#line 142
  memset((void *)(& x->verify_alg), 0, 64UL);
#line 142
  x->verify_alg_len = 0U;
#line 142
  memset((void *)(& x->csums_alg), 0, 64UL);
#line 142
  x->csums_alg_len = 0U;
#line 142
  x->wire_protocol = 3U;
#line 142
  x->connect_int = 10U;
#line 142
  x->timeout = 60U;
#line 142
  x->ping_int = 10U;
#line 142
  x->ping_timeo = 5U;
#line 142
  x->sndbuf_size = 0U;
#line 142
  x->rcvbuf_size = 0U;
#line 142
  x->ko_count = 7U;
#line 142
  x->max_buffers = 2048U;
#line 142
  x->max_epoch_size = 2048U;
#line 142
  x->unplug_watermark = 128U;
#line 142
  x->after_sb_0p = 0U;
#line 142
  x->after_sb_1p = 0U;
#line 142
  x->after_sb_2p = 0U;
#line 142
  x->rr_conflict = 0U;
#line 142
  x->on_congestion = 0U;
#line 142
  x->cong_fill = 0U;
#line 142
  x->cong_extents = 1237U;
#line 142
  x->two_primaries = 0;
#line 142
  x->tcp_cork = 1;
#line 142
  x->always_asbp = 0;
#line 142
  x->use_rle = 1;
#line 143
  return;
}
}
#line 169 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static char *drbd_m_holder  =    (char *)"Hands off! this is DRBD\'s meta data device.";
#line 194 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static struct drbd_config_context adm_ctx  ;
#line 196 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void drbd_adm_send_reply(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct nlmsghdr *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  int tmp___2 ;

  {
#line 198
  tmp = nlmsg_hdr((struct sk_buff  const  *)skb);
#line 198
  tmp___0 = nlmsg_data((struct nlmsghdr  const  *)tmp);
#line 198
  tmp___1 = genlmsg_data((struct genlmsghdr  const  *)tmp___0);
#line 198
  genlmsg_end(skb, tmp___1);
#line 199
  tmp___2 = genlmsg_reply(skb, info);
#line 199
  if (tmp___2 != 0) {
#line 200
    printk("\vdrbd: error sending genl reply\n");
  } else {

  }
#line 201
  return;
}
}
#line 205 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_msg_put_info(char const   *info ) 
{ 
  struct sk_buff *skb ;
  struct nlattr *nla ;
  int err ;

  {
#line 207
  skb = adm_ctx.reply_skb;
#line 209
  err = -90;
#line 211
  if ((unsigned long )info == (unsigned long )((char const   *)0) || (int )((signed char )*info) == 0) {
#line 212
    return (0);
  } else {

  }
#line 214
  nla = nla_nest_start(skb, 1);
#line 215
  if ((unsigned long )nla == (unsigned long )((struct nlattr *)0)) {
#line 216
    return (err);
  } else {

  }
#line 218
  err = nla_put_string(skb, 16385, info);
#line 219
  if (err != 0) {
#line 220
    nla_nest_cancel(skb, nla);
#line 221
    return (err);
  } else {
#line 223
    nla_nest_end(skb, nla);
  }
#line 224
  return (0);
}
}
#line 235 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int drbd_adm_prepare(struct sk_buff *skb , struct genl_info *info , unsigned int flags ) 
{ 
  struct drbd_genlmsghdr *d_in ;
  u8 cmd ;
  int err ;
  bool tmp ;
  int tmp___0 ;
  void *tmp___1 ;
  struct nlattr *nla ;
  void *tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  void *tmp___6 ;
  int tmp___7 ;
  void *tmp___8 ;

  {
#line 238
  d_in = (struct drbd_genlmsghdr *)info->userhdr;
#line 239
  cmd = (info->genlhdr)->cmd;
#line 242
  memset((void *)(& adm_ctx), 0, 64UL);
#line 245
  if ((unsigned int )cmd != 2U) {
#line 245
    tmp = capable(12);
#line 245
    if (tmp) {
#line 245
      tmp___0 = 0;
    } else {
#line 245
      tmp___0 = 1;
    }
#line 245
    if (tmp___0) {
#line 246
      return (-1);
    } else {

    }
  } else {

  }
#line 248
  adm_ctx.reply_skb = genlmsg_new(3776UL, 208U);
#line 249
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 250
    err = -12;
#line 251
    goto fail;
  } else {

  }
#line 254
  tmp___1 = genlmsg_put_reply(adm_ctx.reply_skb, info, & drbd_genl_family, 0, (int )cmd);
#line 254
  adm_ctx.reply_dh = (struct drbd_genlmsghdr *)tmp___1;
#line 258
  if ((unsigned long )adm_ctx.reply_dh == (unsigned long )((struct drbd_genlmsghdr *)0)) {
#line 259
    err = -12;
#line 260
    goto fail;
  } else {

  }
#line 263
  (adm_ctx.reply_dh)->minor = d_in->minor;
#line 264
  (adm_ctx.reply_dh)->ldv_49826.ret_code = 101;
#line 266
  adm_ctx.volume = 4294967295U;
#line 267
  if ((unsigned long )*(info->attrs + 2UL) != (unsigned long )((struct nlattr *)0)) {
#line 270
    err = drbd_cfg_context_from_attrs(0, info);
#line 271
    if (err != 0) {
#line 272
      goto fail;
    } else {

    }
#line 276
    err = nla_put_nohdr(adm_ctx.reply_skb, (int )(*(info->attrs + 2UL))->nla_len,
                        (void const   *)*(info->attrs + 2UL));
#line 279
    if (err != 0) {
#line 280
      goto fail;
    } else {

    }
#line 283
    nla = nested_attr_tb[1];
#line 284
    if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 285
      adm_ctx.volume = nla_get_u32((struct nlattr  const  *)nla);
    } else {

    }
#line 286
    nla = nested_attr_tb[2];
#line 287
    if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 288
      tmp___2 = nla_data((struct nlattr  const  *)nla);
#line 288
      adm_ctx.resource_name = (char *)tmp___2;
    } else {

    }
#line 289
    adm_ctx.my_addr = nested_attr_tb[3];
#line 290
    adm_ctx.peer_addr = nested_attr_tb[4];
#line 291
    if ((unsigned long )adm_ctx.my_addr != (unsigned long )((struct nlattr *)0)) {
#line 291
      tmp___3 = nla_len((struct nlattr  const  *)adm_ctx.my_addr);
#line 291
      if ((unsigned int )tmp___3 > 128U) {
#line 295
        err = -22;
#line 296
        goto fail;
      } else {
#line 291
        goto _L;
      }
    } else
    _L: /* CIL Label */ 
#line 291
    if ((unsigned long )adm_ctx.peer_addr != (unsigned long )((struct nlattr *)0)) {
#line 291
      tmp___4 = nla_len((struct nlattr  const  *)adm_ctx.peer_addr);
#line 291
      if ((unsigned int )tmp___4 > 128U) {
#line 295
        err = -22;
#line 296
        goto fail;
      } else {

      }
    } else {

    }
  } else {

  }
#line 300
  adm_ctx.minor = d_in->minor;
#line 301
  adm_ctx.mdev = minor_to_mdev(d_in->minor);
#line 302
  adm_ctx.tconn = conn_get_by_name((char const   *)adm_ctx.resource_name);
#line 304
  if ((unsigned long )adm_ctx.mdev == (unsigned long )((struct drbd_conf *)0) && (int )flags & 1) {
#line 305
    drbd_msg_put_info("unknown minor");
#line 306
    return (127);
  } else {

  }
#line 308
  if ((unsigned long )adm_ctx.tconn == (unsigned long )((struct drbd_tconn *)0) && (flags & 2U) != 0U) {
#line 309
    drbd_msg_put_info("unknown resource");
#line 310
    return (162);
  } else {

  }
#line 313
  if ((flags & 4U) != 0U) {
#line 314
    if ((unsigned long )adm_ctx.tconn != (unsigned long )((struct drbd_tconn *)0) && (flags & 2U) == 0U) {
#line 315
      drbd_msg_put_info("no resource name expected");
#line 316
      return (162);
    } else {

    }
#line 318
    if ((unsigned long )adm_ctx.mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 319
      drbd_msg_put_info("no minor number expected");
#line 320
      return (162);
    } else {

    }
#line 322
    if ((unsigned long )adm_ctx.my_addr != (unsigned long )((struct nlattr *)0) && (unsigned long )adm_ctx.peer_addr != (unsigned long )((struct nlattr *)0)) {
#line 323
      tmp___5 = nla_len((struct nlattr  const  *)adm_ctx.peer_addr);
#line 323
      tmp___6 = nla_data((struct nlattr  const  *)adm_ctx.peer_addr);
#line 323
      tmp___7 = nla_len((struct nlattr  const  *)adm_ctx.my_addr);
#line 323
      tmp___8 = nla_data((struct nlattr  const  *)adm_ctx.my_addr);
#line 323
      adm_ctx.tconn = conn_get_by_addrs(tmp___8, tmp___7, tmp___6, tmp___5);
    } else {

    }
#line 327
    if ((unsigned long )adm_ctx.tconn == (unsigned long )((struct drbd_tconn *)0)) {
#line 328
      drbd_msg_put_info("unknown connection");
#line 329
      return (162);
    } else {

    }
  } else {

  }
#line 334
  if (((unsigned long )adm_ctx.mdev != (unsigned long )((struct drbd_conf *)0) && (unsigned long )adm_ctx.tconn != (unsigned long )((struct drbd_tconn *)0)) && (unsigned long )(adm_ctx.mdev)->tconn != (unsigned long )adm_ctx.tconn) {
#line 336
    printk("\frequest: minor=%u, resource=%s; but that minor belongs to connection %s\n",
           adm_ctx.minor, adm_ctx.resource_name, ((adm_ctx.mdev)->tconn)->name);
#line 339
    drbd_msg_put_info("minor exists in different resource");
#line 340
    return (162);
  } else {

  }
#line 342
  if (((unsigned long )adm_ctx.mdev != (unsigned long )((struct drbd_conf *)0) && adm_ctx.volume != 4294967295U) && adm_ctx.volume != (unsigned int )(adm_ctx.mdev)->vnr) {
#line 345
    printk("\frequest: minor=%u, volume=%u; but that minor is volume %u in %s\n",
           adm_ctx.minor, adm_ctx.volume, (adm_ctx.mdev)->vnr, ((adm_ctx.mdev)->tconn)->name);
#line 348
    drbd_msg_put_info("minor exists as different volume");
#line 349
    return (162);
  } else {

  }
#line 352
  return (101);
  fail: 
#line 355
  nlmsg_free(adm_ctx.reply_skb);
#line 356
  adm_ctx.reply_skb = 0;
#line 357
  return (err);
}
}
#line 360 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int drbd_adm_finish(struct genl_info *info , int retcode ) 
{ 


  {
#line 362
  if ((unsigned long )adm_ctx.tconn != (unsigned long )((struct drbd_tconn *)0)) {
#line 363
    kref_put(& (adm_ctx.tconn)->kref, & conn_destroy);
#line 364
    adm_ctx.tconn = 0;
  } else {

  }
#line 367
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 368
    return (-12);
  } else {

  }
#line 370
  (adm_ctx.reply_dh)->ldv_49826.ret_code = retcode;
#line 371
  drbd_adm_send_reply(adm_ctx.reply_skb, info);
#line 372
  return (0);
}
}
#line 375 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void setup_khelper_env(struct drbd_tconn *tconn , char **envp ) 
{ 
  char *afs ;

  {
#line 380
  if (tconn->my_addr_len == 0 || tconn->peer_addr_len == 0) {
#line 381
    return;
  } else {

  }
#line 383
  switch ((int )((struct sockaddr *)(& tconn->peer_addr))->sa_family) {
  case 10: 
#line 385
  afs = (char *)"ipv6";
#line 386
  snprintf(*(envp + 4UL), 60UL, "DRBD_PEER_ADDRESS=%pI6", & ((struct sockaddr_in6 *)(& tconn->peer_addr))->sin6_addr);
#line 388
  goto ldv_53159;
  case 2: 
#line 390
  afs = (char *)"ipv4";
#line 391
  snprintf(*(envp + 4UL), 60UL, "DRBD_PEER_ADDRESS=%pI4", & ((struct sockaddr_in *)(& tconn->peer_addr))->sin_addr);
#line 393
  goto ldv_53159;
  default: 
#line 395
  afs = (char *)"ssocks";
#line 396
  snprintf(*(envp + 4UL), 60UL, "DRBD_PEER_ADDRESS=%pI4", & ((struct sockaddr_in *)(& tconn->peer_addr))->sin_addr);
  }
  ldv_53159: 
#line 399
  snprintf(*(envp + 3UL), 20UL, "DRBD_PEER_AF=%s", afs);
#line 400
  return;
}
}
#line 402 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_khelper(struct drbd_conf *mdev , char *cmd ) 
{ 
  char *envp[6U] ;
  char __constr_expr_0[20] ;
  char __constr_expr_1[60] ;
  char mb[12U] ;
  char *argv[4U] ;
  struct drbd_tconn *tconn ;
  struct sib_info sib ;
  int ret ;
  struct task_struct *tmp ;
  unsigned int tmp___0 ;
  struct task_struct *tmp___1 ;

  {
#line 404
  __constr_expr_0[0] = (char)0;
#line 404
  __constr_expr_0[1] = (char)0;
#line 404
  __constr_expr_0[2] = (char)0;
#line 404
  __constr_expr_0[3] = (char)0;
#line 404
  __constr_expr_0[4] = (char)0;
#line 404
  __constr_expr_0[5] = (char)0;
#line 404
  __constr_expr_0[6] = (char)0;
#line 404
  __constr_expr_0[7] = (char)0;
#line 404
  __constr_expr_0[8] = (char)0;
#line 404
  __constr_expr_0[9] = (char)0;
#line 404
  __constr_expr_0[10] = (char)0;
#line 404
  __constr_expr_0[11] = (char)0;
#line 404
  __constr_expr_0[12] = (char)0;
#line 404
  __constr_expr_0[13] = (char)0;
#line 404
  __constr_expr_0[14] = (char)0;
#line 404
  __constr_expr_0[15] = (char)0;
#line 404
  __constr_expr_0[16] = (char)0;
#line 404
  __constr_expr_0[17] = (char)0;
#line 404
  __constr_expr_0[18] = (char)0;
#line 404
  __constr_expr_0[19] = (char)0;
#line 404
  __constr_expr_1[0] = (char)0;
#line 404
  __constr_expr_1[1] = (char)0;
#line 404
  __constr_expr_1[2] = (char)0;
#line 404
  __constr_expr_1[3] = (char)0;
#line 404
  __constr_expr_1[4] = (char)0;
#line 404
  __constr_expr_1[5] = (char)0;
#line 404
  __constr_expr_1[6] = (char)0;
#line 404
  __constr_expr_1[7] = (char)0;
#line 404
  __constr_expr_1[8] = (char)0;
#line 404
  __constr_expr_1[9] = (char)0;
#line 404
  __constr_expr_1[10] = (char)0;
#line 404
  __constr_expr_1[11] = (char)0;
#line 404
  __constr_expr_1[12] = (char)0;
#line 404
  __constr_expr_1[13] = (char)0;
#line 404
  __constr_expr_1[14] = (char)0;
#line 404
  __constr_expr_1[15] = (char)0;
#line 404
  __constr_expr_1[16] = (char)0;
#line 404
  __constr_expr_1[17] = (char)0;
#line 404
  __constr_expr_1[18] = (char)0;
#line 404
  __constr_expr_1[19] = (char)0;
#line 404
  __constr_expr_1[20] = (char)0;
#line 404
  __constr_expr_1[21] = (char)0;
#line 404
  __constr_expr_1[22] = (char)0;
#line 404
  __constr_expr_1[23] = (char)0;
#line 404
  __constr_expr_1[24] = (char)0;
#line 404
  __constr_expr_1[25] = (char)0;
#line 404
  __constr_expr_1[26] = (char)0;
#line 404
  __constr_expr_1[27] = (char)0;
#line 404
  __constr_expr_1[28] = (char)0;
#line 404
  __constr_expr_1[29] = (char)0;
#line 404
  __constr_expr_1[30] = (char)0;
#line 404
  __constr_expr_1[31] = (char)0;
#line 404
  __constr_expr_1[32] = (char)0;
#line 404
  __constr_expr_1[33] = (char)0;
#line 404
  __constr_expr_1[34] = (char)0;
#line 404
  __constr_expr_1[35] = (char)0;
#line 404
  __constr_expr_1[36] = (char)0;
#line 404
  __constr_expr_1[37] = (char)0;
#line 404
  __constr_expr_1[38] = (char)0;
#line 404
  __constr_expr_1[39] = (char)0;
#line 404
  __constr_expr_1[40] = (char)0;
#line 404
  __constr_expr_1[41] = (char)0;
#line 404
  __constr_expr_1[42] = (char)0;
#line 404
  __constr_expr_1[43] = (char)0;
#line 404
  __constr_expr_1[44] = (char)0;
#line 404
  __constr_expr_1[45] = (char)0;
#line 404
  __constr_expr_1[46] = (char)0;
#line 404
  __constr_expr_1[47] = (char)0;
#line 404
  __constr_expr_1[48] = (char)0;
#line 404
  __constr_expr_1[49] = (char)0;
#line 404
  __constr_expr_1[50] = (char)0;
#line 404
  __constr_expr_1[51] = (char)0;
#line 404
  __constr_expr_1[52] = (char)0;
#line 404
  __constr_expr_1[53] = (char)0;
#line 404
  __constr_expr_1[54] = (char)0;
#line 404
  __constr_expr_1[55] = (char)0;
#line 404
  __constr_expr_1[56] = (char)0;
#line 404
  __constr_expr_1[57] = (char)0;
#line 404
  __constr_expr_1[58] = (char)0;
#line 404
  __constr_expr_1[59] = (char)0;
#line 404
  envp[0] = (char *)"HOME=/";
#line 404
  envp[1] = (char *)"TERM=linux";
#line 404
  envp[2] = (char *)"PATH=/sbin:/usr/sbin:/bin:/usr/bin";
#line 404
  envp[3] = (char *)(& __constr_expr_0);
#line 404
  envp[4] = (char *)(& __constr_expr_1);
#line 404
  envp[5] = 0;
#line 411
  argv[0] = (char *)(& usermode_helper);
#line 411
  argv[1] = cmd;
#line 411
  argv[2] = (char *)(& mb);
#line 411
  argv[3] = 0;
#line 412
  tconn = mdev->tconn;
#line 416
  tmp = get_current();
#line 416
  if ((unsigned long )tmp == (unsigned long )tconn->worker.task) {
#line 417
    set_bit(11U, (unsigned long volatile   *)(& tconn->flags));
  } else {

  }
#line 419
  tmp___0 = mdev_to_minor(mdev);
#line 419
  snprintf((char *)(& mb), 12UL, "minor-%d", tmp___0);
#line 420
  setup_khelper_env(tconn, (char **)(& envp));
#line 424
  drbd_md_sync(mdev);
#line 426
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "helper command: %s %s %s\n",
            (char *)(& usermode_helper), cmd, (char *)(& mb));
#line 427
  sib.sib_reason = SIB_HELPER_PRE;
#line 428
  sib.ldv_50742.ldv_50737.helper_name = cmd;
#line 429
  drbd_bcast_event(mdev, (struct sib_info  const  *)(& sib));
#line 430
  ret = call_usermodehelper((char *)(& usermode_helper), (char **)(& argv), (char **)(& envp),
                            2);
#line 431
  if (ret != 0) {
#line 432
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "helper command: %s %s %s exit code %u (0x%x)\n",
             (char *)(& usermode_helper), cmd, (char *)(& mb), (ret >> 8) & 255, ret);
  } else {
#line 436
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "helper command: %s %s %s exit code %u (0x%x)\n",
              (char *)(& usermode_helper), cmd, (char *)(& mb), (ret >> 8) & 255,
              ret);
  }
#line 439
  sib.sib_reason = SIB_HELPER_POST;
#line 440
  sib.ldv_50742.ldv_50737.helper_exit_code = (unsigned int )ret;
#line 441
  drbd_bcast_event(mdev, (struct sib_info  const  *)(& sib));
#line 443
  tmp___1 = get_current();
#line 443
  if ((unsigned long )tmp___1 == (unsigned long )tconn->worker.task) {
#line 444
    clear_bit(11, (unsigned long volatile   *)(& tconn->flags));
  } else {

  }
#line 446
  if (ret < 0) {
#line 447
    ret = 0;
  } else {

  }
#line 449
  return (ret);
}
}
#line 452 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int conn_khelper(struct drbd_tconn *tconn , char *cmd ) 
{ 
  char *envp[6U] ;
  char __constr_expr_0[20] ;
  char __constr_expr_1[60] ;
  char *argv[4U] ;
  int ret ;

  {
#line 454
  __constr_expr_0[0] = (char)0;
#line 454
  __constr_expr_0[1] = (char)0;
#line 454
  __constr_expr_0[2] = (char)0;
#line 454
  __constr_expr_0[3] = (char)0;
#line 454
  __constr_expr_0[4] = (char)0;
#line 454
  __constr_expr_0[5] = (char)0;
#line 454
  __constr_expr_0[6] = (char)0;
#line 454
  __constr_expr_0[7] = (char)0;
#line 454
  __constr_expr_0[8] = (char)0;
#line 454
  __constr_expr_0[9] = (char)0;
#line 454
  __constr_expr_0[10] = (char)0;
#line 454
  __constr_expr_0[11] = (char)0;
#line 454
  __constr_expr_0[12] = (char)0;
#line 454
  __constr_expr_0[13] = (char)0;
#line 454
  __constr_expr_0[14] = (char)0;
#line 454
  __constr_expr_0[15] = (char)0;
#line 454
  __constr_expr_0[16] = (char)0;
#line 454
  __constr_expr_0[17] = (char)0;
#line 454
  __constr_expr_0[18] = (char)0;
#line 454
  __constr_expr_0[19] = (char)0;
#line 454
  __constr_expr_1[0] = (char)0;
#line 454
  __constr_expr_1[1] = (char)0;
#line 454
  __constr_expr_1[2] = (char)0;
#line 454
  __constr_expr_1[3] = (char)0;
#line 454
  __constr_expr_1[4] = (char)0;
#line 454
  __constr_expr_1[5] = (char)0;
#line 454
  __constr_expr_1[6] = (char)0;
#line 454
  __constr_expr_1[7] = (char)0;
#line 454
  __constr_expr_1[8] = (char)0;
#line 454
  __constr_expr_1[9] = (char)0;
#line 454
  __constr_expr_1[10] = (char)0;
#line 454
  __constr_expr_1[11] = (char)0;
#line 454
  __constr_expr_1[12] = (char)0;
#line 454
  __constr_expr_1[13] = (char)0;
#line 454
  __constr_expr_1[14] = (char)0;
#line 454
  __constr_expr_1[15] = (char)0;
#line 454
  __constr_expr_1[16] = (char)0;
#line 454
  __constr_expr_1[17] = (char)0;
#line 454
  __constr_expr_1[18] = (char)0;
#line 454
  __constr_expr_1[19] = (char)0;
#line 454
  __constr_expr_1[20] = (char)0;
#line 454
  __constr_expr_1[21] = (char)0;
#line 454
  __constr_expr_1[22] = (char)0;
#line 454
  __constr_expr_1[23] = (char)0;
#line 454
  __constr_expr_1[24] = (char)0;
#line 454
  __constr_expr_1[25] = (char)0;
#line 454
  __constr_expr_1[26] = (char)0;
#line 454
  __constr_expr_1[27] = (char)0;
#line 454
  __constr_expr_1[28] = (char)0;
#line 454
  __constr_expr_1[29] = (char)0;
#line 454
  __constr_expr_1[30] = (char)0;
#line 454
  __constr_expr_1[31] = (char)0;
#line 454
  __constr_expr_1[32] = (char)0;
#line 454
  __constr_expr_1[33] = (char)0;
#line 454
  __constr_expr_1[34] = (char)0;
#line 454
  __constr_expr_1[35] = (char)0;
#line 454
  __constr_expr_1[36] = (char)0;
#line 454
  __constr_expr_1[37] = (char)0;
#line 454
  __constr_expr_1[38] = (char)0;
#line 454
  __constr_expr_1[39] = (char)0;
#line 454
  __constr_expr_1[40] = (char)0;
#line 454
  __constr_expr_1[41] = (char)0;
#line 454
  __constr_expr_1[42] = (char)0;
#line 454
  __constr_expr_1[43] = (char)0;
#line 454
  __constr_expr_1[44] = (char)0;
#line 454
  __constr_expr_1[45] = (char)0;
#line 454
  __constr_expr_1[46] = (char)0;
#line 454
  __constr_expr_1[47] = (char)0;
#line 454
  __constr_expr_1[48] = (char)0;
#line 454
  __constr_expr_1[49] = (char)0;
#line 454
  __constr_expr_1[50] = (char)0;
#line 454
  __constr_expr_1[51] = (char)0;
#line 454
  __constr_expr_1[52] = (char)0;
#line 454
  __constr_expr_1[53] = (char)0;
#line 454
  __constr_expr_1[54] = (char)0;
#line 454
  __constr_expr_1[55] = (char)0;
#line 454
  __constr_expr_1[56] = (char)0;
#line 454
  __constr_expr_1[57] = (char)0;
#line 454
  __constr_expr_1[58] = (char)0;
#line 454
  __constr_expr_1[59] = (char)0;
#line 454
  envp[0] = (char *)"HOME=/";
#line 454
  envp[1] = (char *)"TERM=linux";
#line 454
  envp[2] = (char *)"PATH=/sbin:/usr/sbin:/bin:/usr/bin";
#line 454
  envp[3] = (char *)(& __constr_expr_0);
#line 454
  envp[4] = (char *)(& __constr_expr_1);
#line 454
  envp[5] = 0;
#line 460
  argv[0] = (char *)(& usermode_helper);
#line 460
  argv[1] = cmd;
#line 460
  argv[2] = tconn->name;
#line 460
  argv[3] = 0;
#line 463
  setup_khelper_env(tconn, (char **)(& envp));
#line 464
  conn_md_sync(tconn);
#line 466
  printk("\016d-con %s: helper command: %s %s %s\n", tconn->name, (char *)(& usermode_helper),
         cmd, tconn->name);
#line 469
  ret = call_usermodehelper((char *)(& usermode_helper), (char **)(& argv), (char **)(& envp),
                            2);
#line 470
  if (ret != 0) {
#line 471
    printk("\fd-con %s: helper command: %s %s %s exit code %u (0x%x)\n", tconn->name,
           (char *)(& usermode_helper), cmd, tconn->name, (ret >> 8) & 255, ret);
  } else {
#line 475
    printk("\016d-con %s: helper command: %s %s %s exit code %u (0x%x)\n", tconn->name,
           (char *)(& usermode_helper), cmd, tconn->name, (ret >> 8) & 255, ret);
  }
#line 480
  if (ret < 0) {
#line 481
    ret = 0;
  } else {

  }
#line 483
  return (ret);
}
}
#line 486 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static enum drbd_fencing_p highest_fencing_policy(struct drbd_tconn *tconn ) 
{ 
  enum drbd_fencing_p fp ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  enum drbd_fencing_p __max1 ;
  enum drbd_fencing_p __max2 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  void *tmp___3 ;

  {
#line 488
  fp = -1;
#line 492
  rcu_read_lock___6();
#line 493
  vnr = 0;
#line 493
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 493
  mdev = (struct drbd_conf *)tmp;
#line 493
  goto ldv_53196;
  ldv_53195: 
#line 494
  tmp___2 = _get_ldev_if_state(mdev, D_CONSISTENT);
#line 494
  if (tmp___2 != 0) {
#line 495
    __max1 = fp;
#line 495
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 495
    tmp___0 = debug_lockdep_rcu_enabled();
#line 495
    if (tmp___0 != 0 && ! __warned) {
#line 495
      tmp___1 = rcu_read_lock_held();
#line 495
      if (tmp___1 == 0 && 1) {
#line 495
        __warned = 1;
#line 495
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                               496, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 495
    __max2 = (enum drbd_fencing_p )_________p1->fencing;
#line 495
    fp = (enum drbd_fencing_p )((int )__max1 > (int )__max2 ? (int )__max1 : (int )__max2);
#line 497
    put_ldev(mdev);
  } else {

  }
#line 493
  vnr = vnr + 1;
#line 493
  tmp___3 = idr_get_next(& tconn->volumes, & vnr);
#line 493
  mdev = (struct drbd_conf *)tmp___3;
  ldv_53196: ;
#line 493
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 494
    goto ldv_53195;
  } else {

  }
#line 500
  rcu_read_unlock___6();
#line 502
  return (fp);
}
}
#line 505 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
bool conn_try_outdate_peer(struct drbd_tconn *tconn ) 
{ 
  union drbd_state mask ;
  union drbd_state val ;
  enum drbd_fencing_p fp ;
  char *ex_to_string ;
  int r ;
  enum drbd_disk_state tmp ;
  int tmp___0 ;
  enum drbd_disk_state tmp___1 ;

  {
#line 507
  mask.ldv_40024.role = (unsigned char)0;
#line 507
  mask.ldv_40024.peer = (unsigned char)0;
#line 507
  mask.ldv_40024.conn = (unsigned char)0;
#line 507
  mask.ldv_40024.disk = (unsigned char)0;
#line 507
  mask.ldv_40024.pdsk = (unsigned char)0;
#line 507
  mask.ldv_40024.susp = (unsigned char)0;
#line 507
  mask.ldv_40024.aftr_isp = (unsigned char)0;
#line 507
  mask.ldv_40024.peer_isp = (unsigned char)0;
#line 507
  mask.ldv_40024.user_isp = (unsigned char)0;
#line 507
  mask.ldv_40024.susp_nod = (unsigned char)0;
#line 507
  mask.ldv_40024.susp_fen = (unsigned char)0;
#line 507
  mask.ldv_40024._pad = (unsigned short)0;
#line 508
  val.ldv_40024.role = (unsigned char)0;
#line 508
  val.ldv_40024.peer = (unsigned char)0;
#line 508
  val.ldv_40024.conn = (unsigned char)0;
#line 508
  val.ldv_40024.disk = (unsigned char)0;
#line 508
  val.ldv_40024.pdsk = (unsigned char)0;
#line 508
  val.ldv_40024.susp = (unsigned char)0;
#line 508
  val.ldv_40024.aftr_isp = (unsigned char)0;
#line 508
  val.ldv_40024.peer_isp = (unsigned char)0;
#line 508
  val.ldv_40024.user_isp = (unsigned char)0;
#line 508
  val.ldv_40024.susp_nod = (unsigned char)0;
#line 508
  val.ldv_40024.susp_fen = (unsigned char)0;
#line 508
  val.ldv_40024._pad = (unsigned short)0;
#line 513
  if ((unsigned int )tconn->cstate > 8U) {
#line 514
    printk("\vd-con %s: Expected cstate < C_WF_REPORT_PARAMS\n", tconn->name);
#line 515
    return (0);
  } else {

  }
#line 518
  fp = highest_fencing_policy(tconn);
#line 519
  switch ((int )fp) {
  case -1: 
#line 521
  printk("\fd-con %s: Not fencing peer, I\'m not even Consistent myself.\n", tconn->name);
#line 522
  goto out;
  case 0: ;
#line 524
  return (1);
  default: ;
  }
#line 528
  r = conn_khelper(tconn, (char *)"fence-peer");
#line 530
  switch ((r >> 8) & 255) {
  case 3: 
#line 532
  ex_to_string = (char *)"peer is inconsistent or worse";
#line 533
  mask.ldv_40024.pdsk = 15U;
#line 534
  val.ldv_40024.pdsk = 4U;
#line 535
  goto ldv_53211;
  case 4: 
#line 537
  ex_to_string = (char *)"peer was fenced";
#line 538
  mask.ldv_40024.pdsk = 15U;
#line 539
  val.ldv_40024.pdsk = 5U;
#line 540
  goto ldv_53211;
  case 5: 
#line 542
  tmp = conn_highest_disk(tconn);
#line 542
  if ((unsigned int )tmp == 8U) {
#line 544
    ex_to_string = (char *)"peer is unreachable, assumed to be dead";
#line 545
    mask.ldv_40024.pdsk = 15U;
#line 546
    val.ldv_40024.pdsk = 5U;
  } else {
#line 548
    ex_to_string = (char *)"peer unreachable, doing nothing since disk != UpToDate";
  }
#line 550
  goto ldv_53211;
  case 6: 
#line 554
  ex_to_string = (char *)"peer is active";
#line 555
  printk("\fd-con %s: Peer is primary, outdating myself.\n", tconn->name);
#line 556
  mask.ldv_40024.disk = 15U;
#line 557
  val.ldv_40024.disk = 5U;
#line 558
  goto ldv_53211;
  case 7: ;
#line 560
  if ((int )fp != 2) {
#line 561
    printk("\vd-con %s: fence-peer() = 7 && fencing != Stonith !!!\n", tconn->name);
  } else {

  }
#line 562
  ex_to_string = (char *)"peer was stonithed";
#line 563
  mask.ldv_40024.pdsk = 15U;
#line 564
  val.ldv_40024.pdsk = 5U;
#line 565
  goto ldv_53211;
  default: 
#line 568
  printk("\vd-con %s: fence-peer helper broken, returned %d\n", tconn->name, (r >> 8) & 255);
#line 569
  return (0);
  }
  ldv_53211: 
#line 572
  printk("\016d-con %s: fence-peer helper returned %d (%s)\n", tconn->name, (r >> 8) & 255,
         ex_to_string);
  out: 
#line 581
  spin_lock_irq(& tconn->req_lock);
#line 582
  if ((unsigned int )tconn->cstate <= 8U) {
#line 582
    tmp___0 = constant_test_bit(10U, (unsigned long const volatile   *)(& tconn->flags));
#line 582
    if (tmp___0 == 0) {
#line 583
      _conn_request_state(tconn, mask, val, CS_VERBOSE);
    } else {

    }
  } else {

  }
#line 584
  spin_unlock_irq(& tconn->req_lock);
#line 586
  tmp___1 = conn_highest_pdsk(tconn);
#line 586
  return ((unsigned int )tmp___1 <= 5U);
}
}
#line 589 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int _try_outdate_peer_async(void *data ) 
{ 
  struct drbd_tconn *tconn ;

  {
#line 591
  tconn = (struct drbd_tconn *)data;
#line 593
  conn_try_outdate_peer(tconn);
#line 595
  kref_put(& tconn->kref, & conn_destroy);
#line 596
  return (0);
}
}
#line 599 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void conn_try_outdate_peer_async(struct drbd_tconn *tconn ) 
{ 
  struct task_struct *opa ;
  struct task_struct *__k ;
  struct task_struct *tmp ;
  long tmp___0 ;
  long tmp___1 ;

  {
#line 603
  kref_get(& tconn->kref);
#line 604
  tmp = kthread_create_on_node(& _try_outdate_peer_async, (void *)tconn, -1, "drbd_async_h");
#line 604
  __k = tmp;
#line 604
  tmp___0 = IS_ERR((void const   *)__k);
#line 604
  if (tmp___0 == 0L) {
#line 604
    wake_up_process(__k);
  } else {

  }
#line 604
  opa = __k;
#line 605
  tmp___1 = IS_ERR((void const   *)opa);
#line 605
  if (tmp___1 != 0L) {
#line 606
    printk("\vd-con %s: out of mem, failed to invoke fence-peer helper\n", tconn->name);
#line 607
    kref_put(& tconn->kref, & conn_destroy);
  } else {

  }
#line 609
  return;
}
}
#line 612 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
enum drbd_state_rv drbd_set_role(struct drbd_conf *mdev , enum drbd_role new_role ,
                                 int force ) 
{ 
  int max_tries ;
  enum drbd_state_rv rv ;
  struct net_conf *nc ;
  int try ;
  int forced ;
  union drbd_state mask ;
  union drbd_state val ;
  bool tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  int timeo ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;

  {
#line 614
  max_tries = 4;
#line 615
  rv = 0;
#line 617
  try = 0;
#line 618
  forced = 0;
#line 621
  if ((unsigned int )new_role == 1U) {
#line 622
    request_ping(mdev->tconn);
  } else {

  }
#line 624
  ldv_mutex_lock_290(mdev->state_mutex);
#line 626
  mask.i = 0U;
#line 626
  mask.ldv_40024.role = 3U;
#line 627
  val.i = 0U;
#line 627
  val.ldv_40024.role = (unsigned char )new_role;
#line 629
  goto ldv_53239;
  ldv_53246: 
#line 630
  rv = _drbd_request_state(mdev, mask, val, CS_WAIT_COMPLETE);
#line 634
  if ((int )rv == -10 && *((unsigned int *)(& mask) + 0UL) != 0U) {
#line 635
    val.ldv_40024.pdsk = 0U;
#line 636
    mask.ldv_40024.pdsk = 0U;
#line 637
    goto ldv_53239;
  } else {

  }
#line 640
  if (((int )rv == -2 && force != 0) && ((int )mdev->state.ldv_49522.disk <= 7 && (int )mdev->state.ldv_49522.disk > 3)) {
#line 643
    mask.ldv_40024.disk = 15U;
#line 644
    val.ldv_40024.disk = 8U;
#line 645
    forced = 1;
#line 646
    goto ldv_53239;
  } else {

  }
#line 649
  if (((int )rv == -2 && (unsigned int )*((unsigned char *)mdev + 749UL) == 14U) && *((unsigned int *)(& mask) + 0UL) == 0U) {
#line 651
    if (*((unsigned int *)mdev + 187UL) != 49152U) {
#line 651
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->state.pdsk == D_UNKNOWN ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
              651);
    } else {

    }
#line 653
    tmp = conn_try_outdate_peer(mdev->tconn);
#line 653
    if ((int )tmp) {
#line 654
      val.ldv_40024.disk = 8U;
#line 655
      mask.ldv_40024.disk = 15U;
    } else {

    }
#line 657
    goto ldv_53239;
  } else {

  }
#line 660
  if ((int )rv == 2) {
#line 661
    goto out;
  } else {

  }
#line 662
  if ((int )rv == -7 && *((unsigned int *)(& mask) + 0UL) == 0U) {
#line 663
    tmp___0 = conn_try_outdate_peer(mdev->tconn);
#line 663
    if (tmp___0) {
#line 663
      tmp___1 = 0;
    } else {
#line 663
      tmp___1 = 1;
    }
#line 663
    if (tmp___1 && force != 0) {
#line 664
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Forced into split brain situation!\n");
#line 665
      mask.ldv_40024.pdsk = 15U;
#line 666
      val.ldv_40024.pdsk = 5U;
    } else {

    }
#line 669
    goto ldv_53239;
  } else {

  }
#line 671
  if ((int )rv == -1) {
#line 675
    rcu_read_lock___6();
#line 676
    _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 676
    tmp___2 = debug_lockdep_rcu_enabled();
#line 676
    if (tmp___2 != 0 && ! __warned) {
#line 676
      tmp___3 = rcu_read_lock_held();
#line 676
      if (tmp___3 == 0 && 1) {
#line 676
        __warned = 1;
#line 676
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                               676, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 676
    nc = _________p1;
#line 677
    timeo = (unsigned long )nc != (unsigned long )((struct net_conf *)0) ? (int )(((nc->ping_timeo + 1U) * 250U) / 10U) : 1;
#line 678
    rcu_read_unlock___6();
#line 679
    schedule_timeout_interruptible((long )timeo);
#line 680
    if (try < max_tries) {
#line 681
      try = max_tries + -1;
    } else {

    }
#line 682
    goto ldv_53239;
  } else {

  }
#line 684
  if ((int )rv <= 0) {
#line 685
    rv = _drbd_request_state(mdev, mask, val, 6);
#line 687
    if ((int )rv <= 0) {
#line 688
      goto out;
    } else {

    }
  } else {

  }
#line 690
  goto ldv_53245;
  ldv_53239: 
#line 629
  tmp___4 = try;
#line 629
  try = try + 1;
#line 629
  if (tmp___4 < max_tries) {
#line 630
    goto ldv_53246;
  } else {

  }
  ldv_53245: ;
#line 693
  if ((int )rv <= 0) {
#line 694
    goto out;
  } else {

  }
#line 696
  if (forced != 0) {
#line 697
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Forced to consider local data as UpToDate!\n");
  } else {

  }
#line 700
  tmp___5 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 700
  if (tmp___5 == 0) {
#line 700
    goto ldv_53247;
  } else {

  }
#line 700
  tmp___6 = get_current();
#line 700
  __wait.flags = 0U;
#line 700
  __wait.private = (void *)tmp___6;
#line 700
  __wait.func = & autoremove_wake_function;
#line 700
  __wait.task_list.next = & __wait.task_list;
#line 700
  __wait.task_list.prev = & __wait.task_list;
  ldv_53250: 
#line 700
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 700
  tmp___7 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 700
  if (tmp___7 == 0) {
#line 700
    goto ldv_53249;
  } else {

  }
#line 700
  schedule();
#line 700
  goto ldv_53250;
  ldv_53249: 
#line 700
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_53247: ;
#line 704
  if ((unsigned int )new_role == 2U) {
#line 705
    set_disk_ro(mdev->vdisk, 1);
#line 706
    tmp___8 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 706
    if (tmp___8 != 0) {
#line 707
      (mdev->ldev)->md.uuid[0] = (mdev->ldev)->md.uuid[0] & 0xfffffffffffffffeULL;
#line 708
      put_ldev(mdev);
    } else {

    }
  } else {
#line 711
    ldv_mutex_lock_291(& (mdev->tconn)->conf_update);
#line 712
    nc = (mdev->tconn)->net_conf;
#line 713
    if ((unsigned long )nc != (unsigned long )((struct net_conf *)0)) {
#line 714
      nc->discard_my_data = 0;
    } else {

    }
#line 715
    ldv_mutex_unlock_292(& (mdev->tconn)->conf_update);
#line 717
    set_disk_ro(mdev->vdisk, 0);
#line 718
    tmp___9 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 718
    if (tmp___9 != 0) {
#line 719
      if ((((int )mdev->state.ldv_49522.conn <= 9 || (int )mdev->state.ldv_49522.pdsk <= 2) && (mdev->ldev)->md.uuid[1] == 0ULL) || forced != 0) {
#line 722
        drbd_uuid_new_current(mdev);
      } else {

      }
#line 724
      (mdev->ldev)->md.uuid[0] = (mdev->ldev)->md.uuid[0] | 1ULL;
#line 725
      put_ldev(mdev);
    } else {

    }
  }
#line 732
  if ((int )mdev->state.ldv_49522.conn > 8) {
#line 734
    if (forced != 0) {
#line 735
      drbd_send_uuids(mdev);
    } else {

    }
#line 736
    drbd_send_current_state(mdev);
  } else {

  }
#line 739
  drbd_md_sync(mdev);
#line 741
  kobject_uevent(& (mdev->vdisk)->part0.__dev.kobj, KOBJ_CHANGE);
  out: 
#line 743
  ldv_mutex_unlock_293(mdev->state_mutex);
#line 744
  return (rv);
}
}
#line 747 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static char const   *from_attrs_err_to_txt(int err ) 
{ 


  {
#line 749
  return (err != -42 ? (err != -95 ? (err == -17 ? "can not change invariant setting" : "invalid attribute value") : "unknown mandatory attribute") : "required attribute missing");
}
}
#line 755 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_set_role(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct set_role_parms parms ;
  int err ;
  enum drbd_ret_code retcode ;
  int tmp ;
  char const   *tmp___0 ;
  enum drbd_state_rv tmp___1 ;
  enum drbd_state_rv tmp___2 ;

  {
#line 761
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 761
  retcode = (enum drbd_ret_code )tmp;
#line 762
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 763
    return ((int )retcode);
  } else {

  }
#line 764
  if ((unsigned int )retcode != 101U) {
#line 765
    goto out;
  } else {

  }
#line 767
  memset((void *)(& parms), 0, 1UL);
#line 768
  if ((unsigned long )*(info->attrs + 6UL) != (unsigned long )((struct nlattr *)0)) {
#line 769
    err = set_role_parms_from_attrs(& parms, info);
#line 770
    if (err != 0) {
#line 771
      retcode = ERR_MANDATORY_TAG;
#line 772
      tmp___0 = from_attrs_err_to_txt(err);
#line 772
      drbd_msg_put_info(tmp___0);
#line 773
      goto out;
    } else {

    }
  } else {

  }
#line 777
  if ((unsigned int )(info->genlhdr)->cmd == 14U) {
#line 778
    tmp___1 = drbd_set_role(adm_ctx.mdev, R_PRIMARY, (int )parms.assume_uptodate);
#line 778
    retcode = (enum drbd_ret_code )tmp___1;
  } else {
#line 780
    tmp___2 = drbd_set_role(adm_ctx.mdev, R_SECONDARY, 0);
#line 780
    retcode = (enum drbd_ret_code )tmp___2;
  }
  out: 
#line 782
  drbd_adm_finish(info, (int )retcode);
#line 783
  return (0);
}
}
#line 788 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void drbd_md_set_sector_offsets(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ) 
{ 
  sector_t md_size_sect ;
  int meta_dev_idx ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  sector_t tmp___1 ;
  sector_t tmp___2 ;
  sector_t tmp___3 ;

  {
#line 791
  md_size_sect = 0UL;
#line 794
  rcu_read_lock___6();
#line 795
  _________p1 = *((struct disk_conf * volatile  *)(& bdev->disk_conf));
#line 795
  tmp = debug_lockdep_rcu_enabled();
#line 795
  if (tmp != 0 && ! __warned) {
#line 795
    tmp___0 = rcu_read_lock_held();
#line 795
    if (tmp___0 == 0 && 1) {
#line 795
      __warned = 1;
#line 795
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                             795, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 795
  meta_dev_idx = _________p1->meta_dev_idx;
#line 797
  switch (meta_dev_idx) {
  default: 
#line 800
  bdev->md.md_size_sect = 262144U;
#line 801
  tmp___1 = drbd_md_ss_____0(mdev, bdev);
#line 801
  bdev->md.md_offset = (u64 )tmp___1;
#line 802
  bdev->md.al_offset = 8;
#line 803
  bdev->md.bm_offset = 72;
#line 804
  goto ldv_53272;
  case -2: 
#line 807
  tmp___2 = drbd_get_capacity(bdev->md_bdev);
#line 807
  bdev->md.md_size_sect = (u32 )tmp___2;
#line 808
  bdev->md.md_offset = 0ULL;
#line 809
  bdev->md.al_offset = 8;
#line 810
  bdev->md.bm_offset = 72;
#line 811
  goto ldv_53272;
  case -1: ;
  case -3: 
#line 814
  tmp___3 = drbd_md_ss_____0(mdev, bdev);
#line 814
  bdev->md.md_offset = (u64 )tmp___3;
#line 816
  bdev->md.al_offset = -64;
#line 818
  md_size_sect = drbd_get_capacity(bdev->backing_bdev);
#line 819
  md_size_sect = (md_size_sect + 32767UL) & 0xffffffffffff8000UL;
#line 820
  md_size_sect = md_size_sect >> 15;
#line 821
  md_size_sect = (md_size_sect + 7UL) & 0xfffffffffffffff8UL;
#line 825
  md_size_sect = md_size_sect + 72UL;
#line 827
  bdev->md.md_size_sect = (u32 )md_size_sect;
#line 829
  bdev->md.bm_offset = (s32 )(8U - (unsigned int )md_size_sect);
#line 830
  goto ldv_53272;
  }
  ldv_53272: 
#line 832
  rcu_read_unlock___6();
#line 833
  return;
}
}
#line 836 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
char *ppsize(char *buf , unsigned long long size ) 
{ 
  char units[6U] ;
  int base ;

  {
#line 840
  units[0] = 75;
#line 840
  units[1] = 77;
#line 840
  units[2] = 71;
#line 840
  units[3] = 84;
#line 840
  units[4] = 80;
#line 840
  units[5] = 69;
#line 841
  base = 0;
#line 842
  goto ldv_53283;
  ldv_53282: 
#line 844
  size = (size >> 10) + (unsigned long long )((size & 512ULL) != 0ULL);
#line 845
  base = base + 1;
  ldv_53283: ;
#line 842
  if (size > 9999ULL && (unsigned int )base <= 4U) {
#line 843
    goto ldv_53282;
  } else {

  }
#line 847
  sprintf(buf, "%u %cB", (unsigned int )size, (int )units[base]);
#line 849
  return (buf);
}
}
#line 871 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void drbd_suspend_io(struct drbd_conf *mdev ) 
{ 
  int tmp ;
  int tmp___0 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;

  {
#line 873
  set_bit(8U, (unsigned long volatile   *)(& mdev->flags));
#line 874
  tmp = drbd_suspended(mdev);
#line 874
  if (tmp != 0) {
#line 875
    return;
  } else {

  }
#line 876
  tmp___0 = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 876
  if (tmp___0 == 0) {
#line 876
    goto ldv_53288;
  } else {

  }
#line 876
  tmp___1 = get_current();
#line 876
  __wait.flags = 0U;
#line 876
  __wait.private = (void *)tmp___1;
#line 876
  __wait.func = & autoremove_wake_function;
#line 876
  __wait.task_list.next = & __wait.task_list;
#line 876
  __wait.task_list.prev = & __wait.task_list;
  ldv_53291: 
#line 876
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 876
  tmp___2 = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 876
  if (tmp___2 == 0) {
#line 876
    goto ldv_53290;
  } else {

  }
#line 876
  schedule();
#line 876
  goto ldv_53291;
  ldv_53290: 
#line 876
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_53288: ;
#line 879
  return;
}
}
#line 879 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void drbd_resume_io(struct drbd_conf *mdev ) 
{ 


  {
#line 881
  clear_bit(8, (unsigned long volatile   *)(& mdev->flags));
#line 882
  __wake_up(& mdev->misc_wait, 3U, 1, 0);
#line 883
  return;
}
}
#line 892 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
enum determine_dev_size drbd_determine_dev_size(struct drbd_conf *mdev , enum dds_flags flags ) 
{ 
  sector_t prev_first_sect ;
  sector_t prev_size ;
  sector_t la_size ;
  sector_t u_size ;
  sector_t size ;
  char ppb[10U] ;
  int md_moved ;
  int la_size_changed ;
  enum determine_dev_size rv ;
  int tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___2 ;
  int tmp___3 ;
  int err ;
  sector_t tmp___4 ;
  long tmp___5 ;
  char *tmp___6 ;
  sector_t tmp___7 ;
  sector_t tmp___8 ;
  sector_t tmp___9 ;
  int err___0 ;

  {
#line 900
  rv = 0;
#line 911
  drbd_suspend_io(mdev);
#line 914
  tmp = lc_try_lock(mdev->act_log);
#line 914
  if (tmp != 0) {
#line 914
    goto ldv_53308;
  } else {

  }
#line 914
  tmp___0 = get_current();
#line 914
  __wait.flags = 0U;
#line 914
  __wait.private = (void *)tmp___0;
#line 914
  __wait.func = & autoremove_wake_function;
#line 914
  __wait.task_list.next = & __wait.task_list;
#line 914
  __wait.task_list.prev = & __wait.task_list;
  ldv_53311: 
#line 914
  prepare_to_wait(& mdev->al_wait, & __wait, 2);
#line 914
  tmp___1 = lc_try_lock(mdev->act_log);
#line 914
  if (tmp___1 != 0) {
#line 914
    goto ldv_53310;
  } else {

  }
#line 914
  schedule();
#line 914
  goto ldv_53311;
  ldv_53310: 
#line 914
  finish_wait(& mdev->al_wait, & __wait);
  ldv_53308: 
#line 916
  prev_first_sect = drbd_md_first_sector___0(mdev->ldev);
#line 917
  prev_size = (sector_t )(mdev->ldev)->md.md_size_sect;
#line 918
  la_size = (sector_t )(mdev->ldev)->md.la_size_sect;
#line 921
  drbd_md_set_sector_offsets(mdev, mdev->ldev);
#line 923
  rcu_read_lock___6();
#line 924
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 924
  tmp___2 = debug_lockdep_rcu_enabled();
#line 924
  if (tmp___2 != 0 && ! __warned) {
#line 924
    tmp___3 = rcu_read_lock_held();
#line 924
    if (tmp___3 == 0 && 1) {
#line 924
      __warned = 1;
#line 924
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                             924, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 924
  u_size = (sector_t )_________p1->disk_size;
#line 925
  rcu_read_unlock___6();
#line 926
  size = drbd_new_dev_size(mdev, mdev->ldev, u_size, (int )flags & 1);
#line 928
  tmp___7 = drbd_get_capacity(mdev->this_bdev);
#line 928
  if (tmp___7 != size) {
#line 928
    goto _L;
  } else {
#line 928
    tmp___8 = drbd_bm_capacity(mdev);
#line 928
    if (tmp___8 != size) {
      _L: /* CIL Label */ 
#line 931
      err = drbd_bm_resize(mdev, size, ((unsigned int )flags & 2U) == 0U);
#line 932
      tmp___5 = __builtin_expect(err != 0, 0L);
#line 932
      if (tmp___5 != 0L) {
#line 934
        tmp___4 = drbd_bm_capacity(mdev);
#line 934
        size = tmp___4 >> 1;
#line 935
        if (size == 0UL) {
#line 936
          dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "OUT OF MEMORY! Could not allocate bitmap!\n");
        } else {
#line 939
          dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "BM resizing failed. Leaving size unchanged at size = %lu KB\n",
                  size);
        }
#line 943
        rv = dev_size_error;
      } else {

      }
#line 946
      drbd_set_my_capacity(mdev, size);
#line 947
      (mdev->ldev)->md.la_size_sect = (u64 )size;
#line 948
      tmp___6 = ppsize((char *)(& ppb), (unsigned long long )(size >> 1));
#line 948
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "size = %s (%llu KB)\n",
                tmp___6, (unsigned long long )size >> 1);
    } else {

    }
  }
#line 951
  if ((int )rv == -1) {
#line 952
    goto out;
  } else {

  }
#line 954
  la_size_changed = (mdev->ldev)->md.la_size_sect != (unsigned long long )la_size;
#line 956
  tmp___9 = drbd_md_first_sector___0(mdev->ldev);
#line 956
  md_moved = tmp___9 != prev_first_sect || (sector_t )(mdev->ldev)->md.md_size_sect != prev_size;
#line 959
  if (la_size_changed != 0 || md_moved != 0) {
#line 962
    drbd_al_shrink(mdev);
#line 963
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Writing the whole bitmap, %s\n",
              la_size_changed == 0 || md_moved == 0 ? (la_size_changed != 0 ? (char *)"size changed" : (char *)"md moved") : (char *)"size changed and md moved");
#line 967
    err___0 = drbd_bitmap_io(mdev, md_moved != 0 ? & drbd_bm_write_all : & drbd_bm_write,
                             (char *)"size changed", BM_LOCKED_MASK);
#line 969
    if (err___0 != 0) {
#line 970
      rv = dev_size_error;
#line 971
      goto out;
    } else {

    }
#line 973
    drbd_md_mark_dirty(mdev);
  } else {

  }
#line 976
  if (size > la_size) {
#line 977
    rv = grew;
  } else {

  }
#line 978
  if (size < la_size) {
#line 979
    rv = shrunk;
  } else {

  }
  out: 
#line 981
  lc_unlock(mdev->act_log);
#line 982
  __wake_up(& mdev->al_wait, 3U, 1, 0);
#line 983
  drbd_resume_io(mdev);
#line 985
  return (rv);
}
}
#line 989 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
sector_t drbd_new_dev_size(struct drbd_conf *mdev , struct drbd_backing_dev *bdev ,
                           sector_t u_size , int assume_peer_has_space ) 
{ 
  sector_t p_size ;
  sector_t la_size ;
  sector_t m_size ;
  sector_t size ;
  sector_t __min1 ;
  sector_t __min2 ;

  {
#line 992
  p_size = mdev->p_size;
#line 993
  la_size = (sector_t )bdev->md.la_size_sect;
#line 995
  size = 0UL;
#line 997
  m_size = drbd_get_max_capacity___1(bdev);
#line 999
  if ((int )mdev->state.ldv_49522.conn <= 9 && assume_peer_has_space != 0) {
#line 1000
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Resize while not connected was forced by the user!\n");
#line 1001
    p_size = m_size;
  } else {

  }
#line 1004
  if (p_size != 0UL && m_size != 0UL) {
#line 1005
    __min1 = p_size;
#line 1005
    __min2 = m_size;
#line 1005
    size = __min1 < __min2 ? __min1 : __min2;
  } else
#line 1007
  if (la_size != 0UL) {
#line 1008
    size = la_size;
#line 1009
    if (m_size != 0UL && m_size < size) {
#line 1010
      size = m_size;
    } else {

    }
#line 1011
    if (p_size != 0UL && p_size < size) {
#line 1012
      size = p_size;
    } else {

    }
  } else {
#line 1014
    if (m_size != 0UL) {
#line 1015
      size = m_size;
    } else {

    }
#line 1016
    if (p_size != 0UL) {
#line 1017
      size = p_size;
    } else {

    }
  }
#line 1021
  if (size == 0UL) {
#line 1022
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Both nodes diskless!\n");
  } else {

  }
#line 1024
  if (u_size != 0UL) {
#line 1025
    if (u_size > size) {
#line 1026
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Requested disk size is too big (%lu > %lu)\n",
              u_size >> 1, size >> 1);
    } else {
#line 1029
      size = u_size;
    }
  } else {

  }
#line 1032
  return (size);
}
}
#line 1043 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int drbd_check_al_size(struct drbd_conf *mdev , struct disk_conf *dc ) 
{ 
  struct lru_cache *n ;
  struct lru_cache *t ;
  struct lc_element *e ;
  unsigned int in_use ;
  int i ;

  {
#line 1050
  if ((unsigned long )mdev->act_log != (unsigned long )((struct lru_cache *)0) && (mdev->act_log)->nr_elements == dc->al_extents) {
#line 1052
    return (0);
  } else {

  }
#line 1054
  in_use = 0U;
#line 1055
  t = mdev->act_log;
#line 1056
  n = lc_create("act_log", drbd_al_ext_cache, 64U, dc->al_extents, 48UL, 0UL);
#line 1059
  if ((unsigned long )n == (unsigned long )((struct lru_cache *)0)) {
#line 1060
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Cannot allocate act_log lru!\n");
#line 1061
    return (-12);
  } else {

  }
#line 1063
  spin_lock_irq(& mdev->al_lock);
#line 1064
  if ((unsigned long )t != (unsigned long )((struct lru_cache *)0)) {
#line 1065
    i = 0;
#line 1065
    goto ldv_53341;
    ldv_53340: 
#line 1066
    e = lc_element_by_index(t, (unsigned int )i);
#line 1067
    if (e->refcnt != 0U) {
#line 1068
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "refcnt(%d)==%d\n",
              e->lc_number, e->refcnt);
    } else {

    }
#line 1070
    in_use = e->refcnt + in_use;
#line 1065
    i = i + 1;
    ldv_53341: ;
#line 1065
    if ((unsigned int )i < t->nr_elements) {
#line 1066
      goto ldv_53340;
    } else {

    }

  } else {

  }
#line 1073
  if (in_use == 0U) {
#line 1074
    mdev->act_log = n;
  } else {

  }
#line 1075
  spin_unlock_irq(& mdev->al_lock);
#line 1076
  if (in_use != 0U) {
#line 1077
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Activity log still in use!\n");
#line 1078
    lc_destroy(n);
#line 1079
    return (-16);
  } else
#line 1081
  if ((unsigned long )t != (unsigned long )((struct lru_cache *)0)) {
#line 1082
    lc_destroy(t);
  } else {

  }
#line 1084
  drbd_md_mark_dirty(mdev);
#line 1085
  return (0);
}
}
#line 1088 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void drbd_setup_queue_param(struct drbd_conf *mdev , unsigned int max_bio_size ) 
{ 
  struct request_queue *q ;
  unsigned int max_hw_sectors ;
  unsigned int max_segments ;
  struct request_queue *b ;
  unsigned int _min1 ;
  unsigned int tmp ;
  unsigned int _min2 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  struct request_queue *b___0 ;
  int tmp___3 ;

  {
#line 1090
  q = mdev->rq_queue;
#line 1091
  max_hw_sectors = max_bio_size >> 9;
#line 1092
  max_segments = 0U;
#line 1094
  tmp___2 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 1094
  if (tmp___2 != 0) {
#line 1095
    b = (((mdev->ldev)->backing_bdev)->bd_disk)->queue;
#line 1097
    tmp = queue_max_hw_sectors(b);
#line 1097
    _min1 = tmp;
#line 1097
    _min2 = max_bio_size >> 9;
#line 1097
    max_hw_sectors = _min1 < _min2 ? _min1 : _min2;
#line 1098
    rcu_read_lock___6();
#line 1099
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1099
    tmp___0 = debug_lockdep_rcu_enabled();
#line 1099
    if (tmp___0 != 0 && ! __warned) {
#line 1099
      tmp___1 = rcu_read_lock_held();
#line 1099
      if (tmp___1 == 0 && 1) {
#line 1099
        __warned = 1;
#line 1099
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                               1099, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 1099
    max_segments = _________p1->max_bio_bvecs;
#line 1100
    rcu_read_unlock___6();
#line 1101
    put_ldev(mdev);
  } else {

  }
#line 1104
  blk_queue_logical_block_size(q, 512);
#line 1105
  blk_queue_max_hw_sectors(q, max_hw_sectors);
#line 1107
  blk_queue_max_segments(q, max_segments != 0U ? (int )((unsigned short )max_segments) : 128);
#line 1108
  blk_queue_segment_boundary(q, 4095UL);
#line 1110
  tmp___3 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 1110
  if (tmp___3 != 0) {
#line 1111
    b___0 = (((mdev->ldev)->backing_bdev)->bd_disk)->queue;
#line 1113
    blk_queue_stack_limits(q, b___0);
#line 1115
    if (q->backing_dev_info.ra_pages != b___0->backing_dev_info.ra_pages) {
#line 1116
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Adjusting my ra_pages to backing device\'s (%lu -> %lu)\n",
                q->backing_dev_info.ra_pages, b___0->backing_dev_info.ra_pages);
#line 1119
      q->backing_dev_info.ra_pages = b___0->backing_dev_info.ra_pages;
    } else {

    }
#line 1121
    put_ldev(mdev);
  } else {

  }
#line 1123
  return;
}
}
#line 1125 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void drbd_reconsider_max_bio_size(struct drbd_conf *mdev ) 
{ 
  unsigned int now ;
  unsigned int new ;
  unsigned int local ;
  unsigned int peer ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  int tmp___1 ;
  unsigned int _min1 ;
  unsigned int _min2 ;
  unsigned int _min1___0 ;
  unsigned int _min2___0 ;
  unsigned int _min1___1 ;
  unsigned int _min2___1 ;

  {
#line 1129
  tmp = queue_max_hw_sectors(mdev->rq_queue);
#line 1129
  now = tmp << 9;
#line 1130
  local = mdev->local_max_bio_size;
#line 1131
  peer = mdev->peer_max_bio_size;
#line 1133
  tmp___1 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 1133
  if (tmp___1 != 0) {
#line 1134
    tmp___0 = queue_max_hw_sectors((((mdev->ldev)->backing_bdev)->bd_disk)->queue);
#line 1134
    local = tmp___0 << 9;
#line 1135
    mdev->local_max_bio_size = local;
#line 1136
    put_ldev(mdev);
  } else {

  }
#line 1138
  _min1 = local;
#line 1138
  _min2 = 1048576U;
#line 1138
  local = _min1 < _min2 ? _min1 : _min2;
#line 1143
  if ((int )mdev->state.ldv_49522.conn > 9) {
#line 1144
    if ((mdev->tconn)->agreed_pro_version <= 93) {
#line 1145
      _min1___0 = mdev->peer_max_bio_size;
#line 1145
      _min2___0 = 32768U;
#line 1145
      peer = _min1___0 < _min2___0 ? _min1___0 : _min2___0;
    } else
#line 1147
    if ((mdev->tconn)->agreed_pro_version == 94) {
#line 1148
      peer = 32768U;
    } else
#line 1149
    if ((mdev->tconn)->agreed_pro_version <= 99) {
#line 1150
      peer = 131072U;
    } else {
#line 1152
      peer = 1048576U;
    }
  } else {

  }
#line 1155
  _min1___1 = local;
#line 1155
  _min2___1 = peer;
#line 1155
  new = _min1___1 < _min2___1 ? _min1___1 : _min2___1;
#line 1157
  if ((unsigned int )*((unsigned char *)mdev + 748UL) == 1U && new < now) {
#line 1158
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED new < now; (%u < %u)\n",
            new, now);
  } else {

  }
#line 1160
  if (new != now) {
#line 1161
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "max BIO size = %u\n",
              new);
  } else {

  }
#line 1163
  drbd_setup_queue_param(mdev, new);
#line 1164
  return;
}
}
#line 1167 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void conn_reconfig_start(struct drbd_tconn *tconn ) 
{ 


  {
#line 1169
  drbd_thread_start(& tconn->worker);
#line 1170
  conn_flush_workqueue(tconn);
#line 1171
  return;
}
}
#line 1174 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void conn_reconfig_done(struct drbd_tconn *tconn ) 
{ 
  bool stop_threads ;
  bool tmp ;

  {
#line 1177
  spin_lock_irq(& tconn->req_lock);
#line 1178
  tmp = conn_all_vols_unconf(tconn);
#line 1178
  stop_threads = (bool )((int )tmp && (unsigned int )tconn->cstate == 0U);
#line 1180
  spin_unlock_irq(& tconn->req_lock);
#line 1181
  if ((int )stop_threads) {
#line 1184
    drbd_thread_stop(& tconn->receiver);
#line 1185
    drbd_thread_stop(& tconn->worker);
  } else {

  }
#line 1187
  return;
}
}
#line 1190 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void drbd_suspend_al(struct drbd_conf *mdev ) 
{ 
  int s ;
  int tmp ;
  int tmp___0 ;

  {
#line 1192
  s = 0;
#line 1194
  tmp = lc_try_lock(mdev->act_log);
#line 1194
  if (tmp == 0) {
#line 1195
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Failed to lock al in drbd_suspend_al()\n");
#line 1196
    return;
  } else {

  }
#line 1199
  drbd_al_shrink(mdev);
#line 1200
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1201
  if ((int )mdev->state.ldv_49522.conn <= 9) {
#line 1202
    tmp___0 = test_and_set_bit(18, (unsigned long volatile   *)(& mdev->flags));
#line 1202
    s = tmp___0 == 0;
  } else {

  }
#line 1203
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1204
  lc_unlock(mdev->act_log);
#line 1206
  if (s != 0) {
#line 1207
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Suspended AL updates\n");
  } else {

  }
#line 1208
  return;
}
}
#line 1211 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static bool should_set_defaults(struct genl_info *info ) 
{ 
  unsigned int flags ;

  {
#line 1213
  flags = ((struct drbd_genlmsghdr *)info->userhdr)->ldv_49826.flags;
#line 1214
  return (((int )flags & 1) != 0);
}
}
#line 1217 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void enforce_disk_conf_limits(struct disk_conf *dc ) 
{ 


  {
#line 1219
  if (dc->al_extents <= 6U) {
#line 1220
    dc->al_extents = 7U;
  } else {

  }
#line 1221
  if (dc->al_extents > 6433U) {
#line 1222
    dc->al_extents = 6433U;
  } else {

  }
#line 1224
  if (dc->c_plan_ahead > 300U) {
#line 1225
    dc->c_plan_ahead = 300U;
  } else {

  }
#line 1226
  return;
}
}
#line 1228 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_disk_opts(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  struct drbd_conf *mdev ;
  struct disk_conf *new_disk_conf ;
  struct disk_conf *old_disk_conf ;
  struct fifo_buffer *old_plan ;
  struct fifo_buffer *new_plan ;
  int err ;
  int fifo_size ;
  int tmp ;
  int tmp___0 ;
  void *tmp___1 ;
  bool tmp___2 ;
  char const   *tmp___3 ;
  bool _bool ;
  int tmp___4 ;
  int tmp___5 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___6 ;
  int tmp___7 ;

  {
#line 1233
  old_plan = 0;
#line 1233
  new_plan = 0;
#line 1236
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 1236
  retcode = (enum drbd_ret_code )tmp;
#line 1237
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 1238
    return ((int )retcode);
  } else {

  }
#line 1239
  if ((unsigned int )retcode != 101U) {
#line 1240
    goto out;
  } else {

  }
#line 1242
  mdev = adm_ctx.mdev;
#line 1246
  tmp___0 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1246
  if (tmp___0 == 0) {
#line 1247
    retcode = ERR_NO_DISK;
#line 1248
    goto out;
  } else {

  }
#line 1251
  tmp___1 = kmalloc(344UL, 208U);
#line 1251
  new_disk_conf = (struct disk_conf *)tmp___1;
#line 1252
  if ((unsigned long )new_disk_conf == (unsigned long )((struct disk_conf *)0)) {
#line 1253
    retcode = ERR_NOMEM;
#line 1254
    goto fail;
  } else {

  }
#line 1257
  ldv_mutex_lock_294(& (mdev->tconn)->conf_update);
#line 1258
  old_disk_conf = (mdev->ldev)->disk_conf;
#line 1259
  *new_disk_conf = *old_disk_conf;
#line 1260
  tmp___2 = should_set_defaults(info);
#line 1260
  if ((int )tmp___2) {
#line 1261
    set_disk_conf_defaults(new_disk_conf);
  } else {

  }
#line 1263
  err = disk_conf_from_attrs_for_change(new_disk_conf, info);
#line 1264
  if (err != 0 && err != -42) {
#line 1265
    retcode = ERR_MANDATORY_TAG;
#line 1266
    tmp___3 = from_attrs_err_to_txt(err);
#line 1266
    drbd_msg_put_info(tmp___3);
  } else {

  }
#line 1269
  _bool = new_disk_conf->resync_rate != 0U;
#line 1269
  if (! _bool) {
#line 1269
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERTION %s FAILED in %s\n",
            (char *)"new_disk_conf->resync_rate >= 1", "drbd_adm_disk_opts");
  } else {

  }
#line 1269
  if (_bool) {
#line 1269
    tmp___4 = 0;
  } else {
#line 1269
    tmp___4 = 1;
  }
#line 1269
  if (tmp___4) {
#line 1270
    new_disk_conf->resync_rate = 1U;
  } else {

  }
#line 1272
  enforce_disk_conf_limits(new_disk_conf);
#line 1274
  fifo_size = (int )((new_disk_conf->c_plan_ahead * 250U) / 250U);
#line 1275
  if ((unsigned int )fifo_size != (mdev->rs_plan_s)->size) {
#line 1276
    new_plan = fifo_alloc(fifo_size);
#line 1277
    if ((unsigned long )new_plan == (unsigned long )((struct fifo_buffer *)0)) {
#line 1278
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "kmalloc of fifo_buffer failed");
#line 1279
      retcode = ERR_NOMEM;
#line 1280
      goto fail_unlock;
    } else {

    }
  } else {

  }
#line 1284
  drbd_suspend_io(mdev);
#line 1285
  tmp___5 = lc_try_lock(mdev->act_log);
#line 1285
  if (tmp___5 != 0) {
#line 1285
    goto ldv_53410;
  } else {

  }
#line 1285
  tmp___6 = get_current();
#line 1285
  __wait.flags = 0U;
#line 1285
  __wait.private = (void *)tmp___6;
#line 1285
  __wait.func = & autoremove_wake_function;
#line 1285
  __wait.task_list.next = & __wait.task_list;
#line 1285
  __wait.task_list.prev = & __wait.task_list;
  ldv_53413: 
#line 1285
  prepare_to_wait(& mdev->al_wait, & __wait, 2);
#line 1285
  tmp___7 = lc_try_lock(mdev->act_log);
#line 1285
  if (tmp___7 != 0) {
#line 1285
    goto ldv_53412;
  } else {

  }
#line 1285
  schedule();
#line 1285
  goto ldv_53413;
  ldv_53412: 
#line 1285
  finish_wait(& mdev->al_wait, & __wait);
  ldv_53410: 
#line 1286
  drbd_al_shrink(mdev);
#line 1287
  err = drbd_check_al_size(mdev, new_disk_conf);
#line 1288
  lc_unlock(mdev->act_log);
#line 1289
  __wake_up(& mdev->al_wait, 3U, 1, 0);
#line 1290
  drbd_resume_io(mdev);
#line 1292
  if (err != 0) {
#line 1293
    retcode = ERR_NOMEM;
#line 1294
    goto fail_unlock;
  } else {

  }
#line 1297
  _raw_write_lock_irq(& global_state_lock);
#line 1298
  retcode = drbd_resync_after_valid(mdev, new_disk_conf->resync_after);
#line 1299
  if ((unsigned int )retcode == 101U) {
#line 1300
    __asm__  volatile   ("": : : "memory");
#line 1300
    (mdev->ldev)->disk_conf = new_disk_conf;
#line 1301
    drbd_resync_after_changed(mdev);
  } else {

  }
#line 1303
  _raw_write_unlock_irq(& global_state_lock);
#line 1305
  if ((unsigned int )retcode != 101U) {
#line 1306
    goto fail_unlock;
  } else {

  }
#line 1308
  if ((unsigned long )new_plan != (unsigned long )((struct fifo_buffer *)0)) {
#line 1309
    old_plan = mdev->rs_plan_s;
#line 1310
    __asm__  volatile   ("": : : "memory");
#line 1310
    mdev->rs_plan_s = new_plan;
  } else {

  }
#line 1313
  ldv_mutex_unlock_295(& (mdev->tconn)->conf_update);
#line 1315
  if ((int )((signed char )new_disk_conf->al_updates) != 0) {
#line 1316
    (mdev->ldev)->md.flags = (mdev->ldev)->md.flags & 4294967039U;
  } else {
#line 1318
    (mdev->ldev)->md.flags = (mdev->ldev)->md.flags | 256U;
  }
#line 1320
  if ((int )((signed char )new_disk_conf->md_flushes) != 0) {
#line 1321
    clear_bit(7, (unsigned long volatile   *)(& mdev->flags));
  } else {
#line 1323
    set_bit(7U, (unsigned long volatile   *)(& mdev->flags));
  }
#line 1325
  drbd_bump_write_ordering(mdev->tconn, WO_bdev_flush);
#line 1327
  drbd_md_sync(mdev);
#line 1329
  if ((int )mdev->state.ldv_49522.conn > 9) {
#line 1330
    drbd_send_sync_param(mdev);
  } else {

  }
#line 1332
  synchronize_rcu();
#line 1333
  kfree((void const   *)old_disk_conf);
#line 1334
  kfree((void const   *)old_plan);
#line 1335
  mod_timer(& mdev->request_timer, (unsigned long )jiffies + 250UL);
#line 1336
  goto success;
  fail_unlock: 
#line 1339
  ldv_mutex_unlock_296(& (mdev->tconn)->conf_update);
  fail: 
#line 1341
  kfree((void const   *)new_disk_conf);
#line 1342
  kfree((void const   *)new_plan);
  success: 
#line 1344
  put_ldev(mdev);
  out: 
#line 1346
  drbd_adm_finish(info, (int )retcode);
#line 1347
  return (0);
}
}
#line 1350 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_attach(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct drbd_conf *mdev ;
  int err ;
  enum drbd_ret_code retcode ;
  enum determine_dev_size dd ;
  sector_t max_possible_sectors ;
  sector_t min_md_device_sectors ;
  struct drbd_backing_dev *nbc ;
  struct disk_conf *new_disk_conf ;
  struct block_device *bdev ;
  struct lru_cache *resync_lru ;
  struct fifo_buffer *new_plan ;
  union drbd_state ns ;
  union drbd_state os ;
  enum drbd_state_rv rv ;
  struct net_conf *nc ;
  int tmp ;
  int tmp___0 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  void *tmp___3 ;
  struct lock_class_key __key ;
  void *tmp___4 ;
  char const   *tmp___5 ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp___6 ;
  int tmp___7 ;
  long tmp___8 ;
  long tmp___9 ;
  long tmp___10 ;
  long tmp___11 ;
  sector_t tmp___12 ;
  sector_t tmp___13 ;
  sector_t tmp___14 ;
  sector_t tmp___15 ;
  sector_t tmp___16 ;
  int tmp___17 ;
  int tmp___18 ;
  wait_queue_t __wait___0 ;
  struct task_struct *tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  union drbd_state val ;
  union drbd_state mask ;
  int tmp___22 ;
  int tmp___23 ;
  int tmp___24 ;
  int tmp___25 ;
  int tmp___26 ;
  sector_t tmp___27 ;
  int tmp___28 ;
  int tmp___29 ;
  int tmp___30 ;
  int tmp___31 ;
  int tmp___32 ;
  int tmp___33 ;
  int tmp___34 ;
  int tmp___35 ;
  int tmp___36 ;
  unsigned long tmp___37 ;
  unsigned long tmp___38 ;
  int tmp___39 ;
  int tmp___40 ;
  int tmp___41 ;
  struct disk_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___42 ;
  int tmp___43 ;
  struct disk_conf *_________p1___1 ;
  bool __warned___1 ;
  int tmp___44 ;
  int tmp___45 ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;

  {
#line 1358
  nbc = 0;
#line 1359
  new_disk_conf = 0;
#line 1361
  resync_lru = 0;
#line 1362
  new_plan = 0;
#line 1367
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 1367
  retcode = (enum drbd_ret_code )tmp;
#line 1368
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 1369
    return ((int )retcode);
  } else {

  }
#line 1370
  if ((unsigned int )retcode != 101U) {
#line 1371
    goto finish;
  } else {

  }
#line 1373
  mdev = adm_ctx.mdev;
#line 1374
  conn_reconfig_start(mdev->tconn);
#line 1377
  if ((int )mdev->state.ldv_49522.disk > 0) {
#line 1378
    retcode = ERR_DISK_CONFIGURED;
#line 1379
    goto fail;
  } else {

  }
#line 1385
  tmp___0 = atomic_read((atomic_t const   *)(& mdev->local_cnt));
#line 1385
  if (tmp___0 == 0) {
#line 1385
    goto ldv_53436;
  } else {

  }
#line 1385
  tmp___1 = get_current();
#line 1385
  __wait.flags = 0U;
#line 1385
  __wait.private = (void *)tmp___1;
#line 1385
  __wait.func = & autoremove_wake_function;
#line 1385
  __wait.task_list.next = & __wait.task_list;
#line 1385
  __wait.task_list.prev = & __wait.task_list;
  ldv_53439: 
#line 1385
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 1385
  tmp___2 = atomic_read((atomic_t const   *)(& mdev->local_cnt));
#line 1385
  if (tmp___2 == 0) {
#line 1385
    goto ldv_53438;
  } else {

  }
#line 1385
  schedule();
#line 1385
  goto ldv_53439;
  ldv_53438: 
#line 1385
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_53436: 
#line 1388
  clear_bit(14, (unsigned long volatile   *)(& mdev->flags));
#line 1389
  clear_bit(12, (unsigned long volatile   *)(& mdev->flags));
#line 1390
  clear_bit(13, (unsigned long volatile   *)(& mdev->flags));
#line 1393
  mdev->rs_total = 0UL;
#line 1394
  mdev->rs_failed = 0UL;
#line 1395
  atomic_set(& mdev->rs_pending_cnt, 0);
#line 1398
  tmp___3 = kzalloc(176UL, 208U);
#line 1398
  nbc = (struct drbd_backing_dev *)tmp___3;
#line 1399
  if ((unsigned long )nbc == (unsigned long )((struct drbd_backing_dev *)0)) {
#line 1400
    retcode = ERR_NOMEM;
#line 1401
    goto fail;
  } else {

  }
#line 1403
  spinlock_check(& nbc->md.uuid_lock);
#line 1403
  __raw_spin_lock_init(& nbc->md.uuid_lock.ldv_5957.rlock, "&(&nbc->md.uuid_lock)->rlock",
                       & __key);
#line 1405
  tmp___4 = kzalloc(344UL, 208U);
#line 1405
  new_disk_conf = (struct disk_conf *)tmp___4;
#line 1406
  if ((unsigned long )new_disk_conf == (unsigned long )((struct disk_conf *)0)) {
#line 1407
    retcode = ERR_NOMEM;
#line 1408
    goto fail;
  } else {

  }
#line 1410
  nbc->disk_conf = new_disk_conf;
#line 1412
  set_disk_conf_defaults(new_disk_conf);
#line 1413
  err = disk_conf_from_attrs(new_disk_conf, info);
#line 1414
  if (err != 0) {
#line 1415
    retcode = ERR_MANDATORY_TAG;
#line 1416
    tmp___5 = from_attrs_err_to_txt(err);
#line 1416
    drbd_msg_put_info(tmp___5);
#line 1417
    goto fail;
  } else {

  }
#line 1420
  enforce_disk_conf_limits(new_disk_conf);
#line 1422
  new_plan = fifo_alloc((int )((new_disk_conf->c_plan_ahead * 250U) / 250U));
#line 1423
  if ((unsigned long )new_plan == (unsigned long )((struct fifo_buffer *)0)) {
#line 1424
    retcode = ERR_NOMEM;
#line 1425
    goto fail;
  } else {

  }
#line 1428
  if (new_disk_conf->meta_dev_idx < -3) {
#line 1429
    retcode = ERR_MD_IDX_INVALID;
#line 1430
    goto fail;
  } else {

  }
#line 1433
  rcu_read_lock___6();
#line 1434
  _________p1 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 1434
  tmp___6 = debug_lockdep_rcu_enabled();
#line 1434
  if (tmp___6 != 0 && ! __warned) {
#line 1434
    tmp___7 = rcu_read_lock_held();
#line 1434
    if (tmp___7 == 0 && 1) {
#line 1434
      __warned = 1;
#line 1434
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                             1434, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1434
  nc = _________p1;
#line 1435
  if ((unsigned long )nc != (unsigned long )((struct net_conf *)0)) {
#line 1436
    if (new_disk_conf->fencing == 2U && nc->wire_protocol == 1U) {
#line 1437
      rcu_read_unlock___6();
#line 1438
      retcode = ERR_STONITH_AND_PROT_A;
#line 1439
      goto fail;
    } else {

    }
  } else {

  }
#line 1442
  rcu_read_unlock___6();
#line 1444
  bdev = blkdev_get_by_path((char const   *)(& new_disk_conf->backing_dev), 131U,
                            (void *)mdev);
#line 1446
  tmp___9 = IS_ERR((void const   *)bdev);
#line 1446
  if (tmp___9 != 0L) {
#line 1447
    tmp___8 = PTR_ERR((void const   *)bdev);
#line 1447
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "open(\"%s\") failed with %ld\n",
            (char *)(& new_disk_conf->backing_dev), tmp___8);
#line 1449
    retcode = ERR_OPEN_DISK;
#line 1450
    goto fail;
  } else {

  }
#line 1452
  nbc->backing_bdev = bdev;
#line 1462
  bdev = blkdev_get_by_path((char const   *)(& new_disk_conf->meta_dev), 131U, new_disk_conf->meta_dev_idx < 0 ? (void *)mdev : (void *)drbd_m_holder);
#line 1466
  tmp___11 = IS_ERR((void const   *)bdev);
#line 1466
  if (tmp___11 != 0L) {
#line 1467
    tmp___10 = PTR_ERR((void const   *)bdev);
#line 1467
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "open(\"%s\") failed with %ld\n",
            (char *)(& new_disk_conf->meta_dev), tmp___10);
#line 1469
    retcode = ERR_OPEN_MD_DISK;
#line 1470
    goto fail;
  } else {

  }
#line 1472
  nbc->md_bdev = bdev;
#line 1474
  if (((unsigned long )nbc->backing_bdev == (unsigned long )nbc->md_bdev) ^ (int )((_Bool )(new_disk_conf->meta_dev_idx == -1 || new_disk_conf->meta_dev_idx == -3))) {
#line 1477
    retcode = ERR_MD_IDX_INVALID;
#line 1478
    goto fail;
  } else {

  }
#line 1481
  resync_lru = lc_create("resync", drbd_bm_ext_cache, 1U, 61U, 64UL, 16UL);
#line 1484
  if ((unsigned long )resync_lru == (unsigned long )((struct lru_cache *)0)) {
#line 1485
    retcode = ERR_NOMEM;
#line 1486
    goto fail;
  } else {

  }
#line 1490
  drbd_md_set_sector_offsets(mdev, nbc);
#line 1492
  tmp___13 = drbd_get_max_capacity___1(nbc);
#line 1492
  if ((unsigned long long )tmp___13 < new_disk_conf->disk_size) {
#line 1493
    tmp___12 = drbd_get_max_capacity___1(nbc);
#line 1493
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "max capacity %llu smaller than disk size %llu\n",
            (unsigned long long )tmp___12, new_disk_conf->disk_size);
#line 1496
    retcode = ERR_DISK_TOO_SMALL;
#line 1497
    goto fail;
  } else {

  }
#line 1500
  if (new_disk_conf->meta_dev_idx < 0) {
#line 1501
    max_possible_sectors = 2251799813685248UL;
#line 1503
    min_md_device_sectors = 2048UL;
  } else {
#line 1505
    max_possible_sectors = 8587575296UL;
#line 1506
    min_md_device_sectors = (unsigned long )(new_disk_conf->meta_dev_idx + 1) * 262144UL;
  }
#line 1509
  tmp___14 = drbd_get_capacity(nbc->md_bdev);
#line 1509
  if (tmp___14 < min_md_device_sectors) {
#line 1510
    retcode = ERR_MD_DISK_TOO_SMALL;
#line 1511
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "refusing attach: md-device too small, at least %llu sectors needed for this meta-disk type\n",
             (unsigned long long )min_md_device_sectors);
#line 1514
    goto fail;
  } else {

  }
#line 1519
  tmp___15 = drbd_get_max_capacity___1(nbc);
#line 1519
  tmp___16 = drbd_get_capacity(mdev->this_bdev);
#line 1519
  if (tmp___15 < tmp___16) {
#line 1521
    retcode = ERR_DISK_TOO_SMALL;
#line 1522
    goto fail;
  } else {

  }
#line 1525
  nbc->known_size = drbd_get_capacity(nbc->backing_bdev);
#line 1527
  if (nbc->known_size > max_possible_sectors) {
#line 1528
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "==> truncating very big lower level device to currently maximum possible %llu sectors <==\n",
             (unsigned long long )max_possible_sectors);
#line 1531
    if (new_disk_conf->meta_dev_idx >= 0) {
#line 1532
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "==>> using internal or flexible meta data may help <<==\n");
    } else {

    }
  } else {

  }
#line 1536
  drbd_suspend_io(mdev);
#line 1544
  tmp___17 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 1544
  if (tmp___17 == 0) {
#line 1544
    goto ldv_53444;
  } else {
#line 1544
    tmp___18 = drbd_suspended(mdev);
#line 1544
    if (tmp___18 != 0) {
#line 1544
      goto ldv_53444;
    } else {

    }
  }
#line 1544
  tmp___19 = get_current();
#line 1544
  __wait___0.flags = 0U;
#line 1544
  __wait___0.private = (void *)tmp___19;
#line 1544
  __wait___0.func = & autoremove_wake_function;
#line 1544
  __wait___0.task_list.next = & __wait___0.task_list;
#line 1544
  __wait___0.task_list.prev = & __wait___0.task_list;
  ldv_53447: 
#line 1544
  prepare_to_wait(& mdev->misc_wait, & __wait___0, 2);
#line 1544
  tmp___20 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 1544
  if (tmp___20 == 0) {
#line 1544
    goto ldv_53446;
  } else {
#line 1544
    tmp___21 = drbd_suspended(mdev);
#line 1544
    if (tmp___21 != 0) {
#line 1544
      goto ldv_53446;
    } else {

    }
  }
#line 1544
  schedule();
#line 1544
  goto ldv_53447;
  ldv_53446: 
#line 1544
  finish_wait(& mdev->misc_wait, & __wait___0);
  ldv_53444: 
#line 1546
  drbd_flush_workqueue(mdev);
#line 1548
  val.i = 0U;
#line 1548
  val.ldv_40024.disk = 1U;
#line 1548
  mask.i = 0U;
#line 1548
  mask.ldv_40024.disk = 15U;
#line 1548
  rv = _drbd_request_state(mdev, mask, val, CS_VERBOSE);
#line 1549
  retcode = (enum drbd_ret_code )rv;
#line 1550
  drbd_resume_io(mdev);
#line 1551
  if ((int )rv <= 0) {
#line 1552
    goto fail;
  } else {

  }
#line 1554
  tmp___22 = _get_ldev_if_state(mdev, D_ATTACHING);
#line 1554
  if (tmp___22 == 0) {
#line 1555
    goto force_diskless;
  } else {

  }
#line 1557
  drbd_md_set_sector_offsets(mdev, nbc);
#line 1559
  if ((unsigned long )mdev->bitmap == (unsigned long )((struct drbd_bitmap *)0)) {
#line 1560
    tmp___23 = drbd_bm_init(mdev);
#line 1560
    if (tmp___23 != 0) {
#line 1561
      retcode = ERR_NOMEM;
#line 1562
      goto force_diskless_dec;
    } else {

    }
  } else {

  }
#line 1566
  tmp___24 = drbd_md_read(mdev, nbc);
#line 1566
  retcode = (enum drbd_ret_code )tmp___24;
#line 1567
  if ((unsigned int )retcode != 101U) {
#line 1568
    goto force_diskless_dec;
  } else {

  }
#line 1570
  if (((int )mdev->state.ldv_49522.conn <= 9 && (unsigned int )*((unsigned char *)mdev + 748UL) == 1U) && ((mdev->ed_uuid ^ nbc->md.uuid[0]) & 0xfffffffffffffffeULL) != 0ULL) {
#line 1573
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Can only attach to data with current UUID=%016llX\n",
            mdev->ed_uuid);
#line 1575
    retcode = ERR_DATA_NOT_CURRENT;
#line 1576
    goto force_diskless_dec;
  } else {

  }
#line 1580
  tmp___25 = drbd_check_al_size(mdev, new_disk_conf);
#line 1580
  if (tmp___25 != 0) {
#line 1581
    retcode = ERR_NOMEM;
#line 1582
    goto force_diskless_dec;
  } else {

  }
#line 1586
  tmp___26 = drbd_md_test_flag(nbc, 1);
#line 1586
  if (tmp___26 != 0) {
#line 1586
    tmp___27 = drbd_new_dev_size(mdev, nbc, (sector_t )(nbc->disk_conf)->disk_size,
                                 0);
#line 1586
    if ((unsigned long long )tmp___27 < nbc->md.la_size_sect) {
#line 1588
      dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "refusing to truncate a consistent device\n");
#line 1589
      retcode = ERR_DISK_TOO_SMALL;
#line 1590
      goto force_diskless_dec;
    } else {

    }
  } else {

  }
#line 1595
  if ((int )((signed char )new_disk_conf->md_flushes) != 0) {
#line 1596
    clear_bit(7, (unsigned long volatile   *)(& mdev->flags));
  } else {
#line 1598
    set_bit(7U, (unsigned long volatile   *)(& mdev->flags));
  }
#line 1604
  if ((unsigned long )mdev->ldev != (unsigned long )((struct drbd_backing_dev *)0)) {
#line 1604
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->ldev == NULL ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
            1604);
  } else {

  }
#line 1605
  mdev->ldev = nbc;
#line 1606
  mdev->resync = resync_lru;
#line 1607
  mdev->rs_plan_s = new_plan;
#line 1608
  nbc = 0;
#line 1609
  resync_lru = 0;
#line 1610
  new_disk_conf = 0;
#line 1611
  new_plan = 0;
#line 1613
  drbd_bump_write_ordering(mdev->tconn, WO_bdev_flush);
#line 1615
  tmp___28 = drbd_md_test_flag(mdev->ldev, 64);
#line 1615
  if (tmp___28 != 0) {
#line 1616
    set_bit(5U, (unsigned long volatile   *)(& mdev->flags));
  } else {
#line 1618
    clear_bit(5, (unsigned long volatile   *)(& mdev->flags));
  }
#line 1620
  tmp___29 = drbd_md_test_flag(mdev->ldev, 2);
#line 1620
  if (tmp___29 != 0 && ((unsigned int )*((unsigned char *)mdev + 748UL) != 1U || (unsigned int )*((unsigned char *)mdev->tconn + 132UL) == 0U)) {
#line 1622
    set_bit(5U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1624
  mdev->send_cnt = 0U;
#line 1625
  mdev->recv_cnt = 0U;
#line 1626
  mdev->read_cnt = 0U;
#line 1627
  mdev->writ_cnt = 0U;
#line 1629
  drbd_reconsider_max_bio_size(mdev);
#line 1645
  clear_bit(2, (unsigned long volatile   *)(& mdev->flags));
#line 1646
  if ((unsigned int )*((unsigned char *)mdev + 748UL) != 1U) {
#line 1646
    tmp___30 = drbd_md_test_flag(mdev->ldev, 2);
#line 1646
    if (tmp___30 != 0) {
#line 1646
      tmp___31 = drbd_md_test_flag(mdev->ldev, 4);
#line 1646
      if (tmp___31 == 0) {
#line 1649
        set_bit(2U, (unsigned long volatile   *)(& mdev->flags));
      } else {

      }
    } else {

    }
  } else {

  }
#line 1651
  dd = drbd_determine_dev_size(mdev, 0);
#line 1652
  if ((int )dd == -1) {
#line 1653
    retcode = ERR_NOMEM_BITMAP;
#line 1654
    goto force_diskless_dec;
  } else
#line 1655
  if ((int )dd == 2) {
#line 1656
    set_bit(15U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1658
  tmp___34 = drbd_md_test_flag(mdev->ldev, 8);
#line 1658
  if (tmp___34 != 0) {
#line 1658
    goto _L;
  } else {
#line 1658
    tmp___35 = constant_test_bit(5U, (unsigned long const volatile   *)(& mdev->flags));
#line 1658
    if (tmp___35 != 0) {
#line 1658
      tmp___36 = drbd_md_test_flag(mdev->ldev, 256);
#line 1658
      if (tmp___36 != 0) {
        _L: /* CIL Label */ 
#line 1661
        _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Assuming that all blocks are out of sync (aka FullSync)\n");
#line 1663
        tmp___32 = drbd_bitmap_io(mdev, & drbd_bmio_set_n_write, (char *)"set_n_write from attaching",
                                  BM_LOCKED_MASK);
#line 1663
        if (tmp___32 != 0) {
#line 1665
          retcode = ERR_IO_MD_DISK;
#line 1666
          goto force_diskless_dec;
        } else {

        }
      } else {
#line 1658
        goto _L___0;
      }
    } else {
      _L___0: /* CIL Label */ 
#line 1669
      tmp___33 = drbd_bitmap_io(mdev, & drbd_bm_read, (char *)"read from attaching",
                                BM_LOCKED_MASK);
#line 1669
      if (tmp___33 != 0) {
#line 1671
        retcode = ERR_IO_MD_DISK;
#line 1672
        goto force_diskless_dec;
      } else {

      }
    }
  }
#line 1676
  tmp___37 = _drbd_bm_total_weight(mdev);
#line 1676
  tmp___38 = drbd_bm_bits(mdev);
#line 1676
  if (tmp___37 == tmp___38) {
#line 1677
    drbd_suspend_al(mdev);
  } else {

  }
#line 1679
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 1680
  os = drbd_read_state(mdev);
#line 1681
  ns = os;
#line 1687
  tmp___40 = drbd_md_test_flag(mdev->ldev, 1);
#line 1687
  if (tmp___40 != 0) {
#line 1688
    tmp___39 = drbd_md_test_flag(mdev->ldev, 16);
#line 1688
    if (tmp___39 != 0) {
#line 1689
      ns.ldv_40024.disk = 7U;
    } else {
#line 1691
      ns.ldv_40024.disk = 5U;
    }
  } else {
#line 1693
    ns.ldv_40024.disk = 4U;
  }
#line 1696
  tmp___41 = drbd_md_test_flag(mdev->ldev, 32);
#line 1696
  if (tmp___41 != 0) {
#line 1697
    ns.ldv_40024.pdsk = 5U;
  } else {

  }
#line 1699
  rcu_read_lock___6();
#line 1701
  if ((unsigned int )*((unsigned char *)(& ns) + 1UL) == 14U) {
#line 1701
    if (*((unsigned int *)(& ns) + 0UL) == 40960U) {
#line 1702
      ns.ldv_40024.disk = 8U;
    } else {
#line 1701
      _________p1___0 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1701
      tmp___42 = debug_lockdep_rcu_enabled();
#line 1701
      if (tmp___42 != 0 && ! __warned___0) {
#line 1701
        tmp___43 = rcu_read_lock_held();
#line 1701
        if (tmp___43 == 0 && 1) {
#line 1701
          __warned___0 = 1;
#line 1701
          lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                                 1701, "suspicious rcu_dereference_check() usage");
        } else {

        }
      } else {

      }
#line 1701
      if (_________p1___0->fencing == 0U) {
#line 1702
        ns.ldv_40024.disk = 8U;
      } else {

      }
    }
  } else {

  }
#line 1709
  _________p1___1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1709
  tmp___44 = debug_lockdep_rcu_enabled();
#line 1709
  if (tmp___44 != 0 && ! __warned___1) {
#line 1709
    tmp___45 = rcu_read_lock_held();
#line 1709
    if (tmp___45 == 0 && 1) {
#line 1709
      __warned___1 = 1;
#line 1709
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                             1709, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1709
  if ((int )((signed char )_________p1___1->al_updates) != 0) {
#line 1710
    (mdev->ldev)->md.flags = (mdev->ldev)->md.flags & 4294967039U;
  } else {
#line 1712
    (mdev->ldev)->md.flags = (mdev->ldev)->md.flags | 256U;
  }
#line 1714
  rcu_read_unlock___6();
#line 1718
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 160U) {
#line 1719
    mdev->new_state_tmp.i = ns.i;
#line 1720
    ns.i = os.i;
#line 1721
    ns.ldv_40024.disk = 3U;
#line 1726
    kfree((void const   *)mdev->p_uuid);
#line 1727
    mdev->p_uuid = 0;
  } else {

  }
#line 1730
  rv = _drbd_set_state(mdev, ns, CS_VERBOSE, 0);
#line 1731
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 1733
  if ((int )rv <= 0) {
#line 1734
    goto force_diskless_dec;
  } else {

  }
#line 1736
  mod_timer(& mdev->request_timer, (unsigned long )jiffies + 250UL);
#line 1738
  if ((unsigned int )*((unsigned char *)mdev + 748UL) == 1U) {
#line 1739
    (mdev->ldev)->md.uuid[0] = (mdev->ldev)->md.uuid[0] | 1ULL;
  } else {
#line 1741
    (mdev->ldev)->md.uuid[0] = (mdev->ldev)->md.uuid[0] & 0xfffffffffffffffeULL;
  }
#line 1743
  drbd_md_mark_dirty(mdev);
#line 1744
  drbd_md_sync(mdev);
#line 1746
  kobject_uevent(& (mdev->vdisk)->part0.__dev.kobj, KOBJ_CHANGE);
#line 1747
  put_ldev(mdev);
#line 1748
  conn_reconfig_done(mdev->tconn);
#line 1749
  drbd_adm_finish(info, (int )retcode);
#line 1750
  return (0);
  force_diskless_dec: 
#line 1753
  put_ldev(mdev);
  force_diskless: 
#line 1755
  val___0.i = 0U;
#line 1755
  val___0.ldv_40024.disk = 0U;
#line 1755
  mask___0.i = 0U;
#line 1755
  mask___0.ldv_40024.disk = 15U;
#line 1755
  drbd_force_state(mdev, mask___0, val___0);
#line 1756
  drbd_md_sync(mdev);
  fail: 
#line 1758
  conn_reconfig_done(mdev->tconn);
#line 1759
  if ((unsigned long )nbc != (unsigned long )((struct drbd_backing_dev *)0)) {
#line 1760
    if ((unsigned long )nbc->backing_bdev != (unsigned long )((struct block_device *)0)) {
#line 1761
      blkdev_put(nbc->backing_bdev, 131U);
    } else {

    }
#line 1763
    if ((unsigned long )nbc->md_bdev != (unsigned long )((struct block_device *)0)) {
#line 1764
      blkdev_put(nbc->md_bdev, 131U);
    } else {

    }
#line 1766
    kfree((void const   *)nbc);
  } else {

  }
#line 1768
  kfree((void const   *)new_disk_conf);
#line 1769
  lc_destroy(resync_lru);
#line 1770
  kfree((void const   *)new_plan);
  finish: 
#line 1773
  drbd_adm_finish(info, (int )retcode);
#line 1774
  return (0);
}
}
#line 1777 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int adm_detach(struct drbd_conf *mdev , int force ) 
{ 
  enum drbd_state_rv retcode ;
  int ret ;
  union drbd_state val ;
  union drbd_state mask ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;
  int tmp ;
  int __ret ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;

  {
#line 1782
  if (force != 0) {
#line 1783
    set_bit(14U, (unsigned long volatile   *)(& mdev->flags));
#line 1784
    val.i = 0U;
#line 1784
    val.ldv_40024.disk = 2U;
#line 1784
    mask.i = 0U;
#line 1784
    mask.ldv_40024.disk = 15U;
#line 1784
    drbd_force_state(mdev, mask, val);
#line 1785
    retcode = SS_SUCCESS;
#line 1786
    goto out;
  } else {

  }
#line 1789
  drbd_suspend_io(mdev);
#line 1790
  drbd_md_get_buffer(mdev);
#line 1791
  val___0.i = 0U;
#line 1791
  val___0.ldv_40024.disk = 2U;
#line 1791
  mask___0.i = 0U;
#line 1791
  mask___0.ldv_40024.disk = 15U;
#line 1791
  tmp = drbd_request_state(mdev, mask___0, val___0);
#line 1791
  retcode = (enum drbd_state_rv )tmp;
#line 1792
  drbd_md_put_buffer(mdev);
#line 1794
  __ret = 0;
#line 1794
  if ((unsigned int )*((unsigned char *)mdev + 749UL) == 4U) {
#line 1794
    tmp___0 = get_current();
#line 1794
    __wait.flags = 0U;
#line 1794
    __wait.private = (void *)tmp___0;
#line 1794
    __wait.func = & autoremove_wake_function;
#line 1794
    __wait.task_list.next = & __wait.task_list;
#line 1794
    __wait.task_list.prev = & __wait.task_list;
    ldv_53483: 
#line 1794
    prepare_to_wait(& mdev->misc_wait, & __wait, 1);
#line 1794
    if ((unsigned int )*((unsigned char *)mdev + 749UL) != 4U) {
#line 1794
      goto ldv_53481;
    } else {

    }
#line 1794
    tmp___1 = get_current();
#line 1794
    tmp___2 = signal_pending(tmp___1);
#line 1794
    if (tmp___2 == 0) {
#line 1794
      schedule();
#line 1794
      goto ldv_53482;
    } else {

    }
#line 1794
    __ret = -512;
#line 1794
    goto ldv_53481;
    ldv_53482: ;
#line 1794
    goto ldv_53483;
    ldv_53481: 
#line 1794
    finish_wait(& mdev->misc_wait, & __wait);
  } else {

  }
#line 1794
  ret = __ret;
#line 1796
  drbd_resume_io(mdev);
#line 1797
  if ((int )retcode == -11) {
#line 1798
    retcode = SS_NOTHING_TO_DO;
  } else {

  }
#line 1799
  if (ret != 0) {
#line 1800
    retcode = 129;
  } else {

  }
  out: ;
#line 1802
  return ((int )retcode);
}
}
#line 1810 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_detach(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  struct detach_parms parms ;
  int err ;
  int tmp ;
  char const   *tmp___0 ;
  int tmp___1 ;

  {
#line 1813
  parms.force_detach = (char)0;
#line 1816
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 1816
  retcode = (enum drbd_ret_code )tmp;
#line 1817
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 1818
    return ((int )retcode);
  } else {

  }
#line 1819
  if ((unsigned int )retcode != 101U) {
#line 1820
    goto out;
  } else {

  }
#line 1822
  if ((unsigned long )*(info->attrs + 13UL) != (unsigned long )((struct nlattr *)0)) {
#line 1823
    err = detach_parms_from_attrs(& parms, info);
#line 1824
    if (err != 0) {
#line 1825
      retcode = ERR_MANDATORY_TAG;
#line 1826
      tmp___0 = from_attrs_err_to_txt(err);
#line 1826
      drbd_msg_put_info(tmp___0);
#line 1827
      goto out;
    } else {

    }
  } else {

  }
#line 1831
  tmp___1 = adm_detach(adm_ctx.mdev, (int )parms.force_detach);
#line 1831
  retcode = (enum drbd_ret_code )tmp___1;
  out: 
#line 1833
  drbd_adm_finish(info, (int )retcode);
#line 1834
  return (0);
}
}
#line 1837 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static bool conn_resync_running(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  bool rv ;
  int vnr ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 1840
  rv = 0;
#line 1843
  rcu_read_lock___6();
#line 1844
  vnr = 0;
#line 1844
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1844
  mdev = (struct drbd_conf *)tmp;
#line 1844
  goto ldv_53501;
  ldv_53500: ;
#line 1845
  if ((((unsigned int )*((unsigned short *)mdev + 374UL) == 256U || (unsigned int )*((unsigned short *)mdev + 374UL) == 272U) || (unsigned int )*((unsigned short *)mdev + 374UL) == 320U) || (unsigned int )*((unsigned short *)mdev + 374UL) == 336U) {
#line 1849
    rv = 1;
#line 1850
    goto ldv_53499;
  } else {

  }
#line 1844
  vnr = vnr + 1;
#line 1844
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 1844
  mdev = (struct drbd_conf *)tmp___0;
  ldv_53501: ;
#line 1844
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1845
    goto ldv_53500;
  } else {

  }
  ldv_53499: 
#line 1853
  rcu_read_unlock___6();
#line 1855
  return (rv);
}
}
#line 1858 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static bool conn_ov_running(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  bool rv ;
  int vnr ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 1861
  rv = 0;
#line 1864
  rcu_read_lock___6();
#line 1865
  vnr = 0;
#line 1865
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1865
  mdev = (struct drbd_conf *)tmp;
#line 1865
  goto ldv_53510;
  ldv_53509: ;
#line 1866
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 288U || (unsigned int )*((unsigned short *)mdev + 374UL) == 304U) {
#line 1868
    rv = 1;
#line 1869
    goto ldv_53508;
  } else {

  }
#line 1865
  vnr = vnr + 1;
#line 1865
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 1865
  mdev = (struct drbd_conf *)tmp___0;
  ldv_53510: ;
#line 1865
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1866
    goto ldv_53509;
  } else {

  }
  ldv_53508: 
#line 1872
  rcu_read_unlock___6();
#line 1874
  return (rv);
}
}
#line 1878 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static enum drbd_ret_code _check_net_options(struct drbd_tconn *tconn , struct net_conf *old_conf ,
                                             struct net_conf *new_conf ) 
{ 
  struct drbd_conf *mdev ;
  int i ;
  int tmp ;
  enum drbd_role tmp___0 ;
  enum drbd_role tmp___1 ;
  void *tmp___2 ;
  enum drbd_fencing_p fp ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  void *tmp___6 ;

  {
#line 1883
  if (((unsigned long )old_conf != (unsigned long )((struct net_conf *)0) && (unsigned int )tconn->cstate == 9U) && tconn->agreed_pro_version <= 99) {
#line 1884
    if (new_conf->wire_protocol != old_conf->wire_protocol) {
#line 1885
      return (ERR_NEED_APV_100);
    } else {

    }
#line 1887
    if ((int )((signed char )new_conf->two_primaries) != (int )((signed char )old_conf->two_primaries)) {
#line 1888
      return (ERR_NEED_APV_100);
    } else {

    }
#line 1890
    tmp = strcmp((char const   *)(& new_conf->integrity_alg), (char const   *)(& old_conf->integrity_alg));
#line 1890
    if (tmp != 0) {
#line 1891
      return (ERR_NEED_APV_100);
    } else {

    }
  } else {

  }
#line 1894
  if ((int )((signed char )new_conf->two_primaries) == 0) {
#line 1894
    tmp___0 = conn_highest_role(tconn);
#line 1894
    if ((unsigned int )tmp___0 == 1U) {
#line 1894
      tmp___1 = conn_highest_peer(tconn);
#line 1894
      if ((unsigned int )tmp___1 == 1U) {
#line 1897
        return (ERR_NEED_ALLOW_TWO_PRI);
      } else {

      }
    } else {

    }
  } else {

  }
#line 1899
  if ((int )((signed char )new_conf->two_primaries) != 0 && new_conf->wire_protocol != 3U) {
#line 1901
    return (ERR_NOT_PROTO_C);
  } else {

  }
#line 1903
  i = 0;
#line 1903
  tmp___2 = idr_get_next(& tconn->volumes, & i);
#line 1903
  mdev = (struct drbd_conf *)tmp___2;
#line 1903
  goto ldv_53523;
  ldv_53522: 
#line 1904
  tmp___5 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1904
  if (tmp___5 != 0) {
#line 1905
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1905
    tmp___3 = debug_lockdep_rcu_enabled();
#line 1905
    if (tmp___3 != 0 && ! __warned) {
#line 1905
      tmp___4 = rcu_read_lock_held();
#line 1905
      if (tmp___4 == 0 && 1) {
#line 1905
        __warned = 1;
#line 1905
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                               1905, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 1905
    fp = (enum drbd_fencing_p )_________p1->fencing;
#line 1906
    put_ldev(mdev);
#line 1907
    if (new_conf->wire_protocol == 1U && (int )fp == 2) {
#line 1908
      return (ERR_STONITH_AND_PROT_A);
    } else {

    }
  } else {

  }
#line 1910
  if ((unsigned int )*((unsigned char *)mdev + 748UL) == 1U && (int )((signed char )new_conf->discard_my_data) != 0) {
#line 1911
    return (ERR_DISCARD_IMPOSSIBLE);
  } else {

  }
#line 1903
  i = i + 1;
#line 1903
  tmp___6 = idr_get_next(& tconn->volumes, & i);
#line 1903
  mdev = (struct drbd_conf *)tmp___6;
  ldv_53523: ;
#line 1903
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1904
    goto ldv_53522;
  } else {

  }

#line 1914
  if (new_conf->on_congestion != 0U && new_conf->wire_protocol != 1U) {
#line 1915
    return (ERR_CONG_NOT_PROTO_A);
  } else {

  }
#line 1917
  return (NO_ERROR);
}
}
#line 1921 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static enum drbd_ret_code check_net_options(struct drbd_tconn *tconn , struct net_conf *new_conf ) 
{ 
  enum drbd_ret_code rv ;
  struct drbd_conf *mdev ;
  int i ;
  struct net_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  void *tmp___1 ;
  int tmp___2 ;
  void *tmp___3 ;

  {
#line 1927
  rcu_read_lock___6();
#line 1928
  _________p1 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 1928
  tmp = debug_lockdep_rcu_enabled();
#line 1928
  if (tmp != 0 && ! __warned) {
#line 1928
    tmp___0 = rcu_read_lock_held();
#line 1928
    if (tmp___0 == 0 && 1) {
#line 1928
      __warned = 1;
#line 1928
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                             1928, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 1928
  rv = _check_net_options(tconn, _________p1, new_conf);
#line 1929
  rcu_read_unlock___6();
#line 1932
  i = 0;
#line 1932
  tmp___1 = idr_get_next(& tconn->volumes, & i);
#line 1932
  mdev = (struct drbd_conf *)tmp___1;
#line 1932
  goto ldv_53536;
  ldv_53535: ;
#line 1933
  if ((unsigned long )mdev->bitmap == (unsigned long )((struct drbd_bitmap *)0)) {
#line 1934
    tmp___2 = drbd_bm_init(mdev);
#line 1934
    if (tmp___2 != 0) {
#line 1935
      return (ERR_NOMEM);
    } else {

    }
  } else {

  }
#line 1932
  i = i + 1;
#line 1932
  tmp___3 = idr_get_next(& tconn->volumes, & i);
#line 1932
  mdev = (struct drbd_conf *)tmp___3;
  ldv_53536: ;
#line 1932
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1933
    goto ldv_53535;
  } else {

  }

#line 1939
  return (rv);
}
}
#line 1950 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int alloc_hash(struct crypto_hash **tfm , char *tfm_name , int err_alg ) 
{ 
  long tmp ;

  {
#line 1952
  if ((int )((signed char )*tfm_name) == 0) {
#line 1953
    return (101);
  } else {

  }
#line 1955
  *tfm = crypto_alloc_hash((char const   *)tfm_name, 0U, 128U);
#line 1956
  tmp = IS_ERR((void const   *)*tfm);
#line 1956
  if (tmp != 0L) {
#line 1957
    *tfm = 0;
#line 1958
    return (err_alg);
  } else {

  }
#line 1961
  return (101);
}
}
#line 1965 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static enum drbd_ret_code alloc_crypto(struct crypto *crypto , struct net_conf *new_conf ) 
{ 
  char hmac_name[64U] ;
  enum drbd_ret_code rv ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 1970
  tmp = alloc_hash(& crypto->csums_tfm, (char *)(& new_conf->csums_alg), 144);
#line 1970
  rv = (enum drbd_ret_code )tmp;
#line 1972
  if ((unsigned int )rv != 101U) {
#line 1973
    return (rv);
  } else {

  }
#line 1974
  tmp___0 = alloc_hash(& crypto->verify_tfm, (char *)(& new_conf->verify_alg), 146);
#line 1974
  rv = (enum drbd_ret_code )tmp___0;
#line 1976
  if ((unsigned int )rv != 101U) {
#line 1977
    return (rv);
  } else {

  }
#line 1978
  tmp___1 = alloc_hash(& crypto->integrity_tfm, (char *)(& new_conf->integrity_alg),
                       141);
#line 1978
  rv = (enum drbd_ret_code )tmp___1;
#line 1980
  if ((unsigned int )rv != 101U) {
#line 1981
    return (rv);
  } else {

  }
#line 1982
  if ((int )((signed char )new_conf->cram_hmac_alg[0]) != 0) {
#line 1983
    snprintf((char *)(& hmac_name), 64UL, "hmac(%s)", (char *)(& new_conf->cram_hmac_alg));
#line 1986
    tmp___2 = alloc_hash(& crypto->cram_hmac_tfm, (char *)(& hmac_name), 120);
#line 1986
    rv = (enum drbd_ret_code )tmp___2;
  } else {

  }
#line 1990
  return (rv);
}
}
#line 1993 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static void free_crypto(struct crypto *crypto ) 
{ 


  {
#line 1995
  crypto_free_hash(crypto->cram_hmac_tfm);
#line 1996
  crypto_free_hash(crypto->integrity_tfm);
#line 1997
  crypto_free_hash(crypto->csums_tfm);
#line 1998
  crypto_free_hash(crypto->verify_tfm);
#line 1999
  return;
}
}
#line 2001 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_net_opts(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  struct drbd_tconn *tconn ;
  struct net_conf *old_conf ;
  struct net_conf *new_conf ;
  int err ;
  int ovr ;
  int rsr ;
  struct crypto crypto ;
  int tmp ;
  void *tmp___0 ;
  bool tmp___1 ;
  char const   *tmp___2 ;
  bool tmp___3 ;
  int tmp___4 ;
  bool tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  struct drbd_conf *tmp___8 ;

  {
#line 2005
  new_conf = 0;
#line 2009
  crypto.verify_tfm = 0;
#line 2009
  crypto.csums_tfm = 0;
#line 2009
  crypto.cram_hmac_tfm = 0;
#line 2009
  crypto.integrity_tfm = 0;
#line 2011
  tmp = drbd_adm_prepare(skb, info, 4U);
#line 2011
  retcode = (enum drbd_ret_code )tmp;
#line 2012
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2013
    return ((int )retcode);
  } else {

  }
#line 2014
  if ((unsigned int )retcode != 101U) {
#line 2015
    goto out;
  } else {

  }
#line 2017
  tconn = adm_ctx.tconn;
#line 2019
  tmp___0 = kzalloc(420UL, 208U);
#line 2019
  new_conf = (struct net_conf *)tmp___0;
#line 2020
  if ((unsigned long )new_conf == (unsigned long )((struct net_conf *)0)) {
#line 2021
    retcode = ERR_NOMEM;
#line 2022
    goto out;
  } else {

  }
#line 2025
  conn_reconfig_start(tconn);
#line 2027
  ldv_mutex_lock_297(& tconn->data.mutex);
#line 2028
  ldv_mutex_lock_298(& tconn->conf_update);
#line 2029
  old_conf = tconn->net_conf;
#line 2031
  if ((unsigned long )old_conf == (unsigned long )((struct net_conf *)0)) {
#line 2032
    drbd_msg_put_info("net conf missing, try connect");
#line 2033
    retcode = ERR_INVALID_REQUEST;
#line 2034
    goto fail;
  } else {

  }
#line 2037
  *new_conf = *old_conf;
#line 2038
  tmp___1 = should_set_defaults(info);
#line 2038
  if ((int )tmp___1) {
#line 2039
    set_net_conf_defaults(new_conf);
  } else {

  }
#line 2041
  err = net_conf_from_attrs_for_change(new_conf, info);
#line 2042
  if (err != 0 && err != -42) {
#line 2043
    retcode = ERR_MANDATORY_TAG;
#line 2044
    tmp___2 = from_attrs_err_to_txt(err);
#line 2044
    drbd_msg_put_info(tmp___2);
#line 2045
    goto fail;
  } else {

  }
#line 2048
  retcode = check_net_options(tconn, new_conf);
#line 2049
  if ((unsigned int )retcode != 101U) {
#line 2050
    goto fail;
  } else {

  }
#line 2053
  tmp___3 = conn_resync_running(tconn);
#line 2053
  rsr = (int )tmp___3;
#line 2054
  if (rsr != 0) {
#line 2054
    tmp___4 = strcmp((char const   *)(& new_conf->csums_alg), (char const   *)(& old_conf->csums_alg));
#line 2054
    if (tmp___4 != 0) {
#line 2055
      retcode = ERR_CSUMS_RESYNC_RUNNING;
#line 2056
      goto fail;
    } else {

    }
  } else {

  }
#line 2060
  tmp___5 = conn_ov_running(tconn);
#line 2060
  ovr = (int )tmp___5;
#line 2061
  if (ovr != 0) {
#line 2061
    tmp___6 = strcmp((char const   *)(& new_conf->verify_alg), (char const   *)(& old_conf->verify_alg));
#line 2061
    if (tmp___6 != 0) {
#line 2062
      retcode = ERR_VERIFY_RUNNING;
#line 2063
      goto fail;
    } else {

    }
  } else {

  }
#line 2066
  retcode = alloc_crypto(& crypto, new_conf);
#line 2067
  if ((unsigned int )retcode != 101U) {
#line 2068
    goto fail;
  } else {

  }
#line 2070
  __asm__  volatile   ("": : : "memory");
#line 2070
  tconn->net_conf = new_conf;
#line 2072
  if (rsr == 0) {
#line 2073
    crypto_free_hash(tconn->csums_tfm);
#line 2074
    tconn->csums_tfm = crypto.csums_tfm;
#line 2075
    crypto.csums_tfm = 0;
  } else {

  }
#line 2077
  if (ovr == 0) {
#line 2078
    crypto_free_hash(tconn->verify_tfm);
#line 2079
    tconn->verify_tfm = crypto.verify_tfm;
#line 2080
    crypto.verify_tfm = 0;
  } else {

  }
#line 2083
  crypto_free_hash(tconn->integrity_tfm);
#line 2084
  tconn->integrity_tfm = crypto.integrity_tfm;
#line 2085
  if ((unsigned int )tconn->cstate > 8U && tconn->agreed_pro_version > 99) {
#line 2087
    __drbd_send_protocol(tconn, P_PROTOCOL_UPDATE);
  } else {

  }
#line 2089
  crypto_free_hash(tconn->cram_hmac_tfm);
#line 2090
  tconn->cram_hmac_tfm = crypto.cram_hmac_tfm;
#line 2092
  ldv_mutex_unlock_299(& tconn->conf_update);
#line 2093
  ldv_mutex_unlock_300(& tconn->data.mutex);
#line 2094
  synchronize_rcu();
#line 2095
  kfree((void const   *)old_conf);
#line 2097
  if ((unsigned int )tconn->cstate > 8U) {
#line 2098
    tmp___7 = conn_lowest_minor(tconn);
#line 2098
    tmp___8 = minor_to_mdev((unsigned int )tmp___7);
#line 2098
    drbd_send_sync_param(tmp___8);
  } else {

  }
#line 2100
  goto done;
  fail: 
#line 2103
  ldv_mutex_unlock_301(& tconn->conf_update);
#line 2104
  ldv_mutex_unlock_302(& tconn->data.mutex);
#line 2105
  free_crypto(& crypto);
#line 2106
  kfree((void const   *)new_conf);
  done: 
#line 2108
  conn_reconfig_done(tconn);
  out: 
#line 2110
  drbd_adm_finish(info, (int )retcode);
#line 2111
  return (0);
}
}
#line 2114 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_connect(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct drbd_conf *mdev ;
  struct net_conf *old_conf ;
  struct net_conf *new_conf ;
  struct crypto crypto ;
  struct drbd_tconn *tconn ;
  enum drbd_ret_code retcode ;
  int i ;
  int err ;
  int tmp ;
  struct list_head  const  *__mptr ;
  int tmp___0 ;
  void *tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  void *tmp___4 ;
  int tmp___5 ;
  struct list_head  const  *__mptr___0 ;
  void *tmp___6 ;
  char const   *tmp___7 ;
  size_t __len ;
  void *__ret ;
  void *tmp___9 ;
  size_t __len___0 ;
  void *__ret___0 ;
  void *tmp___11 ;
  void *tmp___12 ;
  void *tmp___13 ;
  union drbd_state val ;
  union drbd_state mask ;
  enum drbd_state_rv tmp___14 ;

  {
#line 2117
  new_conf = 0;
#line 2118
  crypto.verify_tfm = 0;
#line 2118
  crypto.csums_tfm = 0;
#line 2118
  crypto.cram_hmac_tfm = 0;
#line 2118
  crypto.integrity_tfm = 0;
#line 2124
  tmp = drbd_adm_prepare(skb, info, 2U);
#line 2124
  retcode = (enum drbd_ret_code )tmp;
#line 2126
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2127
    return ((int )retcode);
  } else {

  }
#line 2128
  if ((unsigned int )retcode != 101U) {
#line 2129
    goto out;
  } else {

  }
#line 2130
  if ((unsigned long )adm_ctx.my_addr == (unsigned long )((struct nlattr *)0) || (unsigned long )adm_ctx.peer_addr == (unsigned long )((struct nlattr *)0)) {
#line 2131
    drbd_msg_put_info("connection endpoint(s) missing");
#line 2132
    retcode = ERR_INVALID_REQUEST;
#line 2133
    goto out;
  } else {

  }
#line 2139
  __mptr = (struct list_head  const  *)drbd_tconns.next;
#line 2139
  tconn = (struct drbd_tconn *)__mptr + 0xfffffffffffffff8UL;
#line 2139
  goto ldv_53590;
  ldv_53589: 
#line 2140
  tmp___0 = nla_len((struct nlattr  const  *)adm_ctx.my_addr);
#line 2140
  if (tmp___0 == tconn->my_addr_len) {
#line 2140
    tmp___1 = nla_data((struct nlattr  const  *)adm_ctx.my_addr);
#line 2140
    tmp___2 = memcmp((void const   *)tmp___1, (void const   *)(& tconn->my_addr),
                     (size_t )tconn->my_addr_len);
#line 2140
    if (tmp___2 == 0) {
#line 2142
      retcode = ERR_LOCAL_ADDR;
#line 2143
      goto out;
    } else {

    }
  } else {

  }
#line 2146
  tmp___3 = nla_len((struct nlattr  const  *)adm_ctx.peer_addr);
#line 2146
  if (tmp___3 == tconn->peer_addr_len) {
#line 2146
    tmp___4 = nla_data((struct nlattr  const  *)adm_ctx.peer_addr);
#line 2146
    tmp___5 = memcmp((void const   *)tmp___4, (void const   *)(& tconn->peer_addr),
                     (size_t )tconn->peer_addr_len);
#line 2146
    if (tmp___5 == 0) {
#line 2148
      retcode = ERR_PEER_ADDR;
#line 2149
      goto out;
    } else {

    }
  } else {

  }
#line 2139
  __mptr___0 = (struct list_head  const  *)tconn->all_tconn.next;
#line 2139
  tconn = (struct drbd_tconn *)__mptr___0 + 0xfffffffffffffff8UL;
  ldv_53590: ;
#line 2139
  if ((unsigned long )(& tconn->all_tconn) != (unsigned long )(& drbd_tconns)) {
#line 2140
    goto ldv_53589;
  } else {

  }
#line 2153
  tconn = adm_ctx.tconn;
#line 2154
  conn_reconfig_start(tconn);
#line 2156
  if ((unsigned int )tconn->cstate != 0U) {
#line 2157
    retcode = ERR_NET_CONFIGURED;
#line 2158
    goto fail;
  } else {

  }
#line 2162
  tmp___6 = kzalloc(420UL, 208U);
#line 2162
  new_conf = (struct net_conf *)tmp___6;
#line 2163
  if ((unsigned long )new_conf == (unsigned long )((struct net_conf *)0)) {
#line 2164
    retcode = ERR_NOMEM;
#line 2165
    goto fail;
  } else {

  }
#line 2168
  set_net_conf_defaults(new_conf);
#line 2170
  err = net_conf_from_attrs(new_conf, info);
#line 2171
  if (err != 0 && err != -42) {
#line 2172
    retcode = ERR_MANDATORY_TAG;
#line 2173
    tmp___7 = from_attrs_err_to_txt(err);
#line 2173
    drbd_msg_put_info(tmp___7);
#line 2174
    goto fail;
  } else {

  }
#line 2177
  retcode = check_net_options(tconn, new_conf);
#line 2178
  if ((unsigned int )retcode != 101U) {
#line 2179
    goto fail;
  } else {

  }
#line 2181
  retcode = alloc_crypto(& crypto, new_conf);
#line 2182
  if ((unsigned int )retcode != 101U) {
#line 2183
    goto fail;
  } else {

  }
#line 2185
  *((char *)(& new_conf->shared_secret) + 63UL) = 0;
#line 2187
  conn_flush_workqueue(tconn);
#line 2189
  ldv_mutex_lock_303(& tconn->conf_update);
#line 2190
  old_conf = tconn->net_conf;
#line 2191
  if ((unsigned long )old_conf != (unsigned long )((struct net_conf *)0)) {
#line 2192
    retcode = ERR_NET_CONFIGURED;
#line 2193
    ldv_mutex_unlock_304(& tconn->conf_update);
#line 2194
    goto fail;
  } else {

  }
#line 2196
  __asm__  volatile   ("": : : "memory");
#line 2196
  tconn->net_conf = new_conf;
#line 2198
  conn_free_crypto(tconn);
#line 2199
  tconn->cram_hmac_tfm = crypto.cram_hmac_tfm;
#line 2200
  tconn->integrity_tfm = crypto.integrity_tfm;
#line 2201
  tconn->csums_tfm = crypto.csums_tfm;
#line 2202
  tconn->verify_tfm = crypto.verify_tfm;
#line 2204
  tconn->my_addr_len = nla_len((struct nlattr  const  *)adm_ctx.my_addr);
#line 2205
  __len = (size_t )tconn->my_addr_len;
#line 2205
  tmp___9 = nla_data((struct nlattr  const  *)adm_ctx.my_addr);
#line 2205
  __ret = __builtin_memcpy((void *)(& tconn->my_addr), (void const   *)tmp___9, __len);
#line 2206
  tconn->peer_addr_len = nla_len((struct nlattr  const  *)adm_ctx.peer_addr);
#line 2207
  __len___0 = (size_t )tconn->peer_addr_len;
#line 2207
  tmp___11 = nla_data((struct nlattr  const  *)adm_ctx.peer_addr);
#line 2207
  __ret___0 = __builtin_memcpy((void *)(& tconn->peer_addr), (void const   *)tmp___11,
                               __len___0);
#line 2209
  ldv_mutex_unlock_305(& tconn->conf_update);
#line 2211
  rcu_read_lock___6();
#line 2212
  i = 0;
#line 2212
  tmp___12 = idr_get_next(& tconn->volumes, & i);
#line 2212
  mdev = (struct drbd_conf *)tmp___12;
#line 2212
  goto ldv_53600;
  ldv_53599: 
#line 2213
  mdev->send_cnt = 0U;
#line 2214
  mdev->recv_cnt = 0U;
#line 2212
  i = i + 1;
#line 2212
  tmp___13 = idr_get_next(& tconn->volumes, & i);
#line 2212
  mdev = (struct drbd_conf *)tmp___13;
  ldv_53600: ;
#line 2212
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 2213
    goto ldv_53599;
  } else {

  }
#line 2216
  rcu_read_unlock___6();
#line 2218
  val.i = 0U;
#line 2218
  val.ldv_40024.conn = 2U;
#line 2218
  mask.i = 0U;
#line 2218
  mask.ldv_40024.conn = 31U;
#line 2218
  tmp___14 = conn_request_state(tconn, mask, val, CS_VERBOSE);
#line 2218
  retcode = (enum drbd_ret_code )tmp___14;
#line 2220
  conn_reconfig_done(tconn);
#line 2221
  drbd_adm_finish(info, (int )retcode);
#line 2222
  return (0);
  fail: 
#line 2225
  free_crypto(& crypto);
#line 2226
  kfree((void const   *)new_conf);
#line 2228
  conn_reconfig_done(tconn);
  out: 
#line 2230
  drbd_adm_finish(info, (int )retcode);
#line 2231
  return (0);
}
}
#line 2234 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static enum drbd_state_rv conn_try_disconnect(struct drbd_tconn *tconn , bool force ) 
{ 
  enum drbd_state_rv rv ;
  union drbd_state val ;
  union drbd_state mask ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;
  union drbd_state val___1 ;
  union drbd_state mask___1 ;
  union drbd_state val___2 ;
  union drbd_state mask___2 ;
  enum drbd_state_rv rv2 ;
  union drbd_state val___3 ;
  union drbd_state mask___3 ;

  {
#line 2238
  val.i = 0U;
#line 2238
  val.ldv_40024.conn = 1U;
#line 2238
  mask.i = 0U;
#line 2238
  mask.ldv_40024.conn = 31U;
#line 2238
  rv = conn_request_state(tconn, mask, val, (enum chg_state_flags )force);
#line 2241
  switch ((int )rv) {
  case 2: ;
#line 2243
  goto ldv_53616;
  case -9: ;
#line 2245
  return (SS_SUCCESS);
  case -7: 
#line 2249
  val___0.i = 0U;
#line 2249
  val___0.ldv_40024.conn = 1U;
#line 2249
  val___0.ldv_40024.pdsk = 5U;
#line 2248
  mask___0.i = 0U;
#line 2248
  mask___0.ldv_40024.conn = 31U;
#line 2249
  mask___0.ldv_40024.pdsk = 15U;
#line 2249
  rv = conn_request_state(tconn, mask___0, val___0, CS_VERBOSE);
#line 2250
  goto ldv_53616;
  case -10: 
#line 2254
  val___1.i = 0U;
#line 2254
  val___1.ldv_40024.conn = 1U;
#line 2254
  val___1.ldv_40024.disk = 5U;
#line 2253
  mask___1.i = 0U;
#line 2253
  mask___1.ldv_40024.conn = 31U;
#line 2254
  mask___1.ldv_40024.disk = 15U;
#line 2254
  rv = conn_request_state(tconn, mask___1, val___1, 0);
#line 2255
  if ((int )rv == -11 || (int )rv == -16) {
#line 2256
    val___2.i = 0U;
#line 2256
    val___2.ldv_40024.conn = 1U;
#line 2256
    mask___2.i = 0U;
#line 2256
    mask___2.ldv_40024.conn = 31U;
#line 2256
    rv = conn_request_state(tconn, mask___2, val___2, CS_HARD);
  } else {

  }
#line 2259
  goto ldv_53616;
  default: ;
  }
  ldv_53616: ;
#line 2264
  if ((int )rv > 0) {
#line 2270
    drbd_thread_stop(& (adm_ctx.tconn)->receiver);
#line 2278
    val___3.i = 0U;
#line 2278
    val___3.ldv_40024.conn = 0U;
#line 2278
    mask___3.i = 0U;
#line 2278
    mask___3.ldv_40024.conn = 31U;
#line 2278
    rv2 = conn_request_state(tconn, mask___3, val___3, 3);
#line 2280
    if ((int )rv2 <= 0) {
#line 2281
      printk("\vd-con %s: unexpected rv2=%d in conn_try_disconnect()\n", tconn->name,
             (int )rv2);
    } else {

    }
  } else {

  }
#line 2285
  return (rv);
}
}
#line 2288 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_disconnect(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct disconnect_parms parms ;
  struct drbd_tconn *tconn ;
  enum drbd_state_rv rv ;
  enum drbd_ret_code retcode ;
  int err ;
  int tmp ;
  char const   *tmp___0 ;

  {
#line 2296
  tmp = drbd_adm_prepare(skb, info, 4U);
#line 2296
  retcode = (enum drbd_ret_code )tmp;
#line 2297
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2298
    return ((int )retcode);
  } else {

  }
#line 2299
  if ((unsigned int )retcode != 101U) {
#line 2300
    goto fail;
  } else {

  }
#line 2302
  tconn = adm_ctx.tconn;
#line 2303
  memset((void *)(& parms), 0, 1UL);
#line 2304
  if ((unsigned long )*(info->attrs + 12UL) != (unsigned long )((struct nlattr *)0)) {
#line 2305
    err = disconnect_parms_from_attrs(& parms, info);
#line 2306
    if (err != 0) {
#line 2307
      retcode = ERR_MANDATORY_TAG;
#line 2308
      tmp___0 = from_attrs_err_to_txt(err);
#line 2308
      drbd_msg_put_info(tmp___0);
#line 2309
      goto fail;
    } else {

    }
  } else {

  }
#line 2313
  rv = conn_try_disconnect(tconn, (int )((signed char )parms.force_disconnect) != 0);
#line 2314
  if ((int )rv <= 0) {
#line 2315
    retcode = (enum drbd_ret_code )rv;
  } else {
#line 2317
    retcode = NO_ERROR;
  }
  fail: 
#line 2319
  drbd_adm_finish(info, (int )retcode);
#line 2320
  return (0);
}
}
#line 2323 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void resync_after_online_grow(struct drbd_conf *mdev ) 
{ 
  int iass ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 2327
  _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Resync of new storage after online grow\n");
#line 2328
  if ((int )mdev->state.ldv_49522.role != (int )mdev->state.ldv_49522.peer) {
#line 2329
    iass = (unsigned int )*((unsigned char *)mdev + 748UL) == 1U;
  } else {
#line 2331
    iass = constant_test_bit(1U, (unsigned long const volatile   *)(& (mdev->tconn)->flags));
  }
#line 2333
  if (iass != 0) {
#line 2334
    drbd_start_resync(mdev, C_SYNC_SOURCE);
  } else {
#line 2336
    val.i = 0U;
#line 2336
    val.ldv_40024.conn = 15U;
#line 2336
    mask.i = 0U;
#line 2336
    mask.ldv_40024.conn = 31U;
#line 2336
    _drbd_request_state(mdev, mask, val, 10);
  }
#line 2338
  return;
}
}
#line 2339 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_resize(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct disk_conf *old_disk_conf ;
  struct disk_conf *new_disk_conf ;
  struct resize_parms rs ;
  struct drbd_conf *mdev ;
  enum drbd_ret_code retcode ;
  enum determine_dev_size dd ;
  enum dds_flags ddsf ;
  sector_t u_size ;
  int err ;
  int tmp ;
  char const   *tmp___0 ;
  int tmp___1 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___2 ;
  int tmp___3 ;
  void *tmp___4 ;
  sector_t tmp___5 ;

  {
#line 2341
  new_disk_conf = 0;
#line 2350
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 2350
  retcode = (enum drbd_ret_code )tmp;
#line 2351
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2352
    return ((int )retcode);
  } else {

  }
#line 2353
  if ((unsigned int )retcode != 101U) {
#line 2354
    goto fail;
  } else {

  }
#line 2356
  memset((void *)(& rs), 0, 16UL);
#line 2357
  if ((unsigned long )*(info->attrs + 7UL) != (unsigned long )((struct nlattr *)0)) {
#line 2358
    err = resize_parms_from_attrs(& rs, info);
#line 2359
    if (err != 0) {
#line 2360
      retcode = ERR_MANDATORY_TAG;
#line 2361
      tmp___0 = from_attrs_err_to_txt(err);
#line 2361
      drbd_msg_put_info(tmp___0);
#line 2362
      goto fail;
    } else {

    }
  } else {

  }
#line 2366
  mdev = adm_ctx.mdev;
#line 2367
  if ((int )mdev->state.ldv_49522.conn > 10) {
#line 2368
    retcode = ERR_RESIZE_RESYNC;
#line 2369
    goto fail;
  } else {

  }
#line 2372
  if ((unsigned int )*((unsigned char *)mdev + 748UL) == 2U && (unsigned int )*((unsigned char *)mdev + 748UL) == 8U) {
#line 2374
    retcode = ERR_NO_PRIMARY;
#line 2375
    goto fail;
  } else {

  }
#line 2378
  tmp___1 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 2378
  if (tmp___1 == 0) {
#line 2379
    retcode = ERR_NO_DISK;
#line 2380
    goto fail;
  } else {

  }
#line 2383
  if ((int )((signed char )rs.no_resync) != 0 && (mdev->tconn)->agreed_pro_version <= 92) {
#line 2384
    retcode = ERR_NEED_APV_93;
#line 2385
    goto fail_ldev;
  } else {

  }
#line 2388
  rcu_read_lock___6();
#line 2389
  _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 2389
  tmp___2 = debug_lockdep_rcu_enabled();
#line 2389
  if (tmp___2 != 0 && ! __warned) {
#line 2389
    tmp___3 = rcu_read_lock_held();
#line 2389
    if (tmp___3 == 0 && 1) {
#line 2389
      __warned = 1;
#line 2389
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                             2389, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2389
  u_size = (sector_t )_________p1->disk_size;
#line 2390
  rcu_read_unlock___6();
#line 2391
  if ((unsigned long )rs.resize_size != u_size) {
#line 2392
    tmp___4 = kmalloc(344UL, 208U);
#line 2392
    new_disk_conf = (struct disk_conf *)tmp___4;
#line 2393
    if ((unsigned long )new_disk_conf == (unsigned long )((struct disk_conf *)0)) {
#line 2394
      retcode = ERR_NOMEM;
#line 2395
      goto fail_ldev;
    } else {

    }
  } else {

  }
#line 2399
  tmp___5 = drbd_get_capacity((mdev->ldev)->backing_bdev);
#line 2399
  if ((mdev->ldev)->known_size != tmp___5) {
#line 2400
    (mdev->ldev)->known_size = drbd_get_capacity((mdev->ldev)->backing_bdev);
  } else {

  }
#line 2402
  if ((unsigned long )new_disk_conf != (unsigned long )((struct disk_conf *)0)) {
#line 2403
    ldv_mutex_lock_306(& (mdev->tconn)->conf_update);
#line 2404
    old_disk_conf = (mdev->ldev)->disk_conf;
#line 2405
    *new_disk_conf = *old_disk_conf;
#line 2406
    new_disk_conf->disk_size = rs.resize_size;
#line 2407
    __asm__  volatile   ("": : : "memory");
#line 2407
    (mdev->ldev)->disk_conf = new_disk_conf;
#line 2408
    ldv_mutex_unlock_307(& (mdev->tconn)->conf_update);
#line 2409
    synchronize_rcu();
#line 2410
    kfree((void const   *)old_disk_conf);
  } else {

  }
#line 2413
  ddsf = (enum dds_flags )(((int )((signed char )rs.resize_force) != 0) | ((int )((signed char )rs.no_resync) != 0 ? 2 : 0));
#line 2414
  dd = drbd_determine_dev_size(mdev, ddsf);
#line 2415
  drbd_md_sync(mdev);
#line 2416
  put_ldev(mdev);
#line 2417
  if ((int )dd == -1) {
#line 2418
    retcode = ERR_NOMEM_BITMAP;
#line 2419
    goto fail;
  } else {

  }
#line 2422
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 160U) {
#line 2423
    if ((int )dd == 2) {
#line 2424
      set_bit(16U, (unsigned long volatile   *)(& mdev->flags));
    } else {

    }
#line 2426
    drbd_send_uuids(mdev);
#line 2427
    drbd_send_sizes(mdev, 1, ddsf);
  } else {

  }
  fail: 
#line 2431
  drbd_adm_finish(info, (int )retcode);
#line 2432
  return (0);
  fail_ldev: 
#line 2435
  put_ldev(mdev);
#line 2436
  goto fail;
}
}
#line 2439 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_resource_opts(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  struct drbd_tconn *tconn ;
  struct res_opts res_opts ;
  int err ;
  int tmp ;
  bool tmp___0 ;
  char const   *tmp___1 ;

  {
#line 2446
  tmp = drbd_adm_prepare(skb, info, 2U);
#line 2446
  retcode = (enum drbd_ret_code )tmp;
#line 2447
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2448
    return ((int )retcode);
  } else {

  }
#line 2449
  if ((unsigned int )retcode != 101U) {
#line 2450
    goto fail;
  } else {

  }
#line 2451
  tconn = adm_ctx.tconn;
#line 2453
  res_opts = tconn->res_opts;
#line 2454
  tmp___0 = should_set_defaults(info);
#line 2454
  if ((int )tmp___0) {
#line 2455
    set_res_opts_defaults(& res_opts);
  } else {

  }
#line 2457
  err = res_opts_from_attrs(& res_opts, info);
#line 2458
  if (err != 0 && err != -42) {
#line 2459
    retcode = ERR_MANDATORY_TAG;
#line 2460
    tmp___1 = from_attrs_err_to_txt(err);
#line 2460
    drbd_msg_put_info(tmp___1);
#line 2461
    goto fail;
  } else {

  }
#line 2464
  err = set_resource_options(tconn, & res_opts);
#line 2465
  if (err != 0) {
#line 2466
    retcode = ERR_INVALID_REQUEST;
#line 2467
    if (err == -12) {
#line 2468
      retcode = ERR_NOMEM;
    } else {

    }
  } else {

  }
  fail: 
#line 2472
  drbd_adm_finish(info, (int )retcode);
#line 2473
  return (0);
}
}
#line 2476 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_invalidate(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct drbd_conf *mdev ;
  int retcode ;
  int tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;
  union drbd_state val ;
  union drbd_state mask ;
  enum drbd_state_rv tmp___2 ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;
  union drbd_state __ns ;
  enum drbd_state_rv tmp___3 ;
  union drbd_state val___1 ;
  union drbd_state mask___1 ;

  {
#line 2481
  retcode = drbd_adm_prepare(skb, info, 1U);
#line 2482
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2483
    return (retcode);
  } else {

  }
#line 2484
  if (retcode != 101) {
#line 2485
    goto out;
  } else {

  }
#line 2487
  mdev = adm_ctx.mdev;
#line 2492
  drbd_suspend_io(mdev);
#line 2493
  tmp = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2493
  if (tmp == 0) {
#line 2493
    goto ldv_53690;
  } else {

  }
#line 2493
  tmp___0 = get_current();
#line 2493
  __wait.flags = 0U;
#line 2493
  __wait.private = (void *)tmp___0;
#line 2493
  __wait.func = & autoremove_wake_function;
#line 2493
  __wait.task_list.next = & __wait.task_list;
#line 2493
  __wait.task_list.prev = & __wait.task_list;
  ldv_53693: 
#line 2493
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 2493
  tmp___1 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2493
  if (tmp___1 == 0) {
#line 2493
    goto ldv_53692;
  } else {

  }
#line 2493
  schedule();
#line 2493
  goto ldv_53693;
  ldv_53692: 
#line 2493
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_53690: 
#line 2494
  drbd_flush_workqueue(mdev);
#line 2496
  val.i = 0U;
#line 2496
  val.ldv_40024.conn = 12U;
#line 2496
  mask.i = 0U;
#line 2496
  mask.ldv_40024.conn = 31U;
#line 2496
  tmp___2 = _drbd_request_state(mdev, mask, val, CS_ORDERED);
#line 2496
  retcode = (int )tmp___2;
#line 2498
  if (retcode <= 0 && retcode != -15) {
#line 2499
    val___0.i = 0U;
#line 2499
    val___0.ldv_40024.conn = 12U;
#line 2499
    mask___0.i = 0U;
#line 2499
    mask___0.ldv_40024.conn = 31U;
#line 2499
    retcode = drbd_request_state(mdev, mask___0, val___0);
  } else {

  }
#line 2501
  goto ldv_53710;
  ldv_53709: 
#line 2502
  spin_lock_irq(& (mdev->tconn)->req_lock);
#line 2503
  if ((int )mdev->state.ldv_49522.conn <= 9) {
#line 2504
    __ns = drbd_read_state(mdev);
#line 2504
    __ns.ldv_40024.disk = 4U;
#line 2504
    tmp___3 = _drbd_set_state(mdev, __ns, CS_VERBOSE, 0);
#line 2504
    retcode = (int )tmp___3;
  } else {

  }
#line 2505
  spin_unlock_irq(& (mdev->tconn)->req_lock);
#line 2507
  if (retcode != -15) {
#line 2508
    goto ldv_53704;
  } else {

  }
#line 2510
  val___1.i = 0U;
#line 2510
  val___1.ldv_40024.conn = 12U;
#line 2510
  mask___1.i = 0U;
#line 2510
  mask___1.ldv_40024.conn = 31U;
#line 2510
  retcode = drbd_request_state(mdev, mask___1, val___1);
  ldv_53710: ;
#line 2501
  if (retcode == -15) {
#line 2502
    goto ldv_53709;
  } else {

  }
  ldv_53704: 
#line 2512
  drbd_resume_io(mdev);
  out: 
#line 2515
  drbd_adm_finish(info, retcode);
#line 2516
  return (0);
}
}
#line 2519 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int drbd_adm_simple_request_state(struct sk_buff *skb , struct genl_info *info ,
                                         union drbd_state mask , union drbd_state val ) 
{ 
  enum drbd_ret_code retcode ;
  int tmp ;
  int tmp___0 ;

  {
#line 2524
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 2524
  retcode = (enum drbd_ret_code )tmp;
#line 2525
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2526
    return ((int )retcode);
  } else {

  }
#line 2527
  if ((unsigned int )retcode != 101U) {
#line 2528
    goto out;
  } else {

  }
#line 2530
  tmp___0 = drbd_request_state(adm_ctx.mdev, mask, val);
#line 2530
  retcode = (enum drbd_ret_code )tmp___0;
  out: 
#line 2532
  drbd_adm_finish(info, (int )retcode);
#line 2533
  return (0);
}
}
#line 2536 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static int drbd_bmio_set_susp_al(struct drbd_conf *mdev ) 
{ 
  int rv ;

  {
#line 2540
  rv = drbd_bmio_set_n_write(mdev);
#line 2541
  drbd_suspend_al(mdev);
#line 2542
  return (rv);
}
}
#line 2545 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_invalidate_peer(struct sk_buff *skb , struct genl_info *info ) 
{ 
  int retcode ;
  struct drbd_conf *mdev ;
  int tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  int tmp___1 ;
  union drbd_state val ;
  union drbd_state mask ;
  enum drbd_state_rv tmp___2 ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;
  int tmp___3 ;
  union drbd_state val___1 ;
  union drbd_state mask___1 ;

  {
#line 2550
  retcode = drbd_adm_prepare(skb, info, 1U);
#line 2551
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2552
    return (retcode);
  } else {

  }
#line 2553
  if (retcode != 101) {
#line 2554
    goto out;
  } else {

  }
#line 2556
  mdev = adm_ctx.mdev;
#line 2561
  drbd_suspend_io(mdev);
#line 2562
  tmp = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2562
  if (tmp == 0) {
#line 2562
    goto ldv_53730;
  } else {

  }
#line 2562
  tmp___0 = get_current();
#line 2562
  __wait.flags = 0U;
#line 2562
  __wait.private = (void *)tmp___0;
#line 2562
  __wait.func = & autoremove_wake_function;
#line 2562
  __wait.task_list.next = & __wait.task_list;
#line 2562
  __wait.task_list.prev = & __wait.task_list;
  ldv_53733: 
#line 2562
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 2562
  tmp___1 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 2562
  if (tmp___1 == 0) {
#line 2562
    goto ldv_53732;
  } else {

  }
#line 2562
  schedule();
#line 2562
  goto ldv_53733;
  ldv_53732: 
#line 2562
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_53730: 
#line 2563
  drbd_flush_workqueue(mdev);
#line 2565
  val.i = 0U;
#line 2565
  val.ldv_40024.conn = 11U;
#line 2565
  mask.i = 0U;
#line 2565
  mask.ldv_40024.conn = 31U;
#line 2565
  tmp___2 = _drbd_request_state(mdev, mask, val, CS_ORDERED);
#line 2565
  retcode = (int )tmp___2;
#line 2566
  if (retcode <= 0) {
#line 2567
    if (retcode == -15 && (unsigned int )*((unsigned char *)mdev + 748UL) == 1U) {
#line 2570
      val___0.i = 0U;
#line 2570
      val___0.ldv_40024.pdsk = 4U;
#line 2570
      mask___0.i = 0U;
#line 2570
      mask___0.ldv_40024.pdsk = 15U;
#line 2570
      retcode = drbd_request_state(mdev, mask___0, val___0);
#line 2571
      if (retcode > 0) {
#line 2572
        tmp___3 = drbd_bitmap_io(mdev, & drbd_bmio_set_susp_al, (char *)"set_n_write from invalidate_peer",
                                 BM_LOCKED_SET_ALLOWED);
#line 2572
        if (tmp___3 != 0) {
#line 2575
          retcode = 118;
        } else {

        }
      } else {

      }
    } else {
#line 2578
      val___1.i = 0U;
#line 2578
      val___1.ldv_40024.conn = 11U;
#line 2578
      mask___1.i = 0U;
#line 2578
      mask___1.ldv_40024.conn = 31U;
#line 2578
      retcode = drbd_request_state(mdev, mask___1, val___1);
    }
  } else {

  }
#line 2580
  drbd_resume_io(mdev);
  out: 
#line 2583
  drbd_adm_finish(info, retcode);
#line 2584
  return (0);
}
}
#line 2587 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_pause_sync(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  int tmp ;
  union drbd_state val ;
  union drbd_state mask ;
  int tmp___0 ;

  {
#line 2591
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 2591
  retcode = (enum drbd_ret_code )tmp;
#line 2592
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2593
    return ((int )retcode);
  } else {

  }
#line 2594
  if ((unsigned int )retcode != 101U) {
#line 2595
    goto out;
  } else {

  }
#line 2597
  val.i = 0U;
#line 2597
  val.ldv_40024.user_isp = 1U;
#line 2597
  mask.i = 0U;
#line 2597
  mask.ldv_40024.user_isp = 1U;
#line 2597
  tmp___0 = drbd_request_state(adm_ctx.mdev, mask, val);
#line 2597
  if (tmp___0 == 2) {
#line 2598
    retcode = ERR_PAUSE_IS_SET;
  } else {

  }
  out: 
#line 2600
  drbd_adm_finish(info, (int )retcode);
#line 2601
  return (0);
}
}
#line 2604 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_resume_sync(struct sk_buff *skb , struct genl_info *info ) 
{ 
  union drbd_dev_state s ;
  enum drbd_ret_code retcode ;
  int tmp ;
  union drbd_state val ;
  union drbd_state mask ;
  int tmp___0 ;

  {
#line 2609
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 2609
  retcode = (enum drbd_ret_code )tmp;
#line 2610
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2611
    return ((int )retcode);
  } else {

  }
#line 2612
  if ((unsigned int )retcode != 101U) {
#line 2613
    goto out;
  } else {

  }
#line 2615
  val.i = 0U;
#line 2615
  val.ldv_40024.user_isp = 0U;
#line 2615
  mask.i = 0U;
#line 2615
  mask.ldv_40024.user_isp = 1U;
#line 2615
  tmp___0 = drbd_request_state(adm_ctx.mdev, mask, val);
#line 2615
  if (tmp___0 == 2) {
#line 2616
    s = (adm_ctx.mdev)->state;
#line 2617
    if ((unsigned int )*((unsigned short *)(& s) + 0UL) == 320U || (unsigned int )*((unsigned short *)(& s) + 0UL) == 336U) {
#line 2618
      retcode = (unsigned int )*((unsigned char *)(& s) + 2UL) == 0U ? ((unsigned int )*((unsigned char *)(& s) + 2UL) != 0U ? ERR_PIC_PEER_DEP : ERR_PAUSE_IS_CLEAR) : ERR_PIC_AFTER_DEP;
    } else {
#line 2621
      retcode = ERR_PAUSE_IS_CLEAR;
    }
  } else {

  }
  out: 
#line 2626
  drbd_adm_finish(info, (int )retcode);
#line 2627
  return (0);
}
}
#line 2630 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_suspend_io(struct sk_buff *skb , struct genl_info *info ) 
{ 
  union drbd_state val ;
  union drbd_state mask ;
  int tmp ;

  {
#line 2632
  val.i = 0U;
#line 2632
  val.ldv_40024.susp = 1U;
#line 2632
  mask.i = 0U;
#line 2632
  mask.ldv_40024.susp = 1U;
#line 2632
  tmp = drbd_adm_simple_request_state(skb, info, mask, val);
#line 2632
  return (tmp);
}
}
#line 2635 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_resume_io(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct drbd_conf *mdev ;
  int retcode ;
  int tmp ;
  union drbd_state val ;
  union drbd_state mask ;

  {
#line 2640
  retcode = drbd_adm_prepare(skb, info, 1U);
#line 2641
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2642
    return (retcode);
  } else {

  }
#line 2643
  if (retcode != 101) {
#line 2644
    goto out;
  } else {

  }
#line 2646
  mdev = adm_ctx.mdev;
#line 2647
  tmp = constant_test_bit(17U, (unsigned long const volatile   *)(& mdev->flags));
#line 2647
  if (tmp != 0) {
#line 2648
    drbd_uuid_new_current(mdev);
#line 2649
    clear_bit(17, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 2651
  drbd_suspend_io(mdev);
#line 2652
  val.i = 0U;
#line 2652
  val.ldv_40024.susp = 0U;
#line 2652
  val.ldv_40024.susp_nod = 0U;
#line 2652
  val.ldv_40024.susp_fen = 0U;
#line 2652
  mask.i = 0U;
#line 2652
  mask.ldv_40024.susp = 1U;
#line 2652
  mask.ldv_40024.susp_nod = 1U;
#line 2652
  mask.ldv_40024.susp_fen = 1U;
#line 2652
  retcode = drbd_request_state(mdev, mask, val);
#line 2653
  if (retcode == 1) {
#line 2654
    if ((int )mdev->state.ldv_49522.conn <= 9) {
#line 2655
      tl_clear(mdev->tconn);
    } else {

    }
#line 2656
    if ((unsigned int )*((unsigned char *)mdev + 749UL) == 0U || (unsigned int )*((unsigned char *)mdev + 749UL) == 4U) {
#line 2657
      tl_restart(mdev->tconn, FAIL_FROZEN_DISK_IO);
    } else {

    }
  } else {

  }
#line 2659
  drbd_resume_io(mdev);
  out: 
#line 2662
  drbd_adm_finish(info, retcode);
#line 2663
  return (0);
}
}
#line 2666 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_outdate(struct sk_buff *skb , struct genl_info *info ) 
{ 
  union drbd_state val ;
  union drbd_state mask ;
  int tmp ;

  {
#line 2668
  val.i = 0U;
#line 2668
  val.ldv_40024.disk = 5U;
#line 2668
  mask.i = 0U;
#line 2668
  mask.ldv_40024.disk = 15U;
#line 2668
  tmp = drbd_adm_simple_request_state(skb, info, mask, val);
#line 2668
  return (tmp);
}
}
#line 2671 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int nla_put_drbd_cfg_context(struct sk_buff *skb , struct drbd_tconn *tconn , unsigned int vnr ) 
{ 
  struct nlattr *nla ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 2674
  nla = nla_nest_start(skb, 2);
#line 2675
  if ((unsigned long )nla == (unsigned long )((struct nlattr *)0)) {
#line 2676
    goto nla_put_failure;
  } else {

  }
#line 2677
  if (vnr != 4294967295U) {
#line 2677
    tmp = nla_put_u32(skb, 16385, vnr);
#line 2677
    if (tmp != 0) {
#line 2679
      goto nla_put_failure;
    } else {

    }
  } else {

  }
#line 2680
  tmp___0 = nla_put_string(skb, 16386, (char const   *)tconn->name);
#line 2680
  if (tmp___0 != 0) {
#line 2681
    goto nla_put_failure;
  } else {

  }
#line 2682
  if (tconn->my_addr_len != 0) {
#line 2682
    tmp___1 = nla_put(skb, 16387, tconn->my_addr_len, (void const   *)(& tconn->my_addr));
#line 2682
    if (tmp___1 != 0) {
#line 2684
      goto nla_put_failure;
    } else {

    }
  } else {

  }
#line 2685
  if (tconn->peer_addr_len != 0) {
#line 2685
    tmp___2 = nla_put(skb, 16388, tconn->peer_addr_len, (void const   *)(& tconn->peer_addr));
#line 2685
    if (tmp___2 != 0) {
#line 2687
      goto nla_put_failure;
    } else {

    }
  } else {

  }
#line 2688
  nla_nest_end(skb, nla);
#line 2689
  return (0);
  nla_put_failure: ;
#line 2692
  if ((unsigned long )nla != (unsigned long )((struct nlattr *)0)) {
#line 2693
    nla_nest_cancel(skb, nla);
  } else {

  }
#line 2694
  return (-90);
}
}
#line 2697 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int nla_put_status_info(struct sk_buff *skb , struct drbd_conf *mdev , struct sib_info  const  *sib ) 
{ 
  struct state_info *si ;
  struct net_conf *nc ;
  struct nlattr *nla ;
  int got_ldev ;
  int err ;
  int exclude_sensitive ;
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  struct net_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  sector_t tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;
  int tmp___16 ;
  int tmp___17 ;
  int tmp___18 ;
  int tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  int tmp___22 ;
  int tmp___23 ;
  int tmp___24 ;
  int tmp___25 ;
  int err___0 ;
  int tmp___26 ;
  unsigned long tmp___27 ;
  int tmp___28 ;
  unsigned long tmp___29 ;
  int tmp___30 ;
  int tmp___31 ;
  int tmp___32 ;
  int tmp___33 ;
  int tmp___34 ;
  int tmp___35 ;
  int tmp___36 ;

  {
#line 2700
  si = 0;
#line 2704
  err = 0;
#line 2718
  if ((unsigned long )sib != (unsigned long )((struct sib_info  const  *)0)) {
#line 2718
    tmp___1 = 1;
  } else {
#line 2718
    tmp = capable(21);
#line 2718
    if (tmp) {
#line 2718
      tmp___0 = 0;
    } else {
#line 2718
      tmp___0 = 1;
    }
#line 2718
    if (tmp___0) {
#line 2718
      tmp___1 = 1;
    } else {
#line 2718
      tmp___1 = 0;
    }
  }
#line 2718
  exclude_sensitive = tmp___1;
#line 2720
  got_ldev = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 2724
  tmp___2 = nla_put_drbd_cfg_context(skb, mdev->tconn, (unsigned int )mdev->vnr);
#line 2724
  if (tmp___2 != 0) {
#line 2725
    goto nla_put_failure;
  } else {

  }
#line 2727
  tmp___3 = res_opts_to_skb(skb, & (mdev->tconn)->res_opts, exclude_sensitive != 0);
#line 2727
  if (tmp___3 != 0) {
#line 2728
    goto nla_put_failure;
  } else {

  }
#line 2730
  rcu_read_lock___6();
#line 2731
  if (got_ldev != 0) {
#line 2732
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 2732
    tmp___4 = debug_lockdep_rcu_enabled();
#line 2732
    if (tmp___4 != 0 && ! __warned) {
#line 2732
      tmp___5 = rcu_read_lock_held();
#line 2732
      if (tmp___5 == 0 && 1) {
#line 2732
        __warned = 1;
#line 2732
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                               2732, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 2732
    tmp___6 = disk_conf_to_skb(skb, _________p1, exclude_sensitive != 0);
#line 2732
    if (tmp___6 != 0) {
#line 2733
      goto nla_put_failure;
    } else {

    }
  } else {

  }
#line 2735
  _________p1___0 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 2735
  tmp___7 = debug_lockdep_rcu_enabled();
#line 2735
  if (tmp___7 != 0 && ! __warned___0) {
#line 2735
    tmp___8 = rcu_read_lock_held();
#line 2735
    if (tmp___8 == 0 && 1) {
#line 2735
      __warned___0 = 1;
#line 2735
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                             2735, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 2735
  nc = _________p1___0;
#line 2736
  if ((unsigned long )nc != (unsigned long )((struct net_conf *)0)) {
#line 2737
    err = net_conf_to_skb(skb, nc, exclude_sensitive != 0);
  } else {

  }
#line 2738
  rcu_read_unlock___6();
#line 2739
  if (err != 0) {
#line 2740
    goto nla_put_failure;
  } else {

  }
#line 2742
  nla = nla_nest_start(skb, 8);
#line 2743
  if ((unsigned long )nla == (unsigned long )((struct nlattr *)0)) {
#line 2744
    goto nla_put_failure;
  } else {

  }
#line 2745
  tmp___9 = nla_put_u32(skb, 16385, (unsigned long )sib != (unsigned long )((struct sib_info  const  *)0) ? (unsigned int )sib->sib_reason : 1U);
#line 2745
  if (tmp___9 != 0) {
#line 2758
    goto nla_put_failure;
  } else {
#line 2745
    tmp___10 = nla_put_u32(skb, 2, mdev->state.i);
#line 2745
    if (tmp___10 != 0) {
#line 2758
      goto nla_put_failure;
    } else {
#line 2745
      tmp___11 = nla_put_u64(skb, 16388, mdev->ed_uuid);
#line 2745
      if (tmp___11 != 0) {
#line 2758
        goto nla_put_failure;
      } else {
#line 2745
        tmp___12 = drbd_get_capacity(mdev->this_bdev);
#line 2745
        tmp___13 = nla_put_u64(skb, 16387, (u64 )tmp___12);
#line 2745
        if (tmp___13 != 0) {
#line 2758
          goto nla_put_failure;
        } else {
#line 2745
          tmp___14 = nla_put_u64(skb, 15, (u64 )mdev->send_cnt);
#line 2745
          if (tmp___14 != 0) {
#line 2758
            goto nla_put_failure;
          } else {
#line 2745
            tmp___15 = nla_put_u64(skb, 16, (u64 )mdev->recv_cnt);
#line 2745
            if (tmp___15 != 0) {
#line 2758
              goto nla_put_failure;
            } else {
#line 2745
              tmp___16 = nla_put_u64(skb, 17, (u64 )mdev->read_cnt);
#line 2745
              if (tmp___16 != 0) {
#line 2758
                goto nla_put_failure;
              } else {
#line 2745
                tmp___17 = nla_put_u64(skb, 18, (u64 )mdev->writ_cnt);
#line 2745
                if (tmp___17 != 0) {
#line 2758
                  goto nla_put_failure;
                } else {
#line 2745
                  tmp___18 = nla_put_u64(skb, 19, (u64 )mdev->al_writ_cnt);
#line 2745
                  if (tmp___18 != 0) {
#line 2758
                    goto nla_put_failure;
                  } else {
#line 2745
                    tmp___19 = nla_put_u64(skb, 20, (u64 )mdev->bm_writ_cnt);
#line 2745
                    if (tmp___19 != 0) {
#line 2758
                      goto nla_put_failure;
                    } else {
#line 2745
                      tmp___20 = atomic_read((atomic_t const   *)(& mdev->ap_bio_cnt));
#line 2745
                      tmp___21 = nla_put_u32(skb, 21, (u32 )tmp___20);
#line 2745
                      if (tmp___21 != 0) {
#line 2758
                        goto nla_put_failure;
                      } else {
#line 2745
                        tmp___22 = atomic_read((atomic_t const   *)(& mdev->ap_pending_cnt));
#line 2745
                        tmp___23 = nla_put_u32(skb, 22, (u32 )tmp___22);
#line 2745
                        if (tmp___23 != 0) {
#line 2758
                          goto nla_put_failure;
                        } else {
#line 2745
                          tmp___24 = atomic_read((atomic_t const   *)(& mdev->rs_pending_cnt));
#line 2745
                          tmp___25 = nla_put_u32(skb, 23, (u32 )tmp___24);
#line 2745
                          if (tmp___25 != 0) {
#line 2758
                            goto nla_put_failure;
                          } else {

                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
#line 2760
  if (got_ldev != 0) {
#line 2763
    spin_lock_irq(& (mdev->ldev)->md.uuid_lock);
#line 2764
    err___0 = nla_put(skb, 16391, 32, (void const   *)(& (mdev->ldev)->md.uuid));
#line 2765
    spin_unlock_irq(& (mdev->ldev)->md.uuid_lock);
#line 2767
    if (err___0 != 0) {
#line 2768
      goto nla_put_failure;
    } else {

    }
#line 2770
    tmp___26 = nla_put_u32(skb, 16392, (mdev->ldev)->md.flags);
#line 2770
    if (tmp___26 != 0) {
#line 2773
      goto nla_put_failure;
    } else {
#line 2770
      tmp___27 = drbd_bm_bits(mdev);
#line 2770
      tmp___28 = nla_put_u64(skb, 16393, (u64 )tmp___27);
#line 2770
      if (tmp___28 != 0) {
#line 2773
        goto nla_put_failure;
      } else {
#line 2770
        tmp___29 = drbd_bm_total_weight(mdev);
#line 2770
        tmp___30 = nla_put_u64(skb, 16394, (u64 )tmp___29);
#line 2770
        if (tmp___30 != 0) {
#line 2773
          goto nla_put_failure;
        } else {

        }
      }
    }
#line 2774
    if ((int )mdev->state.ldv_49522.conn > 15 && (int )mdev->state.ldv_49522.conn <= 21) {
#line 2776
      tmp___31 = nla_put_u64(skb, 16395, (u64 )mdev->rs_total);
#line 2776
      if (tmp___31 != 0) {
#line 2778
        goto nla_put_failure;
      } else {
#line 2776
        tmp___32 = nla_put_u64(skb, 16396, (u64 )mdev->rs_failed);
#line 2776
        if (tmp___32 != 0) {
#line 2778
          goto nla_put_failure;
        } else {

        }
      }
    } else {

    }
  } else {

  }
#line 2782
  if ((unsigned long )sib != (unsigned long )((struct sib_info  const  *)0)) {
#line 2783
    switch ((unsigned int )sib->sib_reason) {
    case 5U: ;
    case 1U: ;
#line 2786
    goto ldv_53822;
    case 2U: 
#line 2788
    tmp___33 = nla_put_u32(skb, 16389, sib->ldv_50742.ldv_50741.os.i);
#line 2788
    if (tmp___33 != 0) {
#line 2790
      goto nla_put_failure;
    } else {
#line 2788
      tmp___34 = nla_put_u32(skb, 16390, sib->ldv_50742.ldv_50741.ns.i);
#line 2788
      if (tmp___34 != 0) {
#line 2790
        goto nla_put_failure;
      } else {

      }
    }
#line 2791
    goto ldv_53822;
    case 4U: 
#line 2793
    tmp___35 = nla_put_u32(skb, 16398, sib->ldv_50742.ldv_50737.helper_exit_code);
#line 2793
    if (tmp___35 != 0) {
#line 2795
      goto nla_put_failure;
    } else {

    }
    case 3U: 
#line 2798
    tmp___36 = nla_put_string(skb, 16397, (char const   *)sib->ldv_50742.ldv_50737.helper_name);
#line 2798
    if (tmp___36 != 0) {
#line 2799
      goto nla_put_failure;
    } else {

    }
#line 2800
    goto ldv_53822;
    }
    ldv_53822: ;
  } else {

  }
#line 2803
  nla_nest_end(skb, nla);
#line 2805
  if (0) {
    nla_put_failure: 
#line 2807
    err = -90;
  } else {

  }
#line 2808
  if (got_ldev != 0) {
#line 2809
    put_ldev(mdev);
  } else {

  }
#line 2810
  return (err);
}
}
#line 2813 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_get_status(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  int err ;
  int tmp ;

  {
#line 2818
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 2818
  retcode = (enum drbd_ret_code )tmp;
#line 2819
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 2820
    return ((int )retcode);
  } else {

  }
#line 2821
  if ((unsigned int )retcode != 101U) {
#line 2822
    goto out;
  } else {

  }
#line 2824
  err = nla_put_status_info(adm_ctx.reply_skb, adm_ctx.mdev, 0);
#line 2825
  if (err != 0) {
#line 2826
    nlmsg_free(adm_ctx.reply_skb);
#line 2827
    return (err);
  } else {

  }
  out: 
#line 2830
  drbd_adm_finish(info, (int )retcode);
#line 2831
  return (0);
}
}
#line 2834 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int get_one_status(struct sk_buff *skb , struct netlink_callback *cb ) 
{ 
  struct drbd_conf *mdev ;
  struct drbd_genlmsghdr *dh ;
  struct drbd_tconn *pos ;
  struct drbd_tconn *tconn ;
  struct drbd_tconn *tmp ;
  unsigned int volume ;
  struct list_head *__ptr ;
  struct list_head  const  *__mptr ;
  struct list_head *_________p1 ;
  bool __warned ;
  int tmp___0 ;
  struct list_head *__ptr___0 ;
  struct list_head  const  *__mptr___0 ;
  struct list_head *_________p1___0 ;
  bool __warned___0 ;
  int tmp___1 ;
  void *tmp___2 ;
  struct list_head *__ptr___1 ;
  struct list_head  const  *__mptr___1 ;
  struct list_head *_________p1___1 ;
  bool __warned___1 ;
  int tmp___3 ;
  void *tmp___4 ;
  struct net_conf *nc ;
  int tmp___5 ;
  struct net_conf *_________p1___2 ;
  bool __warned___2 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;

  {
#line 2838
  pos = (struct drbd_tconn *)cb->args[0];
#line 2839
  tconn = 0;
#line 2841
  volume = (unsigned int )cb->args[1];
#line 2864
  rcu_read_lock___6();
#line 2866
  __ptr = drbd_tconns.next;
#line 2866
  _________p1 = *((struct list_head * volatile  *)(& __ptr));
#line 2866
  tmp___0 = debug_lockdep_rcu_enabled();
#line 2866
  if (tmp___0 != 0 && ! __warned) {
#line 2866
    rcu_read_lock_held();
  } else {

  }
#line 2866
  __mptr = (struct list_head  const  *)_________p1;
#line 2866
  tmp = (struct drbd_tconn *)__mptr + 0xfffffffffffffff8UL;
#line 2866
  goto ldv_53859;
  ldv_53858: ;
#line 2867
  if ((unsigned long )pos == (unsigned long )((struct drbd_tconn *)0)) {
#line 2869
    pos = tmp;
#line 2870
    tconn = pos;
#line 2871
    goto ldv_53857;
  } else {

  }
#line 2873
  if ((unsigned long )tmp == (unsigned long )pos) {
#line 2874
    tconn = pos;
#line 2875
    goto ldv_53857;
  } else {

  }
#line 2866
  __ptr___0 = tmp->all_tconn.next;
#line 2866
  _________p1___0 = *((struct list_head * volatile  *)(& __ptr___0));
#line 2866
  tmp___1 = debug_lockdep_rcu_enabled();
#line 2866
  if (tmp___1 != 0 && ! __warned___0) {
#line 2866
    rcu_read_lock_held();
  } else {

  }
#line 2866
  __mptr___0 = (struct list_head  const  *)_________p1___0;
#line 2866
  tmp = (struct drbd_tconn *)__mptr___0 + 0xfffffffffffffff8UL;
  ldv_53859: ;
#line 2866
  if ((unsigned long )(& tmp->all_tconn) != (unsigned long )(& drbd_tconns)) {
#line 2867
    goto ldv_53858;
  } else {

  }
  ldv_53857: ;
#line 2878
  if ((unsigned long )tconn != (unsigned long )((struct drbd_tconn *)0)) {
    next_tconn: 
#line 2880
    tmp___2 = idr_get_next(& tconn->volumes, (int *)(& volume));
#line 2880
    mdev = (struct drbd_conf *)tmp___2;
#line 2881
    if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 2884
      __ptr___1 = tconn->all_tconn.next;
#line 2884
      _________p1___1 = *((struct list_head * volatile  *)(& __ptr___1));
#line 2884
      tmp___3 = debug_lockdep_rcu_enabled();
#line 2884
      if (tmp___3 != 0 && ! __warned___1) {
#line 2884
        rcu_read_lock_held();
      } else {

      }
#line 2884
      __mptr___1 = (struct list_head  const  *)_________p1___1;
#line 2884
      pos = (struct drbd_tconn *)__mptr___1 + 0xfffffffffffffff8UL;
#line 2887
      if (volume != 0U) {
#line 2891
        if ((unsigned long )(& pos->all_tconn) == (unsigned long )(& drbd_tconns) || cb->args[2] != 0L) {
#line 2892
          goto out;
        } else {

        }
#line 2893
        volume = 0U;
#line 2894
        tconn = pos;
#line 2895
        goto next_tconn;
      } else {

      }
    } else {

    }
#line 2899
    tmp___4 = genlmsg_put(skb, ((struct netlink_skb_parms *)(& (cb->skb)->cb))->portid,
                          (cb->nlh)->nlmsg_seq, & drbd_genl_family, 2, 2);
#line 2899
    dh = (struct drbd_genlmsghdr *)tmp___4;
#line 2902
    if ((unsigned long )dh == (unsigned long )((struct drbd_genlmsghdr *)0)) {
#line 2903
      goto out;
    } else {

    }
#line 2905
    if ((unsigned long )mdev == (unsigned long )((struct drbd_conf *)0)) {
#line 2910
      dh->minor = 4294967295U;
#line 2911
      dh->ldv_49826.ret_code = 101;
#line 2912
      tmp___5 = nla_put_drbd_cfg_context(skb, tconn, 4294967295U);
#line 2912
      if (tmp___5 != 0) {
#line 2913
        goto cancel;
      } else {

      }
#line 2914
      _________p1___2 = *((struct net_conf * volatile  *)(& tconn->net_conf));
#line 2914
      tmp___6 = debug_lockdep_rcu_enabled();
#line 2914
      if (tmp___6 != 0 && ! __warned___2) {
#line 2914
        tmp___7 = rcu_read_lock_held();
#line 2914
        if (tmp___7 == 0 && 1) {
#line 2914
          __warned___2 = 1;
#line 2914
          lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
                                 2914, "suspicious rcu_dereference_check() usage");
        } else {

        }
      } else {

      }
#line 2914
      nc = _________p1___2;
#line 2915
      if ((unsigned long )nc != (unsigned long )((struct net_conf *)0)) {
#line 2915
        tmp___8 = net_conf_to_skb(skb, nc, 1);
#line 2915
        if (tmp___8 != 0) {
#line 2916
          goto cancel;
        } else {

        }
      } else {

      }
#line 2917
      goto done;
    } else {

    }
#line 2920
    if ((unsigned int )mdev->vnr != volume) {
#line 2920
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->vnr == volume ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
              2920);
    } else {

    }
#line 2921
    if ((unsigned long )mdev->tconn != (unsigned long )tconn) {
#line 2921
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( mdev->tconn == tconn ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared",
              2921);
    } else {

    }
#line 2923
    dh->minor = mdev_to_minor(mdev);
#line 2924
    dh->ldv_49826.ret_code = 101;
#line 2926
    tmp___9 = nla_put_status_info(skb, mdev, 0);
#line 2926
    if (tmp___9 != 0) {
      cancel: 
#line 2928
      genlmsg_cancel(skb, (void *)dh);
#line 2929
      goto out;
    } else {

    }
    done: 
#line 2932
    genlmsg_end(skb, (void *)dh);
  } else {

  }
  out: 
#line 2936
  rcu_read_unlock___6();
#line 2938
  cb->args[0] = (long )pos;
#line 2939
  cb->args[1] = (unsigned long )pos == (unsigned long )tconn ? (long )(volume + 1U) : 0L;
#line 2943
  return ((int )skb->len);
}
}
#line 2956 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_get_status_all(struct sk_buff *skb , struct netlink_callback *cb ) 
{ 
  unsigned int hdrlen ;
  struct nlattr *nla ;
  char const   *resource_name ;
  struct drbd_tconn *tconn ;
  int maxtype ;
  int tmp ;
  struct nlattr *tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  void *tmp___3 ;
  int tmp___4 ;

  {
#line 2958
  hdrlen = 12U;
#line 2965
  if (cb->args[0] != 0L) {
#line 2968
    if (cb->args[2] != 0L && cb->args[2] != cb->args[0]) {
#line 2969
      return (0);
    } else {

    }
#line 2970
    goto dump;
  } else {

  }
#line 2975
  tmp = nlmsg_attrlen(cb->nlh, (int )hdrlen);
#line 2975
  tmp___0 = nlmsg_attrdata(cb->nlh, (int )hdrlen);
#line 2975
  nla = nla_find((struct nlattr  const  *)tmp___0, tmp, 2);
#line 2980
  if ((unsigned long )nla == (unsigned long )((struct nlattr *)0)) {
#line 2981
    goto dump;
  } else {

  }
#line 2982
  maxtype = 4;
#line 2983
  nla = drbd_nla_find_nested(maxtype, nla, 2);
#line 2984
  tmp___2 = IS_ERR((void const   *)nla);
#line 2984
  if (tmp___2 != 0L) {
#line 2985
    tmp___1 = PTR_ERR((void const   *)nla);
#line 2985
    return ((int )tmp___1);
  } else {

  }
#line 2987
  if ((unsigned long )nla == (unsigned long )((struct nlattr *)0)) {
#line 2988
    return (-22);
  } else {

  }
#line 2989
  tmp___3 = nla_data((struct nlattr  const  *)nla);
#line 2989
  resource_name = (char const   *)tmp___3;
#line 2990
  tconn = conn_get_by_name(resource_name);
#line 2992
  if ((unsigned long )tconn == (unsigned long )((struct drbd_tconn *)0)) {
#line 2993
    return (-19);
  } else {

  }
#line 2995
  kref_put(& tconn->kref, & conn_destroy);
#line 2999
  cb->args[0] = (long )tconn;
#line 3001
  cb->args[2] = (long )tconn;
  dump: 
#line 3004
  tmp___4 = get_one_status(skb, cb);
#line 3004
  return (tmp___4);
}
}
#line 3007 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_get_timeout_type(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  struct timeout_parms tp ;
  int err ;
  int tmp ;
  int tmp___0 ;

  {
#line 3013
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 3013
  retcode = (enum drbd_ret_code )tmp;
#line 3014
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3015
    return ((int )retcode);
  } else {

  }
#line 3016
  if ((unsigned int )retcode != 101U) {
#line 3017
    goto out;
  } else {

  }
#line 3019
  if (*((unsigned int *)adm_ctx.mdev + 187UL) != 40960U) {
#line 3019
    tmp___0 = constant_test_bit(2U, (unsigned long const volatile   *)(& (adm_ctx.mdev)->flags));
#line 3019
    tp.timeout_type = tmp___0 != 0;
  } else {
#line 3019
    tp.timeout_type = 2U;
  }
#line 3024
  err = timeout_parms_to_priv_skb(adm_ctx.reply_skb, & tp);
#line 3025
  if (err != 0) {
#line 3026
    nlmsg_free(adm_ctx.reply_skb);
#line 3027
    return (err);
  } else {

  }
  out: 
#line 3030
  drbd_adm_finish(info, (int )retcode);
#line 3031
  return (0);
}
}
#line 3034 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_start_ov(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct drbd_conf *mdev ;
  enum drbd_ret_code retcode ;
  struct start_ov_parms parms ;
  int tmp ;
  int err ;
  int tmp___0 ;
  char const   *tmp___1 ;
  int tmp___2 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___3 ;
  int tmp___4 ;
  union drbd_state val ;
  union drbd_state mask ;
  int tmp___5 ;

  {
#line 3040
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 3040
  retcode = (enum drbd_ret_code )tmp;
#line 3041
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3042
    return ((int )retcode);
  } else {

  }
#line 3043
  if ((unsigned int )retcode != 101U) {
#line 3044
    goto out;
  } else {

  }
#line 3046
  mdev = adm_ctx.mdev;
#line 3049
  parms.ov_start_sector = (__u64 )mdev->ov_start_sector;
#line 3050
  parms.ov_stop_sector = 0xffffffffffffffffULL;
#line 3051
  if ((unsigned long )*(info->attrs + 9UL) != (unsigned long )((struct nlattr *)0)) {
#line 3052
    tmp___0 = start_ov_parms_from_attrs(& parms, info);
#line 3052
    err = tmp___0;
#line 3053
    if (err != 0) {
#line 3054
      retcode = ERR_MANDATORY_TAG;
#line 3055
      tmp___1 = from_attrs_err_to_txt(err);
#line 3055
      drbd_msg_put_info(tmp___1);
#line 3056
      goto out;
    } else {

    }
  } else {

  }
#line 3060
  mdev->ov_start_sector = (sector_t )parms.ov_start_sector & 0xfffffffffffffff8UL;
#line 3061
  mdev->ov_stop_sector = (sector_t )parms.ov_stop_sector;
#line 3065
  drbd_suspend_io(mdev);
#line 3066
  tmp___2 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 3066
  if (tmp___2 == 0) {
#line 3066
    goto ldv_53904;
  } else {

  }
#line 3066
  tmp___3 = get_current();
#line 3066
  __wait.flags = 0U;
#line 3066
  __wait.private = (void *)tmp___3;
#line 3066
  __wait.func = & autoremove_wake_function;
#line 3066
  __wait.task_list.next = & __wait.task_list;
#line 3066
  __wait.task_list.prev = & __wait.task_list;
  ldv_53907: 
#line 3066
  prepare_to_wait(& mdev->misc_wait, & __wait, 2);
#line 3066
  tmp___4 = constant_test_bit(9U, (unsigned long const volatile   *)(& mdev->flags));
#line 3066
  if (tmp___4 == 0) {
#line 3066
    goto ldv_53906;
  } else {

  }
#line 3066
  schedule();
#line 3066
  goto ldv_53907;
  ldv_53906: 
#line 3066
  finish_wait(& mdev->misc_wait, & __wait);
  ldv_53904: 
#line 3067
  val.i = 0U;
#line 3067
  val.ldv_40024.conn = 18U;
#line 3067
  mask.i = 0U;
#line 3067
  mask.ldv_40024.conn = 31U;
#line 3067
  tmp___5 = drbd_request_state(mdev, mask, val);
#line 3067
  retcode = (enum drbd_ret_code )tmp___5;
#line 3068
  drbd_resume_io(mdev);
  out: 
#line 3070
  drbd_adm_finish(info, (int )retcode);
#line 3071
  return (0);
}
}
#line 3075 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_new_c_uuid(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct drbd_conf *mdev ;
  enum drbd_ret_code retcode ;
  int skip_initial_sync ;
  int err ;
  struct new_c_uuid_parms args ;
  int tmp ;
  char const   *tmp___0 ;
  int tmp___1 ;
  union drbd_state __ns ;

  {
#line 3079
  skip_initial_sync = 0;
#line 3083
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 3083
  retcode = (enum drbd_ret_code )tmp;
#line 3084
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3085
    return ((int )retcode);
  } else {

  }
#line 3086
  if ((unsigned int )retcode != 101U) {
#line 3087
    goto out_nolock;
  } else {

  }
#line 3089
  mdev = adm_ctx.mdev;
#line 3090
  memset((void *)(& args), 0, 1UL);
#line 3091
  if ((unsigned long )*(info->attrs + 10UL) != (unsigned long )((struct nlattr *)0)) {
#line 3092
    err = new_c_uuid_parms_from_attrs(& args, info);
#line 3093
    if (err != 0) {
#line 3094
      retcode = ERR_MANDATORY_TAG;
#line 3095
      tmp___0 = from_attrs_err_to_txt(err);
#line 3095
      drbd_msg_put_info(tmp___0);
#line 3096
      goto out_nolock;
    } else {

    }
  } else {

  }
#line 3100
  ldv_mutex_lock_308(mdev->state_mutex);
#line 3102
  tmp___1 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 3102
  if (tmp___1 == 0) {
#line 3103
    retcode = ERR_NO_DISK;
#line 3104
    goto out;
  } else {

  }
#line 3108
  if ((((unsigned int )*((unsigned short *)mdev + 374UL) == 160U && (mdev->tconn)->agreed_pro_version > 89) && (mdev->ldev)->md.uuid[0] == 4ULL) && (int )((signed char )args.clear_bm) != 0) {
#line 3110
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Preparing to skip initial sync\n");
#line 3111
    skip_initial_sync = 1;
  } else
#line 3112
  if ((unsigned int )*((unsigned short *)mdev + 374UL) != 0U) {
#line 3113
    retcode = ERR_CONNECTED;
#line 3114
    goto out_dec;
  } else {

  }
#line 3117
  drbd_uuid_set(mdev, 1, 0ULL);
#line 3118
  drbd_uuid_new_current(mdev);
#line 3120
  if ((int )((signed char )args.clear_bm) != 0) {
#line 3121
    err = drbd_bitmap_io(mdev, & drbd_bmio_clear_n_write, (char *)"clear_n_write from new_c_uuid",
                         BM_LOCKED_MASK);
#line 3123
    if (err != 0) {
#line 3124
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Writing bitmap failed with %d\n",
              err);
#line 3125
      retcode = ERR_IO_MD_DISK;
    } else {

    }
#line 3127
    if (skip_initial_sync != 0) {
#line 3128
      drbd_send_uuids_skip_initial_sync(mdev);
#line 3129
      _drbd_uuid_set(mdev, 1, 0ULL);
#line 3130
      drbd_print_uuids(mdev, "cleared bitmap UUID");
#line 3131
      spin_lock_irq(& (mdev->tconn)->req_lock);
#line 3132
      __ns = drbd_read_state(mdev);
#line 3132
      __ns.ldv_40024.disk = 8U;
#line 3132
      __ns.ldv_40024.pdsk = 8U;
#line 3132
      _drbd_set_state(mdev, __ns, CS_VERBOSE, 0);
#line 3134
      spin_unlock_irq(& (mdev->tconn)->req_lock);
    } else {

    }
  } else {

  }
#line 3138
  drbd_md_sync(mdev);
  out_dec: 
#line 3140
  put_ldev(mdev);
  out: 
#line 3142
  ldv_mutex_unlock_309(mdev->state_mutex);
  out_nolock: 
#line 3144
  drbd_adm_finish(info, (int )retcode);
#line 3145
  return (0);
}
}
#line 3149 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static enum drbd_ret_code drbd_check_resource_name(char const   *name ) 
{ 
  char *tmp ;

  {
#line 3151
  if ((unsigned long )name == (unsigned long )((char const   *)0) || (int )((signed char )*name) == 0) {
#line 3152
    drbd_msg_put_info("resource name missing");
#line 3153
    return (ERR_MANDATORY_TAG);
  } else {

  }
#line 3157
  tmp = strchr(name, 47);
#line 3157
  if ((unsigned long )tmp != (unsigned long )((char *)0)) {
#line 3158
    drbd_msg_put_info("invalid resource name");
#line 3159
    return (ERR_INVALID_REQUEST);
  } else {

  }
#line 3161
  return (NO_ERROR);
}
}
#line 3164 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_new_resource(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  struct res_opts res_opts ;
  int err ;
  int tmp ;
  char const   *tmp___0 ;
  struct drbd_tconn *tmp___1 ;

  {
#line 3170
  tmp = drbd_adm_prepare(skb, info, 0U);
#line 3170
  retcode = (enum drbd_ret_code )tmp;
#line 3171
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3172
    return ((int )retcode);
  } else {

  }
#line 3173
  if ((unsigned int )retcode != 101U) {
#line 3174
    goto out;
  } else {

  }
#line 3176
  set_res_opts_defaults(& res_opts);
#line 3177
  err = res_opts_from_attrs(& res_opts, info);
#line 3178
  if (err != 0 && err != -42) {
#line 3179
    retcode = ERR_MANDATORY_TAG;
#line 3180
    tmp___0 = from_attrs_err_to_txt(err);
#line 3180
    drbd_msg_put_info(tmp___0);
#line 3181
    goto out;
  } else {

  }
#line 3184
  retcode = drbd_check_resource_name((char const   *)adm_ctx.resource_name);
#line 3185
  if ((unsigned int )retcode != 101U) {
#line 3186
    goto out;
  } else {

  }
#line 3188
  if ((unsigned long )adm_ctx.tconn != (unsigned long )((struct drbd_tconn *)0)) {
#line 3189
    if (((int )(info->nlhdr)->nlmsg_flags & 512) != 0) {
#line 3190
      retcode = ERR_INVALID_REQUEST;
#line 3191
      drbd_msg_put_info("resource exists");
    } else {

    }
#line 3194
    goto out;
  } else {

  }
#line 3197
  tmp___1 = conn_create((char const   *)adm_ctx.resource_name, & res_opts);
#line 3197
  if ((unsigned long )tmp___1 == (unsigned long )((struct drbd_tconn *)0)) {
#line 3198
    retcode = ERR_NOMEM;
  } else {

  }
  out: 
#line 3200
  drbd_adm_finish(info, (int )retcode);
#line 3201
  return (0);
}
}
#line 3204 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_add_minor(struct sk_buff *skb , struct genl_info *info ) 
{ 
  struct drbd_genlmsghdr *dh ;
  enum drbd_ret_code retcode ;
  int tmp ;

  {
#line 3206
  dh = (struct drbd_genlmsghdr *)info->userhdr;
#line 3209
  tmp = drbd_adm_prepare(skb, info, 2U);
#line 3209
  retcode = (enum drbd_ret_code )tmp;
#line 3210
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3211
    return ((int )retcode);
  } else {

  }
#line 3212
  if ((unsigned int )retcode != 101U) {
#line 3213
    goto out;
  } else {

  }
#line 3215
  if (dh->minor > 1048575U) {
#line 3216
    drbd_msg_put_info("requested minor out of range");
#line 3217
    retcode = ERR_INVALID_REQUEST;
#line 3218
    goto out;
  } else {

  }
#line 3220
  if (adm_ctx.volume > 65535U) {
#line 3221
    drbd_msg_put_info("requested volume id out of range");
#line 3222
    retcode = ERR_INVALID_REQUEST;
#line 3223
    goto out;
  } else {

  }
#line 3228
  if ((unsigned long )adm_ctx.mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 3229
    if (((int )(info->nlhdr)->nlmsg_flags & 512) != 0) {
#line 3230
      retcode = ERR_MINOR_EXISTS;
    } else {

    }
#line 3232
    goto out;
  } else {

  }
#line 3235
  retcode = conn_new_minor(adm_ctx.tconn, dh->minor, (int )adm_ctx.volume);
  out: 
#line 3237
  drbd_adm_finish(info, (int )retcode);
#line 3238
  return (0);
}
}
#line 3241 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
static enum drbd_ret_code adm_delete_minor(struct drbd_conf *mdev ) 
{ 
  union drbd_state val ;
  union drbd_state mask ;
  unsigned int tmp ;

  {
#line 3243
  if ((unsigned int )*((unsigned char *)mdev + 749UL) == 0U && (unsigned int )*((unsigned char *)mdev + 748UL) == 2U) {
#line 3248
    val.i = 0U;
#line 3248
    val.ldv_40024.conn = 9U;
#line 3248
    mask.i = 0U;
#line 3248
    mask.ldv_40024.conn = 31U;
#line 3248
    _drbd_request_state(mdev, mask, val, 6);
#line 3250
    idr_remove(& (mdev->tconn)->volumes, mdev->vnr);
#line 3251
    tmp = mdev_to_minor(mdev);
#line 3251
    idr_remove(& minors, (int )tmp);
#line 3252
    del_gendisk(mdev->vdisk);
#line 3253
    synchronize_rcu();
#line 3254
    kref_put(& mdev->kref, & drbd_minor_destroy);
#line 3255
    return (NO_ERROR);
  } else {
#line 3257
    return (ERR_MINOR_CONFIGURED);
  }
}
}
#line 3260 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_delete_minor(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  int tmp ;

  {
#line 3264
  tmp = drbd_adm_prepare(skb, info, 1U);
#line 3264
  retcode = (enum drbd_ret_code )tmp;
#line 3265
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3266
    return ((int )retcode);
  } else {

  }
#line 3267
  if ((unsigned int )retcode != 101U) {
#line 3268
    goto out;
  } else {

  }
#line 3270
  retcode = adm_delete_minor(adm_ctx.mdev);
  out: 
#line 3272
  drbd_adm_finish(info, (int )retcode);
#line 3273
  return (0);
}
}
#line 3276 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_down(struct sk_buff *skb , struct genl_info *info ) 
{ 
  int retcode ;
  struct drbd_conf *mdev ;
  unsigned int i ;
  void *tmp ;
  enum drbd_state_rv tmp___0 ;
  void *tmp___1 ;
  enum drbd_state_rv tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;
  void *tmp___5 ;
  enum drbd_ret_code tmp___6 ;
  void *tmp___7 ;
  int tmp___8 ;

  {
#line 3282
  retcode = drbd_adm_prepare(skb, info, 0U);
#line 3283
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3284
    return (retcode);
  } else {

  }
#line 3285
  if (retcode != 101) {
#line 3286
    goto out;
  } else {

  }
#line 3288
  if ((unsigned long )adm_ctx.tconn == (unsigned long )((struct drbd_tconn *)0)) {
#line 3289
    retcode = 158;
#line 3290
    goto out;
  } else {

  }
#line 3294
  i = 0U;
#line 3294
  tmp = idr_get_next(& (adm_ctx.tconn)->volumes, (int *)(& i));
#line 3294
  mdev = (struct drbd_conf *)tmp;
#line 3294
  goto ldv_53966;
  ldv_53965: 
#line 3295
  tmp___0 = drbd_set_role(mdev, R_SECONDARY, 0);
#line 3295
  retcode = (int )tmp___0;
#line 3296
  if (retcode <= 0) {
#line 3297
    drbd_msg_put_info("failed to demote");
#line 3298
    goto out;
  } else {

  }
#line 3294
  i = i + 1U;
#line 3294
  tmp___1 = idr_get_next(& (adm_ctx.tconn)->volumes, (int *)(& i));
#line 3294
  mdev = (struct drbd_conf *)tmp___1;
  ldv_53966: ;
#line 3294
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 3295
    goto ldv_53965;
  } else {

  }
#line 3302
  tmp___2 = conn_try_disconnect(adm_ctx.tconn, 0);
#line 3302
  retcode = (int )tmp___2;
#line 3303
  if (retcode <= 0) {
#line 3304
    drbd_msg_put_info("failed to disconnect");
#line 3305
    goto out;
  } else {

  }
#line 3309
  i = 0U;
#line 3309
  tmp___3 = idr_get_next(& (adm_ctx.tconn)->volumes, (int *)(& i));
#line 3309
  mdev = (struct drbd_conf *)tmp___3;
#line 3309
  goto ldv_53969;
  ldv_53968: 
#line 3310
  retcode = adm_detach(mdev, 0);
#line 3311
  if (retcode <= 0 || retcode > 101) {
#line 3312
    drbd_msg_put_info("failed to detach");
#line 3313
    goto out;
  } else {

  }
#line 3309
  i = i + 1U;
#line 3309
  tmp___4 = idr_get_next(& (adm_ctx.tconn)->volumes, (int *)(& i));
#line 3309
  mdev = (struct drbd_conf *)tmp___4;
  ldv_53969: ;
#line 3309
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 3310
    goto ldv_53968;
  } else {

  }
#line 3320
  drbd_thread_stop(& (adm_ctx.tconn)->worker);
#line 3325
  i = 0U;
#line 3325
  tmp___5 = idr_get_next(& (adm_ctx.tconn)->volumes, (int *)(& i));
#line 3325
  mdev = (struct drbd_conf *)tmp___5;
#line 3325
  goto ldv_53972;
  ldv_53971: 
#line 3326
  tmp___6 = adm_delete_minor(mdev);
#line 3326
  retcode = (int )tmp___6;
#line 3327
  if (retcode != 101) {
#line 3329
    drbd_msg_put_info("failed to delete volume");
#line 3330
    goto out;
  } else {

  }
#line 3325
  i = i + 1U;
#line 3325
  tmp___7 = idr_get_next(& (adm_ctx.tconn)->volumes, (int *)(& i));
#line 3325
  mdev = (struct drbd_conf *)tmp___7;
  ldv_53972: ;
#line 3325
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 3326
    goto ldv_53971;
  } else {

  }
#line 3335
  tmp___8 = conn_lowest_minor(adm_ctx.tconn);
#line 3335
  if (tmp___8 < 0) {
#line 3336
    list_del_rcu(& (adm_ctx.tconn)->all_tconn);
#line 3337
    synchronize_rcu();
#line 3338
    kref_put(& (adm_ctx.tconn)->kref, & conn_destroy);
#line 3340
    retcode = 101;
  } else {
#line 3343
    retcode = 159;
#line 3344
    drbd_msg_put_info("failed to delete connection");
  }
#line 3346
  goto out;
  out: 
#line 3348
  drbd_adm_finish(info, retcode);
#line 3349
  return (0);
}
}
#line 3352 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int drbd_adm_del_resource(struct sk_buff *skb , struct genl_info *info ) 
{ 
  enum drbd_ret_code retcode ;
  int tmp ;
  int tmp___0 ;

  {
#line 3356
  tmp = drbd_adm_prepare(skb, info, 2U);
#line 3356
  retcode = (enum drbd_ret_code )tmp;
#line 3357
  if ((unsigned long )adm_ctx.reply_skb == (unsigned long )((struct sk_buff *)0)) {
#line 3358
    return ((int )retcode);
  } else {

  }
#line 3359
  if ((unsigned int )retcode != 101U) {
#line 3360
    goto out;
  } else {

  }
#line 3362
  tmp___0 = conn_lowest_minor(adm_ctx.tconn);
#line 3362
  if (tmp___0 < 0) {
#line 3363
    list_del_rcu(& (adm_ctx.tconn)->all_tconn);
#line 3364
    synchronize_rcu();
#line 3365
    kref_put(& (adm_ctx.tconn)->kref, & conn_destroy);
#line 3367
    retcode = NO_ERROR;
  } else {
#line 3369
    retcode = ERR_RES_IN_USE;
  }
#line 3372
  if ((unsigned int )retcode == 101U) {
#line 3373
    drbd_thread_stop(& (adm_ctx.tconn)->worker);
  } else {

  }
  out: 
#line 3375
  drbd_adm_finish(info, (int )retcode);
#line 3376
  return (0);
}
}
#line 3379 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void drbd_bcast_event(struct drbd_conf *mdev , struct sib_info  const  *sib ) 
{ 
  atomic_t drbd_genl_seq ;
  struct sk_buff *msg ;
  struct drbd_genlmsghdr *d_out ;
  unsigned int seq ;
  int err ;
  int tmp ;
  void *tmp___0 ;
  int tmp___1 ;

  {
#line 3381
  drbd_genl_seq.counter = 2;
#line 3385
  err = -12;
#line 3387
  if ((unsigned int )sib->sib_reason == 5U) {
#line 3388
    if ((1 != 0 && 1 != 0) && (long )(mdev->rs_last_bcast + 250UL) - (long )jiffies < 0L) {
#line 3389
      mdev->rs_last_bcast = jiffies;
    } else {
#line 3391
      return;
    }
  } else {

  }
#line 3394
  tmp = atomic_add_return(1, & drbd_genl_seq);
#line 3394
  seq = (unsigned int )tmp;
#line 3395
  msg = genlmsg_new(3776UL, 16U);
#line 3396
  if ((unsigned long )msg == (unsigned long )((struct sk_buff *)0)) {
#line 3397
    goto failed;
  } else {

  }
#line 3399
  err = -90;
#line 3400
  tmp___0 = genlmsg_put(msg, 0U, seq, & drbd_genl_family, 0, 1);
#line 3400
  d_out = (struct drbd_genlmsghdr *)tmp___0;
#line 3401
  if ((unsigned long )d_out == (unsigned long )((struct drbd_genlmsghdr *)0)) {
#line 3402
    goto nla_put_failure;
  } else {

  }
#line 3403
  d_out->minor = mdev_to_minor(mdev);
#line 3404
  d_out->ldv_49826.ret_code = 101;
#line 3406
  tmp___1 = nla_put_status_info(msg, mdev, sib);
#line 3406
  if (tmp___1 != 0) {
#line 3407
    goto nla_put_failure;
  } else {

  }
#line 3408
  genlmsg_end(msg, (void *)d_out);
#line 3409
  err = drbd_genl_multicast_events(msg, 0U);
#line 3411
  if (err != 0 && err != -3) {
#line 3412
    goto failed;
  } else {

  }
#line 3414
  return;
  nla_put_failure: 
#line 3417
  nlmsg_free(msg);
  failed: 
#line 3419
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Error %d while broadcasting event. Event seq:%u sib_reason:%u\n",
          err, seq, (unsigned int )sib->sib_reason);
#line 3422
  return;
}
}
#line 3424 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_279(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3429
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 3431
  mutex_lock(ldv_func_arg1);
#line 3432
  return;
}
}
#line 3434 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_280(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3439
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 3441
  mutex_unlock(ldv_func_arg1);
#line 3442
  return;
}
}
#line 3444 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_281(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3449
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 3451
  mutex_lock(ldv_func_arg1);
#line 3452
  return;
}
}
#line 3454 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
int ldv_mutex_trylock_282(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 3459
  tmp = mutex_trylock(ldv_func_arg1);
#line 3459
  ldv_func_res = tmp;
#line 3461
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 3461
  return (tmp___0);
#line 3463
  return (ldv_func_res);
}
}
#line 3466 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_283(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3471
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 3473
  mutex_unlock(ldv_func_arg1);
#line 3474
  return;
}
}
#line 3476 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_284(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3481
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 3483
  mutex_lock(ldv_func_arg1);
#line 3484
  return;
}
}
#line 3486 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_285(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3491
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 3493
  mutex_unlock(ldv_func_arg1);
#line 3494
  return;
}
}
#line 3496 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_286(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3501
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 3503
  mutex_lock(ldv_func_arg1);
#line 3504
  return;
}
}
#line 3506 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_287(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3511
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 3513
  mutex_unlock(ldv_func_arg1);
#line 3514
  return;
}
}
#line 3516 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_288(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3521
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 3523
  mutex_lock(ldv_func_arg1);
#line 3524
  return;
}
}
#line 3526 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_289(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3531
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 3533
  mutex_unlock(ldv_func_arg1);
#line 3534
  return;
}
}
#line 3536 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_290(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3541
  ldv_mutex_lock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 3543
  mutex_lock(ldv_func_arg1);
#line 3544
  return;
}
}
#line 3546 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_291(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3551
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3553
  mutex_lock(ldv_func_arg1);
#line 3554
  return;
}
}
#line 3556 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_292(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3561
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3563
  mutex_unlock(ldv_func_arg1);
#line 3564
  return;
}
}
#line 3566 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_293(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3571
  ldv_mutex_unlock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 3573
  mutex_unlock(ldv_func_arg1);
#line 3574
  return;
}
}
#line 3576 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_294(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3581
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3583
  mutex_lock(ldv_func_arg1);
#line 3584
  return;
}
}
#line 3586 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_295(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3591
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3593
  mutex_unlock(ldv_func_arg1);
#line 3594
  return;
}
}
#line 3596 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_296(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3601
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3603
  mutex_unlock(ldv_func_arg1);
#line 3604
  return;
}
}
#line 3606 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_297(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3611
  ldv_mutex_lock_mutex_of_drbd_socket(ldv_func_arg1);
#line 3613
  mutex_lock(ldv_func_arg1);
#line 3614
  return;
}
}
#line 3616 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_298(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3621
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3623
  mutex_lock(ldv_func_arg1);
#line 3624
  return;
}
}
#line 3626 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_299(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3631
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3633
  mutex_unlock(ldv_func_arg1);
#line 3634
  return;
}
}
#line 3636 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_300(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3641
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 3643
  mutex_unlock(ldv_func_arg1);
#line 3644
  return;
}
}
#line 3646 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_301(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3651
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3653
  mutex_unlock(ldv_func_arg1);
#line 3654
  return;
}
}
#line 3656 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_302(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3661
  ldv_mutex_unlock_mutex_of_drbd_socket(ldv_func_arg1);
#line 3663
  mutex_unlock(ldv_func_arg1);
#line 3664
  return;
}
}
#line 3666 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_303(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3671
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3673
  mutex_lock(ldv_func_arg1);
#line 3674
  return;
}
}
#line 3676 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_304(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3681
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3683
  mutex_unlock(ldv_func_arg1);
#line 3684
  return;
}
}
#line 3686 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_305(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3691
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3693
  mutex_unlock(ldv_func_arg1);
#line 3694
  return;
}
}
#line 3696 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_306(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3701
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3703
  mutex_lock(ldv_func_arg1);
#line 3704
  return;
}
}
#line 3706 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_307(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3711
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 3713
  mutex_unlock(ldv_func_arg1);
#line 3714
  return;
}
}
#line 3716 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_lock_308(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3721
  ldv_mutex_lock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 3723
  mutex_lock(ldv_func_arg1);
#line 3724
  return;
}
}
#line 3726 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nl.c.prepared"
void ldv_mutex_unlock_309(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 3731
  ldv_mutex_unlock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 3733
  mutex_unlock(ldv_func_arg1);
#line 3734
  return;
}
}
#line 66 "include/linux/rbtree.h"
extern struct rb_node *rb_next(struct rb_node  const  * ) ;
#line 75 "include/linux/rbtree.h"
__inline static void rb_link_node(struct rb_node *node , struct rb_node *parent ,
                                  struct rb_node **rb_link ) 
{ 
  struct rb_node *tmp ;

  {
#line 78
  node->__rb_parent_color = (unsigned long )parent;
#line 79
  tmp = 0;
#line 79
  node->rb_right = tmp;
#line 79
  node->rb_left = tmp;
#line 81
  *rb_link = node;
#line 82
  return;
}
}
#line 44 "include/linux/rbtree_augmented.h"
extern void __rb_insert_augmented(struct rb_node * , struct rb_root * , void (*)(struct rb_node * ,
                                                                                 struct rb_node * ) ) ;
#line 47 "include/linux/rbtree_augmented.h"
__inline static void rb_insert_augmented(struct rb_node *node , struct rb_root *root ,
                                         struct rb_augment_callbacks  const  *augment ) 
{ 


  {
#line 50
  __rb_insert_augmented(node, root, augment->rotate);
#line 51
  return;
}
}
#line 99 "include/linux/rbtree_augmented.h"
__inline static void rb_set_parent(struct rb_node *rb , struct rb_node *p ) 
{ 


  {
#line 101
  rb->__rb_parent_color = (rb->__rb_parent_color & 1UL) | (unsigned long )p;
#line 102
  return;
}
}
#line 104 "include/linux/rbtree_augmented.h"
__inline static void rb_set_parent_color(struct rb_node *rb , struct rb_node *p ,
                                         int color ) 
{ 


  {
#line 107
  rb->__rb_parent_color = (unsigned long )color | (unsigned long )p;
#line 108
  return;
}
}
#line 111 "include/linux/rbtree_augmented.h"
__inline static void __rb_change_child(struct rb_node *old , struct rb_node *new ,
                                       struct rb_node *parent , struct rb_root *root ) 
{ 


  {
#line 114
  if ((unsigned long )parent != (unsigned long )((struct rb_node *)0)) {
#line 115
    if ((unsigned long )parent->rb_left == (unsigned long )old) {
#line 116
      parent->rb_left = new;
    } else {
#line 118
      parent->rb_right = new;
    }
  } else {
#line 120
    root->rb_node = new;
  }
#line 121
  return;
}
}
#line 123
extern void __rb_erase_color(struct rb_node * , struct rb_root * , void (*)(struct rb_node * ,
                                                                            struct rb_node * ) ) ;
#line 127 "include/linux/rbtree_augmented.h"
__inline static void rb_erase_augmented(struct rb_node *node , struct rb_root *root ,
                                        struct rb_augment_callbacks  const  *augment ) 
{ 
  struct rb_node *child ;
  struct rb_node *tmp ;
  struct rb_node *parent ;
  struct rb_node *rebalance ;
  unsigned long pc ;
  struct rb_node *successor ;
  struct rb_node *child2 ;
  unsigned long pc2 ;

  {
#line 130
  child = node->rb_right;
#line 130
  tmp = node->rb_left;
#line 134
  if ((unsigned long )tmp == (unsigned long )((struct rb_node *)0)) {
#line 142
    pc = node->__rb_parent_color;
#line 143
    parent = (struct rb_node *)(pc & 0xfffffffffffffffcUL);
#line 144
    __rb_change_child(node, child, parent, root);
#line 145
    if ((unsigned long )child != (unsigned long )((struct rb_node *)0)) {
#line 146
      child->__rb_parent_color = pc;
#line 147
      rebalance = 0;
    } else {
#line 149
      rebalance = (int )pc & 1 ? parent : 0;
    }
#line 150
    tmp = parent;
  } else
#line 151
  if ((unsigned long )child == (unsigned long )((struct rb_node *)0)) {
#line 153
    pc = node->__rb_parent_color;
#line 153
    tmp->__rb_parent_color = pc;
#line 154
    parent = (struct rb_node *)(pc & 0xfffffffffffffffcUL);
#line 155
    __rb_change_child(node, tmp, parent, root);
#line 156
    rebalance = 0;
#line 157
    tmp = parent;
  } else {
#line 159
    successor = child;
#line 160
    tmp = child->rb_left;
#line 161
    if ((unsigned long )tmp == (unsigned long )((struct rb_node *)0)) {
#line 171
      parent = successor;
#line 172
      child2 = successor->rb_right;
#line 173
      (*(augment->copy))(node, successor);
    } else {
      ldv_6275: 
#line 190
      parent = successor;
#line 191
      successor = tmp;
#line 192
      tmp = tmp->rb_left;
#line 193
      if ((unsigned long )tmp != (unsigned long )((struct rb_node *)0)) {
#line 194
        goto ldv_6275;
      } else {

      }
#line 194
      child2 = successor->rb_right;
#line 194
      parent->rb_left = child2;
#line 195
      successor->rb_right = child;
#line 196
      rb_set_parent(child, successor);
#line 197
      (*(augment->copy))(node, successor);
#line 198
      (*(augment->propagate))(parent, successor);
    }
#line 201
    tmp = node->rb_left;
#line 201
    successor->rb_left = tmp;
#line 202
    rb_set_parent(tmp, successor);
#line 204
    pc = node->__rb_parent_color;
#line 205
    tmp = (struct rb_node *)(pc & 0xfffffffffffffffcUL);
#line 206
    __rb_change_child(node, successor, tmp, root);
#line 207
    if ((unsigned long )child2 != (unsigned long )((struct rb_node *)0)) {
#line 208
      successor->__rb_parent_color = pc;
#line 209
      rb_set_parent_color(child2, parent, 1);
#line 210
      rebalance = 0;
    } else {
#line 212
      pc2 = successor->__rb_parent_color;
#line 213
      successor->__rb_parent_color = pc;
#line 214
      rebalance = (int )pc2 & 1 ? parent : 0;
    }
#line 216
    tmp = successor;
  }
#line 219
  (*(augment->propagate))(tmp, 0);
#line 220
  if ((unsigned long )rebalance != (unsigned long )((struct rb_node *)0)) {
#line 221
    __rb_erase_color(rebalance, root, augment->rotate);
  } else {

  }
#line 222
  return;
}
}
#line 96 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
__inline static sector_t interval_end(struct rb_node *node ) 
{ 
  struct drbd_interval *this ;
  struct rb_node  const  *__mptr ;

  {
#line 98
  __mptr = (struct rb_node  const  *)node;
#line 98
  this = (struct drbd_interval *)__mptr;
#line 99
  return (this->end);
}
}
#line 110 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
__inline static sector_t compute_subtree_last(struct drbd_interval *node ) 
{ 
  sector_t max ;
  sector_t left ;
  sector_t tmp ;
  sector_t right ;
  sector_t tmp___0 ;

  {
#line 112
  max = node->sector + (sector_t )(node->size >> 9);
#line 114
  if ((unsigned long )node->rb.rb_left != (unsigned long )((struct rb_node *)0)) {
#line 115
    tmp = interval_end(node->rb.rb_left);
#line 115
    left = tmp;
#line 116
    if (left > max) {
#line 117
      max = left;
    } else {

    }
  } else {

  }
#line 119
  if ((unsigned long )node->rb.rb_right != (unsigned long )((struct rb_node *)0)) {
#line 120
    tmp___0 = interval_end(node->rb.rb_right);
#line 120
    right = tmp___0;
#line 121
    if (right > max) {
#line 122
      max = right;
    } else {

    }
  } else {

  }
#line 124
  return (max);
}
}
#line 127 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
static void augment_propagate(struct rb_node *rb , struct rb_node *stop ) 
{ 
  struct drbd_interval *node ;
  struct rb_node  const  *__mptr ;
  sector_t subtree_last ;
  sector_t tmp ;

  {
#line 129
  goto ldv_6331;
  ldv_6330: 
#line 130
  __mptr = (struct rb_node  const  *)rb;
#line 130
  node = (struct drbd_interval *)__mptr;
#line 131
  tmp = compute_subtree_last(node);
#line 131
  subtree_last = tmp;
#line 132
  if (node->end == subtree_last) {
#line 133
    goto ldv_6329;
  } else {

  }
#line 134
  node->end = subtree_last;
#line 135
  rb = (struct rb_node *)(node->rb.__rb_parent_color & 0xfffffffffffffffcUL);
  ldv_6331: ;
#line 129
  if ((unsigned long )rb != (unsigned long )stop) {
#line 130
    goto ldv_6330;
  } else {

  }
  ldv_6329: ;
#line 134
  return;
}
}
#line 139 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
static void augment_copy(struct rb_node *rb_old , struct rb_node *rb_new ) 
{ 
  struct drbd_interval *old ;
  struct rb_node  const  *__mptr ;
  struct drbd_interval *new ;
  struct rb_node  const  *__mptr___0 ;

  {
#line 141
  __mptr = (struct rb_node  const  *)rb_old;
#line 141
  old = (struct drbd_interval *)__mptr;
#line 142
  __mptr___0 = (struct rb_node  const  *)rb_new;
#line 142
  new = (struct drbd_interval *)__mptr___0;
#line 144
  new->end = old->end;
#line 145
  return;
}
}
#line 147 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
static void augment_rotate(struct rb_node *rb_old , struct rb_node *rb_new ) 
{ 
  struct drbd_interval *old ;
  struct rb_node  const  *__mptr ;
  struct drbd_interval *new ;
  struct rb_node  const  *__mptr___0 ;

  {
#line 149
  __mptr = (struct rb_node  const  *)rb_old;
#line 149
  old = (struct drbd_interval *)__mptr;
#line 150
  __mptr___0 = (struct rb_node  const  *)rb_new;
#line 150
  new = (struct drbd_interval *)__mptr___0;
#line 152
  new->end = old->end;
#line 153
  old->end = compute_subtree_last(old);
#line 154
  return;
}
}
#line 156 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
static struct rb_augment_callbacks  const  augment_callbacks  =    {& augment_propagate, & augment_copy, & augment_rotate};
#line 166 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
bool drbd_insert_interval(struct rb_root *root , struct drbd_interval *this ) 
{ 
  struct rb_node **new ;
  struct rb_node *parent ;
  long tmp ;
  struct drbd_interval *here ;
  struct rb_node  const  *__mptr ;

  {
#line 168
  new = & root->rb_node;
#line 168
  parent = 0;
#line 170
  tmp = __builtin_expect((this->size & 511U) != 0U, 0L);
#line 170
  if (tmp != 0L) {
#line 170
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"),
                         "i" (170), "i" (12UL));
    ldv_6359: ;
#line 170
    goto ldv_6359;
  } else {

  }
#line 172
  goto ldv_6364;
  ldv_6363: 
#line 174
  __mptr = (struct rb_node  const  *)*new;
#line 174
  here = (struct drbd_interval *)__mptr;
#line 176
  parent = *new;
#line 177
  if (this->sector < here->sector) {
#line 178
    new = & (*new)->rb_left;
  } else
#line 179
  if (this->sector > here->sector) {
#line 180
    new = & (*new)->rb_right;
  } else
#line 181
  if ((unsigned long )this < (unsigned long )here) {
#line 182
    new = & (*new)->rb_left;
  } else
#line 183
  if ((unsigned long )this > (unsigned long )here) {
#line 184
    new = & (*new)->rb_right;
  } else {
#line 186
    return (0);
  }
  ldv_6364: ;
#line 172
  if ((unsigned long )*new != (unsigned long )((struct rb_node *)0)) {
#line 173
    goto ldv_6363;
  } else {

  }
#line 189
  rb_link_node(& this->rb, parent, new);
#line 190
  rb_insert_augmented(& this->rb, root, & augment_callbacks);
#line 191
  return (1);
}
}
#line 205 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
bool drbd_contains_interval(struct rb_root *root , sector_t sector , struct drbd_interval *interval ) 
{ 
  struct rb_node *node ;
  struct drbd_interval *here ;
  struct rb_node  const  *__mptr ;

  {
#line 208
  node = root->rb_node;
#line 210
  goto ldv_6376;
  ldv_6375: 
#line 212
  __mptr = (struct rb_node  const  *)node;
#line 212
  here = (struct drbd_interval *)__mptr;
#line 214
  if (here->sector > sector) {
#line 215
    node = node->rb_left;
  } else
#line 216
  if (here->sector < sector) {
#line 217
    node = node->rb_right;
  } else
#line 218
  if ((unsigned long )interval < (unsigned long )here) {
#line 219
    node = node->rb_left;
  } else
#line 220
  if ((unsigned long )interval > (unsigned long )here) {
#line 221
    node = node->rb_right;
  } else {
#line 223
    return (1);
  }
  ldv_6376: ;
#line 210
  if ((unsigned long )node != (unsigned long )((struct rb_node *)0)) {
#line 211
    goto ldv_6375;
  } else {

  }

#line 225
  return (0);
}
}
#line 232 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
void drbd_remove_interval(struct rb_root *root , struct drbd_interval *this ) 
{ 


  {
#line 234
  rb_erase_augmented(& this->rb, root, & augment_callbacks);
#line 235
  return;
}
}
#line 249 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
struct drbd_interval *drbd_find_overlap(struct rb_root *root , sector_t sector , unsigned int size ) 
{ 
  struct rb_node *node ;
  struct drbd_interval *overlap ;
  sector_t end ;
  long tmp ;
  struct drbd_interval *here ;
  struct rb_node  const  *__mptr ;
  sector_t tmp___0 ;

  {
#line 251
  node = root->rb_node;
#line 252
  overlap = 0;
#line 253
  end = (sector_t )(size >> 9) + sector;
#line 255
  tmp = __builtin_expect((size & 511U) != 0U, 0L);
#line 255
  if (tmp != 0L) {
#line 255
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"),
                         "i" (255), "i" (12UL));
    ldv_6390: ;
#line 255
    goto ldv_6390;
  } else {

  }
#line 257
  goto ldv_6396;
  ldv_6395: 
#line 259
  __mptr = (struct rb_node  const  *)node;
#line 259
  here = (struct drbd_interval *)__mptr;
#line 261
  if ((unsigned long )node->rb_left != (unsigned long )((struct rb_node *)0)) {
#line 261
    tmp___0 = interval_end(node->rb_left);
#line 261
    if (tmp___0 > sector) {
#line 264
      node = node->rb_left;
    } else {
#line 261
      goto _L;
    }
  } else
  _L: /* CIL Label */ 
#line 265
  if (here->sector < end && here->sector + (sector_t )(here->size >> 9) > sector) {
#line 267
    overlap = here;
#line 268
    goto ldv_6394;
  } else
#line 269
  if (here->sector <= sector) {
#line 271
    node = node->rb_right;
  } else {
#line 273
    goto ldv_6394;
  }
  ldv_6396: ;
#line 257
  if ((unsigned long )node != (unsigned long )((struct rb_node *)0)) {
#line 258
    goto ldv_6395;
  } else {

  }
  ldv_6394: ;
#line 275
  return (overlap);
}
}
#line 279 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_interval.c.prepared"
struct drbd_interval *drbd_next_overlap(struct drbd_interval *i , sector_t sector ,
                                        unsigned int size ) 
{ 
  sector_t end ;
  struct rb_node *node ;
  struct rb_node  const  *__mptr ;

  {
#line 281
  end = (sector_t )(size >> 9) + sector;
  ldv_6406: 
#line 285
  node = rb_next((struct rb_node  const  *)(& i->rb));
#line 286
  if ((unsigned long )node == (unsigned long )((struct rb_node *)0)) {
#line 287
    return (0);
  } else {

  }
#line 288
  __mptr = (struct rb_node  const  *)node;
#line 288
  i = (struct drbd_interval *)__mptr;
#line 289
  if (i->sector >= end) {
#line 290
    return (0);
  } else {

  }
#line 291
  if (i->sector + (sector_t )(i->size >> 9) > sector) {
#line 292
    return (i);
  } else {

  }
#line 293
  goto ldv_6406;
}
}
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_346(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_342(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_344(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_347(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_349(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_351(struct mutex *ldv_func_arg1 ) ;
#line 196
void ldv_mutex_unlock_353(struct mutex *ldv_func_arg1 ) ;
#line 200
void ldv_mutex_unlock_355(struct mutex *ldv_func_arg1 ) ;
#line 204
void ldv_mutex_unlock_357(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_341(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_343(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_345(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_348(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_350(struct mutex *ldv_func_arg1 ) ;
#line 30
void ldv_mutex_lock_352(struct mutex *ldv_func_arg1 ) ;
#line 34
void ldv_mutex_lock_354(struct mutex *ldv_func_arg1 ) ;
#line 38
void ldv_mutex_lock_356(struct mutex *ldv_func_arg1 ) ;
#line 67
void ldv_mutex_lock_cstate_mutex_of_drbd_tconn(struct mutex *lock ) ;
#line 71
void ldv_mutex_unlock_cstate_mutex_of_drbd_tconn(struct mutex *lock ) ;
#line 208 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info___7(void) 
{ 
  struct thread_info *ti ;
  unsigned long pfo_ret__ ;

  {
#line 211
  switch (8UL) {
  case 1UL: 
#line 211
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6444;
  case 2UL: 
#line 211
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6444;
  case 4UL: 
#line 211
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6444;
  case 8UL: 
#line 211
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& kernel_stack));
#line 211
  goto ldv_6444;
  default: 
#line 211
  __bad_percpu_size();
  }
  ldv_6444: 
#line 211
  ti = (struct thread_info *)(pfo_ret__ - 8152UL);
#line 213
  return (ti);
}
}
#line 163 "include/linux/rcupdate.h"
__inline static void __rcu_read_lock___7(void) 
{ 
  struct thread_info *tmp ;

  {
#line 165
  tmp = current_thread_info___7();
#line 165
  tmp->preempt_count = tmp->preempt_count + 1;
#line 165
  __asm__  volatile   ("": : : "memory");
#line 166
  return;
}
}
#line 168 "include/linux/rcupdate.h"
__inline static void __rcu_read_unlock___7(void) 
{ 
  struct thread_info *tmp ;

  {
#line 170
  __asm__  volatile   ("": : : "memory");
#line 170
  tmp = current_thread_info___7();
#line 170
  tmp->preempt_count = tmp->preempt_count + -1;
#line 170
  __asm__  volatile   ("": : : "memory");
#line 171
  return;
}
}
#line 732 "include/linux/rcupdate.h"
__inline static void rcu_read_lock___7(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 734
  __rcu_read_lock___7();
#line 736
  rcu_lock_acquire(& rcu_lock_map);
#line 737
  tmp = debug_lockdep_rcu_enabled();
#line 737
  if (tmp != 0 && ! __warned) {
#line 737
    tmp___0 = rcu_is_cpu_idle();
#line 737
    if (tmp___0 != 0) {
#line 737
      __warned = 1;
#line 737
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 738, "rcu_read_lock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 740
  return;
}
}
#line 756 "include/linux/rcupdate.h"
__inline static void rcu_read_unlock___7(void) 
{ 
  bool __warned ;
  int tmp ;
  int tmp___0 ;

  {
#line 758
  tmp = debug_lockdep_rcu_enabled();
#line 758
  if (tmp != 0 && ! __warned) {
#line 758
    tmp___0 = rcu_is_cpu_idle();
#line 758
    if (tmp___0 != 0) {
#line 758
      __warned = 1;
#line 758
      lockdep_rcu_suspicious("include/linux/rcupdate.h", 759, "rcu_read_unlock() used illegally while idle");
    } else {

    }
  } else {

  }
#line 760
  rcu_lock_release(& rcu_lock_map);
#line 762
  __rcu_read_unlock___7();
#line 763
  return;
}
}
#line 123 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_state.h"
void print_st_err(struct drbd_conf *mdev , union drbd_state os , union drbd_state ns ,
                  enum drbd_state_rv err ) ;
#line 157
enum drbd_disk_state conn_lowest_disk(struct drbd_tconn *tconn ) ;
#line 159
enum drbd_conns conn_lowest_conn(struct drbd_tconn *tconn ) ;
#line 1937 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_thread_stop_nowait(struct drbd_thread *thi ) 
{ 


  {
#line 1939
  _drbd_thread_stop(thi, 0, 0);
#line 1940
  return;
}
}
#line 1942 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/block/drbd/drbd_int.h"
__inline static void drbd_thread_restart_nowait(struct drbd_thread *thi ) 
{ 


  {
#line 1944
  _drbd_thread_stop(thi, 1, 0);
#line 1945
  return;
}
}
#line 139 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static int w_after_state_ch(struct drbd_work *w , int unused ) ;
#line 140
static void after_state_ch(struct drbd_conf *mdev , union drbd_state os , union drbd_state ns ,
                           enum chg_state_flags flags ) ;
#line 142
static enum drbd_state_rv is_valid_state(struct drbd_conf *mdev , union drbd_state ns ) ;
#line 143
static enum drbd_state_rv is_valid_soft_transition(union drbd_state os , union drbd_state ns ,
                                                   struct drbd_tconn *tconn ) ;
#line 144
static enum drbd_state_rv is_valid_transition(union drbd_state os , union drbd_state ns ) ;
#line 145
static union drbd_state sanitize_state(struct drbd_conf *mdev , union drbd_state ns ,
                                       enum sanitize_state_warnings *warn ) ;
#line 148 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
__inline static bool is_susp(union drbd_state s ) 
{ 


  {
#line 150
  return ((bool )(((unsigned int )*((unsigned char *)(& s) + 2UL) != 0U || (unsigned int )*((unsigned char *)(& s) + 2UL) != 0U) || (unsigned int )*((unsigned char *)(& s) + 2UL) != 0U));
}
}
#line 153 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
bool conn_all_vols_unconf(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  bool rv ;
  int vnr ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 156
  rv = 1;
#line 159
  rcu_read_lock___7();
#line 160
  vnr = 0;
#line 160
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 160
  mdev = (struct drbd_conf *)tmp;
#line 160
  goto ldv_52059;
  ldv_52058: ;
#line 161
  if (((unsigned int )*((unsigned char *)mdev + 749UL) != 0U || (unsigned int )*((unsigned short *)mdev + 374UL) != 0U) || (unsigned int )*((unsigned char *)mdev + 748UL) != 2U) {
#line 164
    rv = 0;
#line 165
    goto ldv_52057;
  } else {

  }
#line 160
  vnr = vnr + 1;
#line 160
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 160
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52059: ;
#line 160
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 161
    goto ldv_52058;
  } else {

  }
  ldv_52057: 
#line 168
  rcu_read_unlock___7();
#line 170
  return (rv);
}
}
#line 175 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_role max_role(enum drbd_role role1 , enum drbd_role role2 ) 
{ 


  {
#line 177
  if ((unsigned int )role1 == 1U || (unsigned int )role2 == 1U) {
#line 178
    return (R_PRIMARY);
  } else {

  }
#line 179
  if ((unsigned int )role1 == 2U || (unsigned int )role2 == 2U) {
#line 180
    return (R_SECONDARY);
  } else {

  }
#line 181
  return (R_UNKNOWN);
}
}
#line 183 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_role min_role(enum drbd_role role1 , enum drbd_role role2 ) 
{ 


  {
#line 185
  if ((unsigned int )role1 == 0U || (unsigned int )role2 == 0U) {
#line 186
    return (R_UNKNOWN);
  } else {

  }
#line 187
  if ((unsigned int )role1 == 2U || (unsigned int )role2 == 2U) {
#line 188
    return (R_SECONDARY);
  } else {

  }
#line 189
  return (R_PRIMARY);
}
}
#line 192 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_role conn_highest_role(struct drbd_tconn *tconn ) 
{ 
  enum drbd_role role ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 194
  role = R_UNKNOWN;
#line 198
  rcu_read_lock___7();
#line 199
  vnr = 0;
#line 199
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 199
  mdev = (struct drbd_conf *)tmp;
#line 199
  goto ldv_52075;
  ldv_52074: 
#line 200
  role = max_role(role, (enum drbd_role )mdev->state.ldv_49522.role);
#line 199
  vnr = vnr + 1;
#line 199
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 199
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52075: ;
#line 199
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 200
    goto ldv_52074;
  } else {

  }
#line 201
  rcu_read_unlock___7();
#line 203
  return (role);
}
}
#line 206 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_role conn_highest_peer(struct drbd_tconn *tconn ) 
{ 
  enum drbd_role peer ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 208
  peer = R_UNKNOWN;
#line 212
  rcu_read_lock___7();
#line 213
  vnr = 0;
#line 213
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 213
  mdev = (struct drbd_conf *)tmp;
#line 213
  goto ldv_52084;
  ldv_52083: 
#line 214
  peer = max_role(peer, (enum drbd_role )mdev->state.ldv_49522.peer);
#line 213
  vnr = vnr + 1;
#line 213
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 213
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52084: ;
#line 213
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 214
    goto ldv_52083;
  } else {

  }
#line 215
  rcu_read_unlock___7();
#line 217
  return (peer);
}
}
#line 220 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_disk_state conn_highest_disk(struct drbd_tconn *tconn ) 
{ 
  enum drbd_disk_state ds ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  enum drbd_disk_state __max1 ;
  enum drbd_disk_state __max2 ;
  void *tmp___0 ;

  {
#line 222
  ds = D_DISKLESS;
#line 226
  rcu_read_lock___7();
#line 227
  vnr = 0;
#line 227
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 227
  mdev = (struct drbd_conf *)tmp;
#line 227
  goto ldv_52096;
  ldv_52095: 
#line 228
  __max1 = ds;
#line 228
  __max2 = (enum drbd_disk_state )mdev->state.ldv_49522.disk;
#line 228
  ds = (enum drbd_disk_state )((unsigned int )__max1 > (unsigned int )__max2 ? (unsigned int )__max1 : (unsigned int )__max2);
#line 227
  vnr = vnr + 1;
#line 227
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 227
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52096: ;
#line 227
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 228
    goto ldv_52095;
  } else {

  }
#line 229
  rcu_read_unlock___7();
#line 231
  return (ds);
}
}
#line 234 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_disk_state conn_lowest_disk(struct drbd_tconn *tconn ) 
{ 
  enum drbd_disk_state ds ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  enum drbd_disk_state __min1 ;
  enum drbd_disk_state __min2 ;
  void *tmp___0 ;

  {
#line 236
  ds = D_MASK;
#line 240
  rcu_read_lock___7();
#line 241
  vnr = 0;
#line 241
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 241
  mdev = (struct drbd_conf *)tmp;
#line 241
  goto ldv_52108;
  ldv_52107: 
#line 242
  __min1 = ds;
#line 242
  __min2 = (enum drbd_disk_state )mdev->state.ldv_49522.disk;
#line 242
  ds = (enum drbd_disk_state )((unsigned int )__min1 < (unsigned int )__min2 ? (unsigned int )__min1 : (unsigned int )__min2);
#line 241
  vnr = vnr + 1;
#line 241
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 241
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52108: ;
#line 241
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 242
    goto ldv_52107;
  } else {

  }
#line 243
  rcu_read_unlock___7();
#line 245
  return (ds);
}
}
#line 248 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_disk_state conn_highest_pdsk(struct drbd_tconn *tconn ) 
{ 
  enum drbd_disk_state ds ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  enum drbd_disk_state __max1 ;
  enum drbd_disk_state __max2 ;
  void *tmp___0 ;

  {
#line 250
  ds = D_DISKLESS;
#line 254
  rcu_read_lock___7();
#line 255
  vnr = 0;
#line 255
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 255
  mdev = (struct drbd_conf *)tmp;
#line 255
  goto ldv_52120;
  ldv_52119: 
#line 256
  __max1 = ds;
#line 256
  __max2 = (enum drbd_disk_state )mdev->state.ldv_49522.pdsk;
#line 256
  ds = (enum drbd_disk_state )((unsigned int )__max1 > (unsigned int )__max2 ? (unsigned int )__max1 : (unsigned int )__max2);
#line 255
  vnr = vnr + 1;
#line 255
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 255
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52120: ;
#line 255
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 256
    goto ldv_52119;
  } else {

  }
#line 257
  rcu_read_unlock___7();
#line 259
  return (ds);
}
}
#line 262 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_conns conn_lowest_conn(struct drbd_tconn *tconn ) 
{ 
  enum drbd_conns conn ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  enum drbd_conns __min1 ;
  enum drbd_conns __min2 ;
  void *tmp___0 ;

  {
#line 264
  conn = C_MASK;
#line 268
  rcu_read_lock___7();
#line 269
  vnr = 0;
#line 269
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 269
  mdev = (struct drbd_conf *)tmp;
#line 269
  goto ldv_52132;
  ldv_52131: 
#line 270
  __min1 = conn;
#line 270
  __min2 = (enum drbd_conns )mdev->state.ldv_49522.conn;
#line 270
  conn = (enum drbd_conns )((unsigned int )__min1 < (unsigned int )__min2 ? (unsigned int )__min1 : (unsigned int )__min2);
#line 269
  vnr = vnr + 1;
#line 269
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 269
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52132: ;
#line 269
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 270
    goto ldv_52131;
  } else {

  }
#line 271
  rcu_read_unlock___7();
#line 273
  return (conn);
}
}
#line 276 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static bool no_peer_wf_report_params(struct drbd_tconn *tconn ) 
{ 
  struct drbd_conf *mdev ;
  int vnr ;
  bool rv ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 280
  rv = 1;
#line 282
  rcu_read_lock___7();
#line 283
  vnr = 0;
#line 283
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 283
  mdev = (struct drbd_conf *)tmp;
#line 283
  goto ldv_52142;
  ldv_52141: ;
#line 284
  if ((unsigned int )*((unsigned short *)mdev + 374UL) == 144U) {
#line 285
    rv = 0;
#line 286
    goto ldv_52140;
  } else {

  }
#line 283
  vnr = vnr + 1;
#line 283
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 283
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52142: ;
#line 283
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 284
    goto ldv_52141;
  } else {

  }
  ldv_52140: 
#line 288
  rcu_read_unlock___7();
#line 290
  return (rv);
}
}
#line 300 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static int cl_wide_st_chg(struct drbd_conf *mdev , union drbd_state os , union drbd_state ns ) 
{ 


  {
#line 303
  return ((((((int )os.ldv_40024.conn > 9 && (int )ns.ldv_40024.conn > 9) && (((((unsigned int )*((unsigned char *)(& os) + 0UL) != 1U && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U) || ((unsigned int )*((unsigned short *)(& os) + 0UL) != 192U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 192U)) || ((unsigned int )*((unsigned short *)(& os) + 0UL) != 176U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 176U)) || ((unsigned int )*((unsigned char *)(& os) + 1UL) != 4U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 4U))) || ((int )os.ldv_40024.conn > 9 && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 16U)) || ((unsigned int )*((unsigned short *)(& os) + 0UL) == 160U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U)) || ((unsigned int )*((unsigned short *)(& os) + 0UL) == 160U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 144U));
}
}
#line 314 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static union drbd_state apply_mask_val(union drbd_state os , union drbd_state mask ,
                                       union drbd_state val ) 
{ 
  union drbd_state ns ;

  {
#line 317
  ns.i = (os.i & ~ mask.i) | val.i;
#line 318
  return (ns);
}
}
#line 322 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_state_rv drbd_change_state(struct drbd_conf *mdev , enum chg_state_flags f ,
                                     union drbd_state mask , union drbd_state val ) 
{ 
  unsigned long flags ;
  union drbd_state ns ;
  enum drbd_state_rv rv ;
  raw_spinlock_t *tmp ;
  union drbd_state tmp___0 ;

  {
#line 329
  tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 329
  flags = _raw_spin_lock_irqsave(tmp);
#line 330
  tmp___0 = drbd_read_state(mdev);
#line 330
  ns = apply_mask_val(tmp___0, mask, val);
#line 331
  rv = _drbd_set_state(mdev, ns, f, 0);
#line 332
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 334
  return (rv);
}
}
#line 343 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void drbd_force_state(struct drbd_conf *mdev , union drbd_state mask , union drbd_state val ) 
{ 


  {
#line 346
  drbd_change_state(mdev, CS_HARD, mask, val);
#line 347
  return;
}
}
#line 350 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv _req_st_cond(struct drbd_conf *mdev , union drbd_state mask ,
                                       union drbd_state val ) 
{ 
  union drbd_state os ;
  union drbd_state ns ;
  unsigned long flags ;
  enum drbd_state_rv rv ;
  int tmp ;
  int tmp___0 ;
  raw_spinlock_t *tmp___1 ;
  union drbd_state tmp___2 ;
  int tmp___3 ;

  {
#line 357
  tmp = test_and_clear_bit(3, (unsigned long volatile   *)(& mdev->flags));
#line 357
  if (tmp != 0) {
#line 358
    return (SS_CW_SUCCESS);
  } else {

  }
#line 360
  tmp___0 = test_and_clear_bit(4, (unsigned long volatile   *)(& mdev->flags));
#line 360
  if (tmp___0 != 0) {
#line 361
    return (SS_CW_FAILED_BY_PEER);
  } else {

  }
#line 363
  tmp___1 = spinlock_check(& (mdev->tconn)->req_lock);
#line 363
  flags = _raw_spin_lock_irqsave(tmp___1);
#line 364
  os = drbd_read_state(mdev);
#line 365
  tmp___2 = apply_mask_val(os, mask, val);
#line 365
  ns = sanitize_state(mdev, tmp___2, 0);
#line 366
  rv = is_valid_transition(os, ns);
#line 367
  if ((int )rv > 0) {
#line 368
    rv = SS_UNKNOWN_ERROR;
  } else {

  }
#line 370
  tmp___3 = cl_wide_st_chg(mdev, os, ns);
#line 370
  if (tmp___3 == 0) {
#line 371
    rv = SS_CW_NO_NEED;
  } else {

  }
#line 372
  if ((int )rv == 0) {
#line 373
    rv = is_valid_state(mdev, ns);
#line 374
    if ((int )rv > 0) {
#line 375
      rv = is_valid_soft_transition(os, ns, mdev->tconn);
#line 376
      if ((int )rv > 0) {
#line 377
        rv = SS_UNKNOWN_ERROR;
      } else {

      }
    } else {

    }
  } else {

  }
#line 380
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 382
  return (rv);
}
}
#line 396 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv drbd_req_state(struct drbd_conf *mdev , union drbd_state mask ,
                                         union drbd_state val , enum chg_state_flags f ) 
{ 
  struct completion done ;
  unsigned long flags ;
  union drbd_state os ;
  union drbd_state ns ;
  enum drbd_state_rv rv ;
  raw_spinlock_t *tmp ;
  union drbd_state tmp___0 ;
  int tmp___1 ;
  wait_queue_t __wait ;
  struct task_struct *tmp___2 ;
  raw_spinlock_t *tmp___3 ;
  union drbd_state tmp___4 ;
  int tmp___5 ;
  struct task_struct *tmp___6 ;

  {
#line 404
  init_completion(& done);
#line 406
  if (((unsigned int )f & 8U) != 0U) {
#line 407
    ldv_mutex_lock_352(mdev->state_mutex);
  } else {

  }
#line 409
  tmp = spinlock_check(& (mdev->tconn)->req_lock);
#line 409
  flags = _raw_spin_lock_irqsave(tmp);
#line 410
  os = drbd_read_state(mdev);
#line 411
  tmp___0 = apply_mask_val(os, mask, val);
#line 411
  ns = sanitize_state(mdev, tmp___0, 0);
#line 412
  rv = is_valid_transition(os, ns);
#line 413
  if ((int )rv <= 0) {
#line 414
    spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 415
    goto abort;
  } else {

  }
#line 418
  tmp___5 = cl_wide_st_chg(mdev, os, ns);
#line 418
  if (tmp___5 != 0) {
#line 419
    rv = is_valid_state(mdev, ns);
#line 420
    if ((int )rv == 1) {
#line 421
      rv = is_valid_soft_transition(os, ns, mdev->tconn);
    } else {

    }
#line 422
    spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 424
    if ((int )rv <= 0) {
#line 425
      if (((unsigned int )f & 2U) != 0U) {
#line 426
        print_st_err(mdev, os, ns, (int )rv);
      } else {

      }
#line 427
      goto abort;
    } else {

    }
#line 430
    tmp___1 = drbd_send_state_req(mdev, mask, val);
#line 430
    if (tmp___1 != 0) {
#line 431
      rv = SS_CW_FAILED_BY_PEER;
#line 432
      if (((unsigned int )f & 2U) != 0U) {
#line 433
        print_st_err(mdev, os, ns, (int )rv);
      } else {

      }
#line 434
      goto abort;
    } else {

    }
#line 437
    rv = _req_st_cond(mdev, mask, val);
#line 437
    if ((int )rv != 0) {
#line 437
      goto ldv_52198;
    } else {

    }
#line 437
    tmp___2 = get_current();
#line 437
    __wait.flags = 0U;
#line 437
    __wait.private = (void *)tmp___2;
#line 437
    __wait.func = & autoremove_wake_function;
#line 437
    __wait.task_list.next = & __wait.task_list;
#line 437
    __wait.task_list.prev = & __wait.task_list;
    ldv_52201: 
#line 437
    prepare_to_wait(& mdev->state_wait, & __wait, 2);
#line 437
    rv = _req_st_cond(mdev, mask, val);
#line 437
    if ((int )rv != 0) {
#line 437
      goto ldv_52200;
    } else {

    }
#line 437
    schedule();
#line 437
    goto ldv_52201;
    ldv_52200: 
#line 437
    finish_wait(& mdev->state_wait, & __wait);
    ldv_52198: ;
#line 440
    if ((int )rv <= 0) {
#line 441
      if (((unsigned int )f & 2U) != 0U) {
#line 442
        print_st_err(mdev, os, ns, (int )rv);
      } else {

      }
#line 443
      goto abort;
    } else {

    }
#line 445
    tmp___3 = spinlock_check(& (mdev->tconn)->req_lock);
#line 445
    flags = _raw_spin_lock_irqsave(tmp___3);
#line 446
    tmp___4 = drbd_read_state(mdev);
#line 446
    ns = apply_mask_val(tmp___4, mask, val);
#line 447
    rv = _drbd_set_state(mdev, ns, f, & done);
  } else {
#line 449
    rv = _drbd_set_state(mdev, ns, f, & done);
  }
#line 452
  spin_unlock_irqrestore(& (mdev->tconn)->req_lock, flags);
#line 454
  if (((unsigned int )f & 4U) != 0U && (int )rv == 1) {
#line 455
    tmp___6 = get_current();
#line 455
    if ((unsigned long )tmp___6 == (unsigned long )(mdev->tconn)->worker.task) {
#line 455
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( current != mdev->tconn->worker.task ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared",
              455);
    } else {

    }
#line 456
    wait_for_completion(& done);
  } else {

  }
  abort: ;
#line 460
  if (((unsigned int )f & 8U) != 0U) {
#line 461
    ldv_mutex_unlock_353(mdev->state_mutex);
  } else {

  }
#line 463
  return (rv);
}
}
#line 477 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_state_rv _drbd_request_state(struct drbd_conf *mdev , union drbd_state mask ,
                                       union drbd_state val , enum chg_state_flags f ) 
{ 
  enum drbd_state_rv rv ;
  wait_queue_t __wait ;
  struct task_struct *tmp ;

  {
#line 482
  rv = drbd_req_state(mdev, mask, val, f);
#line 482
  if ((int )rv != -18) {
#line 482
    goto ldv_52212;
  } else {

  }
#line 482
  tmp = get_current();
#line 482
  __wait.flags = 0U;
#line 482
  __wait.private = (void *)tmp;
#line 482
  __wait.func = & autoremove_wake_function;
#line 482
  __wait.task_list.next = & __wait.task_list;
#line 482
  __wait.task_list.prev = & __wait.task_list;
  ldv_52215: 
#line 482
  prepare_to_wait(& mdev->state_wait, & __wait, 2);
#line 482
  rv = drbd_req_state(mdev, mask, val, f);
#line 482
  if ((int )rv != -18) {
#line 482
    goto ldv_52214;
  } else {

  }
#line 482
  schedule();
#line 482
  goto ldv_52215;
  ldv_52214: 
#line 482
  finish_wait(& mdev->state_wait, & __wait);
  ldv_52212: ;
#line 485
  return (rv);
}
}
#line 488 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static void print_st(struct drbd_conf *mdev , char *name , union drbd_state ns ) 
{ 
  bool tmp ;
  char const   *tmp___0 ;
  char const   *tmp___1 ;
  char const   *tmp___2 ;
  char const   *tmp___3 ;
  char const   *tmp___4 ;

  {
#line 490
  tmp = is_susp(ns);
#line 490
  tmp___0 = drbd_disk_str((enum drbd_disk_state )ns.ldv_40024.pdsk);
#line 490
  tmp___1 = drbd_disk_str((enum drbd_disk_state )ns.ldv_40024.disk);
#line 490
  tmp___2 = drbd_role_str((enum drbd_role )ns.ldv_40024.peer);
#line 490
  tmp___3 = drbd_role_str((enum drbd_role )ns.ldv_40024.role);
#line 490
  tmp___4 = drbd_conn_str((enum drbd_conns )ns.ldv_40024.conn);
#line 490
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), " %s = { cs:%s ro:%s/%s ds:%s/%s %c%c%c%c%c%c }\n",
          name, tmp___4, tmp___3, tmp___2, tmp___1, tmp___0, (int )tmp ? 115 : 114,
          (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U ? 97 : 45, (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U ? 112 : 45,
          (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U ? 117 : 45, (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U ? 70 : 45,
          (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U ? 78 : 45);
#line 503
  return;
}
}
#line 506 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void print_st_err(struct drbd_conf *mdev , union drbd_state os , union drbd_state ns ,
                  enum drbd_state_rv err ) 
{ 
  char const   *tmp ;

  {
#line 509
  if ((int )err == -18) {
#line 510
    return;
  } else {

  }
#line 511
  tmp = drbd_set_st_err_str(err);
#line 511
  dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "State change failed: %s\n",
          tmp);
#line 512
  print_st(mdev, (char *)" state", os);
#line 513
  print_st(mdev, (char *)"wanted", ns);
#line 514
  return;
}
}
#line 516 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static long print_state_change(char *pb , union drbd_state os , union drbd_state ns ,
                               enum chg_state_flags flags ) 
{ 
  char *pbp ;
  char const   *tmp ;
  char const   *tmp___0 ;
  int tmp___1 ;
  char const   *tmp___2 ;
  char const   *tmp___3 ;
  int tmp___4 ;
  char const   *tmp___5 ;
  char const   *tmp___6 ;
  int tmp___7 ;
  char const   *tmp___8 ;
  char const   *tmp___9 ;
  int tmp___10 ;
  char const   *tmp___11 ;
  char const   *tmp___12 ;
  int tmp___13 ;

  {
#line 520
  pbp = pb;
#line 521
  *pbp = 0;
#line 523
  if ((int )ns.ldv_40024.role != (int )os.ldv_40024.role && ((unsigned int )flags & 32U) != 0U) {
#line 524
    tmp = drbd_role_str((enum drbd_role )ns.ldv_40024.role);
#line 524
    tmp___0 = drbd_role_str((enum drbd_role )os.ldv_40024.role);
#line 524
    tmp___1 = sprintf(pbp, "role( %s -> %s ) ", tmp___0, tmp);
#line 524
    pbp = pbp + (unsigned long )tmp___1;
  } else {

  }
#line 527
  if ((int )ns.ldv_40024.peer != (int )os.ldv_40024.peer && ((unsigned int )flags & 64U) != 0U) {
#line 528
    tmp___2 = drbd_role_str((enum drbd_role )ns.ldv_40024.peer);
#line 528
    tmp___3 = drbd_role_str((enum drbd_role )os.ldv_40024.peer);
#line 528
    tmp___4 = sprintf(pbp, "peer( %s -> %s ) ", tmp___3, tmp___2);
#line 528
    pbp = pbp + (unsigned long )tmp___4;
  } else {

  }
#line 531
  if ((int )ns.ldv_40024.conn != (int )os.ldv_40024.conn && ((unsigned int )flags & 128U) != 0U) {
#line 532
    tmp___5 = drbd_conn_str((enum drbd_conns )ns.ldv_40024.conn);
#line 532
    tmp___6 = drbd_conn_str((enum drbd_conns )os.ldv_40024.conn);
#line 532
    tmp___7 = sprintf(pbp, "conn( %s -> %s ) ", tmp___6, tmp___5);
#line 532
    pbp = pbp + (unsigned long )tmp___7;
  } else {

  }
#line 535
  if ((int )ns.ldv_40024.disk != (int )os.ldv_40024.disk && ((unsigned int )flags & 256U) != 0U) {
#line 536
    tmp___8 = drbd_disk_str((enum drbd_disk_state )ns.ldv_40024.disk);
#line 536
    tmp___9 = drbd_disk_str((enum drbd_disk_state )os.ldv_40024.disk);
#line 536
    tmp___10 = sprintf(pbp, "disk( %s -> %s ) ", tmp___9, tmp___8);
#line 536
    pbp = pbp + (unsigned long )tmp___10;
  } else {

  }
#line 539
  if ((int )ns.ldv_40024.pdsk != (int )os.ldv_40024.pdsk && ((unsigned int )flags & 512U) != 0U) {
#line 540
    tmp___11 = drbd_disk_str((enum drbd_disk_state )ns.ldv_40024.pdsk);
#line 540
    tmp___12 = drbd_disk_str((enum drbd_disk_state )os.ldv_40024.pdsk);
#line 540
    tmp___13 = sprintf(pbp, "pdsk( %s -> %s ) ", tmp___12, tmp___11);
#line 540
    pbp = pbp + (unsigned long )tmp___13;
  } else {

  }
#line 544
  return ((long )pbp - (long )pb);
}
}
#line 547 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static void drbd_pr_state_change(struct drbd_conf *mdev , union drbd_state os , union drbd_state ns ,
                                 enum chg_state_flags flags ) 
{ 
  char pb[300U] ;
  char *pbp ;
  long tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 551
  pbp = (char *)(& pb);
#line 553
  tmp = print_state_change(pbp, os, ns, (enum chg_state_flags )((unsigned int )flags ^ 992U));
#line 553
  pbp = pbp + (unsigned long )tmp;
#line 555
  if ((int )ns.ldv_40024.aftr_isp != (int )os.ldv_40024.aftr_isp) {
#line 556
    tmp___0 = sprintf(pbp, "aftr_isp( %d -> %d ) ", (int )os.ldv_40024.aftr_isp, (int )ns.ldv_40024.aftr_isp);
#line 556
    pbp = pbp + (unsigned long )tmp___0;
  } else {

  }
#line 559
  if ((int )ns.ldv_40024.peer_isp != (int )os.ldv_40024.peer_isp) {
#line 560
    tmp___1 = sprintf(pbp, "peer_isp( %d -> %d ) ", (int )os.ldv_40024.peer_isp, (int )ns.ldv_40024.peer_isp);
#line 560
    pbp = pbp + (unsigned long )tmp___1;
  } else {

  }
#line 563
  if ((int )ns.ldv_40024.user_isp != (int )os.ldv_40024.user_isp) {
#line 564
    tmp___2 = sprintf(pbp, "user_isp( %d -> %d ) ", (int )os.ldv_40024.user_isp, (int )ns.ldv_40024.user_isp);
#line 564
    pbp = pbp + (unsigned long )tmp___2;
  } else {

  }
#line 568
  if ((unsigned long )((char *)(& pb)) != (unsigned long )pbp) {
#line 569
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s\n", (char *)(& pb));
  } else {

  }
#line 570
  return;
}
}
#line 572 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static void conn_pr_state_change(struct drbd_tconn *tconn , union drbd_state os ,
                                 union drbd_state ns , enum chg_state_flags flags ) 
{ 
  char pb[300U] ;
  char *pbp ;
  long tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  bool tmp___3 ;
  bool tmp___4 ;

  {
#line 576
  pbp = (char *)(& pb);
#line 578
  tmp = print_state_change(pbp, os, ns, flags);
#line 578
  pbp = pbp + (unsigned long )tmp;
#line 580
  tmp___3 = is_susp(ns);
#line 580
  tmp___4 = is_susp(os);
#line 580
  if ((int )tmp___3 != (int )tmp___4 && ((unsigned int )flags & 1024U) != 0U) {
#line 581
    tmp___0 = is_susp(ns);
#line 581
    tmp___1 = is_susp(os);
#line 581
    tmp___2 = sprintf(pbp, "susp( %d -> %d ) ", (int )tmp___1, (int )tmp___0);
#line 581
    pbp = pbp + (unsigned long )tmp___2;
  } else {

  }
#line 585
  if ((unsigned long )((char *)(& pb)) != (unsigned long )pbp) {
#line 586
    printk("\016d-con %s: %s\n", tconn->name, (char *)(& pb));
  } else {

  }
#line 587
  return;
}
}
#line 596 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv is_valid_state(struct drbd_conf *mdev , union drbd_state ns ) 
{ 
  enum drbd_fencing_p fp ;
  enum drbd_state_rv rv ;
  struct net_conf *nc ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  struct net_conf *_________p1___0 ;
  bool __warned___0 ;
  int tmp___2 ;
  int tmp___3 ;
  enum drbd_role tmp___4 ;

  {
#line 601
  rv = 1;
#line 604
  rcu_read_lock___7();
#line 605
  fp = FP_DONT_CARE;
#line 606
  tmp___1 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 606
  if (tmp___1 != 0) {
#line 607
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 607
    tmp = debug_lockdep_rcu_enabled();
#line 607
    if (tmp != 0 && ! __warned) {
#line 607
      tmp___0 = rcu_read_lock_held();
#line 607
      if (tmp___0 == 0 && 1) {
#line 607
        __warned = 1;
#line 607
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared",
                               607, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 607
    fp = (enum drbd_fencing_p )_________p1->fencing;
#line 608
    put_ldev(mdev);
  } else {

  }
#line 611
  _________p1___0 = *((struct net_conf * volatile  *)(& (mdev->tconn)->net_conf));
#line 611
  tmp___2 = debug_lockdep_rcu_enabled();
#line 611
  if (tmp___2 != 0 && ! __warned___0) {
#line 611
    tmp___3 = rcu_read_lock_held();
#line 611
    if (tmp___3 == 0 && 1) {
#line 611
      __warned___0 = 1;
#line 611
      lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared",
                             611, "suspicious rcu_dereference_check() usage");
    } else {

    }
  } else {

  }
#line 611
  nc = _________p1___0;
#line 612
  if ((unsigned long )nc != (unsigned long )((struct net_conf *)0)) {
#line 613
    if ((int )((signed char )nc->two_primaries) == 0 && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U) {
#line 614
      if ((unsigned int )*((unsigned char *)(& ns) + 0UL) == 4U) {
#line 615
        rv = SS_TWO_PRIMARIES;
      } else {
#line 616
        tmp___4 = conn_highest_peer(mdev->tconn);
#line 616
        if ((unsigned int )tmp___4 == 1U) {
#line 617
          rv = SS_O_VOL_PEER_PRI;
        } else {

        }
      }
    } else {

    }
  } else {

  }
#line 621
  if ((int )rv <= 0) {

  } else
#line 623
  if ((unsigned int )*((unsigned char *)(& ns) + 0UL) == 2U && mdev->open_cnt != 0) {
#line 624
    rv = SS_DEVICE_IN_USE;
  } else
#line 626
  if (((unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U && (int )ns.ldv_40024.conn <= 9) && (int )ns.ldv_40024.disk <= 7) {
#line 627
    rv = SS_NO_UP_TO_DATE_DISK;
  } else
#line 629
  if ((((int )fp > 0 && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U) && (int )ns.ldv_40024.conn <= 9) && (int )ns.ldv_40024.pdsk > 5) {
#line 631
    rv = SS_PRIMARY_NOP;
  } else
#line 633
  if (((unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U && (int )ns.ldv_40024.disk <= 4) && (int )ns.ldv_40024.pdsk <= 4) {
#line 634
    rv = SS_NO_UP_TO_DATE_DISK;
  } else
#line 636
  if ((int )ns.ldv_40024.conn > 10 && (int )ns.ldv_40024.disk <= 3) {
#line 637
    rv = SS_NO_LOCAL_DISK;
  } else
#line 639
  if ((int )ns.ldv_40024.conn > 10 && (int )ns.ldv_40024.pdsk <= 3) {
#line 640
    rv = SS_NO_REMOTE_DISK;
  } else
#line 642
  if (((int )ns.ldv_40024.conn > 10 && (int )ns.ldv_40024.disk <= 7) && (int )ns.ldv_40024.pdsk <= 7) {
#line 643
    rv = SS_NO_UP_TO_DATE_DISK;
  } else
#line 645
  if (((((unsigned int )*((unsigned short *)(& ns) + 0UL) == 160U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 208U) || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 256U) || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 320U) && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 10U) {
#line 650
    rv = SS_CONNECTED_OUTDATES;
  } else
#line 652
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 304U) && (int )((signed char )nc->verify_alg[0]) == 0) {
#line 654
    rv = SS_NO_VERIFY_ALG;
  } else
#line 656
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 304U) && (mdev->tconn)->agreed_pro_version <= 87) {
#line 658
    rv = SS_NOT_SUPPORTED;
  } else
#line 660
  if ((int )ns.ldv_40024.conn > 9 && *((unsigned int *)(& ns) + 0UL) == 49152U) {
#line 661
    rv = SS_CONNECTED_OUTDATES;
  } else {

  }
#line 663
  rcu_read_unlock___7();
#line 665
  return (rv);
}
}
#line 677 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv is_valid_soft_transition(union drbd_state os , union drbd_state ns ,
                                                   struct drbd_tconn *tconn ) 
{ 
  enum drbd_state_rv rv ;
  int tmp ;

  {
#line 679
  rv = 1;
#line 681
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 192U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 176U) && (int )os.ldv_40024.conn > 10) {
#line 683
    rv = SS_RESYNC_RUNNING;
  } else {

  }
#line 685
  if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 16U && (unsigned int )*((unsigned short *)(& os) + 0UL) == 0U) {
#line 686
    rv = SS_ALREADY_STANDALONE;
  } else {

  }
#line 688
  if ((int )ns.ldv_40024.disk > 1 && (unsigned int )*((unsigned char *)(& os) + 1UL) == 0U) {
#line 689
    rv = SS_IS_DISKLESS;
  } else {

  }
#line 691
  if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 128U && (int )os.ldv_40024.conn <= 1) {
#line 692
    rv = SS_NO_NET_CONFIG;
  } else {

  }
#line 694
  if (((unsigned int )*((unsigned char *)(& ns) + 1UL) == 10U && (int )os.ldv_40024.disk <= 4) && (unsigned int )*((unsigned char *)(& os) + 1UL) != 2U) {
#line 695
    rv = SS_LOWER_THAN_OUTDATED;
  } else {

  }
#line 697
  if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 16U && (unsigned int )*((unsigned short *)(& os) + 0UL) == 32U) {
#line 698
    rv = SS_IN_TRANSIENT_STATE;
  } else {

  }
#line 705
  tmp = constant_test_bit(10U, (unsigned long const volatile   *)(& tconn->flags));
#line 705
  if (tmp != 0 && ((unsigned int )*((unsigned short *)(& os) + 0UL) != 144U && ((unsigned int )*((unsigned short *)(& ns) + 0UL) != 144U || (unsigned int )*((unsigned short *)(& os) + 0UL) != 128U))) {
#line 708
    rv = SS_IN_TRANSIENT_STATE;
  } else {

  }
#line 710
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 304U) && (int )os.ldv_40024.conn <= 9) {
#line 711
    rv = SS_NEED_CONNECTION;
  } else {

  }
#line 713
  if ((((unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 304U) && (int )ns.ldv_40024.conn != (int )os.ldv_40024.conn) && (int )os.ldv_40024.conn > 10) {
#line 715
    rv = SS_RESYNC_RUNNING;
  } else {

  }
#line 717
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 176U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 192U) && (int )os.ldv_40024.conn <= 9) {
#line 719
    rv = SS_NEED_CONNECTION;
  } else {

  }
#line 721
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 272U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 256U) && (int )os.ldv_40024.conn <= 8) {
#line 723
    rv = SS_NEED_CONNECTION;
  } else {

  }
#line 725
  return (rv);
}
}
#line 729 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv is_valid_conn_transition(enum drbd_conns oc , enum drbd_conns nc ) 
{ 


  {
#line 732
  if ((unsigned int )oc == (unsigned int )nc) {
#line 733
    return (SS_NOTHING_TO_DO);
  } else {

  }
#line 736
  if ((unsigned int )oc == 0U && (unsigned int )nc == 1U) {
#line 737
    return (SS_ALREADY_STANDALONE);
  } else {

  }
#line 740
  if ((unsigned int )oc == 0U && (unsigned int )nc != 2U) {
#line 741
    return (SS_NEED_CONNECTION);
  } else {

  }
#line 745
  if ((unsigned int )oc <= 8U && (unsigned int )nc > 9U) {
#line 746
    return (SS_NEED_CONNECTION);
  } else {

  }
#line 749
  if ((((unsigned int )oc > 2U && (unsigned int )oc <= 7U) && (unsigned int )nc != 2U) && (unsigned int )nc != 1U) {
#line 750
    return (SS_IN_TRANSIENT_STATE);
  } else {

  }
#line 753
  if ((unsigned int )oc == 1U && (unsigned int )nc != 0U) {
#line 754
    return (SS_IN_TRANSIENT_STATE);
  } else {

  }
#line 756
  return (SS_SUCCESS);
}
}
#line 769 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv is_valid_transition(union drbd_state os , union drbd_state ns ) 
{ 
  enum drbd_state_rv rv ;

  {
#line 773
  rv = is_valid_conn_transition((enum drbd_conns )os.ldv_40024.conn, (enum drbd_conns )ns.ldv_40024.conn);
#line 776
  if ((unsigned int )*((unsigned char *)(& ns) + 1UL) == 4U && (unsigned int )*((unsigned char *)(& os) + 1UL) == 0U) {
#line 777
    rv = SS_IS_DISKLESS;
  } else {

  }
#line 779
  return (rv);
}
}
#line 782 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static void print_sanitize_warnings(struct drbd_conf *mdev , enum sanitize_state_warnings warn ) 
{ 
  char const   *msg_table[6U] ;

  {
#line 784
  msg_table[0] = "";
#line 784
  msg_table[1] = "Online-verify aborted.";
#line 784
  msg_table[2] = "Resync aborted.";
#line 784
  msg_table[3] = "Connection lost while negotiating, no data!";
#line 784
  msg_table[4] = "Implicitly upgraded disk";
#line 784
  msg_table[5] = "Implicitly upgraded pdsk";
#line 793
  if ((unsigned int )warn != 0U) {
#line 794
    dev_warn((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "%s\n", msg_table[(unsigned int )warn]);
  } else {

  }
#line 795
  return;
}
}
#line 807 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static union drbd_state sanitize_state(struct drbd_conf *mdev , union drbd_state ns ,
                                       enum sanitize_state_warnings *warn ) 
{ 
  enum drbd_fencing_p fp ;
  enum drbd_disk_state disk_min ;
  enum drbd_disk_state disk_max ;
  enum drbd_disk_state pdsk_min ;
  enum drbd_disk_state pdsk_max ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 813
  if ((unsigned long )warn != (unsigned long )((enum sanitize_state_warnings *)0)) {
#line 814
    *warn = NO_WARNING;
  } else {

  }
#line 816
  fp = FP_DONT_CARE;
#line 817
  tmp___1 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 817
  if (tmp___1 != 0) {
#line 818
    rcu_read_lock___7();
#line 819
    _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 819
    tmp = debug_lockdep_rcu_enabled();
#line 819
    if (tmp != 0 && ! __warned) {
#line 819
      tmp___0 = rcu_read_lock_held();
#line 819
      if (tmp___0 == 0 && 1) {
#line 819
        __warned = 1;
#line 819
        lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared",
                               819, "suspicious rcu_dereference_check() usage");
      } else {

      }
    } else {

    }
#line 819
    fp = (enum drbd_fencing_p )_________p1->fencing;
#line 820
    rcu_read_unlock___7();
#line 821
    put_ldev(mdev);
  } else {

  }
#line 825
  if ((int )ns.ldv_40024.conn <= 9) {
#line 826
    ns.ldv_40024.peer_isp = 0U;
#line 827
    ns.ldv_40024.peer = 0U;
#line 828
    if ((int )ns.ldv_40024.pdsk > 6 || (int )ns.ldv_40024.pdsk <= 3) {
#line 829
      ns.ldv_40024.pdsk = 6U;
    } else {

    }
  } else {

  }
#line 833
  if (((unsigned int )*((unsigned short *)(& ns) + 0UL) == 0U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 0U) && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 2U) {
#line 834
    ns.ldv_40024.aftr_isp = 0U;
  } else {

  }
#line 838
  if ((int )ns.ldv_40024.conn > 10 && ((int )ns.ldv_40024.disk <= 2 || (int )ns.ldv_40024.pdsk <= 2)) {
#line 839
    if ((unsigned long )warn != (unsigned long )((enum sanitize_state_warnings *)0)) {
#line 840
      *warn = (unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 304U ? ABORTED_ONLINE_VERIFY : ABORTED_RESYNC;
    } else {

    }
#line 842
    ns.ldv_40024.conn = 10U;
  } else {

  }
#line 846
  if ((int )ns.ldv_40024.conn <= 9 && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 6U) {
#line 846
    tmp___2 = _get_ldev_if_state(mdev, D_NEGOTIATING);
#line 846
    if (tmp___2 != 0) {
#line 848
      if (mdev->ed_uuid == (mdev->ldev)->md.uuid[0]) {
#line 849
        ns.ldv_40024.disk = mdev->new_state_tmp.ldv_40024.disk;
#line 850
        ns.ldv_40024.pdsk = mdev->new_state_tmp.ldv_40024.pdsk;
      } else {
#line 852
        if ((unsigned long )warn != (unsigned long )((enum sanitize_state_warnings *)0)) {
#line 853
          *warn = CONNECTION_LOST_NEGOTIATING;
        } else {

        }
#line 854
        ns.ldv_40024.disk = 0U;
#line 855
        ns.ldv_40024.pdsk = 6U;
      }
#line 857
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 861
  if ((int )ns.ldv_40024.conn > 9 && (int )ns.ldv_40024.conn <= 21) {
#line 862
    if ((unsigned int )*((unsigned char *)(& ns) + 1UL) == 14U || (unsigned int )*((unsigned char *)(& ns) + 1UL) == 10U) {
#line 863
      ns.ldv_40024.disk = 8U;
    } else {

    }
#line 864
    if (*((unsigned int *)(& ns) + 0UL) == 57344U || *((unsigned int *)(& ns) + 0UL) == 40960U) {
#line 865
      ns.ldv_40024.pdsk = 8U;
    } else {

    }
  } else {

  }
#line 869
  disk_min = D_DISKLESS;
#line 870
  disk_max = D_UP_TO_DATE;
#line 871
  pdsk_min = D_INCONSISTENT;
#line 872
  pdsk_max = D_UNKNOWN;
#line 873
  switch ((unsigned int )ns.ldv_40024.conn) {
  case 14U: ;
  case 21U: ;
  case 12U: ;
  case 15U: ;
  case 23U: 
#line 879
  disk_min = D_INCONSISTENT;
#line 880
  disk_max = D_OUTDATED;
#line 881
  pdsk_min = D_UP_TO_DATE;
#line 882
  pdsk_max = D_UP_TO_DATE;
#line 883
  goto ldv_52301;
  case 18U: ;
  case 19U: 
#line 886
  disk_min = D_UP_TO_DATE;
#line 887
  disk_max = D_UP_TO_DATE;
#line 888
  pdsk_min = D_UP_TO_DATE;
#line 889
  pdsk_max = D_UP_TO_DATE;
#line 890
  goto ldv_52301;
  case 10U: 
#line 892
  disk_min = D_DISKLESS;
#line 893
  disk_max = D_UP_TO_DATE;
#line 894
  pdsk_min = D_DISKLESS;
#line 895
  pdsk_max = D_UP_TO_DATE;
#line 896
  goto ldv_52301;
  case 13U: ;
  case 20U: ;
  case 11U: ;
  case 22U: 
#line 901
  disk_min = D_UP_TO_DATE;
#line 902
  disk_max = D_UP_TO_DATE;
#line 903
  pdsk_min = D_INCONSISTENT;
#line 904
  pdsk_max = D_CONSISTENT;
#line 905
  goto ldv_52301;
  case 17U: 
#line 907
  disk_min = D_INCONSISTENT;
#line 908
  disk_max = D_INCONSISTENT;
#line 909
  pdsk_min = D_UP_TO_DATE;
#line 910
  pdsk_max = D_UP_TO_DATE;
#line 911
  goto ldv_52301;
  case 16U: 
#line 913
  disk_min = D_UP_TO_DATE;
#line 914
  disk_max = D_UP_TO_DATE;
#line 915
  pdsk_min = D_INCONSISTENT;
#line 916
  pdsk_max = D_INCONSISTENT;
#line 917
  goto ldv_52301;
  case 0U: ;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 5U: ;
  case 6U: ;
  case 7U: ;
  case 8U: ;
  case 9U: ;
  case 31U: ;
#line 929
  goto ldv_52301;
  }
  ldv_52301: ;
#line 931
  if ((unsigned int )ns.ldv_40024.disk > (unsigned int )disk_max) {
#line 932
    ns.ldv_40024.disk = (unsigned char )disk_max;
  } else {

  }
#line 934
  if ((unsigned int )ns.ldv_40024.disk < (unsigned int )disk_min) {
#line 935
    if ((unsigned long )warn != (unsigned long )((enum sanitize_state_warnings *)0)) {
#line 936
      *warn = IMPLICITLY_UPGRADED_DISK;
    } else {

    }
#line 937
    ns.ldv_40024.disk = (unsigned char )disk_min;
  } else {

  }
#line 939
  if ((unsigned int )ns.ldv_40024.pdsk > (unsigned int )pdsk_max) {
#line 940
    ns.ldv_40024.pdsk = (unsigned char )pdsk_max;
  } else {

  }
#line 942
  if ((unsigned int )ns.ldv_40024.pdsk < (unsigned int )pdsk_min) {
#line 943
    if ((unsigned long )warn != (unsigned long )((enum sanitize_state_warnings *)0)) {
#line 944
      *warn = IMPLICITLY_UPGRADED_PDSK;
    } else {

    }
#line 945
    ns.ldv_40024.pdsk = (unsigned char )pdsk_min;
  } else {

  }
#line 948
  if ((int )fp == 2 && (((unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U && (int )ns.ldv_40024.conn <= 9) && (int )ns.ldv_40024.pdsk > 5)) {
#line 950
    ns.ldv_40024.susp_fen = 1U;
  } else {

  }
#line 952
  if ((mdev->tconn)->res_opts.on_no_data == 1U && (((unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U && (int )ns.ldv_40024.disk <= 7) && (int )ns.ldv_40024.pdsk <= 7)) {
#line 954
    ns.ldv_40024.susp_nod = 1U;
  } else {

  }
#line 956
  if (((unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U || (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U) || (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U) {
#line 957
    if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 256U) {
#line 958
      ns.ldv_40024.conn = 20U;
    } else {

    }
#line 959
    if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 272U) {
#line 960
      ns.ldv_40024.conn = 21U;
    } else {

    }
  } else {
#line 962
    if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 320U) {
#line 963
      ns.ldv_40024.conn = 16U;
    } else {

    }
#line 964
    if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 336U) {
#line 965
      ns.ldv_40024.conn = 17U;
    } else {

    }
  }
#line 968
  return (ns);
}
}
#line 971 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void drbd_resume_al(struct drbd_conf *mdev ) 
{ 
  int tmp ;

  {
#line 973
  tmp = test_and_clear_bit(18, (unsigned long volatile   *)(& mdev->flags));
#line 973
  if (tmp != 0) {
#line 974
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Resumed AL updates\n");
  } else {

  }
#line 975
  return;
}
}
#line 978 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static void set_ov_position(struct drbd_conf *mdev , enum drbd_conns cs ) 
{ 
  unsigned long bit ;

  {
#line 980
  if ((mdev->tconn)->agreed_pro_version <= 89) {
#line 981
    mdev->ov_start_sector = 0UL;
  } else {

  }
#line 982
  mdev->rs_total = drbd_bm_bits(mdev);
#line 983
  mdev->ov_position = 0UL;
#line 984
  if ((unsigned int )cs == 19U) {
#line 990
    mdev->ov_start_sector = 0xffffffffffffffffUL;
  } else {
#line 992
    bit = mdev->ov_start_sector >> 3;
#line 993
    if (mdev->rs_total <= bit) {
#line 994
      mdev->ov_start_sector = (mdev->rs_total - 1UL) << 3;
#line 996
      mdev->rs_total = 1UL;
    } else {
#line 998
      mdev->rs_total = mdev->rs_total - bit;
    }
#line 999
    mdev->ov_position = mdev->ov_start_sector;
  }
#line 1001
  mdev->ov_left = mdev->rs_total;
#line 1002
  return;
}
}
#line 1014 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_state_rv __drbd_set_state(struct drbd_conf *mdev , union drbd_state ns ,
                                    enum chg_state_flags flags , struct completion *done ) 
{ 
  union drbd_state os ;
  enum drbd_state_rv rv ;
  enum sanitize_state_warnings ssw ;
  struct after_state_chg_work *ascw ;
  enum drbd_state_rv tmp ;
  bool tmp___0 ;
  unsigned long tmp___1 ;
  unsigned long now ;
  int i ;
  u32 mdf ;
  int tmp___2 ;
  int tmp___3 ;
  void *tmp___4 ;

  {
#line 1018
  rv = 1;
#line 1022
  os = drbd_read_state(mdev);
#line 1024
  ns = sanitize_state(mdev, ns, & ssw);
#line 1025
  if (ns.i == os.i) {
#line 1026
    return (SS_NOTHING_TO_DO);
  } else {

  }
#line 1028
  rv = is_valid_transition(os, ns);
#line 1029
  if ((int )rv <= 0) {
#line 1030
    return (rv);
  } else {

  }
#line 1032
  if (((unsigned int )flags & 1U) == 0U) {
#line 1036
    rv = is_valid_state(mdev, ns);
#line 1037
    if ((int )rv <= 0) {
#line 1041
      tmp = is_valid_state(mdev, os);
#line 1041
      if ((int )tmp == (int )rv) {
#line 1042
        rv = is_valid_soft_transition(os, ns, mdev->tconn);
      } else {
#line 1044
        rv = is_valid_soft_transition(os, ns, mdev->tconn);
      }
    } else {

    }
  } else {

  }
#line 1047
  if ((int )rv <= 0) {
#line 1048
    if (((unsigned int )flags & 2U) != 0U) {
#line 1049
      print_st_err(mdev, os, ns, rv);
    } else {

    }
#line 1050
    return (rv);
  } else {

  }
#line 1053
  print_sanitize_warnings(mdev, ssw);
#line 1055
  drbd_pr_state_change(mdev, os, ns, flags);
#line 1060
  if (((unsigned int )flags & 1024U) == 0U) {
#line 1061
    conn_pr_state_change(mdev->tconn, os, ns, (enum chg_state_flags )(((unsigned int )flags & 4294965279U) | 1024U));
  } else {

  }
#line 1067
  if (((unsigned int )*((unsigned char *)(& os) + 1UL) != 4U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 4U) || ((unsigned int )*((unsigned char *)(& os) + 1UL) != 0U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 0U)) {
#line 1069
    atomic_inc(& mdev->local_cnt);
  } else {

  }
#line 1071
  mdev->state.i = ns.i;
#line 1072
  (mdev->tconn)->susp = ns.ldv_40024.susp;
#line 1073
  (mdev->tconn)->susp_nod = ns.ldv_40024.susp_nod;
#line 1074
  (mdev->tconn)->susp_fen = ns.ldv_40024.susp_fen;
#line 1076
  if ((unsigned int )*((unsigned char *)(& os) + 1UL) == 2U && (int )ns.ldv_40024.disk > 2) {
#line 1077
    drbd_print_uuids(mdev, "attached to UUIDs");
  } else {

  }
#line 1080
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 144U && (unsigned int )*((unsigned short *)(& ns) + 0UL) != 144U) {
#line 1080
    tmp___0 = no_peer_wf_report_params(mdev->tconn);
#line 1080
    if ((int )tmp___0) {
#line 1082
      clear_bit(10, (unsigned long volatile   *)(& (mdev->tconn)->flags));
    } else {

    }
  } else {

  }
#line 1084
  __wake_up(& mdev->misc_wait, 3U, 1, 0);
#line 1085
  __wake_up(& mdev->state_wait, 3U, 1, 0);
#line 1086
  __wake_up(& (mdev->tconn)->ping_wait, 3U, 1, 0);
#line 1090
  if (((unsigned int )*((unsigned short *)(& os) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 304U) && (int )ns.ldv_40024.conn <= 10) {
#line 1092
    tmp___1 = drbd_bm_bits(mdev);
#line 1092
    mdev->ov_start_sector = (tmp___1 - mdev->ov_left) << 3;
#line 1094
    if (mdev->ov_left != 0UL) {
#line 1095
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Online Verify reached sector %llu\n",
                (unsigned long long )mdev->ov_start_sector);
    } else {

    }
  } else {

  }
#line 1099
  if (((unsigned int )*((unsigned short *)(& os) + 0UL) == 336U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 320U) && ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 272U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 256U)) {
#line 1101
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Syncer continues.\n");
#line 1102
    mdev->rs_paused = mdev->rs_paused + (unsigned long )((long )jiffies - (long )mdev->rs_mark_time[mdev->rs_last_mark]);
#line 1104
    if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 272U) {
#line 1105
      mod_timer(& mdev->resync_timer, jiffies);
    } else {

    }
  } else {

  }
#line 1108
  if (((unsigned int )*((unsigned short *)(& os) + 0UL) == 272U || (unsigned int )*((unsigned short *)(& os) + 0UL) == 256U) && ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 336U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 320U)) {
#line 1110
    _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Resync suspended\n");
#line 1111
    mdev->rs_mark_time[mdev->rs_last_mark] = jiffies;
  } else {

  }
#line 1114
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 160U && ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 304U)) {
#line 1116
    now = jiffies;
#line 1119
    set_ov_position(mdev, (enum drbd_conns )ns.ldv_40024.conn);
#line 1120
    mdev->rs_start = now;
#line 1121
    mdev->rs_last_events = 0;
#line 1122
    mdev->rs_last_sect_ev = 0;
#line 1123
    mdev->ov_last_oos_size = 0UL;
#line 1124
    mdev->ov_last_oos_start = 0UL;
#line 1126
    i = 0;
#line 1126
    goto ldv_52343;
    ldv_52342: 
#line 1127
    mdev->rs_mark_left[i] = mdev->ov_left;
#line 1128
    mdev->rs_mark_time[i] = now;
#line 1126
    i = i + 1;
    ldv_52343: ;
#line 1126
    if (i <= 7) {
#line 1127
      goto ldv_52342;
    } else {

    }
#line 1131
    drbd_rs_controller_reset(mdev);
#line 1133
    if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 288U) {
#line 1134
      _dev_info((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Starting Online Verify from sector %llu\n",
                (unsigned long long )mdev->ov_position);
#line 1136
      mod_timer(& mdev->resync_timer, jiffies);
    } else {

    }
  } else {

  }
#line 1140
  tmp___3 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1140
  if (tmp___3 != 0) {
#line 1141
    mdf = (mdev->ldev)->md.flags & 4294967176U;
#line 1145
    mdf = mdf & 4294967167U;
#line 1146
    tmp___2 = constant_test_bit(5U, (unsigned long const volatile   *)(& mdev->flags));
#line 1146
    if (tmp___2 != 0) {
#line 1147
      mdf = mdf | 64U;
    } else {

    }
#line 1148
    if ((unsigned int )*((unsigned char *)mdev + 748UL) == 1U || ((int )mdev->state.ldv_49522.pdsk <= 3 && (unsigned int )*((unsigned char *)mdev + 748UL) == 4U)) {
#line 1150
      mdf = mdf | 2U;
    } else {

    }
#line 1151
    if ((int )mdev->state.ldv_49522.conn > 9) {
#line 1152
      mdf = mdf | 4U;
    } else {

    }
#line 1153
    if ((int )mdev->state.ldv_49522.disk > 4) {
#line 1154
      mdf = mdf | 1U;
    } else {

    }
#line 1155
    if ((int )mdev->state.ldv_49522.disk > 5) {
#line 1156
      mdf = mdf | 16U;
    } else {

    }
#line 1157
    if ((int )mdev->state.ldv_49522.pdsk <= 5 && (int )mdev->state.ldv_49522.pdsk > 3) {
#line 1158
      mdf = mdf | 32U;
    } else {

    }
#line 1159
    if ((mdev->ldev)->md.flags != mdf) {
#line 1160
      (mdev->ldev)->md.flags = mdf;
#line 1161
      drbd_md_mark_dirty(mdev);
    } else {

    }
#line 1163
    if ((int )os.ldv_40024.disk <= 6 && (int )ns.ldv_40024.disk > 6) {
#line 1164
      drbd_set_ed_uuid(mdev, (mdev->ldev)->md.uuid[0]);
    } else {

    }
#line 1165
    put_ldev(mdev);
  } else {

  }
#line 1169
  if ((((unsigned int )*((unsigned char *)(& os) + 1UL) == 8U && *((unsigned int *)(& os) + 0UL) == 32768U) && (unsigned int )*((unsigned char *)(& os) + 0UL) == 8U) && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 4U) {
#line 1171
    set_bit(6U, (unsigned long volatile   *)(& mdev->flags));
  } else {

  }
#line 1174
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) != 16U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 16U) {
#line 1175
    drbd_thread_stop_nowait(& (mdev->tconn)->receiver);
  } else {

  }
#line 1178
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) != 0U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 0U) {
#line 1179
    drbd_thread_stop_nowait(& (mdev->tconn)->receiver);
  } else {

  }
#line 1182
  if (((int )os.ldv_40024.conn > 8 && (int )ns.ldv_40024.conn <= 7) && (int )ns.ldv_40024.conn > 2) {
#line 1184
    drbd_thread_restart_nowait(& (mdev->tconn)->receiver);
  } else {

  }
#line 1187
  if ((int )os.ldv_40024.conn <= 9 && (int )ns.ldv_40024.conn > 9) {
#line 1188
    drbd_resume_al(mdev);
  } else {

  }
#line 1193
  if (((unsigned int )*((unsigned char *)(& os) + 1UL) == 2U || (unsigned int )*((unsigned char *)(& os) + 1UL) == 6U) && (int )ns.ldv_40024.disk > 3) {
#line 1195
    mdev->last_reattach_jif = jiffies;
  } else {

  }
#line 1197
  tmp___4 = kmalloc(56UL, 32U);
#line 1197
  ascw = (struct after_state_chg_work *)tmp___4;
#line 1198
  if ((unsigned long )ascw != (unsigned long )((struct after_state_chg_work *)0)) {
#line 1199
    ascw->os = os;
#line 1200
    ascw->ns = ns;
#line 1201
    ascw->flags = flags;
#line 1202
    ascw->w.cb = & w_after_state_ch;
#line 1203
    ascw->w.ldv_49807.mdev = mdev;
#line 1204
    ascw->done = done;
#line 1205
    drbd_queue_work(& (mdev->tconn)->sender_work, & ascw->w);
  } else {
#line 1207
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Could not kmalloc an ascw\n");
  }
#line 1210
  return (rv);
}
}
#line 1213 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static int w_after_state_ch(struct drbd_work *w , int unused ) 
{ 
  struct after_state_chg_work *ascw ;
  struct drbd_work  const  *__mptr ;
  struct drbd_conf *mdev ;

  {
#line 1216
  __mptr = (struct drbd_work  const  *)w;
#line 1216
  ascw = (struct after_state_chg_work *)__mptr;
#line 1217
  mdev = w->ldv_49807.mdev;
#line 1219
  after_state_ch(mdev, ascw->os, ascw->ns, ascw->flags);
#line 1220
  if (((unsigned int )ascw->flags & 4U) != 0U) {
#line 1221
    if ((unsigned long )ascw->done == (unsigned long )((struct completion *)0)) {
#line 1221
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( ascw->done != NULL ) in %s:%d\n",
              (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared",
              1221);
    } else {

    }
#line 1222
    complete(ascw->done);
  } else {

  }
#line 1224
  kfree((void const   *)ascw);
#line 1226
  return (0);
}
}
#line 1229 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static void abw_start_sync(struct drbd_conf *mdev , int rv ) 
{ 
  union drbd_state val ;
  union drbd_state mask ;
  union drbd_state val___0 ;
  union drbd_state mask___0 ;

  {
#line 1231
  if (rv != 0) {
#line 1232
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "Writing the bitmap failed not starting resync.\n");
#line 1233
    val.i = 0U;
#line 1233
    val.ldv_40024.conn = 10U;
#line 1233
    mask.i = 0U;
#line 1233
    mask.ldv_40024.conn = 31U;
#line 1233
    _drbd_request_state(mdev, mask, val, CS_VERBOSE);
#line 1234
    return;
  } else {

  }
#line 1237
  switch ((int )mdev->state.ldv_49522.conn) {
  case 12: 
#line 1239
  val___0.i = 0U;
#line 1239
  val___0.ldv_40024.conn = 15U;
#line 1239
  mask___0.i = 0U;
#line 1239
  mask___0.ldv_40024.conn = 31U;
#line 1239
  _drbd_request_state(mdev, mask___0, val___0, CS_VERBOSE);
#line 1240
  goto ldv_52367;
  case 11: 
#line 1242
  drbd_start_resync(mdev, C_SYNC_SOURCE);
#line 1243
  goto ldv_52367;
  }
  ldv_52367: ;
#line 1246
  return;
}
}
#line 1247 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
int drbd_bitmap_io_from_worker(struct drbd_conf *mdev , int (*io_fn)(struct drbd_conf * ) ,
                               char *why , enum bm_flag flags ) 
{ 
  int rv ;
  struct task_struct *tmp ;

  {
#line 1253
  tmp = get_current();
#line 1253
  if ((unsigned long )tmp != (unsigned long )(mdev->tconn)->worker.task) {
#line 1253
    dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT( current == mdev->tconn->worker.task ) in %s:%d\n",
            (char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared",
            1253);
  } else {

  }
#line 1256
  set_bit(8U, (unsigned long volatile   *)(& mdev->flags));
#line 1258
  drbd_bm_lock(mdev, why, flags);
#line 1259
  rv = (*io_fn)(mdev);
#line 1260
  drbd_bm_unlock(mdev);
#line 1262
  drbd_resume_io(mdev);
#line 1264
  return (rv);
}
}
#line 1274 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static void after_state_ch(struct drbd_conf *mdev , union drbd_state os , union drbd_state ns ,
                           enum chg_state_flags flags ) 
{ 
  struct sib_info sib ;
  struct drbd_tconn *tconn ;
  enum drbd_req_event what ;
  enum drbd_conns tmp ;
  enum drbd_disk_state tmp___0 ;
  union drbd_state __constr_expr_0 ;
  union drbd_state __constr_expr_1 ;
  struct drbd_tconn *tconn___0 ;
  struct drbd_conf *odev ;
  int vnr ;
  void *tmp___1 ;
  void *tmp___2 ;
  union drbd_state __constr_expr_2 ;
  union drbd_state __constr_expr_3 ;
  enum drbd_conns tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  enum drbd_io_error_p eh ;
  int was_io_error ;
  struct disk_conf *_________p1 ;
  bool __warned ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  char const   *tmp___12 ;
  char const   *tmp___13 ;
  int tmp___14 ;
  bool tmp___15 ;
  int tmp___16 ;

  {
#line 1279
  sib.sib_reason = SIB_STATE_CHANGE;
#line 1280
  sib.ldv_50742.ldv_50741.os = os;
#line 1281
  sib.ldv_50742.ldv_50741.ns = ns;
#line 1283
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) != 160U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 160U) {
#line 1284
    clear_bit(5, (unsigned long volatile   *)(& mdev->flags));
#line 1285
    if ((unsigned long )mdev->p_uuid != (unsigned long )((u64 *)0)) {
#line 1286
      *(mdev->p_uuid + 5UL) = *(mdev->p_uuid + 5UL) & 0xfffffffffffffffdULL;
    } else {

    }
  } else {

  }
#line 1290
  drbd_bcast_event(mdev, (struct sib_info  const  *)(& sib));
#line 1292
  if ((((unsigned int )*((unsigned char *)(& os) + 0UL) != 1U || (int )os.ldv_40024.disk > 7) || (int )os.ldv_40024.pdsk > 7) && (((unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U && (int )ns.ldv_40024.disk <= 7) && (int )ns.ldv_40024.pdsk <= 7)) {
#line 1294
    drbd_khelper(mdev, (char *)"pri-on-incon-degr");
  } else {

  }
#line 1299
  if ((unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U) {
#line 1300
    tconn = mdev->tconn;
#line 1301
    what = NOTHING;
#line 1303
    spin_lock_irq(& tconn->req_lock);
#line 1304
    if ((int )os.ldv_40024.conn <= 9) {
#line 1304
      tmp = conn_lowest_conn(tconn);
#line 1304
      if ((unsigned int )tmp > 9U) {
#line 1305
        what = RESEND;
      } else {

      }
    } else {

    }
#line 1307
    if ((unsigned int )*((unsigned char *)(& os) + 1UL) == 2U || (unsigned int )*((unsigned char *)(& os) + 1UL) == 6U) {
#line 1307
      tmp___0 = conn_lowest_disk(tconn);
#line 1307
      if ((unsigned int )tmp___0 > 3U) {
#line 1309
        what = RESTART_FROZEN_DISK_IO;
      } else {

      }
    } else {

    }
#line 1311
    if ((unsigned int )*((unsigned char *)tconn + 132UL) != 0U && (unsigned int )what != 28U) {
#line 1312
      _tl_restart(tconn, what);
#line 1313
      __constr_expr_0.ldv_40024.role = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.peer = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.conn = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.disk = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.pdsk = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.susp = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.aftr_isp = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.peer_isp = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.user_isp = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024.susp_nod = 0U;
#line 1313
      __constr_expr_0.ldv_40024.susp_fen = (unsigned char)0;
#line 1313
      __constr_expr_0.ldv_40024._pad = (unsigned short)0;
#line 1313
      __constr_expr_1.ldv_40024.role = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.peer = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.conn = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.disk = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.pdsk = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.susp = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.aftr_isp = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.peer_isp = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.user_isp = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024.susp_nod = 1U;
#line 1313
      __constr_expr_1.ldv_40024.susp_fen = (unsigned char)0;
#line 1313
      __constr_expr_1.ldv_40024._pad = (unsigned short)0;
#line 1313
      _conn_request_state(tconn, __constr_expr_1, __constr_expr_0, CS_VERBOSE);
    } else {

    }
#line 1318
    spin_unlock_irq(& tconn->req_lock);
  } else {

  }
#line 1321
  if ((unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U) {
#line 1322
    tconn___0 = mdev->tconn;
#line 1324
    spin_lock_irq(& tconn___0->req_lock);
#line 1325
    if ((unsigned int )*((unsigned char *)tconn___0 + 132UL) != 0U) {
#line 1325
      tmp___3 = conn_lowest_conn(tconn___0);
#line 1325
      if ((unsigned int )tmp___3 > 9U) {
#line 1330
        rcu_read_lock___7();
#line 1331
        vnr = 0;
#line 1331
        tmp___1 = idr_get_next(& tconn___0->volumes, & vnr);
#line 1331
        odev = (struct drbd_conf *)tmp___1;
#line 1331
        goto ldv_52392;
        ldv_52391: 
#line 1332
        clear_bit(17, (unsigned long volatile   *)(& odev->flags));
#line 1331
        vnr = vnr + 1;
#line 1331
        tmp___2 = idr_get_next(& tconn___0->volumes, & vnr);
#line 1331
        odev = (struct drbd_conf *)tmp___2;
        ldv_52392: ;
#line 1331
        if ((unsigned long )odev != (unsigned long )((struct drbd_conf *)0)) {
#line 1332
          goto ldv_52391;
        } else {

        }
#line 1333
        rcu_read_unlock___7();
#line 1334
        _tl_restart(tconn___0, RESEND);
#line 1335
        __constr_expr_2.ldv_40024.role = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.peer = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.conn = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.disk = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.pdsk = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.susp = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.aftr_isp = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.peer_isp = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.user_isp = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.susp_nod = (unsigned char)0;
#line 1335
        __constr_expr_2.ldv_40024.susp_fen = 0U;
#line 1335
        __constr_expr_2.ldv_40024._pad = (unsigned short)0;
#line 1335
        __constr_expr_3.ldv_40024.role = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.peer = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.conn = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.disk = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.pdsk = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.susp = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.aftr_isp = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.peer_isp = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.user_isp = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.susp_nod = (unsigned char)0;
#line 1335
        __constr_expr_3.ldv_40024.susp_fen = 1U;
#line 1335
        __constr_expr_3.ldv_40024._pad = (unsigned short)0;
#line 1335
        _conn_request_state(tconn___0, __constr_expr_3, __constr_expr_2, CS_VERBOSE);
      } else {

      }
    } else {

    }
#line 1340
    spin_unlock_irq(& tconn___0->req_lock);
  } else {

  }
#line 1347
  if ((((unsigned int )*((unsigned short *)(& os) + 0UL) != 256U && (unsigned int )*((unsigned short *)(& os) + 0UL) != 320U) && ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 256U || (unsigned int )*((unsigned short *)(& ns) + 0UL) == 320U)) && (mdev->tconn)->agreed_pro_version > 95) {
#line 1347
    tmp___4 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1347
    if (tmp___4 != 0) {
#line 1350
      drbd_gen_and_send_sync_uuid(mdev);
#line 1351
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 1355
  if ((*((unsigned int *)(& os) + 0UL) == 0U && (int )ns.ldv_40024.pdsk > 0) && *((unsigned int *)(& ns) + 0UL) != 49152U) {
#line 1359
    mdev->rs_total = 0UL;
#line 1360
    mdev->rs_failed = 0UL;
#line 1361
    atomic_set(& mdev->rs_pending_cnt, 0);
#line 1362
    drbd_rs_cancel_all(mdev);
#line 1364
    drbd_send_uuids(mdev);
#line 1365
    drbd_send_state(mdev, ns);
  } else {

  }
#line 1370
  if (((unsigned int )*((unsigned short *)(& os) + 0UL) != 208U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 208U) && (unsigned int )*((unsigned short *)mdev + 374UL) == 208U) {
#line 1372
    drbd_queue_bitmap_io(mdev, & drbd_send_bitmap, 0, (char *)"send_bitmap (WFBitMapS)",
                         BM_LOCKED_TEST_ALLOWED);
  } else {

  }
#line 1377
  if ((((int )os.ldv_40024.pdsk > 3 && *((unsigned int *)(& os) + 0UL) != 49152U) && *((unsigned int *)(& os) + 0UL) != 40960U) && (((int )ns.ldv_40024.pdsk <= 3 || *((unsigned int *)(& ns) + 0UL) == 49152U) || *((unsigned int *)(& ns) + 0UL) == 40960U)) {
#line 1383
    tmp___6 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1383
    if (tmp___6 != 0) {
#line 1384
      if ((((unsigned int )*((unsigned char *)(& ns) + 0UL) == 1U || (unsigned int )*((unsigned char *)(& ns) + 0UL) == 4U) && (mdev->ldev)->md.uuid[1] == 0ULL) && (int )ns.ldv_40024.disk > 7) {
#line 1386
        tmp___5 = drbd_suspended(mdev);
#line 1386
        if (tmp___5 != 0) {
#line 1387
          set_bit(17U, (unsigned long volatile   *)(& mdev->flags));
        } else {
#line 1389
          drbd_uuid_new_current(mdev);
#line 1390
          drbd_send_uuids(mdev);
        }
      } else {

      }
#line 1393
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 1397
  if ((int )ns.ldv_40024.pdsk <= 3) {
#line 1397
    tmp___7 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1397
    if (tmp___7 != 0) {
#line 1398
      if ((((unsigned int )*((unsigned char *)(& os) + 0UL) == 8U && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 4U) && (mdev->ldev)->md.uuid[1] == 0ULL) && (int )ns.ldv_40024.disk > 7) {
#line 1400
        drbd_uuid_new_current(mdev);
#line 1401
        drbd_send_uuids(mdev);
      } else {

      }
#line 1404
      if ((unsigned int )*((unsigned char *)(& os) + 0UL) == 4U && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 8U) {
#line 1408
        drbd_bitmap_io_from_worker(mdev, & drbd_bm_write, (char *)"demote diskless peer",
                                   BM_LOCKED_SET_ALLOWED);
      } else {

      }
#line 1410
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 1416
  if (((unsigned int )*((unsigned char *)(& os) + 0UL) == 1U && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 2U) && (int )mdev->state.ldv_49522.conn <= 10) {
#line 1416
    tmp___8 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1416
    if (tmp___8 != 0) {
#line 1420
      drbd_bitmap_io_from_worker(mdev, & drbd_bm_write, (char *)"demote", BM_LOCKED_TEST_ALLOWED);
#line 1422
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 1426
  if (((int )ns.ldv_40024.conn > 9 && (unsigned int )*((unsigned char *)(& os) + 1UL) == 2U) && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 6U) {
#line 1428
    drbd_send_sizes(mdev, 0, 0);
#line 1429
    drbd_send_uuids(mdev);
#line 1430
    drbd_send_state(mdev, ns);
  } else {

  }
#line 1434
  if ((int )ns.ldv_40024.conn > 9 && ((int )os.ldv_40024.aftr_isp != (int )ns.ldv_40024.aftr_isp || (int )os.ldv_40024.user_isp != (int )ns.ldv_40024.user_isp)) {
#line 1437
    drbd_send_state(mdev, ns);
  } else {

  }
#line 1440
  if ((((unsigned int )*((unsigned char *)(& os) + 2UL) == 0U && (unsigned int )*((unsigned char *)(& os) + 2UL) == 0U) && (unsigned int )*((unsigned char *)(& os) + 2UL) == 0U) && (((unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U || (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U) || (unsigned int )*((unsigned char *)(& ns) + 2UL) != 0U)) {
#line 1442
    suspend_other_sg(mdev);
  } else {

  }
#line 1446
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 144U && (int )ns.ldv_40024.conn > 9) {
#line 1447
    drbd_send_state(mdev, ns);
  } else {

  }
#line 1449
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) != 352U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 352U) {
#line 1450
    drbd_send_state(mdev, ns);
  } else {

  }
#line 1453
  if (((unsigned int )*((unsigned short *)(& os) + 0UL) != 192U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 192U) || ((unsigned int )*((unsigned short *)(& os) + 0UL) != 176U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 176U)) {
#line 1456
    drbd_queue_bitmap_io(mdev, & drbd_bmio_set_n_write, & abw_start_sync, (char *)"set_n_write from StartingSync",
                         BM_LOCKED_TEST_ALLOWED);
  } else {

  }
#line 1461
  if ((((int )os.ldv_40024.conn <= 9 && (int )ns.ldv_40024.conn <= 9) && (int )os.ldv_40024.disk > 4) && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 8U) {
#line 1464
    drbd_queue_bitmap_io(mdev, & drbd_bmio_set_n_write, 0, (char *)"set_n_write from invalidate",
                         BM_LOCKED_MASK);
  } else {

  }
#line 1469
  if ((unsigned int )*((unsigned char *)(& os) + 1UL) != 4U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 4U) {
#line 1470
    eh = EP_PASS_ON;
#line 1471
    was_io_error = 0;
#line 1476
    if ((unsigned long )mdev->ldev != (unsigned long )((struct drbd_backing_dev *)0)) {
#line 1477
      rcu_read_lock___7();
#line 1478
      _________p1 = *((struct disk_conf * volatile  *)(& (mdev->ldev)->disk_conf));
#line 1478
      tmp___9 = debug_lockdep_rcu_enabled();
#line 1478
      if (tmp___9 != 0 && ! __warned) {
#line 1478
        tmp___10 = rcu_read_lock_held();
#line 1478
        if (tmp___10 == 0 && 1) {
#line 1478
          __warned = 1;
#line 1478
          lockdep_rcu_suspicious("/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared",
                                 1478, "suspicious rcu_dereference_check() usage");
        } else {

        }
      } else {

      }
#line 1478
      eh = (enum drbd_io_error_p )_________p1->on_io_error;
#line 1479
      rcu_read_unlock___7();
#line 1481
      was_io_error = test_and_clear_bit(12, (unsigned long volatile   *)(& mdev->flags));
#line 1483
      if (was_io_error != 0 && (unsigned int )eh == 1U) {
#line 1484
        drbd_khelper(mdev, (char *)"local-io-error");
      } else {

      }
#line 1499
      tmp___11 = test_and_clear_bit(14, (unsigned long volatile   *)(& mdev->flags));
#line 1499
      if (tmp___11 != 0) {
#line 1500
        tl_abort_disk_io(mdev);
      } else {

      }
#line 1505
      if ((unsigned int )*((unsigned char *)mdev + 749UL) != 4U) {
#line 1506
        tmp___12 = drbd_disk_str((enum drbd_disk_state )mdev->state.ldv_49522.disk);
#line 1506
        dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED: disk is %s during detach\n",
                tmp___12);
      } else {

      }
#line 1510
      if ((int )ns.ldv_40024.conn > 9) {
#line 1511
        drbd_send_state(mdev, ns);
      } else {

      }
#line 1513
      drbd_rs_cancel_all(mdev);
#line 1518
      drbd_md_sync(mdev);
    } else {

    }
#line 1520
    put_ldev(mdev);
  } else {

  }
#line 1526
  if ((unsigned int )*((unsigned char *)(& os) + 1UL) != 0U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 0U) {
#line 1529
    if ((unsigned int )*((unsigned char *)mdev + 749UL) != 0U) {
#line 1530
      tmp___13 = drbd_disk_str((enum drbd_disk_state )mdev->state.ldv_49522.disk);
#line 1530
      dev_err((struct device  const  *)(& (mdev->vdisk)->part0.__dev), "ASSERT FAILED: disk is %s while going diskless\n",
              tmp___13);
    } else {

    }
#line 1534
    if ((int )ns.ldv_40024.conn > 9) {
#line 1535
      drbd_send_state(mdev, ns);
    } else {

    }
#line 1538
    put_ldev(mdev);
  } else {

  }
#line 1542
  if (((unsigned int )*((unsigned char *)(& os) + 1UL) == 16U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 8U) && (int )ns.ldv_40024.conn > 9) {
#line 1543
    drbd_send_state(mdev, ns);
  } else {

  }
#line 1546
  if ((int )ns.ldv_40024.disk > 3 && (int )ns.ldv_40024.pdsk > 3) {
#line 1546
    tmp___14 = test_and_clear_bit(15, (unsigned long volatile   *)(& mdev->flags));
#line 1546
    if (tmp___14 != 0) {
#line 1548
      if ((unsigned int )*((unsigned short *)(& ns) + 0UL) == 160U) {
#line 1549
        resync_after_online_grow(mdev);
      } else {

      }
    } else {

    }
  } else {

  }
#line 1553
  if ((((int )os.ldv_40024.conn > 10 && (int )ns.ldv_40024.conn <= 10) || ((unsigned int )*((unsigned char *)(& os) + 2UL) != 0U && (unsigned int )*((unsigned char *)(& ns) + 2UL) == 0U)) || ((unsigned int )*((unsigned char *)(& os) + 2UL) != 0U && (unsigned int )*((unsigned char *)(& ns) + 2UL) == 0U)) {
#line 1556
    resume_next_sg(mdev);
  } else {

  }
#line 1560
  if (((int )os.ldv_40024.disk <= 7 && (int )os.ldv_40024.conn > 15) && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 160U) {
#line 1561
    drbd_send_state(mdev, ns);
  } else {

  }
#line 1566
  if ((unsigned int )*((unsigned short *)(& os) + 0UL) == 288U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 160U) {
#line 1566
    tmp___15 = verify_can_do_stop_sector(mdev);
#line 1566
    if ((int )tmp___15) {
#line 1568
      drbd_send_state(mdev, ns);
    } else {

    }
  } else {

  }
#line 1577
  if ((int )os.ldv_40024.conn > 10 && (int )ns.ldv_40024.conn <= 10) {
#line 1577
    tmp___16 = _get_ldev_if_state(mdev, D_INCONSISTENT);
#line 1577
    if (tmp___16 != 0) {
#line 1578
      drbd_queue_bitmap_io(mdev, & drbd_bm_write_copy_pages, 0, (char *)"write from resync_finished",
                           BM_IS_LOCKED);
#line 1580
      put_ldev(mdev);
    } else {

    }
  } else {

  }
#line 1583
  if (((unsigned int )*((unsigned char *)(& ns) + 1UL) == 0U && (unsigned int )*((unsigned short *)(& ns) + 0UL) == 0U) && (unsigned int )*((unsigned char *)(& ns) + 0UL) == 2U) {
#line 1586
    if ((int )os.ldv_40024.aftr_isp != (int )ns.ldv_40024.aftr_isp) {
#line 1587
      resume_next_sg(mdev);
    } else {

    }
  } else {

  }
#line 1590
  drbd_md_sync(mdev);
#line 1591
  return;
}
}
#line 1601 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static int w_after_conn_state_ch(struct drbd_work *w , int unused ) 
{ 
  struct after_conn_state_chg_work *acscw ;
  struct drbd_work  const  *__mptr ;
  struct drbd_tconn *tconn ;
  enum drbd_conns oc ;
  union drbd_state ns_max ;
  struct drbd_conf *mdev ;
  int vnr ;
  struct net_conf *old_conf ;
  void *tmp ;
  int tmp___0 ;
  void *tmp___1 ;
  union drbd_state __constr_expr_0 ;
  union drbd_state __constr_expr_1 ;

  {
#line 1604
  __mptr = (struct drbd_work  const  *)w;
#line 1604
  acscw = (struct after_conn_state_chg_work *)__mptr;
#line 1605
  tconn = w->ldv_49807.tconn;
#line 1606
  oc = acscw->oc;
#line 1607
  ns_max = acscw->ns_max;
#line 1611
  kfree((void const   *)acscw);
#line 1614
  if ((unsigned int )oc == 0U && (unsigned int )*((unsigned short *)(& ns_max) + 0UL) == 32U) {
#line 1615
    drbd_thread_start(& tconn->receiver);
  } else {

  }
#line 1617
  if ((unsigned int )oc == 1U && (unsigned int )*((unsigned short *)(& ns_max) + 0UL) == 0U) {
#line 1620
    ldv_mutex_lock_354(& tconn->conf_update);
#line 1621
    old_conf = tconn->net_conf;
#line 1622
    tconn->my_addr_len = 0;
#line 1623
    tconn->peer_addr_len = 0;
#line 1624
    __asm__  volatile   ("": : : "memory");
#line 1624
    tconn->net_conf = 0;
#line 1625
    conn_free_crypto(tconn);
#line 1626
    ldv_mutex_unlock_355(& tconn->conf_update);
#line 1628
    synchronize_rcu();
#line 1629
    kfree((void const   *)old_conf);
  } else {

  }
#line 1632
  if ((unsigned int )*((unsigned char *)(& ns_max) + 2UL) != 0U) {
#line 1634
    if ((int )ns_max.ldv_40024.pdsk <= 5) {
#line 1635
      rcu_read_lock___7();
#line 1636
      vnr = 0;
#line 1636
      tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1636
      mdev = (struct drbd_conf *)tmp;
#line 1636
      goto ldv_52421;
      ldv_52420: 
#line 1637
      tmp___0 = constant_test_bit(17U, (unsigned long const volatile   *)(& mdev->flags));
#line 1637
      if (tmp___0 != 0) {
#line 1638
        drbd_uuid_new_current(mdev);
#line 1639
        clear_bit(17, (unsigned long volatile   *)(& mdev->flags));
      } else {

      }
#line 1636
      vnr = vnr + 1;
#line 1636
      tmp___1 = idr_get_next(& tconn->volumes, & vnr);
#line 1636
      mdev = (struct drbd_conf *)tmp___1;
      ldv_52421: ;
#line 1636
      if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1637
        goto ldv_52420;
      } else {

      }
#line 1642
      rcu_read_unlock___7();
#line 1643
      spin_lock_irq(& tconn->req_lock);
#line 1644
      _tl_restart(tconn, CONNECTION_LOST_WHILE_PENDING);
#line 1645
      __constr_expr_0.ldv_40024.role = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.peer = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.conn = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.disk = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.pdsk = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.susp = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.aftr_isp = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.peer_isp = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.user_isp = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.susp_nod = (unsigned char)0;
#line 1645
      __constr_expr_0.ldv_40024.susp_fen = 0U;
#line 1645
      __constr_expr_0.ldv_40024._pad = (unsigned short)0;
#line 1645
      __constr_expr_1.ldv_40024.role = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.peer = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.conn = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.disk = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.pdsk = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.susp = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.aftr_isp = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.peer_isp = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.user_isp = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.susp_nod = (unsigned char)0;
#line 1645
      __constr_expr_1.ldv_40024.susp_fen = 1U;
#line 1645
      __constr_expr_1.ldv_40024._pad = (unsigned short)0;
#line 1645
      _conn_request_state(tconn, __constr_expr_1, __constr_expr_0, CS_VERBOSE);
#line 1649
      spin_unlock_irq(& tconn->req_lock);
    } else {

    }
  } else {

  }
#line 1652
  kref_put(& tconn->kref, & conn_destroy);
#line 1654
  conn_md_sync(tconn);
#line 1656
  return (0);
}
}
#line 1659 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void conn_old_common_state(struct drbd_tconn *tconn , union drbd_state *pcs , enum chg_state_flags *pf ) 
{ 
  enum chg_state_flags flags ;
  struct drbd_conf *mdev ;
  int vnr ;
  int first_vol ;
  union drbd_dev_state os ;
  union drbd_dev_state cs ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 1661
  flags = 4294967295L;
#line 1663
  first_vol = 1;
#line 1664
  cs.ldv_49522.role = 2U;
#line 1664
  cs.ldv_49522.peer = 0U;
#line 1664
  cs.ldv_49522.conn = (unsigned char )tconn->cstate;
#line 1664
  cs.ldv_49522.disk = 0U;
#line 1664
  cs.ldv_49522.pdsk = 6U;
#line 1664
  cs.ldv_49522._unused = (unsigned char)0;
#line 1664
  cs.ldv_49522.aftr_isp = (unsigned char)0;
#line 1664
  cs.ldv_49522.peer_isp = (unsigned char)0;
#line 1664
  cs.ldv_49522.user_isp = (unsigned char)0;
#line 1664
  cs.ldv_49522._pad = (unsigned short)0;
#line 1672
  rcu_read_lock___7();
#line 1673
  vnr = 0;
#line 1673
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1673
  mdev = (struct drbd_conf *)tmp;
#line 1673
  goto ldv_52438;
  ldv_52437: 
#line 1674
  os = mdev->state;
#line 1676
  if (first_vol != 0) {
#line 1677
    cs = os;
#line 1678
    first_vol = 0;
#line 1679
    goto ldv_52436;
  } else {

  }
#line 1682
  if ((int )cs.ldv_49522.role != (int )os.ldv_49522.role) {
#line 1683
    flags = (enum chg_state_flags )((unsigned int )flags & 4294967263U);
  } else {

  }
#line 1685
  if ((int )cs.ldv_49522.peer != (int )os.ldv_49522.peer) {
#line 1686
    flags = (enum chg_state_flags )((unsigned int )flags & 4294967231U);
  } else {

  }
#line 1688
  if ((int )cs.ldv_49522.conn != (int )os.ldv_49522.conn) {
#line 1689
    flags = (enum chg_state_flags )((unsigned int )flags & 4294967167U);
  } else {

  }
#line 1691
  if ((int )cs.ldv_49522.disk != (int )os.ldv_49522.disk) {
#line 1692
    flags = (enum chg_state_flags )((unsigned int )flags & 4294967039U);
  } else {

  }
#line 1694
  if ((int )cs.ldv_49522.pdsk != (int )os.ldv_49522.pdsk) {
#line 1695
    flags = (enum chg_state_flags )((unsigned int )flags & 4294966783U);
  } else {

  }
  ldv_52436: 
#line 1673
  vnr = vnr + 1;
#line 1673
  tmp___0 = idr_get_next(& tconn->volumes, & vnr);
#line 1673
  mdev = (struct drbd_conf *)tmp___0;
  ldv_52438: ;
#line 1673
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1674
    goto ldv_52437;
  } else {

  }
#line 1697
  rcu_read_unlock___7();
#line 1699
  *pf = (enum chg_state_flags )((unsigned int )*pf | 992U);
#line 1700
  *pf = (enum chg_state_flags )((unsigned int )*pf & (unsigned int )flags);
#line 1701
  pcs->i = cs.i;
#line 1702
  return;
}
}
#line 1705 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv conn_is_valid_transition(struct drbd_tconn *tconn , union drbd_state mask ,
                                                   union drbd_state val , enum chg_state_flags flags ) 
{ 
  enum drbd_state_rv rv ;
  union drbd_state ns ;
  union drbd_state os ;
  struct drbd_conf *mdev ;
  int vnr ;
  void *tmp ;
  union drbd_state tmp___0 ;
  enum drbd_state_rv tmp___1 ;
  void *tmp___2 ;

  {
#line 1708
  rv = 1;
#line 1713
  rcu_read_lock___7();
#line 1714
  vnr = 0;
#line 1714
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1714
  mdev = (struct drbd_conf *)tmp;
#line 1714
  goto ldv_52454;
  ldv_52453: 
#line 1715
  os = drbd_read_state(mdev);
#line 1716
  tmp___0 = apply_mask_val(os, mask, val);
#line 1716
  ns = sanitize_state(mdev, tmp___0, 0);
#line 1718
  if ((((unsigned int )flags & 2048U) != 0U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 10U) && (int )os.ldv_40024.disk <= 4) {
#line 1719
    ns.ldv_40024.disk = os.ldv_40024.disk;
  } else {

  }
#line 1721
  if (ns.i == os.i) {
#line 1722
    goto ldv_52451;
  } else {

  }
#line 1724
  rv = is_valid_transition(os, ns);
#line 1725
  if ((int )rv <= 0) {
#line 1726
    goto ldv_52452;
  } else {

  }
#line 1728
  if (((unsigned int )flags & 1U) == 0U) {
#line 1729
    rv = is_valid_state(mdev, ns);
#line 1730
    if ((int )rv <= 0) {
#line 1731
      tmp___1 = is_valid_state(mdev, os);
#line 1731
      if ((int )tmp___1 == (int )rv) {
#line 1732
        rv = is_valid_soft_transition(os, ns, tconn);
      } else {
#line 1734
        rv = is_valid_soft_transition(os, ns, tconn);
      }
    } else {

    }
  } else {

  }
#line 1736
  if ((int )rv <= 0) {
#line 1737
    goto ldv_52452;
  } else {

  }
  ldv_52451: 
#line 1714
  vnr = vnr + 1;
#line 1714
  tmp___2 = idr_get_next(& tconn->volumes, & vnr);
#line 1714
  mdev = (struct drbd_conf *)tmp___2;
  ldv_52454: ;
#line 1714
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1715
    goto ldv_52453;
  } else {

  }
  ldv_52452: 
#line 1739
  rcu_read_unlock___7();
#line 1741
  if ((int )rv <= 0 && ((unsigned int )flags & 2U) != 0U) {
#line 1742
    print_st_err(mdev, os, ns, rv);
  } else {

  }
#line 1744
  return (rv);
}
}
#line 1748 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void conn_set_state(struct drbd_tconn *tconn , union drbd_state mask , union drbd_state val ,
                    union drbd_state *pns_min , union drbd_state *pns_max , enum chg_state_flags flags ) 
{ 
  union drbd_state ns ;
  union drbd_state os ;
  union drbd_state ns_max ;
  union drbd_state ns_min ;
  struct drbd_conf *mdev ;
  enum drbd_state_rv rv ;
  int vnr ;
  int number_of_volumes ;
  void *tmp ;
  enum drbd_role tmp___0 ;
  enum drbd_role tmp___1 ;
  enum drbd_conns __max1 ;
  enum drbd_conns __max2 ;
  enum drbd_disk_state __max1___0 ;
  enum drbd_disk_state __max2___0 ;
  enum drbd_disk_state __max1___1 ;
  enum drbd_disk_state __max2___1 ;
  enum drbd_role tmp___2 ;
  enum drbd_role tmp___3 ;
  enum drbd_conns __min1 ;
  enum drbd_conns __min2 ;
  enum drbd_disk_state __min1___0 ;
  enum drbd_disk_state __min2___0 ;
  enum drbd_disk_state __min1___1 ;
  enum drbd_disk_state __min2___1 ;
  void *tmp___4 ;
  union drbd_state __constr_expr_0 ;

  {
#line 1751
  ns_max.ldv_40024.role = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.peer = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.conn = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.disk = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.pdsk = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.susp = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.aftr_isp = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.peer_isp = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.user_isp = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.susp_nod = (unsigned char)0;
#line 1751
  ns_max.ldv_40024.susp_fen = (unsigned char)0;
#line 1751
  ns_max.ldv_40024._pad = (unsigned short)0;
#line 1752
  ns_min.ldv_40024.role = 3U;
#line 1752
  ns_min.ldv_40024.peer = 3U;
#line 1752
  ns_min.ldv_40024.conn = val.ldv_40024.conn;
#line 1752
  ns_min.ldv_40024.disk = 15U;
#line 1752
  ns_min.ldv_40024.pdsk = 15U;
#line 1752
  ns_min.ldv_40024.susp = (unsigned char)0;
#line 1752
  ns_min.ldv_40024.aftr_isp = (unsigned char)0;
#line 1752
  ns_min.ldv_40024.peer_isp = (unsigned char)0;
#line 1752
  ns_min.ldv_40024.user_isp = (unsigned char)0;
#line 1752
  ns_min.ldv_40024.susp_nod = (unsigned char)0;
#line 1752
  ns_min.ldv_40024.susp_fen = (unsigned char)0;
#line 1752
  ns_min.ldv_40024._pad = (unsigned short)0;
#line 1761
  number_of_volumes = 0;
#line 1763
  if ((unsigned int )*((unsigned short *)(& mask) + 0UL) == 496U) {
#line 1767
    if ((unsigned int )tconn->cstate != 9U && (unsigned int )*((unsigned short *)(& val) + 0UL) == 144U) {
#line 1768
      tconn->last_reconnect_jif = jiffies;
    } else {

    }
#line 1770
    tconn->cstate = (enum drbd_conns )val.ldv_40024.conn;
  } else {

  }
#line 1773
  rcu_read_lock___7();
#line 1774
  vnr = 0;
#line 1774
  tmp = idr_get_next(& tconn->volumes, & vnr);
#line 1774
  mdev = (struct drbd_conf *)tmp;
#line 1774
  goto ldv_52491;
  ldv_52490: 
#line 1775
  number_of_volumes = number_of_volumes + 1;
#line 1776
  os = drbd_read_state(mdev);
#line 1777
  ns = apply_mask_val(os, mask, val);
#line 1778
  ns = sanitize_state(mdev, ns, 0);
#line 1780
  if ((((unsigned int )flags & 2048U) != 0U && (unsigned int )*((unsigned char *)(& ns) + 1UL) == 10U) && (int )os.ldv_40024.disk <= 4) {
#line 1781
    ns.ldv_40024.disk = os.ldv_40024.disk;
  } else {

  }
#line 1783
  rv = __drbd_set_state(mdev, ns, flags, 0);
#line 1784
  if ((int )rv <= 0) {
#line 1785
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"),
                         "i" (1785), "i" (12UL));
    ldv_52471: ;
#line 1785
    goto ldv_52471;
  } else {

  }
#line 1787
  ns.i = mdev->state.i;
#line 1788
  tmp___0 = max_role((enum drbd_role )ns.ldv_40024.role, (enum drbd_role )ns_max.ldv_40024.role);
#line 1788
  ns_max.ldv_40024.role = (unsigned char )tmp___0;
#line 1789
  tmp___1 = max_role((enum drbd_role )ns.ldv_40024.peer, (enum drbd_role )ns_max.ldv_40024.peer);
#line 1789
  ns_max.ldv_40024.peer = (unsigned char )tmp___1;
#line 1790
  __max1 = (enum drbd_conns )ns.ldv_40024.conn;
#line 1790
  __max2 = (enum drbd_conns )ns_max.ldv_40024.conn;
#line 1790
  ns_max.ldv_40024.conn = (unsigned char )((unsigned int )__max1 > (unsigned int )__max2 ? (unsigned int )__max1 : (unsigned int )__max2);
#line 1791
  __max1___0 = (enum drbd_disk_state )ns.ldv_40024.disk;
#line 1791
  __max2___0 = (enum drbd_disk_state )ns_max.ldv_40024.disk;
#line 1791
  ns_max.ldv_40024.disk = (unsigned char )((unsigned int )__max1___0 > (unsigned int )__max2___0 ? (unsigned int )__max1___0 : (unsigned int )__max2___0);
#line 1792
  __max1___1 = (enum drbd_disk_state )ns.ldv_40024.pdsk;
#line 1792
  __max2___1 = (enum drbd_disk_state )ns_max.ldv_40024.pdsk;
#line 1792
  ns_max.ldv_40024.pdsk = (unsigned char )((unsigned int )__max1___1 > (unsigned int )__max2___1 ? (unsigned int )__max1___1 : (unsigned int )__max2___1);
#line 1794
  tmp___2 = min_role((enum drbd_role )ns.ldv_40024.role, (enum drbd_role )ns_min.ldv_40024.role);
#line 1794
  ns_min.ldv_40024.role = (unsigned char )tmp___2;
#line 1795
  tmp___3 = min_role((enum drbd_role )ns.ldv_40024.peer, (enum drbd_role )ns_min.ldv_40024.peer);
#line 1795
  ns_min.ldv_40024.peer = (unsigned char )tmp___3;
#line 1796
  __min1 = (enum drbd_conns )ns.ldv_40024.conn;
#line 1796
  __min2 = (enum drbd_conns )ns_min.ldv_40024.conn;
#line 1796
  ns_min.ldv_40024.conn = (unsigned char )((unsigned int )__min1 < (unsigned int )__min2 ? (unsigned int )__min1 : (unsigned int )__min2);
#line 1797
  __min1___0 = (enum drbd_disk_state )ns.ldv_40024.disk;
#line 1797
  __min2___0 = (enum drbd_disk_state )ns_min.ldv_40024.disk;
#line 1797
  ns_min.ldv_40024.disk = (unsigned char )((unsigned int )__min1___0 < (unsigned int )__min2___0 ? (unsigned int )__min1___0 : (unsigned int )__min2___0);
#line 1798
  __min1___1 = (enum drbd_disk_state )ns.ldv_40024.pdsk;
#line 1798
  __min2___1 = (enum drbd_disk_state )ns_min.ldv_40024.pdsk;
#line 1798
  ns_min.ldv_40024.pdsk = (unsigned char )((unsigned int )__min1___1 < (unsigned int )__min2___1 ? (unsigned int )__min1___1 : (unsigned int )__min2___1);
#line 1774
  vnr = vnr + 1;
#line 1774
  tmp___4 = idr_get_next(& tconn->volumes, & vnr);
#line 1774
  mdev = (struct drbd_conf *)tmp___4;
  ldv_52491: ;
#line 1774
  if ((unsigned long )mdev != (unsigned long )((struct drbd_conf *)0)) {
#line 1775
    goto ldv_52490;
  } else {

  }
#line 1800
  rcu_read_unlock___7();
#line 1802
  if (number_of_volumes == 0) {
#line 1803
    __constr_expr_0.ldv_40024.role = 2U;
#line 1803
    __constr_expr_0.ldv_40024.peer = 0U;
#line 1803
    __constr_expr_0.ldv_40024.conn = val.ldv_40024.conn;
#line 1803
    __constr_expr_0.ldv_40024.disk = 0U;
#line 1803
    __constr_expr_0.ldv_40024.pdsk = 6U;
#line 1803
    __constr_expr_0.ldv_40024.susp = (unsigned char)0;
#line 1803
    __constr_expr_0.ldv_40024.aftr_isp = (unsigned char)0;
#line 1803
    __constr_expr_0.ldv_40024.peer_isp = (unsigned char)0;
#line 1803
    __constr_expr_0.ldv_40024.user_isp = (unsigned char)0;
#line 1803
    __constr_expr_0.ldv_40024.susp_nod = (unsigned char)0;
#line 1803
    __constr_expr_0.ldv_40024.susp_fen = (unsigned char)0;
#line 1803
    __constr_expr_0.ldv_40024._pad = (unsigned short)0;
#line 1803
    ns_max = __constr_expr_0;
#line 1803
    ns_min = ns_max;
  } else {

  }
#line 1812
  ns_max.ldv_40024.susp = tconn->susp;
#line 1812
  ns_min.ldv_40024.susp = ns_max.ldv_40024.susp;
#line 1813
  ns_max.ldv_40024.susp_nod = tconn->susp_nod;
#line 1813
  ns_min.ldv_40024.susp_nod = ns_max.ldv_40024.susp_nod;
#line 1814
  ns_max.ldv_40024.susp_fen = tconn->susp_fen;
#line 1814
  ns_min.ldv_40024.susp_fen = ns_max.ldv_40024.susp_fen;
#line 1816
  *pns_min = ns_min;
#line 1817
  *pns_max = ns_max;
#line 1818
  return;
}
}
#line 1821 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
static enum drbd_state_rv _conn_rq_cond(struct drbd_tconn *tconn , union drbd_state mask ,
                                        union drbd_state val ) 
{ 
  enum drbd_state_rv rv ;
  int tmp ;
  int tmp___0 ;

  {
#line 1825
  tmp = test_and_clear_bit(6, (unsigned long volatile   *)(& tconn->flags));
#line 1825
  if (tmp != 0) {
#line 1826
    return (SS_CW_SUCCESS);
  } else {

  }
#line 1828
  tmp___0 = test_and_clear_bit(7, (unsigned long volatile   *)(& tconn->flags));
#line 1828
  if (tmp___0 != 0) {
#line 1829
    return (SS_CW_FAILED_BY_PEER);
  } else {

  }
#line 1831
  rv = (unsigned int )tconn->cstate != 9U ? SS_CW_NO_NEED : SS_UNKNOWN_ERROR;
#line 1833
  if ((int )rv == 0) {
#line 1834
    rv = conn_is_valid_transition(tconn, mask, val, 0);
  } else {

  }
#line 1836
  if ((int )rv == 1) {
#line 1837
    rv = SS_UNKNOWN_ERROR;
  } else {

  }
#line 1839
  return (rv);
}
}
#line 1843 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_state_rv _conn_request_state(struct drbd_tconn *tconn , union drbd_state mask ,
                                       union drbd_state val , enum chg_state_flags flags ) 
{ 
  enum drbd_state_rv rv ;
  struct after_conn_state_chg_work *acscw ;
  enum drbd_conns oc ;
  union drbd_state ns_max ;
  union drbd_state ns_min ;
  union drbd_state os ;
  bool have_mutex ;
  int tmp ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  void *tmp___1 ;
  char const   *tmp___2 ;
  char const   *tmp___3 ;
  char const   *tmp___4 ;

  {
#line 1846
  rv = 1;
#line 1848
  oc = tconn->cstate;
#line 1850
  have_mutex = 0;
#line 1852
  if ((unsigned int )*((unsigned short *)(& mask) + 0UL) != 0U) {
#line 1853
    rv = is_valid_conn_transition(oc, (enum drbd_conns )val.ldv_40024.conn);
#line 1854
    if ((int )rv <= 0) {
#line 1855
      goto abort;
    } else {

    }
  } else {

  }
#line 1858
  rv = conn_is_valid_transition(tconn, mask, val, flags);
#line 1859
  if ((int )rv <= 0) {
#line 1860
    goto abort;
  } else {

  }
#line 1862
  if (((unsigned int )oc == 9U && (unsigned int )*((unsigned short *)(& val) + 0UL) == 16U) && ((unsigned int )flags & 17U) == 0U) {
#line 1868
    spin_unlock_irq(& tconn->req_lock);
#line 1869
    ldv_mutex_lock_356(& tconn->cstate_mutex);
#line 1870
    have_mutex = 1;
#line 1872
    set_bit(5U, (unsigned long volatile   *)(& tconn->flags));
#line 1873
    tmp = conn_send_state_req(tconn, mask, val);
#line 1873
    if (tmp != 0) {
#line 1875
      clear_bit(5, (unsigned long volatile   *)(& tconn->flags));
#line 1876
      rv = SS_CW_FAILED_BY_PEER;
#line 1878
      goto abort_unlocked;
    } else {

    }
#line 1881
    if ((unsigned int )*((unsigned short *)(& val) + 0UL) == 16U) {
#line 1882
      set_bit(12U, (unsigned long volatile   *)(& tconn->flags));
    } else {

    }
#line 1887
    spin_lock_irq(& tconn->req_lock);
#line 1888
    rv = _conn_rq_cond(tconn, mask, val);
#line 1888
    if ((int )rv != 0) {
#line 1888
      goto ldv_52515;
    } else {

    }
#line 1888
    tmp___0 = get_current();
#line 1888
    __wait.flags = 0U;
#line 1888
    __wait.private = (void *)tmp___0;
#line 1888
    __wait.func = & autoremove_wake_function;
#line 1888
    __wait.task_list.next = & __wait.task_list;
#line 1888
    __wait.task_list.prev = & __wait.task_list;
    ldv_52518: 
#line 1888
    prepare_to_wait(& tconn->ping_wait, & __wait, 2);
#line 1888
    rv = _conn_rq_cond(tconn, mask, val);
#line 1888
    if ((int )rv != 0) {
#line 1888
      goto ldv_52517;
    } else {

    }
#line 1888
    spin_unlock_irq(& tconn->req_lock);
#line 1888
    schedule();
#line 1888
    spin_lock_irq(& tconn->req_lock);
#line 1888
    goto ldv_52518;
    ldv_52517: 
#line 1888
    finish_wait(& tconn->ping_wait, & __wait);
    ldv_52515: 
#line 1891
    clear_bit(5, (unsigned long volatile   *)(& tconn->flags));
#line 1892
    if ((int )rv <= 0) {
#line 1893
      goto abort;
    } else {

    }
  } else {

  }
#line 1896
  conn_old_common_state(tconn, & os, & flags);
#line 1897
  flags = (enum chg_state_flags )((unsigned int )flags | 1024U);
#line 1898
  conn_set_state(tconn, mask, val, & ns_min, & ns_max, flags);
#line 1899
  conn_pr_state_change(tconn, os, ns_max, flags);
#line 1901
  tmp___1 = kmalloc(48UL, 32U);
#line 1901
  acscw = (struct after_conn_state_chg_work *)tmp___1;
#line 1902
  if ((unsigned long )acscw != (unsigned long )((struct after_conn_state_chg_work *)0)) {
#line 1903
    acscw->oc = (enum drbd_conns )os.ldv_40024.conn;
#line 1904
    acscw->ns_min = ns_min;
#line 1905
    acscw->ns_max = ns_max;
#line 1906
    acscw->flags = flags;
#line 1907
    acscw->w.cb = & w_after_conn_state_ch;
#line 1908
    kref_get(& tconn->kref);
#line 1909
    acscw->w.ldv_49807.tconn = tconn;
#line 1910
    drbd_queue_work(& tconn->sender_work, & acscw->w);
  } else {
#line 1912
    printk("\vd-con %s: Could not kmalloc an acscw\n", tconn->name);
  }
  abort: ;
#line 1916
  if ((int )have_mutex) {
#line 1919
    spin_unlock_irq(& tconn->req_lock);
    abort_unlocked: 
#line 1921
    ldv_mutex_unlock_357(& tconn->cstate_mutex);
#line 1922
    spin_lock_irq(& tconn->req_lock);
  } else {

  }
#line 1924
  if ((int )rv <= 0 && ((unsigned int )flags & 2U) != 0U) {
#line 1925
    tmp___2 = drbd_set_st_err_str(rv);
#line 1925
    printk("\vd-con %s: State change failed: %s\n", tconn->name, tmp___2);
#line 1926
    printk("\vd-con %s:  mask = 0x%x val = 0x%x\n", tconn->name, mask.i, val.i);
#line 1927
    tmp___3 = drbd_conn_str((enum drbd_conns )val.ldv_40024.conn);
#line 1927
    tmp___4 = drbd_conn_str(oc);
#line 1927
    printk("\vd-con %s:  old_conn:%s wanted_conn:%s\n", tconn->name, tmp___4, tmp___3);
  } else {

  }
#line 1929
  return (rv);
}
}
#line 1933 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
enum drbd_state_rv conn_request_state(struct drbd_tconn *tconn , union drbd_state mask ,
                                      union drbd_state val , enum chg_state_flags flags ) 
{ 
  enum drbd_state_rv rv ;

  {
#line 1938
  spin_lock_irq(& tconn->req_lock);
#line 1939
  rv = _conn_request_state(tconn, mask, val, flags);
#line 1940
  spin_unlock_irq(& tconn->req_lock);
#line 1942
  return (rv);
}
}
#line 1945 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_341(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1950
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1952
  mutex_lock(ldv_func_arg1);
#line 1953
  return;
}
}
#line 1955 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_342(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1960
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 1962
  mutex_unlock(ldv_func_arg1);
#line 1963
  return;
}
}
#line 1965 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_343(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1970
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 1972
  mutex_lock(ldv_func_arg1);
#line 1973
  return;
}
}
#line 1975 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_344(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1980
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 1982
  mutex_unlock(ldv_func_arg1);
#line 1983
  return;
}
}
#line 1985 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_345(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 1990
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 1992
  mutex_lock(ldv_func_arg1);
#line 1993
  return;
}
}
#line 1995 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
int ldv_mutex_trylock_346(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 2000
  tmp = mutex_trylock(ldv_func_arg1);
#line 2000
  ldv_func_res = tmp;
#line 2002
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 2002
  return (tmp___0);
#line 2004
  return (ldv_func_res);
}
}
#line 2007 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_347(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2012
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 2014
  mutex_unlock(ldv_func_arg1);
#line 2015
  return;
}
}
#line 2017 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_348(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2022
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2024
  mutex_lock(ldv_func_arg1);
#line 2025
  return;
}
}
#line 2027 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_349(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2032
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2034
  mutex_unlock(ldv_func_arg1);
#line 2035
  return;
}
}
#line 2037 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_350(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2042
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2044
  mutex_lock(ldv_func_arg1);
#line 2045
  return;
}
}
#line 2047 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_351(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2052
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 2054
  mutex_unlock(ldv_func_arg1);
#line 2055
  return;
}
}
#line 2057 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_352(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2062
  ldv_mutex_lock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 2064
  mutex_lock(ldv_func_arg1);
#line 2065
  return;
}
}
#line 2067 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_353(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2072
  ldv_mutex_unlock_state_mutex_of_drbd_conf(ldv_func_arg1);
#line 2074
  mutex_unlock(ldv_func_arg1);
#line 2075
  return;
}
}
#line 2077 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_354(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2082
  ldv_mutex_lock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 2084
  mutex_lock(ldv_func_arg1);
#line 2085
  return;
}
}
#line 2087 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_355(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2092
  ldv_mutex_unlock_conf_update_of_drbd_tconn(ldv_func_arg1);
#line 2094
  mutex_unlock(ldv_func_arg1);
#line 2095
  return;
}
}
#line 2097 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_lock_356(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2102
  ldv_mutex_lock_cstate_mutex_of_drbd_tconn(ldv_func_arg1);
#line 2104
  mutex_lock(ldv_func_arg1);
#line 2105
  return;
}
}
#line 2107 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_state.c.prepared"
void ldv_mutex_unlock_357(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 2112
  ldv_mutex_unlock_cstate_mutex_of_drbd_tconn(ldv_func_arg1);
#line 2114
  mutex_unlock(ldv_func_arg1);
#line 2115
  return;
}
}
#line 171 "include/linux/mutex.h"
int ldv_mutex_trylock_380(struct mutex *ldv_func_arg1 ) ;
#line 176
void ldv_mutex_unlock_376(struct mutex *ldv_func_arg1 ) ;
#line 180
void ldv_mutex_unlock_378(struct mutex *ldv_func_arg1 ) ;
#line 184
void ldv_mutex_unlock_381(struct mutex *ldv_func_arg1 ) ;
#line 188
void ldv_mutex_unlock_383(struct mutex *ldv_func_arg1 ) ;
#line 192
void ldv_mutex_unlock_385(struct mutex *ldv_func_arg1 ) ;
#line 10 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_lock_375(struct mutex *ldv_func_arg1 ) ;
#line 14
void ldv_mutex_lock_377(struct mutex *ldv_func_arg1 ) ;
#line 18
void ldv_mutex_lock_379(struct mutex *ldv_func_arg1 ) ;
#line 22
void ldv_mutex_lock_382(struct mutex *ldv_func_arg1 ) ;
#line 26
void ldv_mutex_lock_384(struct mutex *ldv_func_arg1 ) ;
#line 238 "include/net/netlink.h"
extern int nla_parse(struct nlattr ** , int  , struct nlattr  const  * , int  , struct nla_policy  const  * ) ;
#line 672 "include/net/netlink.h"
__inline static int nla_type(struct nlattr  const  *nla ) 
{ 


  {
#line 674
  return ((int )nla->nla_type & -49153);
}
}
#line 700 "include/net/netlink.h"
__inline static int nla_ok(struct nlattr  const  *nla , int remaining ) 
{ 


  {
#line 702
  return ((remaining > 3 && (unsigned int )((unsigned short )nla->nla_len) > 3U) && (int )nla->nla_len <= remaining);
}
}
#line 715 "include/net/netlink.h"
__inline static struct nlattr *nla_next(struct nlattr  const  *nla , int *remaining ) 
{ 
  int totlen ;

  {
#line 717
  totlen = ((int )nla->nla_len + 3) & -4;
#line 719
  *remaining = *remaining - totlen;
#line 720
  return ((struct nlattr *)nla + (unsigned long )totlen);
}
}
#line 731 "include/net/netlink.h"
__inline static struct nlattr *nla_find_nested(struct nlattr  const  *nla , int attrtype ) 
{ 
  int tmp ;
  void *tmp___0 ;
  struct nlattr *tmp___1 ;

  {
#line 733
  tmp = nla_len(nla);
#line 733
  tmp___0 = nla_data(nla);
#line 733
  tmp___1 = nla_find((struct nlattr  const  *)tmp___0, tmp, attrtype);
#line 733
  return (tmp___1);
}
}
#line 745 "include/net/netlink.h"
__inline static int nla_parse_nested(struct nlattr **tb , int maxtype , struct nlattr  const  *nla ,
                                     struct nla_policy  const  *policy ) 
{ 
  int tmp ;
  void *tmp___0 ;
  int tmp___1 ;

  {
#line 749
  tmp = nla_len(nla);
#line 749
  tmp___0 = nla_data(nla);
#line 749
  tmp___1 = nla_parse(tb, maxtype, (struct nlattr  const  *)tmp___0, tmp, policy);
#line 749
  return (tmp___1);
}
}
#line 94 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
static int drbd_nla_check_mandatory(int maxtype , struct nlattr *nla ) 
{ 
  struct nlattr *head ;
  void *tmp ;
  int len ;
  int tmp___0 ;
  int rem ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 96
  tmp = nla_data((struct nlattr  const  *)nla);
#line 96
  head = (struct nlattr *)tmp;
#line 97
  tmp___0 = nla_len((struct nlattr  const  *)nla);
#line 97
  len = tmp___0;
#line 108
  nla = head;
#line 108
  rem = len;
#line 108
  goto ldv_51112;
  ldv_51111: ;
#line 109
  if (((int )nla->nla_type & 16384) != 0) {
#line 110
    nla->nla_type = (unsigned int )nla->nla_type & 49151U;
#line 111
    tmp___1 = nla_type((struct nlattr  const  *)nla);
#line 111
    if (tmp___1 > maxtype) {
#line 112
      return (-95);
    } else {

    }
  } else {

  }
#line 108
  nla = nla_next((struct nlattr  const  *)nla, & rem);
  ldv_51112: 
#line 108
  tmp___2 = nla_ok((struct nlattr  const  *)nla, rem);
#line 108
  if (tmp___2 != 0) {
#line 109
    goto ldv_51111;
  } else {

  }

#line 115
  return (0);
}
}
#line 118 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
int drbd_nla_parse_nested(struct nlattr **tb , int maxtype , struct nlattr *nla ,
                          struct nla_policy  const  *policy ) 
{ 
  int err ;

  {
#line 123
  err = drbd_nla_check_mandatory(maxtype, nla);
#line 124
  if (err == 0) {
#line 125
    err = nla_parse_nested(tb, maxtype, (struct nlattr  const  *)nla, policy);
  } else {

  }
#line 127
  return (err);
}
}
#line 130 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
struct nlattr *drbd_nla_find_nested(int maxtype , struct nlattr *nla , int attrtype ) 
{ 
  int err ;
  void *tmp ;
  struct nlattr *tmp___0 ;

  {
#line 138
  err = drbd_nla_check_mandatory(maxtype, nla);
#line 139
  if (err != 0) {
#line 140
    tmp = ERR_PTR((long )err);
#line 140
    return ((struct nlattr *)tmp);
  } else {

  }
#line 141
  tmp___0 = nla_find_nested((struct nlattr  const  *)nla, attrtype);
#line 141
  return (tmp___0);
}
}
#line 144 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_lock_375(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 149
  ldv_mutex_lock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 151
  mutex_lock(ldv_func_arg1);
#line 152
  return;
}
}
#line 154 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_unlock_376(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 159
  ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(ldv_func_arg1);
#line 161
  mutex_unlock(ldv_func_arg1);
#line 162
  return;
}
}
#line 164 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_lock_377(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 169
  ldv_mutex_lock_lock(ldv_func_arg1);
#line 171
  mutex_lock(ldv_func_arg1);
#line 172
  return;
}
}
#line 174 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_unlock_378(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 179
  ldv_mutex_unlock_lock(ldv_func_arg1);
#line 181
  mutex_unlock(ldv_func_arg1);
#line 182
  return;
}
}
#line 184 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_lock_379(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 189
  ldv_mutex_lock_mutex_of_device(ldv_func_arg1);
#line 191
  mutex_lock(ldv_func_arg1);
#line 192
  return;
}
}
#line 194 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
int ldv_mutex_trylock_380(struct mutex *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;
  int tmp___0 ;

  {
#line 199
  tmp = mutex_trylock(ldv_func_arg1);
#line 199
  ldv_func_res = tmp;
#line 201
  tmp___0 = ldv_mutex_trylock_mutex_of_device(ldv_func_arg1);
#line 201
  return (tmp___0);
#line 203
  return (ldv_func_res);
}
}
#line 206 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_unlock_381(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 211
  ldv_mutex_unlock_mutex_of_device(ldv_func_arg1);
#line 213
  mutex_unlock(ldv_func_arg1);
#line 214
  return;
}
}
#line 216 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_lock_382(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 221
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 223
  mutex_lock(ldv_func_arg1);
#line 224
  return;
}
}
#line 226 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_unlock_383(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 231
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 233
  mutex_unlock(ldv_func_arg1);
#line 234
  return;
}
}
#line 236 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_lock_384(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 241
  ldv_mutex_lock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 243
  mutex_lock(ldv_func_arg1);
#line 244
  return;
}
}
#line 246 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/dscv/ri/32_7a/drivers/block/drbd/drbd_nla.c.prepared"
void ldv_mutex_unlock_385(struct mutex *ldv_func_arg1 ) 
{ 


  {
#line 251
  ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(ldv_func_arg1);
#line 253
  mutex_unlock(ldv_func_arg1);
#line 254
  return;
}
}
#line 10 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
__inline static void ldv_error(void)  __attribute__((__no_instrument_function__)) ;
#line 10 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
__inline static void ldv_error(void) 
{ 


  {
  LDV_ERROR: __VERIFIER_error();
}
}
#line 25
extern int ldv_undef_int(void) ;
#line 49 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
long __builtin_expect(long exp , long c ) 
{ 


  {
#line 51
  return (exp);
}
}
#line 8 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_bm_change_of_drbd_bitmap  ;
#line 11 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_bm_change_of_drbd_bitmap(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 16
  if (ldv_mutex_bm_change_of_drbd_bitmap == 1) {

  } else {
#line 16
    ldv_error();
  }
#line 19
  nondetermined = ldv_undef_int();
#line 22
  if (nondetermined) {
#line 25
    ldv_mutex_bm_change_of_drbd_bitmap = 2;
#line 27
    return (0);
  } else {
#line 32
    return (-4);
  }
}
}
#line 37 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_bm_change_of_drbd_bitmap(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 42
  if (ldv_mutex_bm_change_of_drbd_bitmap == 1) {

  } else {
#line 42
    ldv_error();
  }
#line 45
  nondetermined = ldv_undef_int();
#line 48
  if (nondetermined) {
#line 51
    ldv_mutex_bm_change_of_drbd_bitmap = 2;
#line 53
    return (0);
  } else {
#line 58
    return (-4);
  }
}
}
#line 63 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_bm_change_of_drbd_bitmap(struct mutex *lock ) 
{ 


  {
#line 66
  if (ldv_mutex_bm_change_of_drbd_bitmap == 1) {

  } else {
#line 66
    ldv_error();
  }
#line 68
  ldv_mutex_bm_change_of_drbd_bitmap = 2;
#line 69
  return;
}
}
#line 72 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_bm_change_of_drbd_bitmap(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 77
  if (ldv_mutex_bm_change_of_drbd_bitmap == 1) {

  } else {
#line 77
    ldv_error();
  }
#line 80
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 83
  if (is_mutex_held_by_another_thread) {
#line 86
    return (0);
  } else {
#line 91
    ldv_mutex_bm_change_of_drbd_bitmap = 2;
#line 93
    return (1);
  }
}
}
#line 98 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_bm_change_of_drbd_bitmap(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 103
  if (ldv_mutex_bm_change_of_drbd_bitmap == 1) {

  } else {
#line 103
    ldv_error();
  }
#line 106
  atomic_value_after_dec = ldv_undef_int();
#line 109
  if (atomic_value_after_dec == 0) {
#line 112
    ldv_mutex_bm_change_of_drbd_bitmap = 2;
#line 114
    return (1);
  } else {

  }
#line 118
  return (0);
}
}
#line 123 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_bm_change_of_drbd_bitmap(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 127
  if (ldv_mutex_bm_change_of_drbd_bitmap == 1) {
#line 130
    nondetermined = ldv_undef_int();
#line 133
    if (nondetermined) {
#line 136
      return (0);
    } else {
#line 141
      return (1);
    }
  } else {
#line 147
    return (1);
  }
}
}
#line 152 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_bm_change_of_drbd_bitmap(struct mutex *lock ) 
{ 


  {
#line 155
  if (ldv_mutex_bm_change_of_drbd_bitmap == 2) {

  } else {
#line 155
    ldv_error();
  }
#line 157
  ldv_mutex_bm_change_of_drbd_bitmap = 1;
#line 158
  return;
}
}
#line 160 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_conf_update_of_drbd_tconn  ;
#line 163 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_conf_update_of_drbd_tconn(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 168
  if (ldv_mutex_conf_update_of_drbd_tconn == 1) {

  } else {
#line 168
    ldv_error();
  }
#line 171
  nondetermined = ldv_undef_int();
#line 174
  if (nondetermined) {
#line 177
    ldv_mutex_conf_update_of_drbd_tconn = 2;
#line 179
    return (0);
  } else {
#line 184
    return (-4);
  }
}
}
#line 189 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_conf_update_of_drbd_tconn(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 194
  if (ldv_mutex_conf_update_of_drbd_tconn == 1) {

  } else {
#line 194
    ldv_error();
  }
#line 197
  nondetermined = ldv_undef_int();
#line 200
  if (nondetermined) {
#line 203
    ldv_mutex_conf_update_of_drbd_tconn = 2;
#line 205
    return (0);
  } else {
#line 210
    return (-4);
  }
}
}
#line 215 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_conf_update_of_drbd_tconn(struct mutex *lock ) 
{ 


  {
#line 218
  if (ldv_mutex_conf_update_of_drbd_tconn == 1) {

  } else {
#line 218
    ldv_error();
  }
#line 220
  ldv_mutex_conf_update_of_drbd_tconn = 2;
#line 221
  return;
}
}
#line 224 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_conf_update_of_drbd_tconn(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 229
  if (ldv_mutex_conf_update_of_drbd_tconn == 1) {

  } else {
#line 229
    ldv_error();
  }
#line 232
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 235
  if (is_mutex_held_by_another_thread) {
#line 238
    return (0);
  } else {
#line 243
    ldv_mutex_conf_update_of_drbd_tconn = 2;
#line 245
    return (1);
  }
}
}
#line 250 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_conf_update_of_drbd_tconn(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 255
  if (ldv_mutex_conf_update_of_drbd_tconn == 1) {

  } else {
#line 255
    ldv_error();
  }
#line 258
  atomic_value_after_dec = ldv_undef_int();
#line 261
  if (atomic_value_after_dec == 0) {
#line 264
    ldv_mutex_conf_update_of_drbd_tconn = 2;
#line 266
    return (1);
  } else {

  }
#line 270
  return (0);
}
}
#line 275 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_conf_update_of_drbd_tconn(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 279
  if (ldv_mutex_conf_update_of_drbd_tconn == 1) {
#line 282
    nondetermined = ldv_undef_int();
#line 285
    if (nondetermined) {
#line 288
      return (0);
    } else {
#line 293
      return (1);
    }
  } else {
#line 299
    return (1);
  }
}
}
#line 304 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_conf_update_of_drbd_tconn(struct mutex *lock ) 
{ 


  {
#line 307
  if (ldv_mutex_conf_update_of_drbd_tconn == 2) {

  } else {
#line 307
    ldv_error();
  }
#line 309
  ldv_mutex_conf_update_of_drbd_tconn = 1;
#line 310
  return;
}
}
#line 312 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_cred_guard_mutex_of_signal_struct  ;
#line 315 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_cred_guard_mutex_of_signal_struct(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 320
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 1) {

  } else {
#line 320
    ldv_error();
  }
#line 323
  nondetermined = ldv_undef_int();
#line 326
  if (nondetermined) {
#line 329
    ldv_mutex_cred_guard_mutex_of_signal_struct = 2;
#line 331
    return (0);
  } else {
#line 336
    return (-4);
  }
}
}
#line 341 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_cred_guard_mutex_of_signal_struct(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 346
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 1) {

  } else {
#line 346
    ldv_error();
  }
#line 349
  nondetermined = ldv_undef_int();
#line 352
  if (nondetermined) {
#line 355
    ldv_mutex_cred_guard_mutex_of_signal_struct = 2;
#line 357
    return (0);
  } else {
#line 362
    return (-4);
  }
}
}
#line 367 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_cred_guard_mutex_of_signal_struct(struct mutex *lock ) 
{ 


  {
#line 370
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 1) {

  } else {
#line 370
    ldv_error();
  }
#line 372
  ldv_mutex_cred_guard_mutex_of_signal_struct = 2;
#line 373
  return;
}
}
#line 376 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_cred_guard_mutex_of_signal_struct(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 381
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 1) {

  } else {
#line 381
    ldv_error();
  }
#line 384
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 387
  if (is_mutex_held_by_another_thread) {
#line 390
    return (0);
  } else {
#line 395
    ldv_mutex_cred_guard_mutex_of_signal_struct = 2;
#line 397
    return (1);
  }
}
}
#line 402 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_cred_guard_mutex_of_signal_struct(atomic_t *cnt ,
                                                                    struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 407
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 1) {

  } else {
#line 407
    ldv_error();
  }
#line 410
  atomic_value_after_dec = ldv_undef_int();
#line 413
  if (atomic_value_after_dec == 0) {
#line 416
    ldv_mutex_cred_guard_mutex_of_signal_struct = 2;
#line 418
    return (1);
  } else {

  }
#line 422
  return (0);
}
}
#line 427 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_cred_guard_mutex_of_signal_struct(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 431
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 1) {
#line 434
    nondetermined = ldv_undef_int();
#line 437
    if (nondetermined) {
#line 440
      return (0);
    } else {
#line 445
      return (1);
    }
  } else {
#line 451
    return (1);
  }
}
}
#line 456 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_cred_guard_mutex_of_signal_struct(struct mutex *lock ) 
{ 


  {
#line 459
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 2) {

  } else {
#line 459
    ldv_error();
  }
#line 461
  ldv_mutex_cred_guard_mutex_of_signal_struct = 1;
#line 462
  return;
}
}
#line 464 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_cstate_mutex_of_drbd_tconn  ;
#line 467 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_cstate_mutex_of_drbd_tconn(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 472
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 1) {

  } else {
#line 472
    ldv_error();
  }
#line 475
  nondetermined = ldv_undef_int();
#line 478
  if (nondetermined) {
#line 481
    ldv_mutex_cstate_mutex_of_drbd_tconn = 2;
#line 483
    return (0);
  } else {
#line 488
    return (-4);
  }
}
}
#line 493 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_cstate_mutex_of_drbd_tconn(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 498
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 1) {

  } else {
#line 498
    ldv_error();
  }
#line 501
  nondetermined = ldv_undef_int();
#line 504
  if (nondetermined) {
#line 507
    ldv_mutex_cstate_mutex_of_drbd_tconn = 2;
#line 509
    return (0);
  } else {
#line 514
    return (-4);
  }
}
}
#line 519 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_cstate_mutex_of_drbd_tconn(struct mutex *lock ) 
{ 


  {
#line 522
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 1) {

  } else {
#line 522
    ldv_error();
  }
#line 524
  ldv_mutex_cstate_mutex_of_drbd_tconn = 2;
#line 525
  return;
}
}
#line 528 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_cstate_mutex_of_drbd_tconn(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 533
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 1) {

  } else {
#line 533
    ldv_error();
  }
#line 536
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 539
  if (is_mutex_held_by_another_thread) {
#line 542
    return (0);
  } else {
#line 547
    ldv_mutex_cstate_mutex_of_drbd_tconn = 2;
#line 549
    return (1);
  }
}
}
#line 554 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_cstate_mutex_of_drbd_tconn(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 559
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 1) {

  } else {
#line 559
    ldv_error();
  }
#line 562
  atomic_value_after_dec = ldv_undef_int();
#line 565
  if (atomic_value_after_dec == 0) {
#line 568
    ldv_mutex_cstate_mutex_of_drbd_tconn = 2;
#line 570
    return (1);
  } else {

  }
#line 574
  return (0);
}
}
#line 579 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_cstate_mutex_of_drbd_tconn(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 583
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 1) {
#line 586
    nondetermined = ldv_undef_int();
#line 589
    if (nondetermined) {
#line 592
      return (0);
    } else {
#line 597
      return (1);
    }
  } else {
#line 603
    return (1);
  }
}
}
#line 608 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_cstate_mutex_of_drbd_tconn(struct mutex *lock ) 
{ 


  {
#line 611
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 2) {

  } else {
#line 611
    ldv_error();
  }
#line 613
  ldv_mutex_cstate_mutex_of_drbd_tconn = 1;
#line 614
  return;
}
}
#line 616 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_drbd_main_mutex  ;
#line 619 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_drbd_main_mutex(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 624
  if (ldv_mutex_drbd_main_mutex == 1) {

  } else {
#line 624
    ldv_error();
  }
#line 627
  nondetermined = ldv_undef_int();
#line 630
  if (nondetermined) {
#line 633
    ldv_mutex_drbd_main_mutex = 2;
#line 635
    return (0);
  } else {
#line 640
    return (-4);
  }
}
}
#line 645 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_drbd_main_mutex(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 650
  if (ldv_mutex_drbd_main_mutex == 1) {

  } else {
#line 650
    ldv_error();
  }
#line 653
  nondetermined = ldv_undef_int();
#line 656
  if (nondetermined) {
#line 659
    ldv_mutex_drbd_main_mutex = 2;
#line 661
    return (0);
  } else {
#line 666
    return (-4);
  }
}
}
#line 671 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_drbd_main_mutex(struct mutex *lock ) 
{ 


  {
#line 674
  if (ldv_mutex_drbd_main_mutex == 1) {

  } else {
#line 674
    ldv_error();
  }
#line 676
  ldv_mutex_drbd_main_mutex = 2;
#line 677
  return;
}
}
#line 680 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_drbd_main_mutex(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 685
  if (ldv_mutex_drbd_main_mutex == 1) {

  } else {
#line 685
    ldv_error();
  }
#line 688
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 691
  if (is_mutex_held_by_another_thread) {
#line 694
    return (0);
  } else {
#line 699
    ldv_mutex_drbd_main_mutex = 2;
#line 701
    return (1);
  }
}
}
#line 706 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_drbd_main_mutex(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 711
  if (ldv_mutex_drbd_main_mutex == 1) {

  } else {
#line 711
    ldv_error();
  }
#line 714
  atomic_value_after_dec = ldv_undef_int();
#line 717
  if (atomic_value_after_dec == 0) {
#line 720
    ldv_mutex_drbd_main_mutex = 2;
#line 722
    return (1);
  } else {

  }
#line 726
  return (0);
}
}
#line 731 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_drbd_main_mutex(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 735
  if (ldv_mutex_drbd_main_mutex == 1) {
#line 738
    nondetermined = ldv_undef_int();
#line 741
    if (nondetermined) {
#line 744
      return (0);
    } else {
#line 749
      return (1);
    }
  } else {
#line 755
    return (1);
  }
}
}
#line 760 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_drbd_main_mutex(struct mutex *lock ) 
{ 


  {
#line 763
  if (ldv_mutex_drbd_main_mutex == 2) {

  } else {
#line 763
    ldv_error();
  }
#line 765
  ldv_mutex_drbd_main_mutex = 1;
#line 766
  return;
}
}
#line 768 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_lock  ;
#line 771 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 776
  if (ldv_mutex_lock == 1) {

  } else {
#line 776
    ldv_error();
  }
#line 779
  nondetermined = ldv_undef_int();
#line 782
  if (nondetermined) {
#line 785
    ldv_mutex_lock = 2;
#line 787
    return (0);
  } else {
#line 792
    return (-4);
  }
}
}
#line 797 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 802
  if (ldv_mutex_lock == 1) {

  } else {
#line 802
    ldv_error();
  }
#line 805
  nondetermined = ldv_undef_int();
#line 808
  if (nondetermined) {
#line 811
    ldv_mutex_lock = 2;
#line 813
    return (0);
  } else {
#line 818
    return (-4);
  }
}
}
#line 823 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_lock(struct mutex *lock ) 
{ 


  {
#line 826
  if (ldv_mutex_lock == 1) {

  } else {
#line 826
    ldv_error();
  }
#line 828
  ldv_mutex_lock = 2;
#line 829
  return;
}
}
#line 832 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_lock(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 837
  if (ldv_mutex_lock == 1) {

  } else {
#line 837
    ldv_error();
  }
#line 840
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 843
  if (is_mutex_held_by_another_thread) {
#line 846
    return (0);
  } else {
#line 851
    ldv_mutex_lock = 2;
#line 853
    return (1);
  }
}
}
#line 858 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_lock(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 863
  if (ldv_mutex_lock == 1) {

  } else {
#line 863
    ldv_error();
  }
#line 866
  atomic_value_after_dec = ldv_undef_int();
#line 869
  if (atomic_value_after_dec == 0) {
#line 872
    ldv_mutex_lock = 2;
#line 874
    return (1);
  } else {

  }
#line 878
  return (0);
}
}
#line 883 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_lock(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 887
  if (ldv_mutex_lock == 1) {
#line 890
    nondetermined = ldv_undef_int();
#line 893
    if (nondetermined) {
#line 896
      return (0);
    } else {
#line 901
      return (1);
    }
  } else {
#line 907
    return (1);
  }
}
}
#line 912 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_lock(struct mutex *lock ) 
{ 


  {
#line 915
  if (ldv_mutex_lock == 2) {

  } else {
#line 915
    ldv_error();
  }
#line 917
  ldv_mutex_lock = 1;
#line 918
  return;
}
}
#line 920 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_mtx_of_percpu_rw_semaphore  ;
#line 923 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_mtx_of_percpu_rw_semaphore(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 928
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 1) {

  } else {
#line 928
    ldv_error();
  }
#line 931
  nondetermined = ldv_undef_int();
#line 934
  if (nondetermined) {
#line 937
    ldv_mutex_mtx_of_percpu_rw_semaphore = 2;
#line 939
    return (0);
  } else {
#line 944
    return (-4);
  }
}
}
#line 949 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_mtx_of_percpu_rw_semaphore(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 954
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 1) {

  } else {
#line 954
    ldv_error();
  }
#line 957
  nondetermined = ldv_undef_int();
#line 960
  if (nondetermined) {
#line 963
    ldv_mutex_mtx_of_percpu_rw_semaphore = 2;
#line 965
    return (0);
  } else {
#line 970
    return (-4);
  }
}
}
#line 975 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_mtx_of_percpu_rw_semaphore(struct mutex *lock ) 
{ 


  {
#line 978
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 1) {

  } else {
#line 978
    ldv_error();
  }
#line 980
  ldv_mutex_mtx_of_percpu_rw_semaphore = 2;
#line 981
  return;
}
}
#line 984 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_mtx_of_percpu_rw_semaphore(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 989
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 1) {

  } else {
#line 989
    ldv_error();
  }
#line 992
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 995
  if (is_mutex_held_by_another_thread) {
#line 998
    return (0);
  } else {
#line 1003
    ldv_mutex_mtx_of_percpu_rw_semaphore = 2;
#line 1005
    return (1);
  }
}
}
#line 1010 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_mtx_of_percpu_rw_semaphore(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 1015
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 1) {

  } else {
#line 1015
    ldv_error();
  }
#line 1018
  atomic_value_after_dec = ldv_undef_int();
#line 1021
  if (atomic_value_after_dec == 0) {
#line 1024
    ldv_mutex_mtx_of_percpu_rw_semaphore = 2;
#line 1026
    return (1);
  } else {

  }
#line 1030
  return (0);
}
}
#line 1035 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_mtx_of_percpu_rw_semaphore(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1039
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 1) {
#line 1042
    nondetermined = ldv_undef_int();
#line 1045
    if (nondetermined) {
#line 1048
      return (0);
    } else {
#line 1053
      return (1);
    }
  } else {
#line 1059
    return (1);
  }
}
}
#line 1064 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_mtx_of_percpu_rw_semaphore(struct mutex *lock ) 
{ 


  {
#line 1067
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 2) {

  } else {
#line 1067
    ldv_error();
  }
#line 1069
  ldv_mutex_mtx_of_percpu_rw_semaphore = 1;
#line 1070
  return;
}
}
#line 1072 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_mutex_of_device  ;
#line 1075 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1080
  if (ldv_mutex_mutex_of_device == 1) {

  } else {
#line 1080
    ldv_error();
  }
#line 1083
  nondetermined = ldv_undef_int();
#line 1086
  if (nondetermined) {
#line 1089
    ldv_mutex_mutex_of_device = 2;
#line 1091
    return (0);
  } else {
#line 1096
    return (-4);
  }
}
}
#line 1101 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1106
  if (ldv_mutex_mutex_of_device == 1) {

  } else {
#line 1106
    ldv_error();
  }
#line 1109
  nondetermined = ldv_undef_int();
#line 1112
  if (nondetermined) {
#line 1115
    ldv_mutex_mutex_of_device = 2;
#line 1117
    return (0);
  } else {
#line 1122
    return (-4);
  }
}
}
#line 1127 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_mutex_of_device(struct mutex *lock ) 
{ 


  {
#line 1130
  if (ldv_mutex_mutex_of_device == 1) {

  } else {
#line 1130
    ldv_error();
  }
#line 1132
  ldv_mutex_mutex_of_device = 2;
#line 1133
  return;
}
}
#line 1136 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_mutex_of_device(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 1141
  if (ldv_mutex_mutex_of_device == 1) {

  } else {
#line 1141
    ldv_error();
  }
#line 1144
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 1147
  if (is_mutex_held_by_another_thread) {
#line 1150
    return (0);
  } else {
#line 1155
    ldv_mutex_mutex_of_device = 2;
#line 1157
    return (1);
  }
}
}
#line 1162 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_mutex_of_device(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 1167
  if (ldv_mutex_mutex_of_device == 1) {

  } else {
#line 1167
    ldv_error();
  }
#line 1170
  atomic_value_after_dec = ldv_undef_int();
#line 1173
  if (atomic_value_after_dec == 0) {
#line 1176
    ldv_mutex_mutex_of_device = 2;
#line 1178
    return (1);
  } else {

  }
#line 1182
  return (0);
}
}
#line 1187 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_mutex_of_device(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1191
  if (ldv_mutex_mutex_of_device == 1) {
#line 1194
    nondetermined = ldv_undef_int();
#line 1197
    if (nondetermined) {
#line 1200
      return (0);
    } else {
#line 1205
      return (1);
    }
  } else {
#line 1211
    return (1);
  }
}
}
#line 1216 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_mutex_of_device(struct mutex *lock ) 
{ 


  {
#line 1219
  if (ldv_mutex_mutex_of_device == 2) {

  } else {
#line 1219
    ldv_error();
  }
#line 1221
  ldv_mutex_mutex_of_device = 1;
#line 1222
  return;
}
}
#line 1224 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_mutex_of_drbd_socket  ;
#line 1227 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_mutex_of_drbd_socket(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1232
  if (ldv_mutex_mutex_of_drbd_socket == 1) {

  } else {
#line 1232
    ldv_error();
  }
#line 1235
  nondetermined = ldv_undef_int();
#line 1238
  if (nondetermined) {
#line 1241
    ldv_mutex_mutex_of_drbd_socket = 2;
#line 1243
    return (0);
  } else {
#line 1248
    return (-4);
  }
}
}
#line 1253 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_mutex_of_drbd_socket(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1258
  if (ldv_mutex_mutex_of_drbd_socket == 1) {

  } else {
#line 1258
    ldv_error();
  }
#line 1261
  nondetermined = ldv_undef_int();
#line 1264
  if (nondetermined) {
#line 1267
    ldv_mutex_mutex_of_drbd_socket = 2;
#line 1269
    return (0);
  } else {
#line 1274
    return (-4);
  }
}
}
#line 1279 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_mutex_of_drbd_socket(struct mutex *lock ) 
{ 


  {
#line 1282
  if (ldv_mutex_mutex_of_drbd_socket == 1) {

  } else {
#line 1282
    ldv_error();
  }
#line 1284
  ldv_mutex_mutex_of_drbd_socket = 2;
#line 1285
  return;
}
}
#line 1288 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_mutex_of_drbd_socket(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 1293
  if (ldv_mutex_mutex_of_drbd_socket == 1) {

  } else {
#line 1293
    ldv_error();
  }
#line 1296
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 1299
  if (is_mutex_held_by_another_thread) {
#line 1302
    return (0);
  } else {
#line 1307
    ldv_mutex_mutex_of_drbd_socket = 2;
#line 1309
    return (1);
  }
}
}
#line 1314 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_mutex_of_drbd_socket(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 1319
  if (ldv_mutex_mutex_of_drbd_socket == 1) {

  } else {
#line 1319
    ldv_error();
  }
#line 1322
  atomic_value_after_dec = ldv_undef_int();
#line 1325
  if (atomic_value_after_dec == 0) {
#line 1328
    ldv_mutex_mutex_of_drbd_socket = 2;
#line 1330
    return (1);
  } else {

  }
#line 1334
  return (0);
}
}
#line 1339 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_mutex_of_drbd_socket(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1343
  if (ldv_mutex_mutex_of_drbd_socket == 1) {
#line 1346
    nondetermined = ldv_undef_int();
#line 1349
    if (nondetermined) {
#line 1352
      return (0);
    } else {
#line 1357
      return (1);
    }
  } else {
#line 1363
    return (1);
  }
}
}
#line 1368 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_mutex_of_drbd_socket(struct mutex *lock ) 
{ 


  {
#line 1371
  if (ldv_mutex_mutex_of_drbd_socket == 2) {

  } else {
#line 1371
    ldv_error();
  }
#line 1373
  ldv_mutex_mutex_of_drbd_socket = 1;
#line 1374
  return;
}
}
#line 1376 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
static int ldv_mutex_state_mutex_of_drbd_conf  ;
#line 1379 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_interruptible_state_mutex_of_drbd_conf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1384
  if (ldv_mutex_state_mutex_of_drbd_conf == 1) {

  } else {
#line 1384
    ldv_error();
  }
#line 1387
  nondetermined = ldv_undef_int();
#line 1390
  if (nondetermined) {
#line 1393
    ldv_mutex_state_mutex_of_drbd_conf = 2;
#line 1395
    return (0);
  } else {
#line 1400
    return (-4);
  }
}
}
#line 1405 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_lock_killable_state_mutex_of_drbd_conf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1410
  if (ldv_mutex_state_mutex_of_drbd_conf == 1) {

  } else {
#line 1410
    ldv_error();
  }
#line 1413
  nondetermined = ldv_undef_int();
#line 1416
  if (nondetermined) {
#line 1419
    ldv_mutex_state_mutex_of_drbd_conf = 2;
#line 1421
    return (0);
  } else {
#line 1426
    return (-4);
  }
}
}
#line 1431 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_lock_state_mutex_of_drbd_conf(struct mutex *lock ) 
{ 


  {
#line 1434
  if (ldv_mutex_state_mutex_of_drbd_conf == 1) {

  } else {
#line 1434
    ldv_error();
  }
#line 1436
  ldv_mutex_state_mutex_of_drbd_conf = 2;
#line 1437
  return;
}
}
#line 1440 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_trylock_state_mutex_of_drbd_conf(struct mutex *lock ) 
{ 
  int is_mutex_held_by_another_thread ;

  {
#line 1445
  if (ldv_mutex_state_mutex_of_drbd_conf == 1) {

  } else {
#line 1445
    ldv_error();
  }
#line 1448
  is_mutex_held_by_another_thread = ldv_undef_int();
#line 1451
  if (is_mutex_held_by_another_thread) {
#line 1454
    return (0);
  } else {
#line 1459
    ldv_mutex_state_mutex_of_drbd_conf = 2;
#line 1461
    return (1);
  }
}
}
#line 1466 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_atomic_dec_and_mutex_lock_state_mutex_of_drbd_conf(atomic_t *cnt , struct mutex *lock ) 
{ 
  int atomic_value_after_dec ;

  {
#line 1471
  if (ldv_mutex_state_mutex_of_drbd_conf == 1) {

  } else {
#line 1471
    ldv_error();
  }
#line 1474
  atomic_value_after_dec = ldv_undef_int();
#line 1477
  if (atomic_value_after_dec == 0) {
#line 1480
    ldv_mutex_state_mutex_of_drbd_conf = 2;
#line 1482
    return (1);
  } else {

  }
#line 1486
  return (0);
}
}
#line 1491 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
int ldv_mutex_is_locked_state_mutex_of_drbd_conf(struct mutex *lock ) 
{ 
  int nondetermined ;

  {
#line 1495
  if (ldv_mutex_state_mutex_of_drbd_conf == 1) {
#line 1498
    nondetermined = ldv_undef_int();
#line 1501
    if (nondetermined) {
#line 1504
      return (0);
    } else {
#line 1509
      return (1);
    }
  } else {
#line 1515
    return (1);
  }
}
}
#line 1520 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_mutex_unlock_state_mutex_of_drbd_conf(struct mutex *lock ) 
{ 


  {
#line 1523
  if (ldv_mutex_state_mutex_of_drbd_conf == 2) {

  } else {
#line 1523
    ldv_error();
  }
#line 1525
  ldv_mutex_state_mutex_of_drbd_conf = 1;
#line 1526
  return;
}
}
#line 1530 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_initialize(void) 
{ 


  {
#line 1533
  ldv_mutex_bm_change_of_drbd_bitmap = 1;
#line 1535
  ldv_mutex_conf_update_of_drbd_tconn = 1;
#line 1537
  ldv_mutex_cred_guard_mutex_of_signal_struct = 1;
#line 1539
  ldv_mutex_cstate_mutex_of_drbd_tconn = 1;
#line 1541
  ldv_mutex_drbd_main_mutex = 1;
#line 1543
  ldv_mutex_lock = 1;
#line 1545
  ldv_mutex_mtx_of_percpu_rw_semaphore = 1;
#line 1547
  ldv_mutex_mutex_of_device = 1;
#line 1549
  ldv_mutex_mutex_of_drbd_socket = 1;
#line 1551
  ldv_mutex_state_mutex_of_drbd_conf = 1;
#line 1552
  return;
}
}
#line 1555 "/work/ldvuser/novikov/work/current--X--drivers/block/drbd/drbd.ko--X--defaultlinux--X--32_7a--X--cpachecker/linux/csd_deg_dscv/23/dscv_tempdir/rule-instrumentor/32_7a/common-model/ldv_common_model.c"
void ldv_check_final_state(void) 
{ 


  {
#line 1558
  if (ldv_mutex_bm_change_of_drbd_bitmap == 1) {

  } else {
#line 1558
    ldv_error();
  }
#line 1560
  if (ldv_mutex_conf_update_of_drbd_tconn == 1) {

  } else {
#line 1560
    ldv_error();
  }
#line 1562
  if (ldv_mutex_cred_guard_mutex_of_signal_struct == 1) {

  } else {
#line 1562
    ldv_error();
  }
#line 1564
  if (ldv_mutex_cstate_mutex_of_drbd_tconn == 1) {

  } else {
#line 1564
    ldv_error();
  }
#line 1566
  if (ldv_mutex_drbd_main_mutex == 1) {

  } else {
#line 1566
    ldv_error();
  }
#line 1568
  if (ldv_mutex_lock == 1) {

  } else {
#line 1568
    ldv_error();
  }
#line 1570
  if (ldv_mutex_mtx_of_percpu_rw_semaphore == 1) {

  } else {
#line 1570
    ldv_error();
  }
#line 1572
  if (ldv_mutex_mutex_of_device == 1) {

  } else {
#line 1572
    ldv_error();
  }
#line 1574
  if (ldv_mutex_mutex_of_drbd_socket == 1) {

  } else {
#line 1574
    ldv_error();
  }
#line 1576
  if (ldv_mutex_state_mutex_of_drbd_conf == 1) {

  } else {
#line 1576
    ldv_error();
  }
#line 1577
  return;
}
}
