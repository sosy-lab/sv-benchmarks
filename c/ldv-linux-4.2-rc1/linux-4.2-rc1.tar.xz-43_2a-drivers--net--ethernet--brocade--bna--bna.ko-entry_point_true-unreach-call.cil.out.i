extern void __VERIFIER_error() __attribute__ ((__noreturn__));
typedef unsigned char __u8;
typedef short __s16;
typedef unsigned short __u16;
typedef int __s32;
typedef unsigned int __u32;
typedef unsigned long long __u64;
typedef signed char s8;
typedef unsigned char u8;
typedef unsigned short u16;
typedef int s32;
typedef unsigned int u32;
typedef long long s64;
typedef unsigned long long u64;
typedef long __kernel_long_t;
typedef unsigned long __kernel_ulong_t;
typedef int __kernel_pid_t;
typedef unsigned int __kernel_uid32_t;
typedef unsigned int __kernel_gid32_t;
typedef __kernel_ulong_t __kernel_size_t;
typedef __kernel_long_t __kernel_ssize_t;
typedef long long __kernel_loff_t;
typedef __kernel_long_t __kernel_time_t;
typedef __kernel_long_t __kernel_clock_t;
typedef int __kernel_timer_t;
typedef int __kernel_clockid_t;
typedef __u16 __be16;
typedef __u32 __be32;
typedef __u16 __sum16;
typedef __u32 __wsum;
struct kernel_symbol {
   unsigned long value ;
   char const *name ;
};
struct module;
typedef __u32 __kernel_dev_t;
typedef __kernel_dev_t dev_t;
typedef unsigned short umode_t;
typedef __kernel_pid_t pid_t;
typedef __kernel_clockid_t clockid_t;
typedef _Bool bool;
typedef __kernel_uid32_t uid_t;
typedef __kernel_gid32_t gid_t;
typedef __kernel_loff_t loff_t;
typedef __kernel_size_t size_t;
typedef __kernel_ssize_t ssize_t;
typedef __kernel_time_t time_t;
typedef unsigned int uint;
typedef __s32 int32_t;
typedef __u8 uint8_t;
typedef __u32 uint32_t;
typedef __u64 uint64_t;
typedef unsigned long sector_t;
typedef unsigned long blkcnt_t;
typedef u64 dma_addr_t;
typedef unsigned int gfp_t;
typedef unsigned int fmode_t;
typedef unsigned int oom_flags_t;
typedef u64 phys_addr_t;
typedef phys_addr_t resource_size_t;
struct __anonstruct_atomic_t_6 {
   int counter ;
};
typedef struct __anonstruct_atomic_t_6 atomic_t;
struct __anonstruct_atomic64_t_7 {
   long counter ;
};
typedef struct __anonstruct_atomic64_t_7 atomic64_t;
struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};
struct hlist_node;
struct hlist_head {
   struct hlist_node *first ;
};
struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};
struct callback_head {
   struct callback_head *next ;
   void (*func)(struct callback_head * ) ;
};
struct pt_regs {
   unsigned long r15 ;
   unsigned long r14 ;
   unsigned long r13 ;
   unsigned long r12 ;
   unsigned long bp ;
   unsigned long bx ;
   unsigned long r11 ;
   unsigned long r10 ;
   unsigned long r9 ;
   unsigned long r8 ;
   unsigned long ax ;
   unsigned long cx ;
   unsigned long dx ;
   unsigned long si ;
   unsigned long di ;
   unsigned long orig_ax ;
   unsigned long ip ;
   unsigned long cs ;
   unsigned long flags ;
   unsigned long sp ;
   unsigned long ss ;
};
struct __anonstruct____missing_field_name_9 {
   unsigned int a ;
   unsigned int b ;
};
struct __anonstruct____missing_field_name_10 {
   u16 limit0 ;
   u16 base0 ;
   unsigned char base1 ;
   unsigned char type : 4 ;
   unsigned char s : 1 ;
   unsigned char dpl : 2 ;
   unsigned char p : 1 ;
   unsigned char limit : 4 ;
   unsigned char avl : 1 ;
   unsigned char l : 1 ;
   unsigned char d : 1 ;
   unsigned char g : 1 ;
   unsigned char base2 ;
};
union __anonunion____missing_field_name_8 {
   struct __anonstruct____missing_field_name_9 __annonCompField4 ;
   struct __anonstruct____missing_field_name_10 __annonCompField5 ;
};
struct desc_struct {
   union __anonunion____missing_field_name_8 __annonCompField6 ;
};
typedef unsigned long pteval_t;
typedef unsigned long pgdval_t;
typedef unsigned long pgprotval_t;
struct __anonstruct_pte_t_11 {
   pteval_t pte ;
};
typedef struct __anonstruct_pte_t_11 pte_t;
struct pgprot {
   pgprotval_t pgprot ;
};
typedef struct pgprot pgprot_t;
struct __anonstruct_pgd_t_12 {
   pgdval_t pgd ;
};
typedef struct __anonstruct_pgd_t_12 pgd_t;
struct page;
typedef struct page *pgtable_t;
struct file;
struct seq_file;
struct thread_struct;
struct mm_struct;
struct task_struct;
struct cpumask;
struct qspinlock {
   atomic_t val ;
};
typedef struct qspinlock arch_spinlock_t;
struct qrwlock {
   atomic_t cnts ;
   arch_spinlock_t lock ;
};
typedef struct qrwlock arch_rwlock_t;
typedef void (*ctor_fn_t)(void);
struct device;
struct net_device;
struct file_operations;
struct completion;
struct bug_entry {
   int bug_addr_disp ;
   int file_disp ;
   unsigned short line ;
   unsigned short flags ;
};
struct timespec;
struct compat_timespec;
struct __anonstruct_futex_16 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
   u32 *uaddr2 ;
};
struct __anonstruct_nanosleep_17 {
   clockid_t clockid ;
   struct timespec *rmtp ;
   struct compat_timespec *compat_rmtp ;
   u64 expires ;
};
struct pollfd;
struct __anonstruct_poll_18 {
   struct pollfd *ufds ;
   int nfds ;
   int has_timeout ;
   unsigned long tv_sec ;
   unsigned long tv_nsec ;
};
union __anonunion____missing_field_name_15 {
   struct __anonstruct_futex_16 futex ;
   struct __anonstruct_nanosleep_17 nanosleep ;
   struct __anonstruct_poll_18 poll ;
};
struct restart_block {
   long (*fn)(struct restart_block * ) ;
   union __anonunion____missing_field_name_15 __annonCompField7 ;
};
struct kernel_vm86_regs {
   struct pt_regs pt ;
   unsigned short es ;
   unsigned short __esh ;
   unsigned short ds ;
   unsigned short __dsh ;
   unsigned short fs ;
   unsigned short __fsh ;
   unsigned short gs ;
   unsigned short __gsh ;
};
union __anonunion____missing_field_name_19 {
   struct pt_regs *regs ;
   struct kernel_vm86_regs *vm86 ;
};
struct math_emu_info {
   long ___orig_eip ;
   union __anonunion____missing_field_name_19 __annonCompField8 ;
};
struct cpumask {
   unsigned long bits[128U] ;
};
typedef struct cpumask cpumask_t;
typedef struct cpumask *cpumask_var_t;
struct fregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};
struct __anonstruct____missing_field_name_29 {
   u64 rip ;
   u64 rdp ;
};
struct __anonstruct____missing_field_name_30 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};
union __anonunion____missing_field_name_28 {
   struct __anonstruct____missing_field_name_29 __annonCompField12 ;
   struct __anonstruct____missing_field_name_30 __annonCompField13 ;
};
union __anonunion____missing_field_name_31 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};
struct fxregs_state {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion____missing_field_name_28 __annonCompField14 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion____missing_field_name_31 __annonCompField15 ;
};
struct swregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct math_emu_info *info ;
   u32 entry_eip ;
};
struct xstate_header {
   u64 xfeatures ;
   u64 xcomp_bv ;
   u64 reserved[6U] ;
};
struct xregs_state {
   struct fxregs_state i387 ;
   struct xstate_header header ;
   u8 __reserved[464U] ;
};
union fpregs_state {
   struct fregs_state fsave ;
   struct fxregs_state fxsave ;
   struct swregs_state soft ;
   struct xregs_state xsave ;
};
struct fpu {
   union fpregs_state state ;
   unsigned int last_cpu ;
   unsigned char fpstate_active ;
   unsigned char fpregs_active ;
   unsigned char counter ;
};
struct seq_operations;
struct perf_event;
struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp0 ;
   unsigned long sp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
   unsigned short gsindex ;
   unsigned long fs ;
   unsigned long gs ;
   struct fpu fpu ;
   struct perf_event *ptrace_bps[4U] ;
   unsigned long debugreg6 ;
   unsigned long ptrace_dr7 ;
   unsigned long cr2 ;
   unsigned long trap_nr ;
   unsigned long error_code ;
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
   unsigned int io_bitmap_max ;
};
typedef atomic64_t atomic_long_t;
struct lockdep_map;
struct stack_trace {
   unsigned int nr_entries ;
   unsigned int max_entries ;
   unsigned long *entries ;
   int skip ;
};
struct lockdep_subclass_key {
   char __one_byte ;
};
struct lock_class_key {
   struct lockdep_subclass_key subkeys[8U] ;
};
struct lock_class {
   struct list_head hash_entry ;
   struct list_head lock_entry ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
   unsigned int dep_gen_id ;
   unsigned long usage_mask ;
   struct stack_trace usage_traces[13U] ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   unsigned int version ;
   unsigned long ops ;
   char const *name ;
   int name_version ;
   unsigned long contention_point[4U] ;
   unsigned long contending_point[4U] ;
};
struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache[2U] ;
   char const *name ;
   int cpu ;
   unsigned long ip ;
};
struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned short class_idx : 13 ;
   unsigned char irq_context : 2 ;
   unsigned char trylock : 1 ;
   unsigned char read : 2 ;
   unsigned char check : 1 ;
   unsigned char hardirqs_off : 1 ;
   unsigned short references : 12 ;
   unsigned int pin_count ;
};
struct raw_spinlock {
   arch_spinlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct raw_spinlock raw_spinlock_t;
struct __anonstruct____missing_field_name_35 {
   u8 __padding[24U] ;
   struct lockdep_map dep_map ;
};
union __anonunion____missing_field_name_34 {
   struct raw_spinlock rlock ;
   struct __anonstruct____missing_field_name_35 __annonCompField17 ;
};
struct spinlock {
   union __anonunion____missing_field_name_34 __annonCompField18 ;
};
typedef struct spinlock spinlock_t;
struct __anonstruct_rwlock_t_36 {
   arch_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_rwlock_t_36 rwlock_t;
struct seqcount {
   unsigned int sequence ;
   struct lockdep_map dep_map ;
};
typedef struct seqcount seqcount_t;
struct __anonstruct_seqlock_t_45 {
   struct seqcount seqcount ;
   spinlock_t lock ;
};
typedef struct __anonstruct_seqlock_t_45 seqlock_t;
struct timespec {
   __kernel_time_t tv_sec ;
   long tv_nsec ;
};
struct user_namespace;
struct __anonstruct_kuid_t_46 {
   uid_t val ;
};
typedef struct __anonstruct_kuid_t_46 kuid_t;
struct __anonstruct_kgid_t_47 {
   gid_t val ;
};
typedef struct __anonstruct_kgid_t_47 kgid_t;
struct kstat {
   u64 ino ;
   dev_t dev ;
   umode_t mode ;
   unsigned int nlink ;
   kuid_t uid ;
   kgid_t gid ;
   dev_t rdev ;
   loff_t size ;
   struct timespec atime ;
   struct timespec mtime ;
   struct timespec ctime ;
   unsigned long blksize ;
   unsigned long long blocks ;
};
struct vm_area_struct;
struct __wait_queue_head {
   spinlock_t lock ;
   struct list_head task_list ;
};
typedef struct __wait_queue_head wait_queue_head_t;
struct __anonstruct_nodemask_t_48 {
   unsigned long bits[16U] ;
};
typedef struct __anonstruct_nodemask_t_48 nodemask_t;
struct optimistic_spin_queue {
   atomic_t tail ;
};
struct mutex {
   atomic_t count ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct task_struct *owner ;
   void *magic ;
   struct lockdep_map dep_map ;
};
struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   void *magic ;
};
struct rw_semaphore;
struct rw_semaphore {
   long count ;
   struct list_head wait_list ;
   raw_spinlock_t wait_lock ;
   struct optimistic_spin_queue osq ;
   struct task_struct *owner ;
   struct lockdep_map dep_map ;
};
struct completion {
   unsigned int done ;
   wait_queue_head_t wait ;
};
union ktime {
   s64 tv64 ;
};
typedef union ktime ktime_t;
struct notifier_block;
struct timer_list {
   struct hlist_node entry ;
   unsigned long expires ;
   void (*function)(unsigned long ) ;
   unsigned long data ;
   u32 flags ;
   int slack ;
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
   struct lockdep_map lockdep_map ;
};
struct hrtimer;
enum hrtimer_restart;
struct rb_node {
   unsigned long __rb_parent_color ;
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};
struct rb_root {
   struct rb_node *rb_node ;
};
struct ctl_table;
struct nsproxy;
struct ctl_table_root;
struct ctl_table_header;
struct ctl_dir;
typedef int proc_handler(struct ctl_table * , int , void * , size_t * , loff_t * );
struct ctl_table_poll {
   atomic_t event ;
   wait_queue_head_t wait ;
};
struct ctl_table {
   char const *procname ;
   void *data ;
   int maxlen ;
   umode_t mode ;
   struct ctl_table *child ;
   proc_handler *proc_handler ;
   struct ctl_table_poll *poll ;
   void *extra1 ;
   void *extra2 ;
};
struct ctl_node {
   struct rb_node node ;
   struct ctl_table_header *header ;
};
struct __anonstruct____missing_field_name_50 {
   struct ctl_table *ctl_table ;
   int used ;
   int count ;
   int nreg ;
};
union __anonunion____missing_field_name_49 {
   struct __anonstruct____missing_field_name_50 __annonCompField19 ;
   struct callback_head rcu ;
};
struct ctl_table_set;
struct ctl_table_header {
   union __anonunion____missing_field_name_49 __annonCompField20 ;
   struct completion *unregistering ;
   struct ctl_table *ctl_table_arg ;
   struct ctl_table_root *root ;
   struct ctl_table_set *set ;
   struct ctl_dir *parent ;
   struct ctl_node *node ;
};
struct ctl_dir {
   struct ctl_table_header header ;
   struct rb_root root ;
};
struct ctl_table_set {
   int (*is_seen)(struct ctl_table_set * ) ;
   struct ctl_dir dir ;
};
struct ctl_table_root {
   struct ctl_table_set default_set ;
   struct ctl_table_set *(*lookup)(struct ctl_table_root * , struct nsproxy * ) ;
   int (*permissions)(struct ctl_table_header * , struct ctl_table * ) ;
};
struct workqueue_struct;
struct work_struct;
struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct * ) ;
   struct lockdep_map lockdep_map ;
};
struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
   struct workqueue_struct *wq ;
   int cpu ;
};
struct notifier_block {
   int (*notifier_call)(struct notifier_block * , unsigned long , void * ) ;
   struct notifier_block *next ;
   int priority ;
};
struct resource {
   resource_size_t start ;
   resource_size_t end ;
   char const *name ;
   unsigned long flags ;
   struct resource *parent ;
   struct resource *sibling ;
   struct resource *child ;
};
struct pci_dev;
struct pm_message {
   int event ;
};
typedef struct pm_message pm_message_t;
struct dev_pm_ops {
   int (*prepare)(struct device * ) ;
   void (*complete)(struct device * ) ;
   int (*suspend)(struct device * ) ;
   int (*resume)(struct device * ) ;
   int (*freeze)(struct device * ) ;
   int (*thaw)(struct device * ) ;
   int (*poweroff)(struct device * ) ;
   int (*restore)(struct device * ) ;
   int (*suspend_late)(struct device * ) ;
   int (*resume_early)(struct device * ) ;
   int (*freeze_late)(struct device * ) ;
   int (*thaw_early)(struct device * ) ;
   int (*poweroff_late)(struct device * ) ;
   int (*restore_early)(struct device * ) ;
   int (*suspend_noirq)(struct device * ) ;
   int (*resume_noirq)(struct device * ) ;
   int (*freeze_noirq)(struct device * ) ;
   int (*thaw_noirq)(struct device * ) ;
   int (*poweroff_noirq)(struct device * ) ;
   int (*restore_noirq)(struct device * ) ;
   int (*runtime_suspend)(struct device * ) ;
   int (*runtime_resume)(struct device * ) ;
   int (*runtime_idle)(struct device * ) ;
};
enum rpm_status {
    RPM_ACTIVE = 0,
    RPM_RESUMING = 1,
    RPM_SUSPENDED = 2,
    RPM_SUSPENDING = 3
} ;
enum rpm_request {
    RPM_REQ_NONE = 0,
    RPM_REQ_IDLE = 1,
    RPM_REQ_SUSPEND = 2,
    RPM_REQ_AUTOSUSPEND = 3,
    RPM_REQ_RESUME = 4
} ;
struct wakeup_source;
struct wake_irq;
struct pm_subsys_data {
   spinlock_t lock ;
   unsigned int refcount ;
   struct list_head clock_list ;
};
struct dev_pm_qos;
struct dev_pm_info {
   pm_message_t power_state ;
   unsigned char can_wakeup : 1 ;
   unsigned char async_suspend : 1 ;
   bool is_prepared ;
   bool is_suspended ;
   bool is_noirq_suspended ;
   bool is_late_suspended ;
   bool ignore_children ;
   bool early_init ;
   bool direct_complete ;
   spinlock_t lock ;
   struct list_head entry ;
   struct completion completion ;
   struct wakeup_source *wakeup ;
   bool wakeup_path ;
   bool syscore ;
   struct timer_list suspend_timer ;
   unsigned long timer_expires ;
   struct work_struct work ;
   wait_queue_head_t wait_queue ;
   struct wake_irq *wakeirq ;
   atomic_t usage_count ;
   atomic_t child_count ;
   unsigned char disable_depth : 3 ;
   unsigned char idle_notification : 1 ;
   unsigned char request_pending : 1 ;
   unsigned char deferred_resume : 1 ;
   unsigned char run_wake : 1 ;
   unsigned char runtime_auto : 1 ;
   unsigned char no_callbacks : 1 ;
   unsigned char irq_safe : 1 ;
   unsigned char use_autosuspend : 1 ;
   unsigned char timer_autosuspends : 1 ;
   unsigned char memalloc_noio : 1 ;
   enum rpm_request request ;
   enum rpm_status runtime_status ;
   int runtime_error ;
   int autosuspend_delay ;
   unsigned long last_busy ;
   unsigned long active_jiffies ;
   unsigned long suspended_jiffies ;
   unsigned long accounting_timestamp ;
   struct pm_subsys_data *subsys_data ;
   void (*set_latency_tolerance)(struct device * , s32 ) ;
   struct dev_pm_qos *qos ;
};
struct dev_pm_domain {
   struct dev_pm_ops ops ;
   void (*detach)(struct device * , bool ) ;
   int (*activate)(struct device * ) ;
   void (*sync)(struct device * ) ;
   void (*dismiss)(struct device * ) ;
};
struct pci_bus;
struct __anonstruct_mm_context_t_115 {
   void *ldt ;
   int size ;
   unsigned short ia32_compat ;
   struct mutex lock ;
   void *vdso ;
   atomic_t perf_rdpmc_allowed ;
};
typedef struct __anonstruct_mm_context_t_115 mm_context_t;
struct bio_vec;
struct llist_node;
struct llist_node {
   struct llist_node *next ;
};
struct cred;
struct inode;
struct arch_uprobe_task {
   unsigned long saved_scratch_register ;
   unsigned int saved_trap_nr ;
   unsigned int saved_tf ;
};
enum uprobe_task_state {
    UTASK_RUNNING = 0,
    UTASK_SSTEP = 1,
    UTASK_SSTEP_ACK = 2,
    UTASK_SSTEP_TRAPPED = 3
} ;
struct __anonstruct____missing_field_name_148 {
   struct arch_uprobe_task autask ;
   unsigned long vaddr ;
};
struct __anonstruct____missing_field_name_149 {
   struct callback_head dup_xol_work ;
   unsigned long dup_xol_addr ;
};
union __anonunion____missing_field_name_147 {
   struct __anonstruct____missing_field_name_148 __annonCompField33 ;
   struct __anonstruct____missing_field_name_149 __annonCompField34 ;
};
struct uprobe;
struct return_instance;
struct uprobe_task {
   enum uprobe_task_state state ;
   union __anonunion____missing_field_name_147 __annonCompField35 ;
   struct uprobe *active_uprobe ;
   unsigned long xol_vaddr ;
   struct return_instance *return_instances ;
   unsigned int depth ;
};
struct xol_area;
struct uprobes_state {
   struct xol_area *xol_area ;
};
struct address_space;
struct mem_cgroup;
typedef void compound_page_dtor(struct page * );
union __anonunion____missing_field_name_150 {
   struct address_space *mapping ;
   void *s_mem ;
};
union __anonunion____missing_field_name_152 {
   unsigned long index ;
   void *freelist ;
   bool pfmemalloc ;
};
struct __anonstruct____missing_field_name_156 {
   unsigned short inuse ;
   unsigned short objects : 15 ;
   unsigned char frozen : 1 ;
};
union __anonunion____missing_field_name_155 {
   atomic_t _mapcount ;
   struct __anonstruct____missing_field_name_156 __annonCompField38 ;
   int units ;
};
struct __anonstruct____missing_field_name_154 {
   union __anonunion____missing_field_name_155 __annonCompField39 ;
   atomic_t _count ;
};
union __anonunion____missing_field_name_153 {
   unsigned long counters ;
   struct __anonstruct____missing_field_name_154 __annonCompField40 ;
   unsigned int active ;
};
struct __anonstruct____missing_field_name_151 {
   union __anonunion____missing_field_name_152 __annonCompField37 ;
   union __anonunion____missing_field_name_153 __annonCompField41 ;
};
struct __anonstruct____missing_field_name_158 {
   struct page *next ;
   int pages ;
   int pobjects ;
};
struct slab;
struct __anonstruct____missing_field_name_159 {
   compound_page_dtor *compound_dtor ;
   unsigned long compound_order ;
};
union __anonunion____missing_field_name_157 {
   struct list_head lru ;
   struct __anonstruct____missing_field_name_158 __annonCompField43 ;
   struct slab *slab_page ;
   struct callback_head callback_head ;
   struct __anonstruct____missing_field_name_159 __annonCompField44 ;
   pgtable_t pmd_huge_pte ;
};
struct kmem_cache;
union __anonunion____missing_field_name_160 {
   unsigned long private ;
   spinlock_t *ptl ;
   struct kmem_cache *slab_cache ;
   struct page *first_page ;
};
struct page {
   unsigned long flags ;
   union __anonunion____missing_field_name_150 __annonCompField36 ;
   struct __anonstruct____missing_field_name_151 __annonCompField42 ;
   union __anonunion____missing_field_name_157 __annonCompField45 ;
   union __anonunion____missing_field_name_160 __annonCompField46 ;
   struct mem_cgroup *mem_cgroup ;
};
struct page_frag {
   struct page *page ;
   __u32 offset ;
   __u32 size ;
};
struct __anonstruct_shared_161 {
   struct rb_node rb ;
   unsigned long rb_subtree_last ;
};
struct anon_vma;
struct vm_operations_struct;
struct mempolicy;
struct vm_area_struct {
   unsigned long vm_start ;
   unsigned long vm_end ;
   struct vm_area_struct *vm_next ;
   struct vm_area_struct *vm_prev ;
   struct rb_node vm_rb ;
   unsigned long rb_subtree_gap ;
   struct mm_struct *vm_mm ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
   struct __anonstruct_shared_161 shared ;
   struct list_head anon_vma_chain ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct const *vm_ops ;
   unsigned long vm_pgoff ;
   struct file *vm_file ;
   void *vm_private_data ;
   struct mempolicy *vm_policy ;
};
struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};
struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};
struct task_rss_stat {
   int events ;
   int count[3U] ;
};
struct mm_rss_stat {
   atomic_long_t count[3U] ;
};
struct kioctx_table;
struct linux_binfmt;
struct mmu_notifier_mm;
struct mm_struct {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   u32 vmacache_seqnum ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long , unsigned long ,
                                      unsigned long , unsigned long ) ;
   unsigned long mmap_base ;
   unsigned long mmap_legacy_base ;
   unsigned long task_size ;
   unsigned long highest_vm_end ;
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   atomic_long_t nr_ptes ;
   atomic_long_t nr_pmds ;
   int map_count ;
   spinlock_t page_table_lock ;
   struct rw_semaphore mmap_sem ;
   struct list_head mmlist ;
   unsigned long hiwater_rss ;
   unsigned long hiwater_vm ;
   unsigned long total_vm ;
   unsigned long locked_vm ;
   unsigned long pinned_vm ;
   unsigned long shared_vm ;
   unsigned long exec_vm ;
   unsigned long stack_vm ;
   unsigned long def_flags ;
   unsigned long start_code ;
   unsigned long end_code ;
   unsigned long start_data ;
   unsigned long end_data ;
   unsigned long start_brk ;
   unsigned long brk ;
   unsigned long start_stack ;
   unsigned long arg_start ;
   unsigned long arg_end ;
   unsigned long env_start ;
   unsigned long env_end ;
   unsigned long saved_auxv[46U] ;
   struct mm_rss_stat rss_stat ;
   struct linux_binfmt *binfmt ;
   cpumask_var_t cpu_vm_mask_var ;
   mm_context_t context ;
   unsigned long flags ;
   struct core_state *core_state ;
   spinlock_t ioctx_lock ;
   struct kioctx_table *ioctx_table ;
   struct task_struct *owner ;
   struct file *exe_file ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
   struct cpumask cpumask_allocation ;
   unsigned long numa_next_scan ;
   unsigned long numa_scan_offset ;
   int numa_scan_seq ;
   bool tlb_flush_pending ;
   struct uprobes_state uprobes_state ;
   void *bd_addr ;
};
typedef __u64 Elf64_Addr;
typedef __u16 Elf64_Half;
typedef __u32 Elf64_Word;
typedef __u64 Elf64_Xword;
struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
   unsigned char st_other ;
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};
typedef struct elf64_sym Elf64_Sym;
union __anonunion____missing_field_name_166 {
   unsigned long bitmap[4U] ;
   struct callback_head callback_head ;
};
struct idr_layer {
   int prefix ;
   int layer ;
   struct idr_layer *ary[256U] ;
   int count ;
   union __anonunion____missing_field_name_166 __annonCompField47 ;
};
struct idr {
   struct idr_layer *hint ;
   struct idr_layer *top ;
   int layers ;
   int cur ;
   spinlock_t lock ;
   int id_free_cnt ;
   struct idr_layer *id_free ;
};
struct ida_bitmap {
   long nr_busy ;
   unsigned long bitmap[15U] ;
};
struct ida {
   struct idr idr ;
   struct ida_bitmap *free_bitmap ;
};
struct dentry;
struct iattr;
struct super_block;
struct file_system_type;
struct kernfs_open_node;
struct kernfs_iattrs;
struct kernfs_root;
struct kernfs_elem_dir {
   unsigned long subdirs ;
   struct rb_root children ;
   struct kernfs_root *root ;
};
struct kernfs_node;
struct kernfs_elem_symlink {
   struct kernfs_node *target_kn ;
};
struct kernfs_ops;
struct kernfs_elem_attr {
   struct kernfs_ops const *ops ;
   struct kernfs_open_node *open ;
   loff_t size ;
   struct kernfs_node *notify_next ;
};
union __anonunion____missing_field_name_171 {
   struct kernfs_elem_dir dir ;
   struct kernfs_elem_symlink symlink ;
   struct kernfs_elem_attr attr ;
};
struct kernfs_node {
   atomic_t count ;
   atomic_t active ;
   struct lockdep_map dep_map ;
   struct kernfs_node *parent ;
   char const *name ;
   struct rb_node rb ;
   void const *ns ;
   unsigned int hash ;
   union __anonunion____missing_field_name_171 __annonCompField48 ;
   void *priv ;
   unsigned short flags ;
   umode_t mode ;
   unsigned int ino ;
   struct kernfs_iattrs *iattr ;
};
struct kernfs_syscall_ops {
   int (*remount_fs)(struct kernfs_root * , int * , char * ) ;
   int (*show_options)(struct seq_file * , struct kernfs_root * ) ;
   int (*mkdir)(struct kernfs_node * , char const * , umode_t ) ;
   int (*rmdir)(struct kernfs_node * ) ;
   int (*rename)(struct kernfs_node * , struct kernfs_node * , char const * ) ;
};
struct kernfs_root {
   struct kernfs_node *kn ;
   unsigned int flags ;
   struct ida ino_ida ;
   struct kernfs_syscall_ops *syscall_ops ;
   struct list_head supers ;
   wait_queue_head_t deactivate_waitq ;
};
struct kernfs_open_file {
   struct kernfs_node *kn ;
   struct file *file ;
   void *priv ;
   struct mutex mutex ;
   int event ;
   struct list_head list ;
   char *prealloc_buf ;
   size_t atomic_write_len ;
   bool mmapped ;
   struct vm_operations_struct const *vm_ops ;
};
struct kernfs_ops {
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   ssize_t (*read)(struct kernfs_open_file * , char * , size_t , loff_t ) ;
   size_t atomic_write_len ;
   bool prealloc ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t , loff_t ) ;
   int (*mmap)(struct kernfs_open_file * , struct vm_area_struct * ) ;
   struct lock_class_key lockdep_key ;
};
struct sock;
struct kobject;
enum kobj_ns_type {
    KOBJ_NS_TYPE_NONE = 0,
    KOBJ_NS_TYPE_NET = 1,
    KOBJ_NS_TYPES = 2
} ;
struct kobj_ns_type_operations {
   enum kobj_ns_type type ;
   bool (*current_may_mount)(void) ;
   void *(*grab_current_ns)(void) ;
   void const *(*netlink_ns)(struct sock * ) ;
   void const *(*initial_ns)(void) ;
   void (*drop_ns)(void * ) ;
};
struct bin_attribute;
struct attribute {
   char const *name ;
   umode_t mode ;
   bool ignore_lockdep ;
   struct lock_class_key *key ;
   struct lock_class_key skey ;
};
struct attribute_group {
   char const *name ;
   umode_t (*is_visible)(struct kobject * , struct attribute * , int ) ;
   struct attribute **attrs ;
   struct bin_attribute **bin_attrs ;
};
struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                   loff_t , size_t ) ;
   ssize_t (*write)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                    loff_t , size_t ) ;
   int (*mmap)(struct file * , struct kobject * , struct bin_attribute * , struct vm_area_struct * ) ;
};
struct sysfs_ops {
   ssize_t (*show)(struct kobject * , struct attribute * , char * ) ;
   ssize_t (*store)(struct kobject * , struct attribute * , char const * , size_t ) ;
};
struct kref {
   atomic_t refcount ;
};
struct kset;
struct kobj_type;
struct kobject {
   char const *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct kernfs_node *sd ;
   struct kref kref ;
   struct delayed_work release ;
   unsigned char state_initialized : 1 ;
   unsigned char state_in_sysfs : 1 ;
   unsigned char state_add_uevent_sent : 1 ;
   unsigned char state_remove_uevent_sent : 1 ;
   unsigned char uevent_suppress : 1 ;
};
struct kobj_type {
   void (*release)(struct kobject * ) ;
   struct sysfs_ops const *sysfs_ops ;
   struct attribute **default_attrs ;
   struct kobj_ns_type_operations const *(*child_ns_type)(struct kobject * ) ;
   void const *(*namespace)(struct kobject * ) ;
};
struct kobj_uevent_env {
   char *argv[3U] ;
   char *envp[32U] ;
   int envp_idx ;
   char buf[2048U] ;
   int buflen ;
};
struct kset_uevent_ops {
   int (* const filter)(struct kset * , struct kobject * ) ;
   char const *(* const name)(struct kset * , struct kobject * ) ;
   int (* const uevent)(struct kset * , struct kobject * , struct kobj_uevent_env * ) ;
};
struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops const *uevent_ops ;
};
struct kernel_param;
struct kernel_param_ops {
   unsigned int flags ;
   int (*set)(char const * , struct kernel_param const * ) ;
   int (*get)(char * , struct kernel_param const * ) ;
   void (*free)(void * ) ;
};
struct kparam_string;
struct kparam_array;
union __anonunion____missing_field_name_172 {
   void *arg ;
   struct kparam_string const *str ;
   struct kparam_array const *arr ;
};
struct kernel_param {
   char const *name ;
   struct module *mod ;
   struct kernel_param_ops const *ops ;
   u16 const perm ;
   s8 level ;
   u8 flags ;
   union __anonunion____missing_field_name_172 __annonCompField49 ;
};
struct kparam_string {
   unsigned int maxlen ;
   char *string ;
};
struct kparam_array {
   unsigned int max ;
   unsigned int elemsize ;
   unsigned int *num ;
   struct kernel_param_ops const *ops ;
   void *elem ;
};
struct latch_tree_node {
   struct rb_node node[2U] ;
};
struct mod_arch_specific {
};
struct module_param_attrs;
struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
   struct completion *kobj_completion ;
};
struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute * , struct module_kobject * , char * ) ;
   ssize_t (*store)(struct module_attribute * , struct module_kobject * , char const * ,
                    size_t ) ;
   void (*setup)(struct module * , char const * ) ;
   int (*test)(struct module * ) ;
   void (*free)(struct module * ) ;
};
struct exception_table_entry;
enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2,
    MODULE_STATE_UNFORMED = 3
} ;
struct mod_tree_node {
   struct module *mod ;
   struct latch_tree_node node ;
};
struct module_sect_attrs;
struct module_notes_attrs;
struct tracepoint;
struct trace_event_call;
struct trace_enum_map;
struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const *version ;
   char const *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol const *syms ;
   unsigned long const *crcs ;
   unsigned int num_syms ;
   struct mutex param_lock ;
   struct kernel_param *kp ;
   unsigned int num_kp ;
   unsigned int num_gpl_syms ;
   struct kernel_symbol const *gpl_syms ;
   unsigned long const *gpl_crcs ;
   struct kernel_symbol const *unused_syms ;
   unsigned long const *unused_crcs ;
   unsigned int num_unused_syms ;
   unsigned int num_unused_gpl_syms ;
   struct kernel_symbol const *unused_gpl_syms ;
   unsigned long const *unused_gpl_crcs ;
   bool sig_ok ;
   bool async_probe_requested ;
   struct kernel_symbol const *gpl_future_syms ;
   unsigned long const *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
   unsigned int num_exentries ;
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   void *module_init ;
   void *module_core ;
   unsigned int init_size ;
   unsigned int core_size ;
   unsigned int init_text_size ;
   unsigned int core_text_size ;
   struct mod_tree_node mtn_core ;
   struct mod_tree_node mtn_init ;
   unsigned int init_ro_size ;
   unsigned int core_ro_size ;
   struct mod_arch_specific arch ;
   unsigned int taints ;
   unsigned int num_bugs ;
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   Elf64_Sym *symtab ;
   Elf64_Sym *core_symtab ;
   unsigned int num_symtab ;
   unsigned int core_num_syms ;
   char *strtab ;
   char *core_strtab ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   char *args ;
   void *percpu ;
   unsigned int percpu_size ;
   unsigned int num_tracepoints ;
   struct tracepoint * const *tracepoints_ptrs ;
   unsigned int num_trace_bprintk_fmt ;
   char const **trace_bprintk_fmt_start ;
   struct trace_event_call **trace_events ;
   unsigned int num_trace_events ;
   struct trace_enum_map **trace_enums ;
   unsigned int num_trace_enums ;
   unsigned int num_ftrace_callsites ;
   unsigned long *ftrace_callsites ;
   bool klp_alive ;
   struct list_head source_list ;
   struct list_head target_list ;
   void (*exit)(void) ;
   atomic_t refcnt ;
   ctor_fn_t (**ctors)(void) ;
   unsigned int num_ctors ;
};
struct kernel_cap_struct {
   __u32 cap[2U] ;
};
typedef struct kernel_cap_struct kernel_cap_t;
struct plist_node {
   int prio ;
   struct list_head prio_list ;
   struct list_head node_list ;
};
typedef unsigned long cputime_t;
struct sem_undo_list;
struct sysv_sem {
   struct sem_undo_list *undo_list ;
};
struct user_struct;
struct sysv_shm {
   struct list_head shm_clist ;
};
struct __anonstruct_sigset_t_180 {
   unsigned long sig[1U] ;
};
typedef struct __anonstruct_sigset_t_180 sigset_t;
struct siginfo;
typedef void __signalfn_t(int );
typedef __signalfn_t *__sighandler_t;
typedef void __restorefn_t(void);
typedef __restorefn_t *__sigrestore_t;
union sigval {
   int sival_int ;
   void *sival_ptr ;
};
typedef union sigval sigval_t;
struct __anonstruct__kill_182 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
};
struct __anonstruct__timer_183 {
   __kernel_timer_t _tid ;
   int _overrun ;
   char _pad[0U] ;
   sigval_t _sigval ;
   int _sys_private ;
};
struct __anonstruct__rt_184 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   sigval_t _sigval ;
};
struct __anonstruct__sigchld_185 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   int _status ;
   __kernel_clock_t _utime ;
   __kernel_clock_t _stime ;
};
struct __anonstruct__addr_bnd_187 {
   void *_lower ;
   void *_upper ;
};
struct __anonstruct__sigfault_186 {
   void *_addr ;
   short _addr_lsb ;
   struct __anonstruct__addr_bnd_187 _addr_bnd ;
};
struct __anonstruct__sigpoll_188 {
   long _band ;
   int _fd ;
};
struct __anonstruct__sigsys_189 {
   void *_call_addr ;
   int _syscall ;
   unsigned int _arch ;
};
union __anonunion__sifields_181 {
   int _pad[28U] ;
   struct __anonstruct__kill_182 _kill ;
   struct __anonstruct__timer_183 _timer ;
   struct __anonstruct__rt_184 _rt ;
   struct __anonstruct__sigchld_185 _sigchld ;
   struct __anonstruct__sigfault_186 _sigfault ;
   struct __anonstruct__sigpoll_188 _sigpoll ;
   struct __anonstruct__sigsys_189 _sigsys ;
};
struct siginfo {
   int si_signo ;
   int si_errno ;
   int si_code ;
   union __anonunion__sifields_181 _sifields ;
};
typedef struct siginfo siginfo_t;
struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};
struct sigaction {
   __sighandler_t sa_handler ;
   unsigned long sa_flags ;
   __sigrestore_t sa_restorer ;
   sigset_t sa_mask ;
};
struct k_sigaction {
   struct sigaction sa ;
};
enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_PGID = 1,
    PIDTYPE_SID = 2,
    PIDTYPE_MAX = 3
} ;
struct pid_namespace;
struct upid {
   int nr ;
   struct pid_namespace *ns ;
   struct hlist_node pid_chain ;
};
struct pid {
   atomic_t count ;
   unsigned int level ;
   struct hlist_head tasks[3U] ;
   struct callback_head rcu ;
   struct upid numbers[1U] ;
};
struct pid_link {
   struct hlist_node node ;
   struct pid *pid ;
};
struct percpu_counter {
   raw_spinlock_t lock ;
   s64 count ;
   struct list_head list ;
   s32 *counters ;
};
struct seccomp_filter;
struct seccomp {
   int mode ;
   struct seccomp_filter *filter ;
};
struct rt_mutex_waiter;
struct rlimit {
   __kernel_ulong_t rlim_cur ;
   __kernel_ulong_t rlim_max ;
};
struct timerqueue_node {
   struct rb_node node ;
   ktime_t expires ;
};
struct timerqueue_head {
   struct rb_root head ;
   struct timerqueue_node *next ;
};
struct hrtimer_clock_base;
struct hrtimer_cpu_base;
enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
} ;
struct hrtimer {
   struct timerqueue_node node ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer * ) ;
   struct hrtimer_clock_base *base ;
   unsigned long state ;
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
};
struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   int index ;
   clockid_t clockid ;
   struct timerqueue_head active ;
   ktime_t (*get_time)(void) ;
   ktime_t offset ;
};
struct hrtimer_cpu_base {
   raw_spinlock_t lock ;
   seqcount_t seq ;
   struct hrtimer *running ;
   unsigned int cpu ;
   unsigned int active_bases ;
   unsigned int clock_was_set_seq ;
   bool migration_enabled ;
   bool nohz_active ;
   unsigned char in_hrtirq : 1 ;
   unsigned char hres_active : 1 ;
   unsigned char hang_detected : 1 ;
   ktime_t expires_next ;
   struct hrtimer *next_timer ;
   unsigned int nr_events ;
   unsigned int nr_retries ;
   unsigned int nr_hangs ;
   unsigned int max_hang_time ;
   struct hrtimer_clock_base clock_base[4U] ;
};
struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};
struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
   unsigned long max ;
};
struct assoc_array_ptr;
struct assoc_array {
   struct assoc_array_ptr *root ;
   unsigned long nr_leaves_on_tree ;
};
typedef int32_t key_serial_t;
typedef uint32_t key_perm_t;
struct key;
struct signal_struct;
struct key_type;
struct keyring_index_key {
   struct key_type *type ;
   char const *description ;
   size_t desc_len ;
};
union __anonunion____missing_field_name_196 {
   struct list_head graveyard_link ;
   struct rb_node serial_node ;
};
struct key_user;
union __anonunion____missing_field_name_197 {
   time_t expiry ;
   time_t revoked_at ;
};
struct __anonstruct____missing_field_name_199 {
   struct key_type *type ;
   char *description ;
};
union __anonunion____missing_field_name_198 {
   struct keyring_index_key index_key ;
   struct __anonstruct____missing_field_name_199 __annonCompField52 ;
};
union __anonunion_type_data_200 {
   struct list_head link ;
   unsigned long x[2U] ;
   void *p[2U] ;
   int reject_error ;
};
union __anonunion_payload_202 {
   unsigned long value ;
   void *rcudata ;
   void *data ;
   void *data2[2U] ;
};
union __anonunion____missing_field_name_201 {
   union __anonunion_payload_202 payload ;
   struct assoc_array keys ;
};
struct key {
   atomic_t usage ;
   key_serial_t serial ;
   union __anonunion____missing_field_name_196 __annonCompField50 ;
   struct rw_semaphore sem ;
   struct key_user *user ;
   void *security ;
   union __anonunion____missing_field_name_197 __annonCompField51 ;
   time_t last_used_at ;
   kuid_t uid ;
   kgid_t gid ;
   key_perm_t perm ;
   unsigned short quotalen ;
   unsigned short datalen ;
   unsigned long flags ;
   union __anonunion____missing_field_name_198 __annonCompField53 ;
   union __anonunion_type_data_200 type_data ;
   union __anonunion____missing_field_name_201 __annonCompField54 ;
};
struct audit_context;
struct group_info {
   atomic_t usage ;
   int ngroups ;
   int nblocks ;
   kgid_t small_block[32U] ;
   kgid_t *blocks[0U] ;
};
struct cred {
   atomic_t usage ;
   atomic_t subscribers ;
   void *put_addr ;
   unsigned int magic ;
   kuid_t uid ;
   kgid_t gid ;
   kuid_t suid ;
   kgid_t sgid ;
   kuid_t euid ;
   kgid_t egid ;
   kuid_t fsuid ;
   kgid_t fsgid ;
   unsigned int securebits ;
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_bset ;
   unsigned char jit_keyring ;
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct key *thread_keyring ;
   struct key *request_key_auth ;
   void *security ;
   struct user_struct *user ;
   struct user_namespace *user_ns ;
   struct group_info *group_info ;
   struct callback_head rcu ;
};
struct percpu_ref;
typedef void percpu_ref_func_t(struct percpu_ref * );
struct percpu_ref {
   atomic_long_t count ;
   unsigned long percpu_count_ptr ;
   percpu_ref_func_t *release ;
   percpu_ref_func_t *confirm_switch ;
   bool force_atomic ;
   struct callback_head rcu ;
};
struct cgroup;
struct cgroup_root;
struct cgroup_subsys;
struct cgroup_taskset;
struct cgroup_subsys_state {
   struct cgroup *cgroup ;
   struct cgroup_subsys *ss ;
   struct percpu_ref refcnt ;
   struct cgroup_subsys_state *parent ;
   struct list_head sibling ;
   struct list_head children ;
   int id ;
   unsigned int flags ;
   u64 serial_nr ;
   struct callback_head callback_head ;
   struct work_struct destroy_work ;
};
struct css_set {
   atomic_t refcount ;
   struct hlist_node hlist ;
   struct list_head tasks ;
   struct list_head mg_tasks ;
   struct list_head cgrp_links ;
   struct cgroup *dfl_cgrp ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct list_head mg_preload_node ;
   struct list_head mg_node ;
   struct cgroup *mg_src_cgrp ;
   struct css_set *mg_dst_cset ;
   struct list_head e_cset_node[12U] ;
   struct callback_head callback_head ;
};
struct cgroup {
   struct cgroup_subsys_state self ;
   unsigned long flags ;
   int id ;
   int populated_cnt ;
   struct kernfs_node *kn ;
   struct kernfs_node *procs_kn ;
   struct kernfs_node *populated_kn ;
   unsigned int subtree_control ;
   unsigned int child_subsys_mask ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct cgroup_root *root ;
   struct list_head cset_links ;
   struct list_head e_csets[12U] ;
   struct list_head pidlists ;
   struct mutex pidlist_mutex ;
   wait_queue_head_t offline_waitq ;
   struct work_struct release_agent_work ;
};
struct cgroup_root {
   struct kernfs_root *kf_root ;
   unsigned int subsys_mask ;
   int hierarchy_id ;
   struct cgroup cgrp ;
   atomic_t nr_cgrps ;
   struct list_head root_list ;
   unsigned int flags ;
   struct idr cgroup_idr ;
   char release_agent_path[4096U] ;
   char name[64U] ;
};
struct cftype {
   char name[64U] ;
   int private ;
   umode_t mode ;
   size_t max_write_len ;
   unsigned int flags ;
   struct cgroup_subsys *ss ;
   struct list_head node ;
   struct kernfs_ops *kf_ops ;
   u64 (*read_u64)(struct cgroup_subsys_state * , struct cftype * ) ;
   s64 (*read_s64)(struct cgroup_subsys_state * , struct cftype * ) ;
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   int (*write_u64)(struct cgroup_subsys_state * , struct cftype * , u64 ) ;
   int (*write_s64)(struct cgroup_subsys_state * , struct cftype * , s64 ) ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t , loff_t ) ;
   struct lock_class_key lockdep_key ;
};
struct cgroup_subsys {
   struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state * ) ;
   int (*css_online)(struct cgroup_subsys_state * ) ;
   void (*css_offline)(struct cgroup_subsys_state * ) ;
   void (*css_released)(struct cgroup_subsys_state * ) ;
   void (*css_free)(struct cgroup_subsys_state * ) ;
   void (*css_reset)(struct cgroup_subsys_state * ) ;
   void (*css_e_css_changed)(struct cgroup_subsys_state * ) ;
   int (*can_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*cancel_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*fork)(struct task_struct * ) ;
   void (*exit)(struct cgroup_subsys_state * , struct cgroup_subsys_state * , struct task_struct * ) ;
   void (*bind)(struct cgroup_subsys_state * ) ;
   int disabled ;
   int early_init ;
   bool broken_hierarchy ;
   bool warned_broken_hierarchy ;
   int id ;
   char const *name ;
   struct cgroup_root *root ;
   struct idr css_idr ;
   struct list_head cfts ;
   struct cftype *dfl_cftypes ;
   struct cftype *legacy_cftypes ;
   unsigned int depends_on ;
};
struct futex_pi_state;
struct robust_list_head;
struct bio_list;
struct fs_struct;
struct perf_event_context;
struct blk_plug;
struct nameidata;
struct cfs_rq;
struct task_group;
struct sighand_struct {
   atomic_t count ;
   struct k_sigaction action[64U] ;
   spinlock_t siglock ;
   wait_queue_head_t signalfd_wqh ;
};
struct pacct_struct {
   int ac_flag ;
   long ac_exitcode ;
   unsigned long ac_mem ;
   cputime_t ac_utime ;
   cputime_t ac_stime ;
   unsigned long ac_minflt ;
   unsigned long ac_majflt ;
};
struct cpu_itimer {
   cputime_t expires ;
   cputime_t incr ;
   u32 error ;
   u32 incr_error ;
};
struct cputime {
   cputime_t utime ;
   cputime_t stime ;
};
struct task_cputime {
   cputime_t utime ;
   cputime_t stime ;
   unsigned long long sum_exec_runtime ;
};
struct task_cputime_atomic {
   atomic64_t utime ;
   atomic64_t stime ;
   atomic64_t sum_exec_runtime ;
};
struct thread_group_cputimer {
   struct task_cputime_atomic cputime_atomic ;
   int running ;
};
struct autogroup;
struct tty_struct;
struct taskstats;
struct tty_audit_buf;
struct signal_struct {
   atomic_t sigcnt ;
   atomic_t live ;
   int nr_threads ;
   struct list_head thread_head ;
   wait_queue_head_t wait_chldexit ;
   struct task_struct *curr_target ;
   struct sigpending shared_pending ;
   int group_exit_code ;
   int notify_count ;
   struct task_struct *group_exit_task ;
   int group_stop_count ;
   unsigned int flags ;
   unsigned char is_child_subreaper : 1 ;
   unsigned char has_child_subreaper : 1 ;
   int posix_timer_id ;
   struct list_head posix_timers ;
   struct hrtimer real_timer ;
   struct pid *leader_pid ;
   ktime_t it_real_incr ;
   struct cpu_itimer it[2U] ;
   struct thread_group_cputimer cputimer ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct pid *tty_old_pgrp ;
   int leader ;
   struct tty_struct *tty ;
   struct autogroup *autogroup ;
   seqlock_t stats_lock ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t cutime ;
   cputime_t cstime ;
   cputime_t gtime ;
   cputime_t cgtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   unsigned long cnvcsw ;
   unsigned long cnivcsw ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   unsigned long cmin_flt ;
   unsigned long cmaj_flt ;
   unsigned long inblock ;
   unsigned long oublock ;
   unsigned long cinblock ;
   unsigned long coublock ;
   unsigned long maxrss ;
   unsigned long cmaxrss ;
   struct task_io_accounting ioac ;
   unsigned long long sum_sched_runtime ;
   struct rlimit rlim[16U] ;
   struct pacct_struct pacct ;
   struct taskstats *stats ;
   unsigned int audit_tty ;
   unsigned int audit_tty_log_passwd ;
   struct tty_audit_buf *tty_audit_buf ;
   oom_flags_t oom_flags ;
   short oom_score_adj ;
   short oom_score_adj_min ;
   struct mutex cred_guard_mutex ;
};
struct user_struct {
   atomic_t __count ;
   atomic_t processes ;
   atomic_t sigpending ;
   atomic_t inotify_watches ;
   atomic_t inotify_devs ;
   atomic_t fanotify_listeners ;
   atomic_long_t epoll_watches ;
   unsigned long mq_bytes ;
   unsigned long locked_shm ;
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   kuid_t uid ;
   atomic_long_t locked_vm ;
};
struct backing_dev_info;
struct reclaim_state;
struct sched_info {
   unsigned long pcount ;
   unsigned long long run_delay ;
   unsigned long long last_arrival ;
   unsigned long long last_queued ;
};
struct task_delay_info {
   spinlock_t lock ;
   unsigned int flags ;
   u64 blkio_start ;
   u64 blkio_delay ;
   u64 swapin_delay ;
   u32 blkio_count ;
   u32 swapin_count ;
   u64 freepages_start ;
   u64 freepages_delay ;
   u32 freepages_count ;
};
struct wake_q_node {
   struct wake_q_node *next ;
};
struct io_context;
struct pipe_inode_info;
struct uts_namespace;
struct load_weight {
   unsigned long weight ;
   u32 inv_weight ;
};
struct sched_avg {
   u64 last_runnable_update ;
   s64 decay_count ;
   unsigned long load_avg_contrib ;
   unsigned long utilization_avg_contrib ;
   u32 runnable_avg_sum ;
   u32 avg_period ;
   u32 running_avg_sum ;
};
struct sched_statistics {
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 iowait_count ;
   u64 iowait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
};
struct sched_entity {
   struct load_weight load ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 nr_migrations ;
   struct sched_statistics statistics ;
   int depth ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
   struct sched_avg avg ;
};
struct rt_rq;
struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
   unsigned long watchdog_stamp ;
   unsigned int time_slice ;
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};
struct sched_dl_entity {
   struct rb_node rb_node ;
   u64 dl_runtime ;
   u64 dl_deadline ;
   u64 dl_period ;
   u64 dl_bw ;
   s64 runtime ;
   u64 deadline ;
   unsigned int flags ;
   int dl_throttled ;
   int dl_new ;
   int dl_boosted ;
   int dl_yielded ;
   struct hrtimer dl_timer ;
};
struct memcg_oom_info {
   struct mem_cgroup *memcg ;
   gfp_t gfp_mask ;
   int order ;
   unsigned char may_oom : 1 ;
};
struct sched_class;
struct files_struct;
struct compat_robust_list_head;
struct numa_group;
struct ftrace_ret_stack;
struct task_struct {
   long volatile state ;
   void *stack ;
   atomic_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
   struct llist_node wake_entry ;
   int on_cpu ;
   struct task_struct *last_wakee ;
   unsigned long wakee_flips ;
   unsigned long wakee_flip_decay_ts ;
   int wake_cpu ;
   int on_rq ;
   int prio ;
   int static_prio ;
   int normal_prio ;
   unsigned int rt_priority ;
   struct sched_class const *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct task_group *sched_task_group ;
   struct sched_dl_entity dl ;
   struct hlist_head preempt_notifiers ;
   unsigned int btrace_seq ;
   unsigned int policy ;
   int nr_cpus_allowed ;
   cpumask_t cpus_allowed ;
   unsigned long rcu_tasks_nvcsw ;
   bool rcu_tasks_holdout ;
   struct list_head rcu_tasks_holdout_list ;
   int rcu_tasks_idle_cpu ;
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct plist_node pushable_tasks ;
   struct rb_node pushable_dl_tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   u32 vmacache_seqnum ;
   struct vm_area_struct *vmacache[4U] ;
   struct task_rss_stat rss_stat ;
   int exit_state ;
   int exit_code ;
   int exit_signal ;
   int pdeath_signal ;
   unsigned long jobctl ;
   unsigned int personality ;
   unsigned char in_execve : 1 ;
   unsigned char in_iowait : 1 ;
   unsigned char sched_reset_on_fork : 1 ;
   unsigned char sched_contributes_to_load : 1 ;
   unsigned char sched_migrated : 1 ;
   unsigned char memcg_kmem_skip_account : 1 ;
   unsigned char brk_randomized : 1 ;
   unsigned long atomic_flags ;
   struct restart_block restart_block ;
   pid_t pid ;
   pid_t tgid ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid_link pids[3U] ;
   struct list_head thread_group ;
   struct list_head thread_node ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t utimescaled ;
   cputime_t stimescaled ;
   cputime_t gtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   u64 start_time ;
   u64 real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct cred const *real_cred ;
   struct cred const *cred ;
   char comm[16U] ;
   struct nameidata *nameidata ;
   struct sysv_sem sysvsem ;
   struct sysv_shm sysvshm ;
   unsigned long last_switch_count ;
   struct thread_struct thread ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
   size_t sas_ss_size ;
   int (*notifier)(void * ) ;
   void *notifier_data ;
   sigset_t *notifier_mask ;
   struct callback_head *task_works ;
   struct audit_context *audit_context ;
   kuid_t loginuid ;
   unsigned int sessionid ;
   struct seccomp seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   raw_spinlock_t pi_lock ;
   struct wake_q_node wake_q ;
   struct rb_root pi_waiters ;
   struct rb_node *pi_waiters_leftmost ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
   unsigned long hardirq_enable_ip ;
   unsigned long hardirq_disable_ip ;
   unsigned int hardirq_enable_event ;
   unsigned int hardirq_disable_event ;
   int hardirqs_enabled ;
   int hardirq_context ;
   unsigned long softirq_disable_ip ;
   unsigned long softirq_enable_ip ;
   unsigned int softirq_disable_event ;
   unsigned int softirq_enable_event ;
   int softirqs_enabled ;
   int softirq_context ;
   u64 curr_chain_key ;
   int lockdep_depth ;
   unsigned int lockdep_recursion ;
   struct held_lock held_locks[48U] ;
   gfp_t lockdep_reclaim_gfp ;
   void *journal_info ;
   struct bio_list *bio_list ;
   struct blk_plug *plug ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   unsigned long ptrace_message ;
   siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   cputime_t acct_timexpd ;
   nodemask_t mems_allowed ;
   seqcount_t mems_allowed_seq ;
   int cpuset_mem_spread_rotor ;
   int cpuset_slab_spread_rotor ;
   struct css_set *cgroups ;
   struct list_head cg_list ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct perf_event_context *perf_event_ctxp[2U] ;
   struct mutex perf_event_mutex ;
   struct list_head perf_event_list ;
   struct mempolicy *mempolicy ;
   short il_next ;
   short pref_node_fork ;
   int numa_scan_seq ;
   unsigned int numa_scan_period ;
   unsigned int numa_scan_period_max ;
   int numa_preferred_nid ;
   unsigned long numa_migrate_retry ;
   u64 node_stamp ;
   u64 last_task_numa_placement ;
   u64 last_sum_exec_runtime ;
   struct callback_head numa_work ;
   struct list_head numa_entry ;
   struct numa_group *numa_group ;
   unsigned long *numa_faults ;
   unsigned long total_numa_faults ;
   unsigned long numa_faults_locality[3U] ;
   unsigned long numa_pages_migrated ;
   struct callback_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct page_frag task_frag ;
   struct task_delay_info *delays ;
   int make_it_fail ;
   int nr_dirtied ;
   int nr_dirtied_pause ;
   unsigned long dirty_paused_when ;
   int latency_record_count ;
   struct latency_record latency_record[32U] ;
   unsigned long timer_slack_ns ;
   unsigned long default_timer_slack_ns ;
   unsigned int kasan_depth ;
   int curr_ret_stack ;
   struct ftrace_ret_stack *ret_stack ;
   unsigned long long ftrace_timestamp ;
   atomic_t trace_overrun ;
   atomic_t tracing_graph_pause ;
   unsigned long trace ;
   unsigned long trace_recursion ;
   struct memcg_oom_info memcg_oom ;
   struct uprobe_task *utask ;
   unsigned int sequential_io ;
   unsigned int sequential_io_avg ;
   unsigned long task_state_change ;
   int pagefault_disabled ;
};
enum irqreturn {
    IRQ_NONE = 0,
    IRQ_HANDLED = 1,
    IRQ_WAKE_THREAD = 2
} ;
typedef enum irqreturn irqreturn_t;
struct ethtool_cmd;
struct ethtool_pauseparam;
struct ethtool_eeprom;
struct bfa_ioc;
struct ethtool_ringparam;
struct ethtool_coalesce;
struct klist_node;
struct klist_node {
   void *n_klist ;
   struct list_head n_node ;
   struct kref n_ref ;
};
struct path;
struct seq_file {
   char *buf ;
   size_t size ;
   size_t from ;
   size_t count ;
   size_t pad_until ;
   loff_t index ;
   loff_t read_pos ;
   u64 version ;
   struct mutex lock ;
   struct seq_operations const *op ;
   int poll_event ;
   struct user_namespace *user_ns ;
   void *private ;
};
struct seq_operations {
   void *(*start)(struct seq_file * , loff_t * ) ;
   void (*stop)(struct seq_file * , void * ) ;
   void *(*next)(struct seq_file * , void * , loff_t * ) ;
   int (*show)(struct seq_file * , void * ) ;
};
struct pinctrl;
struct pinctrl_state;
struct dev_pin_info {
   struct pinctrl *p ;
   struct pinctrl_state *default_state ;
   struct pinctrl_state *sleep_state ;
   struct pinctrl_state *idle_state ;
};
struct dma_map_ops;
struct dev_archdata {
   struct dma_map_ops *dma_ops ;
   void *iommu ;
};
struct device_private;
struct device_driver;
struct driver_private;
struct class;
struct subsys_private;
struct bus_type;
struct device_node;
struct fwnode_handle;
struct iommu_ops;
struct iommu_group;
struct device_attribute;
struct bus_type {
   char const *name ;
   char const *dev_name ;
   struct device *dev_root ;
   struct device_attribute *dev_attrs ;
   struct attribute_group const **bus_groups ;
   struct attribute_group const **dev_groups ;
   struct attribute_group const **drv_groups ;
   int (*match)(struct device * , struct device_driver * ) ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*online)(struct device * ) ;
   int (*offline)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t ) ;
   int (*resume)(struct device * ) ;
   struct dev_pm_ops const *pm ;
   struct iommu_ops const *iommu_ops ;
   struct subsys_private *p ;
   struct lock_class_key lock_key ;
};
struct device_type;
enum probe_type {
    PROBE_DEFAULT_STRATEGY = 0,
    PROBE_PREFER_ASYNCHRONOUS = 1,
    PROBE_FORCE_SYNCHRONOUS = 2
} ;
struct of_device_id;
struct acpi_device_id;
struct device_driver {
   char const *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const *mod_name ;
   bool suppress_bind_attrs ;
   enum probe_type probe_type ;
   struct of_device_id const *of_match_table ;
   struct acpi_device_id const *acpi_match_table ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t ) ;
   int (*resume)(struct device * ) ;
   struct attribute_group const **groups ;
   struct dev_pm_ops const *pm ;
   struct driver_private *p ;
};
struct class_attribute;
struct class {
   char const *name ;
   struct module *owner ;
   struct class_attribute *class_attrs ;
   struct attribute_group const **dev_groups ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * ) ;
   void (*class_release)(struct class * ) ;
   void (*dev_release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t ) ;
   int (*resume)(struct device * ) ;
   struct kobj_ns_type_operations const *ns_type ;
   void const *(*namespace)(struct device * ) ;
   struct dev_pm_ops const *pm ;
   struct subsys_private *p ;
};
struct class_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct class * , struct class_attribute * , char * ) ;
   ssize_t (*store)(struct class * , struct class_attribute * , char const * , size_t ) ;
};
struct device_type {
   char const *name ;
   struct attribute_group const **groups ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * , kuid_t * , kgid_t * ) ;
   void (*release)(struct device * ) ;
   struct dev_pm_ops const *pm ;
};
struct device_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device * , struct device_attribute * , char * ) ;
   ssize_t (*store)(struct device * , struct device_attribute * , char const * ,
                    size_t ) ;
};
struct device_dma_parameters {
   unsigned int max_segment_size ;
   unsigned long segment_boundary_mask ;
};
struct dma_coherent_mem;
struct cma;
struct device {
   struct device *parent ;
   struct device_private *p ;
   struct kobject kobj ;
   char const *init_name ;
   struct device_type const *type ;
   struct mutex mutex ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *platform_data ;
   void *driver_data ;
   struct dev_pm_info power ;
   struct dev_pm_domain *pm_domain ;
   struct dev_pin_info *pins ;
   int numa_node ;
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   unsigned long dma_pfn_offset ;
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct cma *cma_area ;
   struct dev_archdata archdata ;
   struct device_node *of_node ;
   struct fwnode_handle *fwnode ;
   dev_t devt ;
   u32 id ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct klist_node knode_class ;
   struct class *class ;
   struct attribute_group const **groups ;
   void (*release)(struct device * ) ;
   struct iommu_group *iommu_group ;
   bool offline_disabled ;
   bool offline ;
};
struct wakeup_source {
   char const *name ;
   struct list_head entry ;
   spinlock_t lock ;
   struct wake_irq *wakeirq ;
   struct timer_list timer ;
   unsigned long timer_expires ;
   ktime_t total_time ;
   ktime_t max_time ;
   ktime_t last_time ;
   ktime_t start_prevent_time ;
   ktime_t prevent_sleep_time ;
   unsigned long event_count ;
   unsigned long active_count ;
   unsigned long relax_count ;
   unsigned long expire_count ;
   unsigned long wakeup_count ;
   bool active ;
   bool autosleep_enabled ;
};
struct iovec {
   void *iov_base ;
   __kernel_size_t iov_len ;
};
struct kvec {
   void *iov_base ;
   size_t iov_len ;
};
union __anonunion____missing_field_name_217 {
   struct iovec const *iov ;
   struct kvec const *kvec ;
   struct bio_vec const *bvec ;
};
struct iov_iter {
   int type ;
   size_t iov_offset ;
   size_t count ;
   union __anonunion____missing_field_name_217 __annonCompField58 ;
   unsigned long nr_segs ;
};
struct shrink_control {
   gfp_t gfp_mask ;
   unsigned long nr_to_scan ;
   int nid ;
   struct mem_cgroup *memcg ;
};
struct shrinker {
   unsigned long (*count_objects)(struct shrinker * , struct shrink_control * ) ;
   unsigned long (*scan_objects)(struct shrinker * , struct shrink_control * ) ;
   int seeks ;
   long batch ;
   unsigned long flags ;
   struct list_head list ;
   atomic_long_t *nr_deferred ;
};
struct file_ra_state;
struct writeback_control;
struct bdi_writeback;
struct vm_fault {
   unsigned int flags ;
   unsigned long pgoff ;
   void *virtual_address ;
   struct page *cow_page ;
   struct page *page ;
   unsigned long max_pgoff ;
   pte_t *pte ;
};
struct vm_operations_struct {
   void (*open)(struct vm_area_struct * ) ;
   void (*close)(struct vm_area_struct * ) ;
   int (*fault)(struct vm_area_struct * , struct vm_fault * ) ;
   void (*map_pages)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*page_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*pfn_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*access)(struct vm_area_struct * , unsigned long , void * , int , int ) ;
   char const *(*name)(struct vm_area_struct * ) ;
   int (*set_policy)(struct vm_area_struct * , struct mempolicy * ) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct * , unsigned long ) ;
   struct page *(*find_special_page)(struct vm_area_struct * , unsigned long ) ;
};
struct scatterlist {
   unsigned long sg_magic ;
   unsigned long page_link ;
   unsigned int offset ;
   unsigned int length ;
   dma_addr_t dma_address ;
   unsigned int dma_length ;
};
struct sg_table {
   struct scatterlist *sgl ;
   unsigned int nents ;
   unsigned int orig_nents ;
};
struct dql {
   unsigned int num_queued ;
   unsigned int adj_limit ;
   unsigned int last_obj_cnt ;
   unsigned int limit ;
   unsigned int num_completed ;
   unsigned int prev_ovlimit ;
   unsigned int prev_num_queued ;
   unsigned int prev_last_obj_cnt ;
   unsigned int lowest_slack ;
   unsigned long slack_start_time ;
   unsigned int max_limit ;
   unsigned int min_limit ;
   unsigned int slack_hold_time ;
};
typedef unsigned short __kernel_sa_family_t;
typedef __kernel_sa_family_t sa_family_t;
struct sockaddr {
   sa_family_t sa_family ;
   char sa_data[14U] ;
};
struct kiocb;
struct msghdr {
   void *msg_name ;
   int msg_namelen ;
   struct iov_iter msg_iter ;
   void *msg_control ;
   __kernel_size_t msg_controllen ;
   unsigned int msg_flags ;
   struct kiocb *msg_iocb ;
};
struct __anonstruct_sync_serial_settings_219 {
   unsigned int clock_rate ;
   unsigned int clock_type ;
   unsigned short loopback ;
};
typedef struct __anonstruct_sync_serial_settings_219 sync_serial_settings;
struct __anonstruct_te1_settings_220 {
   unsigned int clock_rate ;
   unsigned int clock_type ;
   unsigned short loopback ;
   unsigned int slot_map ;
};
typedef struct __anonstruct_te1_settings_220 te1_settings;
struct __anonstruct_raw_hdlc_proto_221 {
   unsigned short encoding ;
   unsigned short parity ;
};
typedef struct __anonstruct_raw_hdlc_proto_221 raw_hdlc_proto;
struct __anonstruct_fr_proto_222 {
   unsigned int t391 ;
   unsigned int t392 ;
   unsigned int n391 ;
   unsigned int n392 ;
   unsigned int n393 ;
   unsigned short lmi ;
   unsigned short dce ;
};
typedef struct __anonstruct_fr_proto_222 fr_proto;
struct __anonstruct_fr_proto_pvc_223 {
   unsigned int dlci ;
};
typedef struct __anonstruct_fr_proto_pvc_223 fr_proto_pvc;
struct __anonstruct_fr_proto_pvc_info_224 {
   unsigned int dlci ;
   char master[16U] ;
};
typedef struct __anonstruct_fr_proto_pvc_info_224 fr_proto_pvc_info;
struct __anonstruct_cisco_proto_225 {
   unsigned int interval ;
   unsigned int timeout ;
};
typedef struct __anonstruct_cisco_proto_225 cisco_proto;
struct ifmap {
   unsigned long mem_start ;
   unsigned long mem_end ;
   unsigned short base_addr ;
   unsigned char irq ;
   unsigned char dma ;
   unsigned char port ;
};
union __anonunion_ifs_ifsu_226 {
   raw_hdlc_proto *raw_hdlc ;
   cisco_proto *cisco ;
   fr_proto *fr ;
   fr_proto_pvc *fr_pvc ;
   fr_proto_pvc_info *fr_pvc_info ;
   sync_serial_settings *sync ;
   te1_settings *te1 ;
};
struct if_settings {
   unsigned int type ;
   unsigned int size ;
   union __anonunion_ifs_ifsu_226 ifs_ifsu ;
};
union __anonunion_ifr_ifrn_227 {
   char ifrn_name[16U] ;
};
union __anonunion_ifr_ifru_228 {
   struct sockaddr ifru_addr ;
   struct sockaddr ifru_dstaddr ;
   struct sockaddr ifru_broadaddr ;
   struct sockaddr ifru_netmask ;
   struct sockaddr ifru_hwaddr ;
   short ifru_flags ;
   int ifru_ivalue ;
   int ifru_mtu ;
   struct ifmap ifru_map ;
   char ifru_slave[16U] ;
   char ifru_newname[16U] ;
   void *ifru_data ;
   struct if_settings ifru_settings ;
};
struct ifreq {
   union __anonunion_ifr_ifrn_227 ifr_ifrn ;
   union __anonunion_ifr_ifru_228 ifr_ifru ;
};
struct hlist_bl_node;
struct hlist_bl_head {
   struct hlist_bl_node *first ;
};
struct hlist_bl_node {
   struct hlist_bl_node *next ;
   struct hlist_bl_node **pprev ;
};
struct __anonstruct____missing_field_name_233 {
   spinlock_t lock ;
   int count ;
};
union __anonunion____missing_field_name_232 {
   struct __anonstruct____missing_field_name_233 __annonCompField59 ;
};
struct lockref {
   union __anonunion____missing_field_name_232 __annonCompField60 ;
};
struct vfsmount;
struct __anonstruct____missing_field_name_235 {
   u32 hash ;
   u32 len ;
};
union __anonunion____missing_field_name_234 {
   struct __anonstruct____missing_field_name_235 __annonCompField61 ;
   u64 hash_len ;
};
struct qstr {
   union __anonunion____missing_field_name_234 __annonCompField62 ;
   unsigned char const *name ;
};
struct dentry_operations;
union __anonunion_d_u_236 {
   struct hlist_node d_alias ;
   struct callback_head d_rcu ;
};
struct dentry {
   unsigned int d_flags ;
   seqcount_t d_seq ;
   struct hlist_bl_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct inode *d_inode ;
   unsigned char d_iname[32U] ;
   struct lockref d_lockref ;
   struct dentry_operations const *d_op ;
   struct super_block *d_sb ;
   unsigned long d_time ;
   void *d_fsdata ;
   struct list_head d_lru ;
   struct list_head d_child ;
   struct list_head d_subdirs ;
   union __anonunion_d_u_236 d_u ;
};
struct dentry_operations {
   int (*d_revalidate)(struct dentry * , unsigned int ) ;
   int (*d_weak_revalidate)(struct dentry * , unsigned int ) ;
   int (*d_hash)(struct dentry const * , struct qstr * ) ;
   int (*d_compare)(struct dentry const * , struct dentry const * , unsigned int ,
                    char const * , struct qstr const * ) ;
   int (*d_delete)(struct dentry const * ) ;
   void (*d_release)(struct dentry * ) ;
   void (*d_prune)(struct dentry * ) ;
   void (*d_iput)(struct dentry * , struct inode * ) ;
   char *(*d_dname)(struct dentry * , char * , int ) ;
   struct vfsmount *(*d_automount)(struct path * ) ;
   int (*d_manage)(struct dentry * , bool ) ;
   struct inode *(*d_select_inode)(struct dentry * , unsigned int ) ;
};
struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};
struct list_lru_one {
   struct list_head list ;
   long nr_items ;
};
struct list_lru_memcg {
   struct list_lru_one *lru[0U] ;
};
struct list_lru_node {
   spinlock_t lock ;
   struct list_lru_one lru ;
   struct list_lru_memcg *memcg_lrus ;
};
struct list_lru {
   struct list_lru_node *node ;
   struct list_head list ;
};
struct __anonstruct____missing_field_name_240 {
   struct radix_tree_node *parent ;
   void *private_data ;
};
union __anonunion____missing_field_name_239 {
   struct __anonstruct____missing_field_name_240 __annonCompField63 ;
   struct callback_head callback_head ;
};
struct radix_tree_node {
   unsigned int path ;
   unsigned int count ;
   union __anonunion____missing_field_name_239 __annonCompField64 ;
   struct list_head private_list ;
   void *slots[64U] ;
   unsigned long tags[3U][1U] ;
};
struct radix_tree_root {
   unsigned int height ;
   gfp_t gfp_mask ;
   struct radix_tree_node *rnode ;
};
struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};
enum migrate_mode {
    MIGRATE_ASYNC = 0,
    MIGRATE_SYNC_LIGHT = 1,
    MIGRATE_SYNC = 2
} ;
struct block_device;
struct bio_vec {
   struct page *bv_page ;
   unsigned int bv_len ;
   unsigned int bv_offset ;
};
struct export_operations;
struct poll_table_struct;
struct kstatfs;
struct swap_info_struct;
struct iattr {
   unsigned int ia_valid ;
   umode_t ia_mode ;
   kuid_t ia_uid ;
   kgid_t ia_gid ;
   loff_t ia_size ;
   struct timespec ia_atime ;
   struct timespec ia_mtime ;
   struct timespec ia_ctime ;
   struct file *ia_file ;
};
struct dquot;
typedef __kernel_uid32_t projid_t;
struct __anonstruct_kprojid_t_244 {
   projid_t val ;
};
typedef struct __anonstruct_kprojid_t_244 kprojid_t;
enum quota_type {
    USRQUOTA = 0,
    GRPQUOTA = 1,
    PRJQUOTA = 2
} ;
typedef long long qsize_t;
union __anonunion____missing_field_name_245 {
   kuid_t uid ;
   kgid_t gid ;
   kprojid_t projid ;
};
struct kqid {
   union __anonunion____missing_field_name_245 __annonCompField66 ;
   enum quota_type type ;
};
struct mem_dqblk {
   qsize_t dqb_bhardlimit ;
   qsize_t dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   qsize_t dqb_rsvspace ;
   qsize_t dqb_ihardlimit ;
   qsize_t dqb_isoftlimit ;
   qsize_t dqb_curinodes ;
   time_t dqb_btime ;
   time_t dqb_itime ;
};
struct quota_format_type;
struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
   unsigned int dqi_bgrace ;
   unsigned int dqi_igrace ;
   qsize_t dqi_max_spc_limit ;
   qsize_t dqi_max_ino_limit ;
   void *dqi_priv ;
};
struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   atomic_t dq_count ;
   wait_queue_head_t dq_wait_unused ;
   struct super_block *dq_sb ;
   struct kqid dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
   struct mem_dqblk dq_dqb ;
};
struct quota_format_ops {
   int (*check_quota_file)(struct super_block * , int ) ;
   int (*read_file_info)(struct super_block * , int ) ;
   int (*write_file_info)(struct super_block * , int ) ;
   int (*free_file_info)(struct super_block * , int ) ;
   int (*read_dqblk)(struct dquot * ) ;
   int (*commit_dqblk)(struct dquot * ) ;
   int (*release_dqblk)(struct dquot * ) ;
};
struct dquot_operations {
   int (*write_dquot)(struct dquot * ) ;
   struct dquot *(*alloc_dquot)(struct super_block * , int ) ;
   void (*destroy_dquot)(struct dquot * ) ;
   int (*acquire_dquot)(struct dquot * ) ;
   int (*release_dquot)(struct dquot * ) ;
   int (*mark_dirty)(struct dquot * ) ;
   int (*write_info)(struct super_block * , int ) ;
   qsize_t *(*get_reserved_space)(struct inode * ) ;
   int (*get_projid)(struct inode * , kprojid_t * ) ;
};
struct qc_dqblk {
   int d_fieldmask ;
   u64 d_spc_hardlimit ;
   u64 d_spc_softlimit ;
   u64 d_ino_hardlimit ;
   u64 d_ino_softlimit ;
   u64 d_space ;
   u64 d_ino_count ;
   s64 d_ino_timer ;
   s64 d_spc_timer ;
   int d_ino_warns ;
   int d_spc_warns ;
   u64 d_rt_spc_hardlimit ;
   u64 d_rt_spc_softlimit ;
   u64 d_rt_space ;
   s64 d_rt_spc_timer ;
   int d_rt_spc_warns ;
};
struct qc_type_state {
   unsigned int flags ;
   unsigned int spc_timelimit ;
   unsigned int ino_timelimit ;
   unsigned int rt_spc_timelimit ;
   unsigned int spc_warnlimit ;
   unsigned int ino_warnlimit ;
   unsigned int rt_spc_warnlimit ;
   unsigned long long ino ;
   blkcnt_t blocks ;
   blkcnt_t nextents ;
};
struct qc_state {
   unsigned int s_incoredqs ;
   struct qc_type_state s_state[3U] ;
};
struct qc_info {
   int i_fieldmask ;
   unsigned int i_flags ;
   unsigned int i_spc_timelimit ;
   unsigned int i_ino_timelimit ;
   unsigned int i_rt_spc_timelimit ;
   unsigned int i_spc_warnlimit ;
   unsigned int i_ino_warnlimit ;
   unsigned int i_rt_spc_warnlimit ;
};
struct quotactl_ops {
   int (*quota_on)(struct super_block * , int , int , struct path * ) ;
   int (*quota_off)(struct super_block * , int ) ;
   int (*quota_enable)(struct super_block * , unsigned int ) ;
   int (*quota_disable)(struct super_block * , unsigned int ) ;
   int (*quota_sync)(struct super_block * , int ) ;
   int (*set_info)(struct super_block * , int , struct qc_info * ) ;
   int (*get_dqblk)(struct super_block * , struct kqid , struct qc_dqblk * ) ;
   int (*set_dqblk)(struct super_block * , struct kqid , struct qc_dqblk * ) ;
   int (*get_state)(struct super_block * , struct qc_state * ) ;
   int (*rm_xquota)(struct super_block * , unsigned int ) ;
};
struct quota_format_type {
   int qf_fmt_id ;
   struct quota_format_ops const *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};
struct quota_info {
   unsigned int flags ;
   struct mutex dqio_mutex ;
   struct mutex dqonoff_mutex ;
   struct inode *files[3U] ;
   struct mem_dqinfo info[3U] ;
   struct quota_format_ops const *ops[3U] ;
};
struct kiocb {
   struct file *ki_filp ;
   loff_t ki_pos ;
   void (*ki_complete)(struct kiocb * , long , long ) ;
   void *private ;
   int ki_flags ;
};
struct address_space_operations {
   int (*writepage)(struct page * , struct writeback_control * ) ;
   int (*readpage)(struct file * , struct page * ) ;
   int (*writepages)(struct address_space * , struct writeback_control * ) ;
   int (*set_page_dirty)(struct page * ) ;
   int (*readpages)(struct file * , struct address_space * , struct list_head * ,
                    unsigned int ) ;
   int (*write_begin)(struct file * , struct address_space * , loff_t , unsigned int ,
                      unsigned int , struct page ** , void ** ) ;
   int (*write_end)(struct file * , struct address_space * , loff_t , unsigned int ,
                    unsigned int , struct page * , void * ) ;
   sector_t (*bmap)(struct address_space * , sector_t ) ;
   void (*invalidatepage)(struct page * , unsigned int , unsigned int ) ;
   int (*releasepage)(struct page * , gfp_t ) ;
   void (*freepage)(struct page * ) ;
   ssize_t (*direct_IO)(struct kiocb * , struct iov_iter * , loff_t ) ;
   int (*migratepage)(struct address_space * , struct page * , struct page * , enum migrate_mode ) ;
   int (*launder_page)(struct page * ) ;
   int (*is_partially_uptodate)(struct page * , unsigned long , unsigned long ) ;
   void (*is_dirty_writeback)(struct page * , bool * , bool * ) ;
   int (*error_remove_page)(struct address_space * , struct page * ) ;
   int (*swap_activate)(struct swap_info_struct * , struct file * , sector_t * ) ;
   void (*swap_deactivate)(struct file * ) ;
};
struct address_space {
   struct inode *host ;
   struct radix_tree_root page_tree ;
   spinlock_t tree_lock ;
   atomic_t i_mmap_writable ;
   struct rb_root i_mmap ;
   struct rw_semaphore i_mmap_rwsem ;
   unsigned long nrpages ;
   unsigned long nrshadows ;
   unsigned long writeback_index ;
   struct address_space_operations const *a_ops ;
   unsigned long flags ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   void *private_data ;
};
struct request_queue;
struct hd_struct;
struct gendisk;
struct block_device {
   dev_t bd_dev ;
   int bd_openers ;
   struct inode *bd_inode ;
   struct super_block *bd_super ;
   struct mutex bd_mutex ;
   struct list_head bd_inodes ;
   void *bd_claiming ;
   void *bd_holder ;
   int bd_holders ;
   bool bd_write_holder ;
   struct list_head bd_holder_disks ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
   int bd_invalidated ;
   struct gendisk *bd_disk ;
   struct request_queue *bd_queue ;
   struct list_head bd_list ;
   unsigned long bd_private ;
   int bd_fsfreeze_count ;
   struct mutex bd_fsfreeze_mutex ;
};
struct posix_acl;
struct inode_operations;
union __anonunion____missing_field_name_248 {
   unsigned int const i_nlink ;
   unsigned int __i_nlink ;
};
union __anonunion____missing_field_name_249 {
   struct hlist_head i_dentry ;
   struct callback_head i_rcu ;
};
struct file_lock_context;
struct cdev;
union __anonunion____missing_field_name_250 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
   char *i_link ;
};
struct inode {
   umode_t i_mode ;
   unsigned short i_opflags ;
   kuid_t i_uid ;
   kgid_t i_gid ;
   unsigned int i_flags ;
   struct posix_acl *i_acl ;
   struct posix_acl *i_default_acl ;
   struct inode_operations const *i_op ;
   struct super_block *i_sb ;
   struct address_space *i_mapping ;
   void *i_security ;
   unsigned long i_ino ;
   union __anonunion____missing_field_name_248 __annonCompField67 ;
   dev_t i_rdev ;
   loff_t i_size ;
   struct timespec i_atime ;
   struct timespec i_mtime ;
   struct timespec i_ctime ;
   spinlock_t i_lock ;
   unsigned short i_bytes ;
   unsigned int i_blkbits ;
   blkcnt_t i_blocks ;
   unsigned long i_state ;
   struct mutex i_mutex ;
   unsigned long dirtied_when ;
   unsigned long dirtied_time_when ;
   struct hlist_node i_hash ;
   struct list_head i_wb_list ;
   struct bdi_writeback *i_wb ;
   int i_wb_frn_winner ;
   u16 i_wb_frn_avg_time ;
   u16 i_wb_frn_history ;
   struct list_head i_lru ;
   struct list_head i_sb_list ;
   union __anonunion____missing_field_name_249 __annonCompField68 ;
   u64 i_version ;
   atomic_t i_count ;
   atomic_t i_dio_count ;
   atomic_t i_writecount ;
   atomic_t i_readcount ;
   struct file_operations const *i_fop ;
   struct file_lock_context *i_flctx ;
   struct address_space i_data ;
   struct list_head i_devices ;
   union __anonunion____missing_field_name_250 __annonCompField69 ;
   __u32 i_generation ;
   __u32 i_fsnotify_mask ;
   struct hlist_head i_fsnotify_marks ;
   void *i_private ;
};
struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   kuid_t uid ;
   kuid_t euid ;
   int signum ;
};
struct file_ra_state {
   unsigned long start ;
   unsigned int size ;
   unsigned int async_size ;
   unsigned int ra_pages ;
   unsigned int mmap_miss ;
   loff_t prev_pos ;
};
union __anonunion_f_u_251 {
   struct llist_node fu_llist ;
   struct callback_head fu_rcuhead ;
};
struct file {
   union __anonunion_f_u_251 f_u ;
   struct path f_path ;
   struct inode *f_inode ;
   struct file_operations const *f_op ;
   spinlock_t f_lock ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
   fmode_t f_mode ;
   struct mutex f_pos_lock ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   struct cred const *f_cred ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   struct list_head f_tfile_llink ;
   struct address_space *f_mapping ;
};
typedef void *fl_owner_t;
struct file_lock;
struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
};
struct lock_manager_operations {
   int (*lm_compare_owner)(struct file_lock * , struct file_lock * ) ;
   unsigned long (*lm_owner_key)(struct file_lock * ) ;
   fl_owner_t (*lm_get_owner)(fl_owner_t ) ;
   void (*lm_put_owner)(fl_owner_t ) ;
   void (*lm_notify)(struct file_lock * ) ;
   int (*lm_grant)(struct file_lock * , int ) ;
   bool (*lm_break)(struct file_lock * ) ;
   int (*lm_change)(struct file_lock * , int , struct list_head * ) ;
   void (*lm_setup)(struct file_lock * , void ** ) ;
};
struct net;
struct nlm_lockowner;
struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};
struct nfs4_lock_state;
struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};
struct fasync_struct;
struct __anonstruct_afs_253 {
   struct list_head link ;
   int state ;
};
union __anonunion_fl_u_252 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_253 afs ;
};
struct file_lock {
   struct file_lock *fl_next ;
   struct list_head fl_list ;
   struct hlist_node fl_link ;
   struct list_head fl_block ;
   fl_owner_t fl_owner ;
   unsigned int fl_flags ;
   unsigned char fl_type ;
   unsigned int fl_pid ;
   int fl_link_cpu ;
   struct pid *fl_nspid ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
   unsigned long fl_downgrade_time ;
   struct file_lock_operations const *fl_ops ;
   struct lock_manager_operations const *fl_lmops ;
   union __anonunion_fl_u_252 fl_u ;
};
struct file_lock_context {
   spinlock_t flc_lock ;
   struct list_head flc_flock ;
   struct list_head flc_posix ;
   struct list_head flc_lease ;
};
struct fasync_struct {
   spinlock_t fa_lock ;
   int magic ;
   int fa_fd ;
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
   struct callback_head fa_rcu ;
};
struct sb_writers {
   struct percpu_counter counter[3U] ;
   wait_queue_head_t wait ;
   int frozen ;
   wait_queue_head_t wait_unfrozen ;
   struct lockdep_map lock_map[3U] ;
};
struct super_operations;
struct xattr_handler;
struct mtd_info;
struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned char s_blocksize_bits ;
   unsigned long s_blocksize ;
   loff_t s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations const *s_op ;
   struct dquot_operations const *dq_op ;
   struct quotactl_ops const *s_qcop ;
   struct export_operations const *s_export_op ;
   unsigned long s_flags ;
   unsigned long s_iflags ;
   unsigned long s_magic ;
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   int s_count ;
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler const **s_xattr ;
   struct list_head s_inodes ;
   struct hlist_bl_head s_anon ;
   struct list_head s_mounts ;
   struct block_device *s_bdev ;
   struct backing_dev_info *s_bdi ;
   struct mtd_info *s_mtd ;
   struct hlist_node s_instances ;
   unsigned int s_quota_types ;
   struct quota_info s_dquot ;
   struct sb_writers s_writers ;
   char s_id[32U] ;
   u8 s_uuid[16U] ;
   void *s_fs_info ;
   unsigned int s_max_links ;
   fmode_t s_mode ;
   u32 s_time_gran ;
   struct mutex s_vfs_rename_mutex ;
   char *s_subtype ;
   char *s_options ;
   struct dentry_operations const *s_d_op ;
   int cleancache_poolid ;
   struct shrinker s_shrink ;
   atomic_long_t s_remove_count ;
   int s_readonly_remount ;
   struct workqueue_struct *s_dio_done_wq ;
   struct hlist_head s_pins ;
   struct list_lru s_dentry_lru ;
   struct list_lru s_inode_lru ;
   struct callback_head rcu ;
   int s_stack_depth ;
};
struct fiemap_extent_info {
   unsigned int fi_flags ;
   unsigned int fi_extents_mapped ;
   unsigned int fi_extents_max ;
   struct fiemap_extent *fi_extents_start ;
};
struct dir_context;
struct dir_context {
   int (*actor)(struct dir_context * , char const * , int , loff_t , u64 , unsigned int ) ;
   loff_t pos ;
};
struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file * , loff_t , int ) ;
   ssize_t (*read)(struct file * , char * , size_t , loff_t * ) ;
   ssize_t (*write)(struct file * , char const * , size_t , loff_t * ) ;
   ssize_t (*read_iter)(struct kiocb * , struct iov_iter * ) ;
   ssize_t (*write_iter)(struct kiocb * , struct iov_iter * ) ;
   int (*iterate)(struct file * , struct dir_context * ) ;
   unsigned int (*poll)(struct file * , struct poll_table_struct * ) ;
   long (*unlocked_ioctl)(struct file * , unsigned int , unsigned long ) ;
   long (*compat_ioctl)(struct file * , unsigned int , unsigned long ) ;
   int (*mmap)(struct file * , struct vm_area_struct * ) ;
   int (*mremap)(struct file * , struct vm_area_struct * ) ;
   int (*open)(struct inode * , struct file * ) ;
   int (*flush)(struct file * , fl_owner_t ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*fsync)(struct file * , loff_t , loff_t , int ) ;
   int (*aio_fsync)(struct kiocb * , int ) ;
   int (*fasync)(int , struct file * , int ) ;
   int (*lock)(struct file * , int , struct file_lock * ) ;
   ssize_t (*sendpage)(struct file * , struct page * , int , size_t , loff_t * ,
                       int ) ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long , unsigned long ,
                                      unsigned long , unsigned long ) ;
   int (*check_flags)(int ) ;
   int (*flock)(struct file * , int , struct file_lock * ) ;
   ssize_t (*splice_write)(struct pipe_inode_info * , struct file * , loff_t * , size_t ,
                           unsigned int ) ;
   ssize_t (*splice_read)(struct file * , loff_t * , struct pipe_inode_info * , size_t ,
                          unsigned int ) ;
   int (*setlease)(struct file * , long , struct file_lock ** , void ** ) ;
   long (*fallocate)(struct file * , int , loff_t , loff_t ) ;
   void (*show_fdinfo)(struct seq_file * , struct file * ) ;
};
struct inode_operations {
   struct dentry *(*lookup)(struct inode * , struct dentry * , unsigned int ) ;
   char const *(*follow_link)(struct dentry * , void ** ) ;
   int (*permission)(struct inode * , int ) ;
   struct posix_acl *(*get_acl)(struct inode * , int ) ;
   int (*readlink)(struct dentry * , char * , int ) ;
   void (*put_link)(struct inode * , void * ) ;
   int (*create)(struct inode * , struct dentry * , umode_t , bool ) ;
   int (*link)(struct dentry * , struct inode * , struct dentry * ) ;
   int (*unlink)(struct inode * , struct dentry * ) ;
   int (*symlink)(struct inode * , struct dentry * , char const * ) ;
   int (*mkdir)(struct inode * , struct dentry * , umode_t ) ;
   int (*rmdir)(struct inode * , struct dentry * ) ;
   int (*mknod)(struct inode * , struct dentry * , umode_t , dev_t ) ;
   int (*rename)(struct inode * , struct dentry * , struct inode * , struct dentry * ) ;
   int (*rename2)(struct inode * , struct dentry * , struct inode * , struct dentry * ,
                  unsigned int ) ;
   int (*setattr)(struct dentry * , struct iattr * ) ;
   int (*getattr)(struct vfsmount * , struct dentry * , struct kstat * ) ;
   int (*setxattr)(struct dentry * , char const * , void const * , size_t , int ) ;
   ssize_t (*getxattr)(struct dentry * , char const * , void * , size_t ) ;
   ssize_t (*listxattr)(struct dentry * , char * , size_t ) ;
   int (*removexattr)(struct dentry * , char const * ) ;
   int (*fiemap)(struct inode * , struct fiemap_extent_info * , u64 , u64 ) ;
   int (*update_time)(struct inode * , struct timespec * , int ) ;
   int (*atomic_open)(struct inode * , struct dentry * , struct file * , unsigned int ,
                      umode_t , int * ) ;
   int (*tmpfile)(struct inode * , struct dentry * , umode_t ) ;
   int (*set_acl)(struct inode * , struct posix_acl * , int ) ;
};
struct super_operations {
   struct inode *(*alloc_inode)(struct super_block * ) ;
   void (*destroy_inode)(struct inode * ) ;
   void (*dirty_inode)(struct inode * , int ) ;
   int (*write_inode)(struct inode * , struct writeback_control * ) ;
   int (*drop_inode)(struct inode * ) ;
   void (*evict_inode)(struct inode * ) ;
   void (*put_super)(struct super_block * ) ;
   int (*sync_fs)(struct super_block * , int ) ;
   int (*freeze_super)(struct super_block * ) ;
   int (*freeze_fs)(struct super_block * ) ;
   int (*thaw_super)(struct super_block * ) ;
   int (*unfreeze_fs)(struct super_block * ) ;
   int (*statfs)(struct dentry * , struct kstatfs * ) ;
   int (*remount_fs)(struct super_block * , int * , char * ) ;
   void (*umount_begin)(struct super_block * ) ;
   int (*show_options)(struct seq_file * , struct dentry * ) ;
   int (*show_devname)(struct seq_file * , struct dentry * ) ;
   int (*show_path)(struct seq_file * , struct dentry * ) ;
   int (*show_stats)(struct seq_file * , struct dentry * ) ;
   ssize_t (*quota_read)(struct super_block * , int , char * , size_t , loff_t ) ;
   ssize_t (*quota_write)(struct super_block * , int , char const * , size_t ,
                          loff_t ) ;
   struct dquot **(*get_dquots)(struct inode * ) ;
   int (*bdev_try_to_free_page)(struct super_block * , struct page * , gfp_t ) ;
   long (*nr_cached_objects)(struct super_block * , struct shrink_control * ) ;
   long (*free_cached_objects)(struct super_block * , struct shrink_control * ) ;
};
struct file_system_type {
   char const *name ;
   int fs_flags ;
   struct dentry *(*mount)(struct file_system_type * , int , char const * , void * ) ;
   void (*kill_sb)(struct super_block * ) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct hlist_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key s_vfs_rename_key ;
   struct lock_class_key s_writers_key[3U] ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
};
typedef s32 compat_time_t;
typedef s32 compat_long_t;
typedef u32 compat_uptr_t;
struct compat_timespec {
   compat_time_t tv_sec ;
   s32 tv_nsec ;
};
struct compat_robust_list {
   compat_uptr_t next ;
};
struct compat_robust_list_head {
   struct compat_robust_list list ;
   compat_long_t futex_offset ;
   compat_uptr_t list_op_pending ;
};
enum ldv_23684 {
    SS_FREE = 0,
    SS_UNCONNECTED = 1,
    SS_CONNECTING = 2,
    SS_CONNECTED = 3,
    SS_DISCONNECTING = 4
} ;
typedef enum ldv_23684 socket_state;
struct socket_wq {
   wait_queue_head_t wait ;
   struct fasync_struct *fasync_list ;
   struct callback_head rcu ;
};
struct proto_ops;
struct socket {
   socket_state state ;
   short type ;
   unsigned long flags ;
   struct socket_wq *wq ;
   struct file *file ;
   struct sock *sk ;
   struct proto_ops const *ops ;
};
struct proto_ops {
   int family ;
   struct module *owner ;
   int (*release)(struct socket * ) ;
   int (*bind)(struct socket * , struct sockaddr * , int ) ;
   int (*connect)(struct socket * , struct sockaddr * , int , int ) ;
   int (*socketpair)(struct socket * , struct socket * ) ;
   int (*accept)(struct socket * , struct socket * , int ) ;
   int (*getname)(struct socket * , struct sockaddr * , int * , int ) ;
   unsigned int (*poll)(struct file * , struct socket * , struct poll_table_struct * ) ;
   int (*ioctl)(struct socket * , unsigned int , unsigned long ) ;
   int (*compat_ioctl)(struct socket * , unsigned int , unsigned long ) ;
   int (*listen)(struct socket * , int ) ;
   int (*shutdown)(struct socket * , int ) ;
   int (*setsockopt)(struct socket * , int , int , char * , unsigned int ) ;
   int (*getsockopt)(struct socket * , int , int , char * , int * ) ;
   int (*compat_setsockopt)(struct socket * , int , int , char * , unsigned int ) ;
   int (*compat_getsockopt)(struct socket * , int , int , char * , int * ) ;
   int (*sendmsg)(struct socket * , struct msghdr * , size_t ) ;
   int (*recvmsg)(struct socket * , struct msghdr * , size_t , int ) ;
   int (*mmap)(struct file * , struct socket * , struct vm_area_struct * ) ;
   ssize_t (*sendpage)(struct socket * , struct page * , int , size_t , int ) ;
   ssize_t (*splice_read)(struct socket * , loff_t * , struct pipe_inode_info * ,
                          size_t , unsigned int ) ;
   int (*set_peek_off)(struct sock * , int ) ;
};
struct exception_table_entry {
   int insn ;
   int fixup ;
};
struct in6_addr;
struct sk_buff;
struct dma_attrs {
   unsigned long flags[1U] ;
};
enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3
} ;
struct dma_map_ops {
   void *(*alloc)(struct device * , size_t , dma_addr_t * , gfp_t , struct dma_attrs * ) ;
   void (*free)(struct device * , size_t , void * , dma_addr_t , struct dma_attrs * ) ;
   int (*mmap)(struct device * , struct vm_area_struct * , void * , dma_addr_t ,
               size_t , struct dma_attrs * ) ;
   int (*get_sgtable)(struct device * , struct sg_table * , void * , dma_addr_t ,
                      size_t , struct dma_attrs * ) ;
   dma_addr_t (*map_page)(struct device * , struct page * , unsigned long , size_t ,
                          enum dma_data_direction , struct dma_attrs * ) ;
   void (*unmap_page)(struct device * , dma_addr_t , size_t , enum dma_data_direction ,
                      struct dma_attrs * ) ;
   int (*map_sg)(struct device * , struct scatterlist * , int , enum dma_data_direction ,
                 struct dma_attrs * ) ;
   void (*unmap_sg)(struct device * , struct scatterlist * , int , enum dma_data_direction ,
                    struct dma_attrs * ) ;
   void (*sync_single_for_cpu)(struct device * , dma_addr_t , size_t , enum dma_data_direction ) ;
   void (*sync_single_for_device)(struct device * , dma_addr_t , size_t , enum dma_data_direction ) ;
   void (*sync_sg_for_cpu)(struct device * , struct scatterlist * , int , enum dma_data_direction ) ;
   void (*sync_sg_for_device)(struct device * , struct scatterlist * , int , enum dma_data_direction ) ;
   int (*mapping_error)(struct device * , dma_addr_t ) ;
   int (*dma_supported)(struct device * , u64 ) ;
   int (*set_dma_mask)(struct device * , u64 ) ;
   int is_phys ;
};
typedef u64 netdev_features_t;
union __anonunion_in6_u_268 {
   __u8 u6_addr8[16U] ;
   __be16 u6_addr16[8U] ;
   __be32 u6_addr32[4U] ;
};
struct in6_addr {
   union __anonunion_in6_u_268 in6_u ;
};
struct ethhdr {
   unsigned char h_dest[6U] ;
   unsigned char h_source[6U] ;
   __be16 h_proto ;
};
struct pipe_buf_operations;
struct pipe_buffer {
   struct page *page ;
   unsigned int offset ;
   unsigned int len ;
   struct pipe_buf_operations const *ops ;
   unsigned int flags ;
   unsigned long private ;
};
struct pipe_inode_info {
   struct mutex mutex ;
   wait_queue_head_t wait ;
   unsigned int nrbufs ;
   unsigned int curbuf ;
   unsigned int buffers ;
   unsigned int readers ;
   unsigned int writers ;
   unsigned int files ;
   unsigned int waiting_writers ;
   unsigned int r_counter ;
   unsigned int w_counter ;
   struct page *tmp_page ;
   struct fasync_struct *fasync_readers ;
   struct fasync_struct *fasync_writers ;
   struct pipe_buffer *bufs ;
};
struct pipe_buf_operations {
   int can_merge ;
   int (*confirm)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*release)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   int (*steal)(struct pipe_inode_info * , struct pipe_buffer * ) ;
   void (*get)(struct pipe_inode_info * , struct pipe_buffer * ) ;
};
struct napi_struct;
struct nf_conntrack {
   atomic_t use ;
};
union __anonunion____missing_field_name_273 {
   struct net_device *physoutdev ;
   char neigh_header[8U] ;
};
union __anonunion____missing_field_name_274 {
   __be32 ipv4_daddr ;
   struct in6_addr ipv6_daddr ;
};
struct nf_bridge_info {
   atomic_t use ;
   unsigned char orig_proto ;
   bool pkt_otherhost ;
   __u16 frag_max_size ;
   unsigned int mask ;
   struct net_device *physindev ;
   union __anonunion____missing_field_name_273 __annonCompField73 ;
   union __anonunion____missing_field_name_274 __annonCompField74 ;
};
struct sk_buff_head {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   __u32 qlen ;
   spinlock_t lock ;
};
struct skb_frag_struct;
typedef struct skb_frag_struct skb_frag_t;
struct __anonstruct_page_275 {
   struct page *p ;
};
struct skb_frag_struct {
   struct __anonstruct_page_275 page ;
   __u32 page_offset ;
   __u32 size ;
};
struct skb_shared_hwtstamps {
   ktime_t hwtstamp ;
};
struct skb_shared_info {
   unsigned char nr_frags ;
   __u8 tx_flags ;
   unsigned short gso_size ;
   unsigned short gso_segs ;
   unsigned short gso_type ;
   struct sk_buff *frag_list ;
   struct skb_shared_hwtstamps hwtstamps ;
   u32 tskey ;
   __be32 ip6_frag_id ;
   atomic_t dataref ;
   void *destructor_arg ;
   skb_frag_t frags[17U] ;
};
typedef unsigned int sk_buff_data_t;
struct __anonstruct____missing_field_name_277 {
   u32 stamp_us ;
   u32 stamp_jiffies ;
};
union __anonunion____missing_field_name_276 {
   u64 v64 ;
   struct __anonstruct____missing_field_name_277 __annonCompField75 ;
};
struct skb_mstamp {
   union __anonunion____missing_field_name_276 __annonCompField76 ;
};
union __anonunion____missing_field_name_280 {
   ktime_t tstamp ;
   struct skb_mstamp skb_mstamp ;
};
struct __anonstruct____missing_field_name_279 {
   struct sk_buff *next ;
   struct sk_buff *prev ;
   union __anonunion____missing_field_name_280 __annonCompField77 ;
};
union __anonunion____missing_field_name_278 {
   struct __anonstruct____missing_field_name_279 __annonCompField78 ;
   struct rb_node rbnode ;
};
struct sec_path;
struct __anonstruct____missing_field_name_282 {
   __u16 csum_start ;
   __u16 csum_offset ;
};
union __anonunion____missing_field_name_281 {
   __wsum csum ;
   struct __anonstruct____missing_field_name_282 __annonCompField80 ;
};
union __anonunion____missing_field_name_283 {
   unsigned int napi_id ;
   unsigned int sender_cpu ;
};
union __anonunion____missing_field_name_284 {
   __u32 mark ;
   __u32 reserved_tailroom ;
};
union __anonunion____missing_field_name_285 {
   __be16 inner_protocol ;
   __u8 inner_ipproto ;
};
struct sk_buff {
   union __anonunion____missing_field_name_278 __annonCompField79 ;
   struct sock *sk ;
   struct net_device *dev ;
   char cb[48U] ;
   unsigned long _skb_refdst ;
   void (*destructor)(struct sk_buff * ) ;
   struct sec_path *sp ;
   struct nf_conntrack *nfct ;
   struct nf_bridge_info *nf_bridge ;
   unsigned int len ;
   unsigned int data_len ;
   __u16 mac_len ;
   __u16 hdr_len ;
   __u16 queue_mapping ;
   unsigned char cloned : 1 ;
   unsigned char nohdr : 1 ;
   unsigned char fclone : 2 ;
   unsigned char peeked : 1 ;
   unsigned char head_frag : 1 ;
   unsigned char xmit_more : 1 ;
   __u32 headers_start[0U] ;
   __u8 __pkt_type_offset[0U] ;
   unsigned char pkt_type : 3 ;
   unsigned char pfmemalloc : 1 ;
   unsigned char ignore_df : 1 ;
   unsigned char nfctinfo : 3 ;
   unsigned char nf_trace : 1 ;
   unsigned char ip_summed : 2 ;
   unsigned char ooo_okay : 1 ;
   unsigned char l4_hash : 1 ;
   unsigned char sw_hash : 1 ;
   unsigned char wifi_acked_valid : 1 ;
   unsigned char wifi_acked : 1 ;
   unsigned char no_fcs : 1 ;
   unsigned char encapsulation : 1 ;
   unsigned char encap_hdr_csum : 1 ;
   unsigned char csum_valid : 1 ;
   unsigned char csum_complete_sw : 1 ;
   unsigned char csum_level : 2 ;
   unsigned char csum_bad : 1 ;
   unsigned char ndisc_nodetype : 2 ;
   unsigned char ipvs_property : 1 ;
   unsigned char inner_protocol_type : 1 ;
   unsigned char remcsum_offload : 1 ;
   __u16 tc_index ;
   __u16 tc_verd ;
   union __anonunion____missing_field_name_281 __annonCompField81 ;
   __u32 priority ;
   int skb_iif ;
   __u32 hash ;
   __be16 vlan_proto ;
   __u16 vlan_tci ;
   union __anonunion____missing_field_name_283 __annonCompField82 ;
   __u32 secmark ;
   union __anonunion____missing_field_name_284 __annonCompField83 ;
   union __anonunion____missing_field_name_285 __annonCompField84 ;
   __u16 inner_transport_header ;
   __u16 inner_network_header ;
   __u16 inner_mac_header ;
   __be16 protocol ;
   __u16 transport_header ;
   __u16 network_header ;
   __u16 mac_header ;
   __u32 headers_end[0U] ;
   sk_buff_data_t tail ;
   sk_buff_data_t end ;
   unsigned char *head ;
   unsigned char *data ;
   unsigned int truesize ;
   atomic_t users ;
};
struct dst_entry;
struct rtable;
struct ethtool_cmd {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertising ;
   __u16 speed ;
   __u8 duplex ;
   __u8 port ;
   __u8 phy_address ;
   __u8 transceiver ;
   __u8 autoneg ;
   __u8 mdio_support ;
   __u32 maxtxpkt ;
   __u32 maxrxpkt ;
   __u16 speed_hi ;
   __u8 eth_tp_mdix ;
   __u8 eth_tp_mdix_ctrl ;
   __u32 lp_advertising ;
   __u32 reserved[2U] ;
};
struct ethtool_drvinfo {
   __u32 cmd ;
   char driver[32U] ;
   char version[32U] ;
   char fw_version[32U] ;
   char bus_info[32U] ;
   char erom_version[32U] ;
   char reserved2[12U] ;
   __u32 n_priv_flags ;
   __u32 n_stats ;
   __u32 testinfo_len ;
   __u32 eedump_len ;
   __u32 regdump_len ;
};
struct ethtool_wolinfo {
   __u32 cmd ;
   __u32 supported ;
   __u32 wolopts ;
   __u8 sopass[6U] ;
};
struct ethtool_tunable {
   __u32 cmd ;
   __u32 id ;
   __u32 type_id ;
   __u32 len ;
   void *data[0U] ;
};
struct ethtool_regs {
   __u32 cmd ;
   __u32 version ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eeprom {
   __u32 cmd ;
   __u32 magic ;
   __u32 offset ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_eee {
   __u32 cmd ;
   __u32 supported ;
   __u32 advertised ;
   __u32 lp_advertised ;
   __u32 eee_active ;
   __u32 eee_enabled ;
   __u32 tx_lpi_enabled ;
   __u32 tx_lpi_timer ;
   __u32 reserved[2U] ;
};
struct ethtool_modinfo {
   __u32 cmd ;
   __u32 type ;
   __u32 eeprom_len ;
   __u32 reserved[8U] ;
};
struct ethtool_coalesce {
   __u32 cmd ;
   __u32 rx_coalesce_usecs ;
   __u32 rx_max_coalesced_frames ;
   __u32 rx_coalesce_usecs_irq ;
   __u32 rx_max_coalesced_frames_irq ;
   __u32 tx_coalesce_usecs ;
   __u32 tx_max_coalesced_frames ;
   __u32 tx_coalesce_usecs_irq ;
   __u32 tx_max_coalesced_frames_irq ;
   __u32 stats_block_coalesce_usecs ;
   __u32 use_adaptive_rx_coalesce ;
   __u32 use_adaptive_tx_coalesce ;
   __u32 pkt_rate_low ;
   __u32 rx_coalesce_usecs_low ;
   __u32 rx_max_coalesced_frames_low ;
   __u32 tx_coalesce_usecs_low ;
   __u32 tx_max_coalesced_frames_low ;
   __u32 pkt_rate_high ;
   __u32 rx_coalesce_usecs_high ;
   __u32 rx_max_coalesced_frames_high ;
   __u32 tx_coalesce_usecs_high ;
   __u32 tx_max_coalesced_frames_high ;
   __u32 rate_sample_interval ;
};
struct ethtool_ringparam {
   __u32 cmd ;
   __u32 rx_max_pending ;
   __u32 rx_mini_max_pending ;
   __u32 rx_jumbo_max_pending ;
   __u32 tx_max_pending ;
   __u32 rx_pending ;
   __u32 rx_mini_pending ;
   __u32 rx_jumbo_pending ;
   __u32 tx_pending ;
};
struct ethtool_channels {
   __u32 cmd ;
   __u32 max_rx ;
   __u32 max_tx ;
   __u32 max_other ;
   __u32 max_combined ;
   __u32 rx_count ;
   __u32 tx_count ;
   __u32 other_count ;
   __u32 combined_count ;
};
struct ethtool_pauseparam {
   __u32 cmd ;
   __u32 autoneg ;
   __u32 rx_pause ;
   __u32 tx_pause ;
};
struct ethtool_test {
   __u32 cmd ;
   __u32 flags ;
   __u32 reserved ;
   __u32 len ;
   __u64 data[0U] ;
};
struct ethtool_stats {
   __u32 cmd ;
   __u32 n_stats ;
   __u64 data[0U] ;
};
struct ethtool_tcpip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be16 psrc ;
   __be16 pdst ;
   __u8 tos ;
};
struct ethtool_ah_espip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 spi ;
   __u8 tos ;
};
struct ethtool_usrip4_spec {
   __be32 ip4src ;
   __be32 ip4dst ;
   __be32 l4_4_bytes ;
   __u8 tos ;
   __u8 ip_ver ;
   __u8 proto ;
};
union ethtool_flow_union {
   struct ethtool_tcpip4_spec tcp_ip4_spec ;
   struct ethtool_tcpip4_spec udp_ip4_spec ;
   struct ethtool_tcpip4_spec sctp_ip4_spec ;
   struct ethtool_ah_espip4_spec ah_ip4_spec ;
   struct ethtool_ah_espip4_spec esp_ip4_spec ;
   struct ethtool_usrip4_spec usr_ip4_spec ;
   struct ethhdr ether_spec ;
   __u8 hdata[52U] ;
};
struct ethtool_flow_ext {
   __u8 padding[2U] ;
   unsigned char h_dest[6U] ;
   __be16 vlan_etype ;
   __be16 vlan_tci ;
   __be32 data[2U] ;
};
struct ethtool_rx_flow_spec {
   __u32 flow_type ;
   union ethtool_flow_union h_u ;
   struct ethtool_flow_ext h_ext ;
   union ethtool_flow_union m_u ;
   struct ethtool_flow_ext m_ext ;
   __u64 ring_cookie ;
   __u32 location ;
};
struct ethtool_rxnfc {
   __u32 cmd ;
   __u32 flow_type ;
   __u64 data ;
   struct ethtool_rx_flow_spec fs ;
   __u32 rule_cnt ;
   __u32 rule_locs[0U] ;
};
struct ethtool_flash {
   __u32 cmd ;
   __u32 region ;
   char data[128U] ;
};
struct ethtool_dump {
   __u32 cmd ;
   __u32 version ;
   __u32 flag ;
   __u32 len ;
   __u8 data[0U] ;
};
struct ethtool_ts_info {
   __u32 cmd ;
   __u32 so_timestamping ;
   __s32 phc_index ;
   __u32 tx_types ;
   __u32 tx_reserved[3U] ;
   __u32 rx_filters ;
   __u32 rx_reserved[3U] ;
};
enum ethtool_phys_id_state {
    ETHTOOL_ID_INACTIVE = 0,
    ETHTOOL_ID_ACTIVE = 1,
    ETHTOOL_ID_ON = 2,
    ETHTOOL_ID_OFF = 3
} ;
struct ethtool_ops {
   int (*get_settings)(struct net_device * , struct ethtool_cmd * ) ;
   int (*set_settings)(struct net_device * , struct ethtool_cmd * ) ;
   void (*get_drvinfo)(struct net_device * , struct ethtool_drvinfo * ) ;
   int (*get_regs_len)(struct net_device * ) ;
   void (*get_regs)(struct net_device * , struct ethtool_regs * , void * ) ;
   void (*get_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct net_device * , struct ethtool_wolinfo * ) ;
   u32 (*get_msglevel)(struct net_device * ) ;
   void (*set_msglevel)(struct net_device * , u32 ) ;
   int (*nway_reset)(struct net_device * ) ;
   u32 (*get_link)(struct net_device * ) ;
   int (*get_eeprom_len)(struct net_device * ) ;
   int (*get_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   int (*set_coalesce)(struct net_device * , struct ethtool_coalesce * ) ;
   void (*get_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   int (*set_ringparam)(struct net_device * , struct ethtool_ringparam * ) ;
   void (*get_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   int (*set_pauseparam)(struct net_device * , struct ethtool_pauseparam * ) ;
   void (*self_test)(struct net_device * , struct ethtool_test * , u64 * ) ;
   void (*get_strings)(struct net_device * , u32 , u8 * ) ;
   int (*set_phys_id)(struct net_device * , enum ethtool_phys_id_state ) ;
   void (*get_ethtool_stats)(struct net_device * , struct ethtool_stats * , u64 * ) ;
   int (*begin)(struct net_device * ) ;
   void (*complete)(struct net_device * ) ;
   u32 (*get_priv_flags)(struct net_device * ) ;
   int (*set_priv_flags)(struct net_device * , u32 ) ;
   int (*get_sset_count)(struct net_device * , int ) ;
   int (*get_rxnfc)(struct net_device * , struct ethtool_rxnfc * , u32 * ) ;
   int (*set_rxnfc)(struct net_device * , struct ethtool_rxnfc * ) ;
   int (*flash_device)(struct net_device * , struct ethtool_flash * ) ;
   int (*reset)(struct net_device * , u32 * ) ;
   u32 (*get_rxfh_key_size)(struct net_device * ) ;
   u32 (*get_rxfh_indir_size)(struct net_device * ) ;
   int (*get_rxfh)(struct net_device * , u32 * , u8 * , u8 * ) ;
   int (*set_rxfh)(struct net_device * , u32 const * , u8 const * , u8 const ) ;
   void (*get_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*set_channels)(struct net_device * , struct ethtool_channels * ) ;
   int (*get_dump_flag)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_dump_data)(struct net_device * , struct ethtool_dump * , void * ) ;
   int (*set_dump)(struct net_device * , struct ethtool_dump * ) ;
   int (*get_ts_info)(struct net_device * , struct ethtool_ts_info * ) ;
   int (*get_module_info)(struct net_device * , struct ethtool_modinfo * ) ;
   int (*get_module_eeprom)(struct net_device * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*set_eee)(struct net_device * , struct ethtool_eee * ) ;
   int (*get_tunable)(struct net_device * , struct ethtool_tunable const * , void * ) ;
   int (*set_tunable)(struct net_device * , struct ethtool_tunable const * , void const * ) ;
};
struct prot_inuse;
struct netns_core {
   struct ctl_table_header *sysctl_hdr ;
   int sysctl_somaxconn ;
   struct prot_inuse *inuse ;
};
struct u64_stats_sync {
};
struct ipstats_mib {
   u64 mibs[36U] ;
   struct u64_stats_sync syncp ;
};
struct icmp_mib {
   unsigned long mibs[28U] ;
};
struct icmpmsg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6_mib {
   unsigned long mibs[6U] ;
};
struct icmpv6_mib_device {
   atomic_long_t mibs[6U] ;
};
struct icmpv6msg_mib {
   atomic_long_t mibs[512U] ;
};
struct icmpv6msg_mib_device {
   atomic_long_t mibs[512U] ;
};
struct tcp_mib {
   unsigned long mibs[16U] ;
};
struct udp_mib {
   unsigned long mibs[9U] ;
};
struct linux_mib {
   unsigned long mibs[115U] ;
};
struct linux_xfrm_mib {
   unsigned long mibs[29U] ;
};
struct proc_dir_entry;
struct netns_mib {
   struct tcp_mib *tcp_statistics ;
   struct ipstats_mib *ip_statistics ;
   struct linux_mib *net_statistics ;
   struct udp_mib *udp_statistics ;
   struct udp_mib *udplite_statistics ;
   struct icmp_mib *icmp_statistics ;
   struct icmpmsg_mib *icmpmsg_statistics ;
   struct proc_dir_entry *proc_net_devsnmp6 ;
   struct udp_mib *udp_stats_in6 ;
   struct udp_mib *udplite_stats_in6 ;
   struct ipstats_mib *ipv6_statistics ;
   struct icmpv6_mib *icmpv6_statistics ;
   struct icmpv6msg_mib *icmpv6msg_statistics ;
   struct linux_xfrm_mib *xfrm_statistics ;
};
struct netns_unix {
   int sysctl_max_dgram_qlen ;
   struct ctl_table_header *ctl ;
};
struct netns_packet {
   struct mutex sklist_lock ;
   struct hlist_head sklist ;
};
struct netns_frags {
   struct percpu_counter mem ;
   int timeout ;
   int high_thresh ;
   int low_thresh ;
};
struct ipv4_devconf;
struct fib_rules_ops;
struct fib_table;
struct local_ports {
   seqlock_t lock ;
   int range[2U] ;
   bool warned ;
};
struct ping_group_range {
   seqlock_t lock ;
   kgid_t range[2U] ;
};
struct inet_peer_base;
struct xt_table;
struct netns_ipv4 {
   struct ctl_table_header *forw_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *ipv4_hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *xfrm4_hdr ;
   struct ipv4_devconf *devconf_all ;
   struct ipv4_devconf *devconf_dflt ;
   struct fib_rules_ops *rules_ops ;
   bool fib_has_custom_rules ;
   struct fib_table *fib_local ;
   struct fib_table *fib_main ;
   struct fib_table *fib_default ;
   int fib_num_tclassid_users ;
   struct hlist_head *fib_table_hash ;
   bool fib_offload_disabled ;
   struct sock *fibnl ;
   struct sock **icmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct inet_peer_base *peers ;
   struct sock **tcp_sk ;
   struct netns_frags frags ;
   struct xt_table *iptable_filter ;
   struct xt_table *iptable_mangle ;
   struct xt_table *iptable_raw ;
   struct xt_table *arptable_filter ;
   struct xt_table *iptable_security ;
   struct xt_table *nat_table ;
   int sysctl_icmp_echo_ignore_all ;
   int sysctl_icmp_echo_ignore_broadcasts ;
   int sysctl_icmp_ignore_bogus_error_responses ;
   int sysctl_icmp_ratelimit ;
   int sysctl_icmp_ratemask ;
   int sysctl_icmp_errors_use_inbound_ifaddr ;
   struct local_ports ip_local_ports ;
   int sysctl_tcp_ecn ;
   int sysctl_tcp_ecn_fallback ;
   int sysctl_ip_no_pmtu_disc ;
   int sysctl_ip_fwd_use_pmtu ;
   int sysctl_ip_nonlocal_bind ;
   int sysctl_fwmark_reflect ;
   int sysctl_tcp_fwmark_accept ;
   int sysctl_tcp_mtu_probing ;
   int sysctl_tcp_base_mss ;
   int sysctl_tcp_probe_threshold ;
   u32 sysctl_tcp_probe_interval ;
   struct ping_group_range ping_group_range ;
   atomic_t dev_addr_genid ;
   unsigned long *sysctl_local_reserved_ports ;
   struct list_head mr_tables ;
   struct fib_rules_ops *mr_rules_ops ;
   atomic_t rt_genid ;
};
struct neighbour;
struct dst_ops {
   unsigned short family ;
   unsigned int gc_thresh ;
   int (*gc)(struct dst_ops * ) ;
   struct dst_entry *(*check)(struct dst_entry * , __u32 ) ;
   unsigned int (*default_advmss)(struct dst_entry const * ) ;
   unsigned int (*mtu)(struct dst_entry const * ) ;
   u32 *(*cow_metrics)(struct dst_entry * , unsigned long ) ;
   void (*destroy)(struct dst_entry * ) ;
   void (*ifdown)(struct dst_entry * , struct net_device * , int ) ;
   struct dst_entry *(*negative_advice)(struct dst_entry * ) ;
   void (*link_failure)(struct sk_buff * ) ;
   void (*update_pmtu)(struct dst_entry * , struct sock * , struct sk_buff * , u32 ) ;
   void (*redirect)(struct dst_entry * , struct sock * , struct sk_buff * ) ;
   int (*local_out)(struct sk_buff * ) ;
   struct neighbour *(*neigh_lookup)(struct dst_entry const * , struct sk_buff * ,
                                     void const * ) ;
   struct kmem_cache *kmem_cachep ;
   struct percpu_counter pcpuc_entries ;
};
struct netns_sysctl_ipv6 {
   struct ctl_table_header *hdr ;
   struct ctl_table_header *route_hdr ;
   struct ctl_table_header *icmp_hdr ;
   struct ctl_table_header *frags_hdr ;
   struct ctl_table_header *xfrm6_hdr ;
   int bindv6only ;
   int flush_delay ;
   int ip6_rt_max_size ;
   int ip6_rt_gc_min_interval ;
   int ip6_rt_gc_timeout ;
   int ip6_rt_gc_interval ;
   int ip6_rt_gc_elasticity ;
   int ip6_rt_mtu_expires ;
   int ip6_rt_min_advmss ;
   int flowlabel_consistency ;
   int auto_flowlabels ;
   int icmpv6_time ;
   int anycast_src_echo_reply ;
   int fwmark_reflect ;
   int idgen_retries ;
   int idgen_delay ;
   int flowlabel_state_ranges ;
};
struct ipv6_devconf;
struct rt6_info;
struct rt6_statistics;
struct fib6_table;
struct netns_ipv6 {
   struct netns_sysctl_ipv6 sysctl ;
   struct ipv6_devconf *devconf_all ;
   struct ipv6_devconf *devconf_dflt ;
   struct inet_peer_base *peers ;
   struct netns_frags frags ;
   struct xt_table *ip6table_filter ;
   struct xt_table *ip6table_mangle ;
   struct xt_table *ip6table_raw ;
   struct xt_table *ip6table_security ;
   struct xt_table *ip6table_nat ;
   struct rt6_info *ip6_null_entry ;
   struct rt6_statistics *rt6_stats ;
   struct timer_list ip6_fib_timer ;
   struct hlist_head *fib_table_hash ;
   struct fib6_table *fib6_main_tbl ;
   struct dst_ops ip6_dst_ops ;
   unsigned int ip6_rt_gc_expire ;
   unsigned long ip6_rt_last_gc ;
   struct rt6_info *ip6_prohibit_entry ;
   struct rt6_info *ip6_blk_hole_entry ;
   struct fib6_table *fib6_local_tbl ;
   struct fib_rules_ops *fib6_rules_ops ;
   struct sock **icmp_sk ;
   struct sock *ndisc_sk ;
   struct sock *tcp_sk ;
   struct sock *igmp_sk ;
   struct sock *mc_autojoin_sk ;
   struct list_head mr6_tables ;
   struct fib_rules_ops *mr6_rules_ops ;
   atomic_t dev_addr_genid ;
   atomic_t fib6_sernum ;
};
struct netns_nf_frag {
   struct netns_sysctl_ipv6 sysctl ;
   struct netns_frags frags ;
};
struct netns_sysctl_lowpan {
   struct ctl_table_header *frags_hdr ;
};
struct netns_ieee802154_lowpan {
   struct netns_sysctl_lowpan sysctl ;
   struct netns_frags frags ;
};
struct sctp_mib;
struct netns_sctp {
   struct sctp_mib *sctp_statistics ;
   struct proc_dir_entry *proc_net_sctp ;
   struct ctl_table_header *sysctl_header ;
   struct sock *ctl_sock ;
   struct list_head local_addr_list ;
   struct list_head addr_waitq ;
   struct timer_list addr_wq_timer ;
   struct list_head auto_asconf_splist ;
   spinlock_t addr_wq_lock ;
   spinlock_t local_addr_lock ;
   unsigned int rto_initial ;
   unsigned int rto_min ;
   unsigned int rto_max ;
   int rto_alpha ;
   int rto_beta ;
   int max_burst ;
   int cookie_preserve_enable ;
   char *sctp_hmac_alg ;
   unsigned int valid_cookie_life ;
   unsigned int sack_timeout ;
   unsigned int hb_interval ;
   int max_retrans_association ;
   int max_retrans_path ;
   int max_retrans_init ;
   int pf_retrans ;
   int sndbuf_policy ;
   int rcvbuf_policy ;
   int default_auto_asconf ;
   int addip_enable ;
   int addip_noauth ;
   int prsctp_enable ;
   int auth_enable ;
   int scope_policy ;
   int rwnd_upd_shift ;
   unsigned long max_autoclose ;
};
struct netns_dccp {
   struct sock *v4_ctl_sk ;
   struct sock *v6_ctl_sk ;
};
struct nf_logger;
struct netns_nf {
   struct proc_dir_entry *proc_netfilter ;
   struct nf_logger const *nf_loggers[13U] ;
   struct ctl_table_header *nf_log_dir_header ;
};
struct ebt_table;
struct netns_xt {
   struct list_head tables[13U] ;
   bool notrack_deprecated_warning ;
   bool clusterip_deprecated_warning ;
   struct ebt_table *broute_table ;
   struct ebt_table *frame_filter ;
   struct ebt_table *frame_nat ;
};
struct hlist_nulls_node;
struct hlist_nulls_head {
   struct hlist_nulls_node *first ;
};
struct hlist_nulls_node {
   struct hlist_nulls_node *next ;
   struct hlist_nulls_node **pprev ;
};
struct nf_proto_net {
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
   struct ctl_table_header *ctl_compat_header ;
   struct ctl_table *ctl_compat_table ;
   unsigned int users ;
};
struct nf_generic_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_tcp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[14U] ;
   unsigned int tcp_loose ;
   unsigned int tcp_be_liberal ;
   unsigned int tcp_max_retrans ;
};
struct nf_udp_net {
   struct nf_proto_net pn ;
   unsigned int timeouts[2U] ;
};
struct nf_icmp_net {
   struct nf_proto_net pn ;
   unsigned int timeout ;
};
struct nf_ip_net {
   struct nf_generic_net generic ;
   struct nf_tcp_net tcp ;
   struct nf_udp_net udp ;
   struct nf_icmp_net icmp ;
   struct nf_icmp_net icmpv6 ;
   struct ctl_table_header *ctl_table_header ;
   struct ctl_table *ctl_table ;
};
struct ct_pcpu {
   spinlock_t lock ;
   struct hlist_nulls_head unconfirmed ;
   struct hlist_nulls_head dying ;
   struct hlist_nulls_head tmpl ;
};
struct ip_conntrack_stat;
struct nf_ct_event_notifier;
struct nf_exp_event_notifier;
struct netns_ct {
   atomic_t count ;
   unsigned int expect_count ;
   struct delayed_work ecache_dwork ;
   bool ecache_dwork_pending ;
   struct ctl_table_header *sysctl_header ;
   struct ctl_table_header *acct_sysctl_header ;
   struct ctl_table_header *tstamp_sysctl_header ;
   struct ctl_table_header *event_sysctl_header ;
   struct ctl_table_header *helper_sysctl_header ;
   char *slabname ;
   unsigned int sysctl_log_invalid ;
   int sysctl_events ;
   int sysctl_acct ;
   int sysctl_auto_assign_helper ;
   bool auto_assign_helper_warned ;
   int sysctl_tstamp ;
   int sysctl_checksum ;
   unsigned int htable_size ;
   seqcount_t generation ;
   struct kmem_cache *nf_conntrack_cachep ;
   struct hlist_nulls_head *hash ;
   struct hlist_head *expect_hash ;
   struct ct_pcpu *pcpu_lists ;
   struct ip_conntrack_stat *stat ;
   struct nf_ct_event_notifier *nf_conntrack_event_cb ;
   struct nf_exp_event_notifier *nf_expect_event_cb ;
   struct nf_ip_net nf_ct_proto ;
   unsigned int labels_used ;
   u8 label_words ;
   struct hlist_head *nat_bysource ;
   unsigned int nat_htable_size ;
};
struct nft_af_info;
struct netns_nftables {
   struct list_head af_info ;
   struct list_head commit_list ;
   struct nft_af_info *ipv4 ;
   struct nft_af_info *ipv6 ;
   struct nft_af_info *inet ;
   struct nft_af_info *arp ;
   struct nft_af_info *bridge ;
   struct nft_af_info *netdev ;
   unsigned int base_seq ;
   u8 gencursor ;
};
struct tasklet_struct {
   struct tasklet_struct *next ;
   unsigned long state ;
   atomic_t count ;
   void (*func)(unsigned long ) ;
   unsigned long data ;
};
struct flow_cache_percpu {
   struct hlist_head *hash_table ;
   int hash_count ;
   u32 hash_rnd ;
   int hash_rnd_recalc ;
   struct tasklet_struct flush_tasklet ;
};
struct flow_cache {
   u32 hash_shift ;
   struct flow_cache_percpu *percpu ;
   struct notifier_block hotcpu_notifier ;
   int low_watermark ;
   int high_watermark ;
   struct timer_list rnd_timer ;
};
struct xfrm_policy_hash {
   struct hlist_head *table ;
   unsigned int hmask ;
   u8 dbits4 ;
   u8 sbits4 ;
   u8 dbits6 ;
   u8 sbits6 ;
};
struct xfrm_policy_hthresh {
   struct work_struct work ;
   seqlock_t lock ;
   u8 lbits4 ;
   u8 rbits4 ;
   u8 lbits6 ;
   u8 rbits6 ;
};
struct netns_xfrm {
   struct list_head state_all ;
   struct hlist_head *state_bydst ;
   struct hlist_head *state_bysrc ;
   struct hlist_head *state_byspi ;
   unsigned int state_hmask ;
   unsigned int state_num ;
   struct work_struct state_hash_work ;
   struct hlist_head state_gc_list ;
   struct work_struct state_gc_work ;
   struct list_head policy_all ;
   struct hlist_head *policy_byidx ;
   unsigned int policy_idx_hmask ;
   struct hlist_head policy_inexact[3U] ;
   struct xfrm_policy_hash policy_bydst[3U] ;
   unsigned int policy_count[6U] ;
   struct work_struct policy_hash_work ;
   struct xfrm_policy_hthresh policy_hthresh ;
   struct sock *nlsk ;
   struct sock *nlsk_stash ;
   u32 sysctl_aevent_etime ;
   u32 sysctl_aevent_rseqth ;
   int sysctl_larval_drop ;
   u32 sysctl_acq_expires ;
   struct ctl_table_header *sysctl_hdr ;
   struct dst_ops xfrm4_dst_ops ;
   struct dst_ops xfrm6_dst_ops ;
   spinlock_t xfrm_state_lock ;
   rwlock_t xfrm_policy_lock ;
   struct mutex xfrm_cfg_mutex ;
   struct flow_cache flow_cache_global ;
   atomic_t flow_cache_genid ;
   struct list_head flow_cache_gc_list ;
   spinlock_t flow_cache_gc_lock ;
   struct work_struct flow_cache_gc_work ;
   struct work_struct flow_cache_flush_work ;
   struct mutex flow_flush_sem ;
};
struct mpls_route;
struct netns_mpls {
   size_t platform_labels ;
   struct mpls_route **platform_label ;
   struct ctl_table_header *ctl ;
};
struct proc_ns_operations;
struct ns_common {
   atomic_long_t stashed ;
   struct proc_ns_operations const *ops ;
   unsigned int inum ;
};
struct net_generic;
struct netns_ipvs;
struct net {
   atomic_t passive ;
   atomic_t count ;
   spinlock_t rules_mod_lock ;
   atomic64_t cookie_gen ;
   struct list_head list ;
   struct list_head cleanup_list ;
   struct list_head exit_list ;
   struct user_namespace *user_ns ;
   spinlock_t nsid_lock ;
   struct idr netns_ids ;
   struct ns_common ns ;
   struct proc_dir_entry *proc_net ;
   struct proc_dir_entry *proc_net_stat ;
   struct ctl_table_set sysctls ;
   struct sock *rtnl ;
   struct sock *genl_sock ;
   struct list_head dev_base_head ;
   struct hlist_head *dev_name_head ;
   struct hlist_head *dev_index_head ;
   unsigned int dev_base_seq ;
   int ifindex ;
   unsigned int dev_unreg_count ;
   struct list_head rules_ops ;
   struct net_device *loopback_dev ;
   struct netns_core core ;
   struct netns_mib mib ;
   struct netns_packet packet ;
   struct netns_unix unx ;
   struct netns_ipv4 ipv4 ;
   struct netns_ipv6 ipv6 ;
   struct netns_ieee802154_lowpan ieee802154_lowpan ;
   struct netns_sctp sctp ;
   struct netns_dccp dccp ;
   struct netns_nf nf ;
   struct netns_xt xt ;
   struct netns_ct ct ;
   struct netns_nftables nft ;
   struct netns_nf_frag nf_frag ;
   struct sock *nfnl ;
   struct sock *nfnl_stash ;
   struct sk_buff_head wext_nlevents ;
   struct net_generic *gen ;
   struct netns_xfrm xfrm ;
   struct netns_ipvs *ipvs ;
   struct netns_mpls mpls ;
   struct sock *diag_nlsk ;
   atomic_t fnhe_genid ;
};
struct __anonstruct_possible_net_t_302 {
   struct net *net ;
};
typedef struct __anonstruct_possible_net_t_302 possible_net_t;
typedef unsigned long kernel_ulong_t;
struct pci_device_id {
   __u32 vendor ;
   __u32 device ;
   __u32 subvendor ;
   __u32 subdevice ;
   __u32 class ;
   __u32 class_mask ;
   kernel_ulong_t driver_data ;
};
struct acpi_device_id {
   __u8 id[9U] ;
   kernel_ulong_t driver_data ;
};
struct of_device_id {
   char name[32U] ;
   char type[32U] ;
   char compatible[128U] ;
   void const *data ;
};
enum fwnode_type {
    FWNODE_INVALID = 0,
    FWNODE_OF = 1,
    FWNODE_ACPI = 2,
    FWNODE_PDATA = 3
} ;
struct fwnode_handle {
   enum fwnode_type type ;
   struct fwnode_handle *secondary ;
};
typedef u32 phandle;
struct property {
   char *name ;
   int length ;
   void *value ;
   struct property *next ;
   unsigned long _flags ;
   unsigned int unique_id ;
   struct bin_attribute attr ;
};
struct device_node {
   char const *name ;
   char const *type ;
   phandle phandle ;
   char const *full_name ;
   struct fwnode_handle fwnode ;
   struct property *properties ;
   struct property *deadprops ;
   struct device_node *parent ;
   struct device_node *child ;
   struct device_node *sibling ;
   struct kobject kobj ;
   unsigned long _flags ;
   void *data ;
};
enum ldv_27995 {
    PHY_INTERFACE_MODE_NA = 0,
    PHY_INTERFACE_MODE_MII = 1,
    PHY_INTERFACE_MODE_GMII = 2,
    PHY_INTERFACE_MODE_SGMII = 3,
    PHY_INTERFACE_MODE_TBI = 4,
    PHY_INTERFACE_MODE_REVMII = 5,
    PHY_INTERFACE_MODE_RMII = 6,
    PHY_INTERFACE_MODE_RGMII = 7,
    PHY_INTERFACE_MODE_RGMII_ID = 8,
    PHY_INTERFACE_MODE_RGMII_RXID = 9,
    PHY_INTERFACE_MODE_RGMII_TXID = 10,
    PHY_INTERFACE_MODE_RTBI = 11,
    PHY_INTERFACE_MODE_SMII = 12,
    PHY_INTERFACE_MODE_XGMII = 13,
    PHY_INTERFACE_MODE_MOCA = 14,
    PHY_INTERFACE_MODE_QSGMII = 15,
    PHY_INTERFACE_MODE_MAX = 16
} ;
typedef enum ldv_27995 phy_interface_t;
enum ldv_28049 {
    MDIOBUS_ALLOCATED = 1,
    MDIOBUS_REGISTERED = 2,
    MDIOBUS_UNREGISTERED = 3,
    MDIOBUS_RELEASED = 4
} ;
struct phy_device;
struct mii_bus {
   char const *name ;
   char id[17U] ;
   void *priv ;
   int (*read)(struct mii_bus * , int , int ) ;
   int (*write)(struct mii_bus * , int , int , u16 ) ;
   int (*reset)(struct mii_bus * ) ;
   struct mutex mdio_lock ;
   struct device *parent ;
   enum ldv_28049 state ;
   struct device dev ;
   struct phy_device *phy_map[32U] ;
   u32 phy_mask ;
   u32 phy_ignore_ta_mask ;
   int *irq ;
};
enum phy_state {
    PHY_DOWN = 0,
    PHY_STARTING = 1,
    PHY_READY = 2,
    PHY_PENDING = 3,
    PHY_UP = 4,
    PHY_AN = 5,
    PHY_RUNNING = 6,
    PHY_NOLINK = 7,
    PHY_FORCING = 8,
    PHY_CHANGELINK = 9,
    PHY_HALTED = 10,
    PHY_RESUMING = 11
} ;
struct phy_c45_device_ids {
   u32 devices_in_package ;
   u32 device_ids[8U] ;
};
struct phy_driver;
struct phy_device {
   struct phy_driver *drv ;
   struct mii_bus *bus ;
   struct device dev ;
   u32 phy_id ;
   struct phy_c45_device_ids c45_ids ;
   bool is_c45 ;
   bool is_internal ;
   bool has_fixups ;
   bool suspended ;
   enum phy_state state ;
   u32 dev_flags ;
   phy_interface_t interface ;
   int addr ;
   int speed ;
   int duplex ;
   int pause ;
   int asym_pause ;
   int link ;
   u32 interrupts ;
   u32 supported ;
   u32 advertising ;
   u32 lp_advertising ;
   int autoneg ;
   int link_timeout ;
   int irq ;
   void *priv ;
   struct work_struct phy_queue ;
   struct delayed_work state_queue ;
   atomic_t irq_disable ;
   struct mutex lock ;
   struct net_device *attached_dev ;
   void (*adjust_link)(struct net_device * ) ;
};
struct phy_driver {
   u32 phy_id ;
   char *name ;
   unsigned int phy_id_mask ;
   u32 features ;
   u32 flags ;
   void const *driver_data ;
   int (*soft_reset)(struct phy_device * ) ;
   int (*config_init)(struct phy_device * ) ;
   int (*probe)(struct phy_device * ) ;
   int (*suspend)(struct phy_device * ) ;
   int (*resume)(struct phy_device * ) ;
   int (*config_aneg)(struct phy_device * ) ;
   int (*aneg_done)(struct phy_device * ) ;
   int (*read_status)(struct phy_device * ) ;
   int (*ack_interrupt)(struct phy_device * ) ;
   int (*config_intr)(struct phy_device * ) ;
   int (*did_interrupt)(struct phy_device * ) ;
   void (*remove)(struct phy_device * ) ;
   int (*match_phy_device)(struct phy_device * ) ;
   int (*ts_info)(struct phy_device * , struct ethtool_ts_info * ) ;
   int (*hwtstamp)(struct phy_device * , struct ifreq * ) ;
   bool (*rxtstamp)(struct phy_device * , struct sk_buff * , int ) ;
   void (*txtstamp)(struct phy_device * , struct sk_buff * , int ) ;
   int (*set_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*get_wol)(struct phy_device * , struct ethtool_wolinfo * ) ;
   void (*link_change_notify)(struct phy_device * ) ;
   int (*read_mmd_indirect)(struct phy_device * , int , int , int ) ;
   void (*write_mmd_indirect)(struct phy_device * , int , int , int , u32 ) ;
   int (*module_info)(struct phy_device * , struct ethtool_modinfo * ) ;
   int (*module_eeprom)(struct phy_device * , struct ethtool_eeprom * , u8 * ) ;
   struct device_driver driver ;
};
struct fixed_phy_status {
   int link ;
   int speed ;
   int duplex ;
   int pause ;
   int asym_pause ;
};
enum dsa_tag_protocol {
    DSA_TAG_PROTO_NONE = 0,
    DSA_TAG_PROTO_DSA = 1,
    DSA_TAG_PROTO_TRAILER = 2,
    DSA_TAG_PROTO_EDSA = 3,
    DSA_TAG_PROTO_BRCM = 4
} ;
struct dsa_chip_data {
   struct device *host_dev ;
   int sw_addr ;
   int eeprom_len ;
   struct device_node *of_node ;
   char *port_names[12U] ;
   struct device_node *port_dn[12U] ;
   s8 *rtable ;
};
struct dsa_platform_data {
   struct device *netdev ;
   struct net_device *of_netdev ;
   int nr_chips ;
   struct dsa_chip_data *chip ;
};
struct packet_type;
struct dsa_switch;
struct dsa_switch_tree {
   struct dsa_platform_data *pd ;
   struct net_device *master_netdev ;
   int (*rcv)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   enum dsa_tag_protocol tag_protocol ;
   s8 cpu_switch ;
   s8 cpu_port ;
   int link_poll_needed ;
   struct work_struct link_poll_work ;
   struct timer_list link_poll_timer ;
   struct dsa_switch *ds[4U] ;
};
struct dsa_switch_driver;
struct dsa_switch {
   struct dsa_switch_tree *dst ;
   int index ;
   enum dsa_tag_protocol tag_protocol ;
   struct dsa_chip_data *pd ;
   struct dsa_switch_driver *drv ;
   struct device *master_dev ;
   char hwmon_name[24U] ;
   struct device *hwmon_dev ;
   u32 dsa_port_mask ;
   u32 phys_port_mask ;
   u32 phys_mii_mask ;
   struct mii_bus *slave_mii_bus ;
   struct net_device *ports[12U] ;
};
struct dsa_switch_driver {
   struct list_head list ;
   enum dsa_tag_protocol tag_protocol ;
   int priv_size ;
   char *(*probe)(struct device * , int ) ;
   int (*setup)(struct dsa_switch * ) ;
   int (*set_addr)(struct dsa_switch * , u8 * ) ;
   u32 (*get_phy_flags)(struct dsa_switch * , int ) ;
   int (*phy_read)(struct dsa_switch * , int , int ) ;
   int (*phy_write)(struct dsa_switch * , int , int , u16 ) ;
   void (*poll_link)(struct dsa_switch * ) ;
   void (*adjust_link)(struct dsa_switch * , int , struct phy_device * ) ;
   void (*fixed_link_update)(struct dsa_switch * , int , struct fixed_phy_status * ) ;
   void (*get_strings)(struct dsa_switch * , int , uint8_t * ) ;
   void (*get_ethtool_stats)(struct dsa_switch * , int , uint64_t * ) ;
   int (*get_sset_count)(struct dsa_switch * ) ;
   void (*get_wol)(struct dsa_switch * , int , struct ethtool_wolinfo * ) ;
   int (*set_wol)(struct dsa_switch * , int , struct ethtool_wolinfo * ) ;
   int (*suspend)(struct dsa_switch * ) ;
   int (*resume)(struct dsa_switch * ) ;
   int (*port_enable)(struct dsa_switch * , int , struct phy_device * ) ;
   void (*port_disable)(struct dsa_switch * , int , struct phy_device * ) ;
   int (*set_eee)(struct dsa_switch * , int , struct phy_device * , struct ethtool_eee * ) ;
   int (*get_eee)(struct dsa_switch * , int , struct ethtool_eee * ) ;
   int (*get_temp)(struct dsa_switch * , int * ) ;
   int (*get_temp_limit)(struct dsa_switch * , int * ) ;
   int (*set_temp_limit)(struct dsa_switch * , int ) ;
   int (*get_temp_alarm)(struct dsa_switch * , bool * ) ;
   int (*get_eeprom_len)(struct dsa_switch * ) ;
   int (*get_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*set_eeprom)(struct dsa_switch * , struct ethtool_eeprom * , u8 * ) ;
   int (*get_regs_len)(struct dsa_switch * , int ) ;
   void (*get_regs)(struct dsa_switch * , int , struct ethtool_regs * , void * ) ;
   int (*port_join_bridge)(struct dsa_switch * , int , u32 ) ;
   int (*port_leave_bridge)(struct dsa_switch * , int , u32 ) ;
   int (*port_stp_update)(struct dsa_switch * , int , u8 ) ;
   int (*fdb_add)(struct dsa_switch * , int , unsigned char const * , u16 ) ;
   int (*fdb_del)(struct dsa_switch * , int , unsigned char const * , u16 ) ;
   int (*fdb_getnext)(struct dsa_switch * , int , unsigned char * , bool * ) ;
};
struct ieee_ets {
   __u8 willing ;
   __u8 ets_cap ;
   __u8 cbs ;
   __u8 tc_tx_bw[8U] ;
   __u8 tc_rx_bw[8U] ;
   __u8 tc_tsa[8U] ;
   __u8 prio_tc[8U] ;
   __u8 tc_reco_bw[8U] ;
   __u8 tc_reco_tsa[8U] ;
   __u8 reco_prio_tc[8U] ;
};
struct ieee_maxrate {
   __u64 tc_maxrate[8U] ;
};
struct ieee_qcn {
   __u8 rpg_enable[8U] ;
   __u32 rppp_max_rps[8U] ;
   __u32 rpg_time_reset[8U] ;
   __u32 rpg_byte_reset[8U] ;
   __u32 rpg_threshold[8U] ;
   __u32 rpg_max_rate[8U] ;
   __u32 rpg_ai_rate[8U] ;
   __u32 rpg_hai_rate[8U] ;
   __u32 rpg_gd[8U] ;
   __u32 rpg_min_dec_fac[8U] ;
   __u32 rpg_min_rate[8U] ;
   __u32 cndd_state_machine[8U] ;
};
struct ieee_qcn_stats {
   __u64 rppp_rp_centiseconds[8U] ;
   __u32 rppp_created_rps[8U] ;
};
struct ieee_pfc {
   __u8 pfc_cap ;
   __u8 pfc_en ;
   __u8 mbc ;
   __u16 delay ;
   __u64 requests[8U] ;
   __u64 indications[8U] ;
};
struct cee_pg {
   __u8 willing ;
   __u8 error ;
   __u8 pg_en ;
   __u8 tcs_supported ;
   __u8 pg_bw[8U] ;
   __u8 prio_pg[8U] ;
};
struct cee_pfc {
   __u8 willing ;
   __u8 error ;
   __u8 pfc_en ;
   __u8 tcs_supported ;
};
struct dcb_app {
   __u8 selector ;
   __u8 priority ;
   __u16 protocol ;
};
struct dcb_peer_app_info {
   __u8 willing ;
   __u8 error ;
};
struct dcbnl_rtnl_ops {
   int (*ieee_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_setets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_getmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_setmaxrate)(struct net_device * , struct ieee_maxrate * ) ;
   int (*ieee_getqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_setqcn)(struct net_device * , struct ieee_qcn * ) ;
   int (*ieee_getqcnstats)(struct net_device * , struct ieee_qcn_stats * ) ;
   int (*ieee_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_setpfc)(struct net_device * , struct ieee_pfc * ) ;
   int (*ieee_getapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_setapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_delapp)(struct net_device * , struct dcb_app * ) ;
   int (*ieee_peer_getets)(struct net_device * , struct ieee_ets * ) ;
   int (*ieee_peer_getpfc)(struct net_device * , struct ieee_pfc * ) ;
   u8 (*getstate)(struct net_device * ) ;
   u8 (*setstate)(struct net_device * , u8 ) ;
   void (*getpermhwaddr)(struct net_device * , u8 * ) ;
   void (*setpgtccfgtx)(struct net_device * , int , u8 , u8 , u8 , u8 ) ;
   void (*setpgbwgcfgtx)(struct net_device * , int , u8 ) ;
   void (*setpgtccfgrx)(struct net_device * , int , u8 , u8 , u8 , u8 ) ;
   void (*setpgbwgcfgrx)(struct net_device * , int , u8 ) ;
   void (*getpgtccfgtx)(struct net_device * , int , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgtx)(struct net_device * , int , u8 * ) ;
   void (*getpgtccfgrx)(struct net_device * , int , u8 * , u8 * , u8 * , u8 * ) ;
   void (*getpgbwgcfgrx)(struct net_device * , int , u8 * ) ;
   void (*setpfccfg)(struct net_device * , int , u8 ) ;
   void (*getpfccfg)(struct net_device * , int , u8 * ) ;
   u8 (*setall)(struct net_device * ) ;
   u8 (*getcap)(struct net_device * , int , u8 * ) ;
   int (*getnumtcs)(struct net_device * , int , u8 * ) ;
   int (*setnumtcs)(struct net_device * , int , u8 ) ;
   u8 (*getpfcstate)(struct net_device * ) ;
   void (*setpfcstate)(struct net_device * , u8 ) ;
   void (*getbcncfg)(struct net_device * , int , u32 * ) ;
   void (*setbcncfg)(struct net_device * , int , u32 ) ;
   void (*getbcnrp)(struct net_device * , int , u8 * ) ;
   void (*setbcnrp)(struct net_device * , int , u8 ) ;
   int (*setapp)(struct net_device * , u8 , u16 , u8 ) ;
   int (*getapp)(struct net_device * , u8 , u16 ) ;
   u8 (*getfeatcfg)(struct net_device * , int , u8 * ) ;
   u8 (*setfeatcfg)(struct net_device * , int , u8 ) ;
   u8 (*getdcbx)(struct net_device * ) ;
   u8 (*setdcbx)(struct net_device * , u8 ) ;
   int (*peer_getappinfo)(struct net_device * , struct dcb_peer_app_info * , u16 * ) ;
   int (*peer_getapptable)(struct net_device * , struct dcb_app * ) ;
   int (*cee_peer_getpg)(struct net_device * , struct cee_pg * ) ;
   int (*cee_peer_getpfc)(struct net_device * , struct cee_pfc * ) ;
};
struct taskstats {
   __u16 version ;
   __u32 ac_exitcode ;
   __u8 ac_flag ;
   __u8 ac_nice ;
   __u64 cpu_count ;
   __u64 cpu_delay_total ;
   __u64 blkio_count ;
   __u64 blkio_delay_total ;
   __u64 swapin_count ;
   __u64 swapin_delay_total ;
   __u64 cpu_run_real_total ;
   __u64 cpu_run_virtual_total ;
   char ac_comm[32U] ;
   __u8 ac_sched ;
   __u8 ac_pad[3U] ;
   __u32 ac_uid ;
   __u32 ac_gid ;
   __u32 ac_pid ;
   __u32 ac_ppid ;
   __u32 ac_btime ;
   __u64 ac_etime ;
   __u64 ac_utime ;
   __u64 ac_stime ;
   __u64 ac_minflt ;
   __u64 ac_majflt ;
   __u64 coremem ;
   __u64 virtmem ;
   __u64 hiwater_rss ;
   __u64 hiwater_vm ;
   __u64 read_char ;
   __u64 write_char ;
   __u64 read_syscalls ;
   __u64 write_syscalls ;
   __u64 read_bytes ;
   __u64 write_bytes ;
   __u64 cancelled_write_bytes ;
   __u64 nvcsw ;
   __u64 nivcsw ;
   __u64 ac_utimescaled ;
   __u64 ac_stimescaled ;
   __u64 cpu_scaled_run_real_total ;
   __u64 freepages_count ;
   __u64 freepages_delay_total ;
};
struct netprio_map {
   struct callback_head rcu ;
   u32 priomap_len ;
   u32 priomap[] ;
};
struct xfrm_policy;
struct xfrm_state;
struct request_sock;
struct mnt_namespace;
struct ipc_namespace;
struct nsproxy {
   atomic_t count ;
   struct uts_namespace *uts_ns ;
   struct ipc_namespace *ipc_ns ;
   struct mnt_namespace *mnt_ns ;
   struct pid_namespace *pid_ns_for_children ;
   struct net *net_ns ;
};
struct nlmsghdr {
   __u32 nlmsg_len ;
   __u16 nlmsg_type ;
   __u16 nlmsg_flags ;
   __u32 nlmsg_seq ;
   __u32 nlmsg_pid ;
};
struct nlattr {
   __u16 nla_len ;
   __u16 nla_type ;
};
struct netlink_callback {
   struct sk_buff *skb ;
   struct nlmsghdr const *nlh ;
   int (*dump)(struct sk_buff * , struct netlink_callback * ) ;
   int (*done)(struct netlink_callback * ) ;
   void *data ;
   struct module *module ;
   u16 family ;
   u16 min_dump_alloc ;
   unsigned int prev_seq ;
   unsigned int seq ;
   long args[6U] ;
};
struct ndmsg {
   __u8 ndm_family ;
   __u8 ndm_pad1 ;
   __u16 ndm_pad2 ;
   __s32 ndm_ifindex ;
   __u16 ndm_state ;
   __u8 ndm_flags ;
   __u8 ndm_type ;
};
struct rtnl_link_stats64 {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 rx_errors ;
   __u64 tx_errors ;
   __u64 rx_dropped ;
   __u64 tx_dropped ;
   __u64 multicast ;
   __u64 collisions ;
   __u64 rx_length_errors ;
   __u64 rx_over_errors ;
   __u64 rx_crc_errors ;
   __u64 rx_frame_errors ;
   __u64 rx_fifo_errors ;
   __u64 rx_missed_errors ;
   __u64 tx_aborted_errors ;
   __u64 tx_carrier_errors ;
   __u64 tx_fifo_errors ;
   __u64 tx_heartbeat_errors ;
   __u64 tx_window_errors ;
   __u64 rx_compressed ;
   __u64 tx_compressed ;
};
struct ifla_vf_stats {
   __u64 rx_packets ;
   __u64 tx_packets ;
   __u64 rx_bytes ;
   __u64 tx_bytes ;
   __u64 broadcast ;
   __u64 multicast ;
};
struct ifla_vf_info {
   __u32 vf ;
   __u8 mac[32U] ;
   __u32 vlan ;
   __u32 qos ;
   __u32 spoofchk ;
   __u32 linkstate ;
   __u32 min_tx_rate ;
   __u32 max_tx_rate ;
   __u32 rss_query_en ;
};
struct netpoll_info;
struct wireless_dev;
struct wpan_dev;
struct mpls_dev;
enum netdev_tx {
    __NETDEV_TX_MIN = (-0x7FFFFFFF-1),
    NETDEV_TX_OK = 0,
    NETDEV_TX_BUSY = 16,
    NETDEV_TX_LOCKED = 32
} ;
typedef enum netdev_tx netdev_tx_t;
struct net_device_stats {
   unsigned long rx_packets ;
   unsigned long tx_packets ;
   unsigned long rx_bytes ;
   unsigned long tx_bytes ;
   unsigned long rx_errors ;
   unsigned long tx_errors ;
   unsigned long rx_dropped ;
   unsigned long tx_dropped ;
   unsigned long multicast ;
   unsigned long collisions ;
   unsigned long rx_length_errors ;
   unsigned long rx_over_errors ;
   unsigned long rx_crc_errors ;
   unsigned long rx_frame_errors ;
   unsigned long rx_fifo_errors ;
   unsigned long rx_missed_errors ;
   unsigned long tx_aborted_errors ;
   unsigned long tx_carrier_errors ;
   unsigned long tx_fifo_errors ;
   unsigned long tx_heartbeat_errors ;
   unsigned long tx_window_errors ;
   unsigned long rx_compressed ;
   unsigned long tx_compressed ;
};
struct neigh_parms;
struct netdev_hw_addr {
   struct list_head list ;
   unsigned char addr[32U] ;
   unsigned char type ;
   bool global_use ;
   int sync_cnt ;
   int refcount ;
   int synced ;
   struct callback_head callback_head ;
};
struct netdev_hw_addr_list {
   struct list_head list ;
   int count ;
};
struct hh_cache {
   u16 hh_len ;
   u16 __pad ;
   seqlock_t hh_lock ;
   unsigned long hh_data[16U] ;
};
struct header_ops {
   int (*create)(struct sk_buff * , struct net_device * , unsigned short , void const * ,
                 void const * , unsigned int ) ;
   int (*parse)(struct sk_buff const * , unsigned char * ) ;
   int (*cache)(struct neighbour const * , struct hh_cache * , __be16 ) ;
   void (*cache_update)(struct hh_cache * , struct net_device const * , unsigned char const * ) ;
};
struct napi_struct {
   struct list_head poll_list ;
   unsigned long state ;
   int weight ;
   unsigned int gro_count ;
   int (*poll)(struct napi_struct * , int ) ;
   spinlock_t poll_lock ;
   int poll_owner ;
   struct net_device *dev ;
   struct sk_buff *gro_list ;
   struct sk_buff *skb ;
   struct hrtimer timer ;
   struct list_head dev_list ;
   struct hlist_node napi_hash_node ;
   unsigned int napi_id ;
};
enum gro_result {
    GRO_MERGED = 0,
    GRO_MERGED_FREE = 1,
    GRO_HELD = 2,
    GRO_NORMAL = 3,
    GRO_DROP = 4
} ;
typedef enum gro_result gro_result_t;
enum rx_handler_result {
    RX_HANDLER_CONSUMED = 0,
    RX_HANDLER_ANOTHER = 1,
    RX_HANDLER_EXACT = 2,
    RX_HANDLER_PASS = 3
} ;
typedef enum rx_handler_result rx_handler_result_t;
typedef rx_handler_result_t rx_handler_func_t(struct sk_buff ** );
struct Qdisc;
struct netdev_queue {
   struct net_device *dev ;
   struct Qdisc *qdisc ;
   struct Qdisc *qdisc_sleeping ;
   struct kobject kobj ;
   int numa_node ;
   spinlock_t _xmit_lock ;
   int xmit_lock_owner ;
   unsigned long trans_start ;
   unsigned long trans_timeout ;
   unsigned long state ;
   struct dql dql ;
   unsigned long tx_maxrate ;
};
struct rps_map {
   unsigned int len ;
   struct callback_head rcu ;
   u16 cpus[0U] ;
};
struct rps_dev_flow {
   u16 cpu ;
   u16 filter ;
   unsigned int last_qtail ;
};
struct rps_dev_flow_table {
   unsigned int mask ;
   struct callback_head rcu ;
   struct rps_dev_flow flows[0U] ;
};
struct netdev_rx_queue {
   struct rps_map *rps_map ;
   struct rps_dev_flow_table *rps_flow_table ;
   struct kobject kobj ;
   struct net_device *dev ;
};
struct xps_map {
   unsigned int len ;
   unsigned int alloc_len ;
   struct callback_head rcu ;
   u16 queues[0U] ;
};
struct xps_dev_maps {
   struct callback_head rcu ;
   struct xps_map *cpu_map[0U] ;
};
struct netdev_tc_txq {
   u16 count ;
   u16 offset ;
};
struct netdev_fcoe_hbainfo {
   char manufacturer[64U] ;
   char serial_number[64U] ;
   char hardware_version[64U] ;
   char driver_version[64U] ;
   char optionrom_version[64U] ;
   char firmware_version[64U] ;
   char model[256U] ;
   char model_description[256U] ;
};
struct netdev_phys_item_id {
   unsigned char id[32U] ;
   unsigned char id_len ;
};
struct net_device_ops {
   int (*ndo_init)(struct net_device * ) ;
   void (*ndo_uninit)(struct net_device * ) ;
   int (*ndo_open)(struct net_device * ) ;
   int (*ndo_stop)(struct net_device * ) ;
   netdev_tx_t (*ndo_start_xmit)(struct sk_buff * , struct net_device * ) ;
   u16 (*ndo_select_queue)(struct net_device * , struct sk_buff * , void * , u16 (*)(struct net_device * ,
                                                                                     struct sk_buff * ) ) ;
   void (*ndo_change_rx_flags)(struct net_device * , int ) ;
   void (*ndo_set_rx_mode)(struct net_device * ) ;
   int (*ndo_set_mac_address)(struct net_device * , void * ) ;
   int (*ndo_validate_addr)(struct net_device * ) ;
   int (*ndo_do_ioctl)(struct net_device * , struct ifreq * , int ) ;
   int (*ndo_set_config)(struct net_device * , struct ifmap * ) ;
   int (*ndo_change_mtu)(struct net_device * , int ) ;
   int (*ndo_neigh_setup)(struct net_device * , struct neigh_parms * ) ;
   void (*ndo_tx_timeout)(struct net_device * ) ;
   struct rtnl_link_stats64 *(*ndo_get_stats64)(struct net_device * , struct rtnl_link_stats64 * ) ;
   struct net_device_stats *(*ndo_get_stats)(struct net_device * ) ;
   int (*ndo_vlan_rx_add_vid)(struct net_device * , __be16 , u16 ) ;
   int (*ndo_vlan_rx_kill_vid)(struct net_device * , __be16 , u16 ) ;
   void (*ndo_poll_controller)(struct net_device * ) ;
   int (*ndo_netpoll_setup)(struct net_device * , struct netpoll_info * ) ;
   void (*ndo_netpoll_cleanup)(struct net_device * ) ;
   int (*ndo_busy_poll)(struct napi_struct * ) ;
   int (*ndo_set_vf_mac)(struct net_device * , int , u8 * ) ;
   int (*ndo_set_vf_vlan)(struct net_device * , int , u16 , u8 ) ;
   int (*ndo_set_vf_rate)(struct net_device * , int , int , int ) ;
   int (*ndo_set_vf_spoofchk)(struct net_device * , int , bool ) ;
   int (*ndo_get_vf_config)(struct net_device * , int , struct ifla_vf_info * ) ;
   int (*ndo_set_vf_link_state)(struct net_device * , int , int ) ;
   int (*ndo_get_vf_stats)(struct net_device * , int , struct ifla_vf_stats * ) ;
   int (*ndo_set_vf_port)(struct net_device * , int , struct nlattr ** ) ;
   int (*ndo_get_vf_port)(struct net_device * , int , struct sk_buff * ) ;
   int (*ndo_set_vf_rss_query_en)(struct net_device * , int , bool ) ;
   int (*ndo_setup_tc)(struct net_device * , u8 ) ;
   int (*ndo_fcoe_enable)(struct net_device * ) ;
   int (*ndo_fcoe_disable)(struct net_device * ) ;
   int (*ndo_fcoe_ddp_setup)(struct net_device * , u16 , struct scatterlist * , unsigned int ) ;
   int (*ndo_fcoe_ddp_done)(struct net_device * , u16 ) ;
   int (*ndo_fcoe_ddp_target)(struct net_device * , u16 , struct scatterlist * ,
                              unsigned int ) ;
   int (*ndo_fcoe_get_hbainfo)(struct net_device * , struct netdev_fcoe_hbainfo * ) ;
   int (*ndo_fcoe_get_wwn)(struct net_device * , u64 * , int ) ;
   int (*ndo_rx_flow_steer)(struct net_device * , struct sk_buff const * , u16 ,
                            u32 ) ;
   int (*ndo_add_slave)(struct net_device * , struct net_device * ) ;
   int (*ndo_del_slave)(struct net_device * , struct net_device * ) ;
   netdev_features_t (*ndo_fix_features)(struct net_device * , netdev_features_t ) ;
   int (*ndo_set_features)(struct net_device * , netdev_features_t ) ;
   int (*ndo_neigh_construct)(struct neighbour * ) ;
   void (*ndo_neigh_destroy)(struct neighbour * ) ;
   int (*ndo_fdb_add)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const * ,
                      u16 , u16 ) ;
   int (*ndo_fdb_del)(struct ndmsg * , struct nlattr ** , struct net_device * , unsigned char const * ,
                      u16 ) ;
   int (*ndo_fdb_dump)(struct sk_buff * , struct netlink_callback * , struct net_device * ,
                       struct net_device * , int ) ;
   int (*ndo_bridge_setlink)(struct net_device * , struct nlmsghdr * , u16 ) ;
   int (*ndo_bridge_getlink)(struct sk_buff * , u32 , u32 , struct net_device * ,
                             u32 , int ) ;
   int (*ndo_bridge_dellink)(struct net_device * , struct nlmsghdr * , u16 ) ;
   int (*ndo_change_carrier)(struct net_device * , bool ) ;
   int (*ndo_get_phys_port_id)(struct net_device * , struct netdev_phys_item_id * ) ;
   int (*ndo_get_phys_port_name)(struct net_device * , char * , size_t ) ;
   void (*ndo_add_vxlan_port)(struct net_device * , sa_family_t , __be16 ) ;
   void (*ndo_del_vxlan_port)(struct net_device * , sa_family_t , __be16 ) ;
   void *(*ndo_dfwd_add_station)(struct net_device * , struct net_device * ) ;
   void (*ndo_dfwd_del_station)(struct net_device * , void * ) ;
   netdev_tx_t (*ndo_dfwd_start_xmit)(struct sk_buff * , struct net_device * , void * ) ;
   int (*ndo_get_lock_subclass)(struct net_device * ) ;
   netdev_features_t (*ndo_features_check)(struct sk_buff * , struct net_device * ,
                                           netdev_features_t ) ;
   int (*ndo_set_tx_maxrate)(struct net_device * , int , u32 ) ;
   int (*ndo_get_iflink)(struct net_device const * ) ;
};
struct __anonstruct_adj_list_315 {
   struct list_head upper ;
   struct list_head lower ;
};
struct __anonstruct_all_adj_list_316 {
   struct list_head upper ;
   struct list_head lower ;
};
struct iw_handler_def;
struct iw_public_data;
struct switchdev_ops;
struct vlan_info;
struct tipc_bearer;
struct in_device;
struct dn_dev;
struct inet6_dev;
struct tcf_proto;
struct cpu_rmap;
struct pcpu_lstats;
struct pcpu_sw_netstats;
struct pcpu_dstats;
struct pcpu_vstats;
union __anonunion____missing_field_name_317 {
   void *ml_priv ;
   struct pcpu_lstats *lstats ;
   struct pcpu_sw_netstats *tstats ;
   struct pcpu_dstats *dstats ;
   struct pcpu_vstats *vstats ;
};
struct garp_port;
struct mrp_port;
struct rtnl_link_ops;
struct net_device {
   char name[16U] ;
   struct hlist_node name_hlist ;
   char *ifalias ;
   unsigned long mem_end ;
   unsigned long mem_start ;
   unsigned long base_addr ;
   int irq ;
   atomic_t carrier_changes ;
   unsigned long state ;
   struct list_head dev_list ;
   struct list_head napi_list ;
   struct list_head unreg_list ;
   struct list_head close_list ;
   struct list_head ptype_all ;
   struct list_head ptype_specific ;
   struct __anonstruct_adj_list_315 adj_list ;
   struct __anonstruct_all_adj_list_316 all_adj_list ;
   netdev_features_t features ;
   netdev_features_t hw_features ;
   netdev_features_t wanted_features ;
   netdev_features_t vlan_features ;
   netdev_features_t hw_enc_features ;
   netdev_features_t mpls_features ;
   int ifindex ;
   int group ;
   struct net_device_stats stats ;
   atomic_long_t rx_dropped ;
   atomic_long_t tx_dropped ;
   struct iw_handler_def const *wireless_handlers ;
   struct iw_public_data *wireless_data ;
   struct net_device_ops const *netdev_ops ;
   struct ethtool_ops const *ethtool_ops ;
   struct switchdev_ops const *switchdev_ops ;
   struct header_ops const *header_ops ;
   unsigned int flags ;
   unsigned int priv_flags ;
   unsigned short gflags ;
   unsigned short padded ;
   unsigned char operstate ;
   unsigned char link_mode ;
   unsigned char if_port ;
   unsigned char dma ;
   unsigned int mtu ;
   unsigned short type ;
   unsigned short hard_header_len ;
   unsigned short needed_headroom ;
   unsigned short needed_tailroom ;
   unsigned char perm_addr[32U] ;
   unsigned char addr_assign_type ;
   unsigned char addr_len ;
   unsigned short neigh_priv_len ;
   unsigned short dev_id ;
   unsigned short dev_port ;
   spinlock_t addr_list_lock ;
   unsigned char name_assign_type ;
   bool uc_promisc ;
   struct netdev_hw_addr_list uc ;
   struct netdev_hw_addr_list mc ;
   struct netdev_hw_addr_list dev_addrs ;
   struct kset *queues_kset ;
   unsigned int promiscuity ;
   unsigned int allmulti ;
   struct vlan_info *vlan_info ;
   struct dsa_switch_tree *dsa_ptr ;
   struct tipc_bearer *tipc_ptr ;
   void *atalk_ptr ;
   struct in_device *ip_ptr ;
   struct dn_dev *dn_ptr ;
   struct inet6_dev *ip6_ptr ;
   void *ax25_ptr ;
   struct wireless_dev *ieee80211_ptr ;
   struct wpan_dev *ieee802154_ptr ;
   struct mpls_dev *mpls_ptr ;
   unsigned long last_rx ;
   unsigned char *dev_addr ;
   struct netdev_rx_queue *_rx ;
   unsigned int num_rx_queues ;
   unsigned int real_num_rx_queues ;
   unsigned long gro_flush_timeout ;
   rx_handler_func_t *rx_handler ;
   void *rx_handler_data ;
   struct tcf_proto *ingress_cl_list ;
   struct netdev_queue *ingress_queue ;
   struct list_head nf_hooks_ingress ;
   unsigned char broadcast[32U] ;
   struct cpu_rmap *rx_cpu_rmap ;
   struct hlist_node index_hlist ;
   struct netdev_queue *_tx ;
   unsigned int num_tx_queues ;
   unsigned int real_num_tx_queues ;
   struct Qdisc *qdisc ;
   unsigned long tx_queue_len ;
   spinlock_t tx_global_lock ;
   int watchdog_timeo ;
   struct xps_dev_maps *xps_maps ;
   unsigned long trans_start ;
   struct timer_list watchdog_timer ;
   int *pcpu_refcnt ;
   struct list_head todo_list ;
   struct list_head link_watch_list ;
   unsigned char reg_state ;
   bool dismantle ;
   unsigned short rtnl_link_state ;
   void (*destructor)(struct net_device * ) ;
   struct netpoll_info *npinfo ;
   possible_net_t nd_net ;
   union __anonunion____missing_field_name_317 __annonCompField94 ;
   struct garp_port *garp_port ;
   struct mrp_port *mrp_port ;
   struct device dev ;
   struct attribute_group const *sysfs_groups[4U] ;
   struct attribute_group const *sysfs_rx_queue_group ;
   struct rtnl_link_ops const *rtnl_link_ops ;
   unsigned int gso_max_size ;
   u16 gso_max_segs ;
   u16 gso_min_segs ;
   struct dcbnl_rtnl_ops const *dcbnl_ops ;
   u8 num_tc ;
   struct netdev_tc_txq tc_to_txq[16U] ;
   u8 prio_tc_map[16U] ;
   unsigned int fcoe_ddp_xid ;
   struct netprio_map *priomap ;
   struct phy_device *phydev ;
   struct lock_class_key *qdisc_tx_busylock ;
};
struct packet_type {
   __be16 type ;
   struct net_device *dev ;
   int (*func)(struct sk_buff * , struct net_device * , struct packet_type * , struct net_device * ) ;
   bool (*id_match)(struct packet_type * , struct sock * ) ;
   void *af_packet_priv ;
   struct list_head list ;
};
struct pcpu_sw_netstats {
   u64 rx_packets ;
   u64 rx_bytes ;
   u64 tx_packets ;
   u64 tx_bytes ;
   struct u64_stats_sync syncp ;
};
enum skb_free_reason {
    SKB_REASON_CONSUMED = 0,
    SKB_REASON_DROPPED = 1
} ;
struct vlan_hdr {
   __be16 h_vlan_TCI ;
   __be16 h_vlan_encapsulated_proto ;
};
struct iphdr {
   unsigned char ihl : 4 ;
   unsigned char version : 4 ;
   __u8 tos ;
   __be16 tot_len ;
   __be16 id ;
   __be16 frag_off ;
   __u8 ttl ;
   __u8 protocol ;
   __sum16 check ;
   __be32 saddr ;
   __be32 daddr ;
};
struct ipv6hdr {
   unsigned char priority : 4 ;
   unsigned char version : 4 ;
   __u8 flow_lbl[3U] ;
   __be16 payload_len ;
   __u8 nexthdr ;
   __u8 hop_limit ;
   struct in6_addr saddr ;
   struct in6_addr daddr ;
};
struct ipv6_stable_secret {
   bool initialized ;
   struct in6_addr secret ;
};
struct ipv6_devconf {
   __s32 forwarding ;
   __s32 hop_limit ;
   __s32 mtu6 ;
   __s32 accept_ra ;
   __s32 accept_redirects ;
   __s32 autoconf ;
   __s32 dad_transmits ;
   __s32 rtr_solicits ;
   __s32 rtr_solicit_interval ;
   __s32 rtr_solicit_delay ;
   __s32 force_mld_version ;
   __s32 mldv1_unsolicited_report_interval ;
   __s32 mldv2_unsolicited_report_interval ;
   __s32 use_tempaddr ;
   __s32 temp_valid_lft ;
   __s32 temp_prefered_lft ;
   __s32 regen_max_retry ;
   __s32 max_desync_factor ;
   __s32 max_addresses ;
   __s32 accept_ra_defrtr ;
   __s32 accept_ra_pinfo ;
   __s32 accept_ra_rtr_pref ;
   __s32 rtr_probe_interval ;
   __s32 accept_ra_rt_info_max_plen ;
   __s32 proxy_ndp ;
   __s32 accept_source_route ;
   __s32 accept_ra_from_local ;
   __s32 optimistic_dad ;
   __s32 use_optimistic ;
   __s32 mc_forwarding ;
   __s32 disable_ipv6 ;
   __s32 accept_dad ;
   __s32 force_tllao ;
   __s32 ndisc_notify ;
   __s32 suppress_frag_ndisc ;
   __s32 accept_ra_mtu ;
   struct ipv6_stable_secret stable_secret ;
   void *sysctl ;
};
struct page_counter {
   atomic_long_t count ;
   unsigned long limit ;
   struct page_counter *parent ;
   unsigned long watermark ;
   unsigned long failcnt ;
};
struct sock_filter {
   __u16 code ;
   __u8 jt ;
   __u8 jf ;
   __u32 k ;
};
struct bpf_insn {
   __u8 code ;
   unsigned char dst_reg : 4 ;
   unsigned char src_reg : 4 ;
   __s16 off ;
   __s32 imm ;
};
enum bpf_prog_type {
    BPF_PROG_TYPE_UNSPEC = 0,
    BPF_PROG_TYPE_SOCKET_FILTER = 1,
    BPF_PROG_TYPE_KPROBE = 2,
    BPF_PROG_TYPE_SCHED_CLS = 3,
    BPF_PROG_TYPE_SCHED_ACT = 4
} ;
struct bpf_prog_aux;
struct sock_fprog_kern {
   u16 len ;
   struct sock_filter *filter ;
};
union __anonunion____missing_field_name_337 {
   struct sock_filter insns[0U] ;
   struct bpf_insn insnsi[0U] ;
};
struct bpf_prog {
   u16 pages ;
   bool jited ;
   bool gpl_compatible ;
   u32 len ;
   enum bpf_prog_type type ;
   struct bpf_prog_aux *aux ;
   struct sock_fprog_kern *orig_prog ;
   unsigned int (*bpf_func)(struct sk_buff const * , struct bpf_insn const * ) ;
   union __anonunion____missing_field_name_337 __annonCompField99 ;
};
struct sk_filter {
   atomic_t refcnt ;
   struct callback_head rcu ;
   struct bpf_prog *prog ;
};
struct pollfd {
   int fd ;
   short events ;
   short revents ;
};
struct poll_table_struct {
   void (*_qproc)(struct file * , wait_queue_head_t * , struct poll_table_struct * ) ;
   unsigned long _key ;
};
struct nla_policy {
   u16 type ;
   u16 len ;
};
struct rtnl_link_ops {
   struct list_head list ;
   char const *kind ;
   size_t priv_size ;
   void (*setup)(struct net_device * ) ;
   int maxtype ;
   struct nla_policy const *policy ;
   int (*validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*newlink)(struct net * , struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   int (*changelink)(struct net_device * , struct nlattr ** , struct nlattr ** ) ;
   void (*dellink)(struct net_device * , struct list_head * ) ;
   size_t (*get_size)(struct net_device const * ) ;
   int (*fill_info)(struct sk_buff * , struct net_device const * ) ;
   size_t (*get_xstats_size)(struct net_device const * ) ;
   int (*fill_xstats)(struct sk_buff * , struct net_device const * ) ;
   unsigned int (*get_num_tx_queues)(void) ;
   unsigned int (*get_num_rx_queues)(void) ;
   int slave_maxtype ;
   struct nla_policy const *slave_policy ;
   int (*slave_validate)(struct nlattr ** , struct nlattr ** ) ;
   int (*slave_changelink)(struct net_device * , struct net_device * , struct nlattr ** ,
                           struct nlattr ** ) ;
   size_t (*get_slave_size)(struct net_device const * , struct net_device const * ) ;
   int (*fill_slave_info)(struct sk_buff * , struct net_device const * , struct net_device const * ) ;
   struct net *(*get_link_net)(struct net_device const * ) ;
};
struct neigh_table;
struct neigh_parms {
   possible_net_t net ;
   struct net_device *dev ;
   struct list_head list ;
   int (*neigh_setup)(struct neighbour * ) ;
   void (*neigh_cleanup)(struct neighbour * ) ;
   struct neigh_table *tbl ;
   void *sysctl_table ;
   int dead ;
   atomic_t refcnt ;
   struct callback_head callback_head ;
   int reachable_time ;
   int data[13U] ;
   unsigned long data_state[1U] ;
};
struct neigh_statistics {
   unsigned long allocs ;
   unsigned long destroys ;
   unsigned long hash_grows ;
   unsigned long res_failed ;
   unsigned long lookups ;
   unsigned long hits ;
   unsigned long rcv_probes_mcast ;
   unsigned long rcv_probes_ucast ;
   unsigned long periodic_gc_runs ;
   unsigned long forced_gc_runs ;
   unsigned long unres_discards ;
};
struct neigh_ops;
struct neighbour {
   struct neighbour *next ;
   struct neigh_table *tbl ;
   struct neigh_parms *parms ;
   unsigned long confirmed ;
   unsigned long updated ;
   rwlock_t lock ;
   atomic_t refcnt ;
   struct sk_buff_head arp_queue ;
   unsigned int arp_queue_len_bytes ;
   struct timer_list timer ;
   unsigned long used ;
   atomic_t probes ;
   __u8 flags ;
   __u8 nud_state ;
   __u8 type ;
   __u8 dead ;
   seqlock_t ha_lock ;
   unsigned char ha[32U] ;
   struct hh_cache hh ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   struct neigh_ops const *ops ;
   struct callback_head rcu ;
   struct net_device *dev ;
   u8 primary_key[0U] ;
};
struct neigh_ops {
   int family ;
   void (*solicit)(struct neighbour * , struct sk_buff * ) ;
   void (*error_report)(struct neighbour * , struct sk_buff * ) ;
   int (*output)(struct neighbour * , struct sk_buff * ) ;
   int (*connected_output)(struct neighbour * , struct sk_buff * ) ;
};
struct pneigh_entry {
   struct pneigh_entry *next ;
   possible_net_t net ;
   struct net_device *dev ;
   u8 flags ;
   u8 key[0U] ;
};
struct neigh_hash_table {
   struct neighbour **hash_buckets ;
   unsigned int hash_shift ;
   __u32 hash_rnd[4U] ;
   struct callback_head rcu ;
};
struct neigh_table {
   int family ;
   int entry_size ;
   int key_len ;
   __be16 protocol ;
   __u32 (*hash)(void const * , struct net_device const * , __u32 * ) ;
   bool (*key_eq)(struct neighbour const * , void const * ) ;
   int (*constructor)(struct neighbour * ) ;
   int (*pconstructor)(struct pneigh_entry * ) ;
   void (*pdestructor)(struct pneigh_entry * ) ;
   void (*proxy_redo)(struct sk_buff * ) ;
   char *id ;
   struct neigh_parms parms ;
   struct list_head parms_list ;
   int gc_interval ;
   int gc_thresh1 ;
   int gc_thresh2 ;
   int gc_thresh3 ;
   unsigned long last_flush ;
   struct delayed_work gc_work ;
   struct timer_list proxy_timer ;
   struct sk_buff_head proxy_queue ;
   atomic_t entries ;
   rwlock_t lock ;
   unsigned long last_rand ;
   struct neigh_statistics *stats ;
   struct neigh_hash_table *nht ;
   struct pneigh_entry **phash_buckets ;
};
struct dn_route;
union __anonunion____missing_field_name_345 {
   struct dst_entry *next ;
   struct rtable *rt_next ;
   struct rt6_info *rt6_next ;
   struct dn_route *dn_next ;
};
struct dst_entry {
   struct callback_head callback_head ;
   struct dst_entry *child ;
   struct net_device *dev ;
   struct dst_ops *ops ;
   unsigned long _metrics ;
   unsigned long expires ;
   struct dst_entry *path ;
   struct dst_entry *from ;
   struct xfrm_state *xfrm ;
   int (*input)(struct sk_buff * ) ;
   int (*output)(struct sock * , struct sk_buff * ) ;
   unsigned short flags ;
   unsigned short pending_confirm ;
   short error ;
   short obsolete ;
   unsigned short header_len ;
   unsigned short trailer_len ;
   __u32 tclassid ;
   long __pad_to_align_refcnt[2U] ;
   atomic_t __refcnt ;
   int __use ;
   unsigned long lastuse ;
   union __anonunion____missing_field_name_345 __annonCompField100 ;
};
struct __anonstruct_socket_lock_t_346 {
   spinlock_t slock ;
   int owned ;
   wait_queue_head_t wq ;
   struct lockdep_map dep_map ;
};
typedef struct __anonstruct_socket_lock_t_346 socket_lock_t;
struct proto;
typedef __u32 __portpair;
typedef __u64 __addrpair;
struct __anonstruct____missing_field_name_348 {
   __be32 skc_daddr ;
   __be32 skc_rcv_saddr ;
};
union __anonunion____missing_field_name_347 {
   __addrpair skc_addrpair ;
   struct __anonstruct____missing_field_name_348 __annonCompField101 ;
};
union __anonunion____missing_field_name_349 {
   unsigned int skc_hash ;
   __u16 skc_u16hashes[2U] ;
};
struct __anonstruct____missing_field_name_351 {
   __be16 skc_dport ;
   __u16 skc_num ;
};
union __anonunion____missing_field_name_350 {
   __portpair skc_portpair ;
   struct __anonstruct____missing_field_name_351 __annonCompField104 ;
};
union __anonunion____missing_field_name_352 {
   struct hlist_node skc_bind_node ;
   struct hlist_nulls_node skc_portaddr_node ;
};
union __anonunion____missing_field_name_353 {
   struct hlist_node skc_node ;
   struct hlist_nulls_node skc_nulls_node ;
};
struct sock_common {
   union __anonunion____missing_field_name_347 __annonCompField102 ;
   union __anonunion____missing_field_name_349 __annonCompField103 ;
   union __anonunion____missing_field_name_350 __annonCompField105 ;
   unsigned short skc_family ;
   unsigned char volatile skc_state ;
   unsigned char skc_reuse : 4 ;
   unsigned char skc_reuseport : 1 ;
   unsigned char skc_ipv6only : 1 ;
   unsigned char skc_net_refcnt : 1 ;
   int skc_bound_dev_if ;
   union __anonunion____missing_field_name_352 __annonCompField106 ;
   struct proto *skc_prot ;
   possible_net_t skc_net ;
   struct in6_addr skc_v6_daddr ;
   struct in6_addr skc_v6_rcv_saddr ;
   atomic64_t skc_cookie ;
   int skc_dontcopy_begin[0U] ;
   union __anonunion____missing_field_name_353 __annonCompField107 ;
   int skc_tx_queue_mapping ;
   atomic_t skc_refcnt ;
   int skc_dontcopy_end[0U] ;
};
struct cg_proto;
struct __anonstruct_sk_backlog_354 {
   atomic_t rmem_alloc ;
   int len ;
   struct sk_buff *head ;
   struct sk_buff *tail ;
};
struct sock {
   struct sock_common __sk_common ;
   socket_lock_t sk_lock ;
   struct sk_buff_head sk_receive_queue ;
   struct __anonstruct_sk_backlog_354 sk_backlog ;
   int sk_forward_alloc ;
   __u32 sk_rxhash ;
   u16 sk_incoming_cpu ;
   __u32 sk_txhash ;
   unsigned int sk_napi_id ;
   unsigned int sk_ll_usec ;
   atomic_t sk_drops ;
   int sk_rcvbuf ;
   struct sk_filter *sk_filter ;
   struct socket_wq *sk_wq ;
   struct xfrm_policy *sk_policy[2U] ;
   unsigned long sk_flags ;
   struct dst_entry *sk_rx_dst ;
   struct dst_entry *sk_dst_cache ;
   spinlock_t sk_dst_lock ;
   atomic_t sk_wmem_alloc ;
   atomic_t sk_omem_alloc ;
   int sk_sndbuf ;
   struct sk_buff_head sk_write_queue ;
   unsigned char sk_shutdown : 2 ;
   unsigned char sk_no_check_tx : 1 ;
   unsigned char sk_no_check_rx : 1 ;
   unsigned char sk_userlocks : 4 ;
   unsigned char sk_protocol ;
   unsigned short sk_type ;
   int sk_wmem_queued ;
   gfp_t sk_allocation ;
   u32 sk_pacing_rate ;
   u32 sk_max_pacing_rate ;
   netdev_features_t sk_route_caps ;
   netdev_features_t sk_route_nocaps ;
   int sk_gso_type ;
   unsigned int sk_gso_max_size ;
   u16 sk_gso_max_segs ;
   int sk_rcvlowat ;
   unsigned long sk_lingertime ;
   struct sk_buff_head sk_error_queue ;
   struct proto *sk_prot_creator ;
   rwlock_t sk_callback_lock ;
   int sk_err ;
   int sk_err_soft ;
   u32 sk_ack_backlog ;
   u32 sk_max_ack_backlog ;
   __u32 sk_priority ;
   __u32 sk_cgrp_prioidx ;
   struct pid *sk_peer_pid ;
   struct cred const *sk_peer_cred ;
   long sk_rcvtimeo ;
   long sk_sndtimeo ;
   struct timer_list sk_timer ;
   ktime_t sk_stamp ;
   u16 sk_tsflags ;
   u32 sk_tskey ;
   struct socket *sk_socket ;
   void *sk_user_data ;
   struct page_frag sk_frag ;
   struct sk_buff *sk_send_head ;
   __s32 sk_peek_off ;
   int sk_write_pending ;
   void *sk_security ;
   __u32 sk_mark ;
   u32 sk_classid ;
   struct cg_proto *sk_cgrp ;
   void (*sk_state_change)(struct sock * ) ;
   void (*sk_data_ready)(struct sock * ) ;
   void (*sk_write_space)(struct sock * ) ;
   void (*sk_error_report)(struct sock * ) ;
   int (*sk_backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*sk_destruct)(struct sock * ) ;
};
struct request_sock_ops;
struct timewait_sock_ops;
struct inet_hashinfo;
struct raw_hashinfo;
struct udp_table;
union __anonunion_h_357 {
   struct inet_hashinfo *hashinfo ;
   struct udp_table *udp_table ;
   struct raw_hashinfo *raw_hash ;
};
struct proto {
   void (*close)(struct sock * , long ) ;
   int (*connect)(struct sock * , struct sockaddr * , int ) ;
   int (*disconnect)(struct sock * , int ) ;
   struct sock *(*accept)(struct sock * , int , int * ) ;
   int (*ioctl)(struct sock * , int , unsigned long ) ;
   int (*init)(struct sock * ) ;
   void (*destroy)(struct sock * ) ;
   void (*shutdown)(struct sock * , int ) ;
   int (*setsockopt)(struct sock * , int , int , char * , unsigned int ) ;
   int (*getsockopt)(struct sock * , int , int , char * , int * ) ;
   int (*compat_setsockopt)(struct sock * , int , int , char * , unsigned int ) ;
   int (*compat_getsockopt)(struct sock * , int , int , char * , int * ) ;
   int (*compat_ioctl)(struct sock * , unsigned int , unsigned long ) ;
   int (*sendmsg)(struct sock * , struct msghdr * , size_t ) ;
   int (*recvmsg)(struct sock * , struct msghdr * , size_t , int , int , int * ) ;
   int (*sendpage)(struct sock * , struct page * , int , size_t , int ) ;
   int (*bind)(struct sock * , struct sockaddr * , int ) ;
   int (*backlog_rcv)(struct sock * , struct sk_buff * ) ;
   void (*release_cb)(struct sock * ) ;
   void (*hash)(struct sock * ) ;
   void (*unhash)(struct sock * ) ;
   void (*rehash)(struct sock * ) ;
   int (*get_port)(struct sock * , unsigned short ) ;
   void (*clear_sk)(struct sock * , int ) ;
   unsigned int inuse_idx ;
   bool (*stream_memory_free)(struct sock const * ) ;
   void (*enter_memory_pressure)(struct sock * ) ;
   atomic_long_t *memory_allocated ;
   struct percpu_counter *sockets_allocated ;
   int *memory_pressure ;
   long *sysctl_mem ;
   int *sysctl_wmem ;
   int *sysctl_rmem ;
   int max_header ;
   bool no_autobind ;
   struct kmem_cache *slab ;
   unsigned int obj_size ;
   int slab_flags ;
   struct percpu_counter *orphan_count ;
   struct request_sock_ops *rsk_prot ;
   struct timewait_sock_ops *twsk_prot ;
   union __anonunion_h_357 h ;
   struct module *owner ;
   char name[32U] ;
   struct list_head node ;
   int (*init_cgroup)(struct mem_cgroup * , struct cgroup_subsys * ) ;
   void (*destroy_cgroup)(struct mem_cgroup * ) ;
   struct cg_proto *(*proto_cgroup)(struct mem_cgroup * ) ;
};
struct cg_proto {
   struct page_counter memory_allocated ;
   struct percpu_counter sockets_allocated ;
   int memory_pressure ;
   long sysctl_mem[3U] ;
   unsigned long flags ;
   struct mem_cgroup *memcg ;
};
struct request_sock_ops {
   int family ;
   int obj_size ;
   struct kmem_cache *slab ;
   char *slab_name ;
   int (*rtx_syn_ack)(struct sock * , struct request_sock * ) ;
   void (*send_ack)(struct sock * , struct sk_buff * , struct request_sock * ) ;
   void (*send_reset)(struct sock * , struct sk_buff * ) ;
   void (*destructor)(struct request_sock * ) ;
   void (*syn_ack_timeout)(struct request_sock const * ) ;
};
struct request_sock {
   struct sock_common __req_common ;
   struct request_sock *dl_next ;
   struct sock *rsk_listener ;
   u16 mss ;
   u8 num_retrans ;
   unsigned char cookie_ts : 1 ;
   unsigned char num_timeout : 7 ;
   u32 window_clamp ;
   u32 rcv_wnd ;
   u32 ts_recent ;
   struct timer_list rsk_timer ;
   struct request_sock_ops const *rsk_ops ;
   struct sock *sk ;
   u32 *saved_syn ;
   u32 secid ;
   u32 peer_secid ;
};
struct timewait_sock_ops {
   struct kmem_cache *twsk_slab ;
   char *twsk_slab_name ;
   unsigned int twsk_obj_size ;
   int (*twsk_unique)(struct sock * , struct sock * , void * ) ;
   void (*twsk_destructor)(struct sock * ) ;
};
struct tcphdr {
   __be16 source ;
   __be16 dest ;
   __be32 seq ;
   __be32 ack_seq ;
   unsigned char res1 : 4 ;
   unsigned char doff : 4 ;
   unsigned char fin : 1 ;
   unsigned char syn : 1 ;
   unsigned char rst : 1 ;
   unsigned char psh : 1 ;
   unsigned char ack : 1 ;
   unsigned char urg : 1 ;
   unsigned char ece : 1 ;
   unsigned char cwr : 1 ;
   __be16 window ;
   __sum16 check ;
   __be16 urg_ptr ;
};
struct firmware {
   size_t size ;
   u8 const *data ;
   struct page **pages ;
   void *priv ;
};
struct ip6_sf_list {
   struct ip6_sf_list *sf_next ;
   struct in6_addr sf_addr ;
   unsigned long sf_count[2U] ;
   unsigned char sf_gsresp ;
   unsigned char sf_oldin ;
   unsigned char sf_crcount ;
};
struct ifmcaddr6 {
   struct in6_addr mca_addr ;
   struct inet6_dev *idev ;
   struct ifmcaddr6 *next ;
   struct ip6_sf_list *mca_sources ;
   struct ip6_sf_list *mca_tomb ;
   unsigned int mca_sfmode ;
   unsigned char mca_crcount ;
   unsigned long mca_sfcount[2U] ;
   struct timer_list mca_timer ;
   unsigned int mca_flags ;
   int mca_users ;
   atomic_t mca_refcnt ;
   spinlock_t mca_lock ;
   unsigned long mca_cstamp ;
   unsigned long mca_tstamp ;
};
struct ifacaddr6 {
   struct in6_addr aca_addr ;
   struct inet6_dev *aca_idev ;
   struct rt6_info *aca_rt ;
   struct ifacaddr6 *aca_next ;
   int aca_users ;
   atomic_t aca_refcnt ;
   unsigned long aca_cstamp ;
   unsigned long aca_tstamp ;
};
struct ipv6_devstat {
   struct proc_dir_entry *proc_dir_entry ;
   struct ipstats_mib *ipv6 ;
   struct icmpv6_mib_device *icmpv6dev ;
   struct icmpv6msg_mib_device *icmpv6msgdev ;
};
struct inet6_dev {
   struct net_device *dev ;
   struct list_head addr_list ;
   struct ifmcaddr6 *mc_list ;
   struct ifmcaddr6 *mc_tomb ;
   spinlock_t mc_lock ;
   unsigned char mc_qrv ;
   unsigned char mc_gq_running ;
   unsigned char mc_ifc_count ;
   unsigned char mc_dad_count ;
   unsigned long mc_v1_seen ;
   unsigned long mc_qi ;
   unsigned long mc_qri ;
   unsigned long mc_maxdelay ;
   struct timer_list mc_gq_timer ;
   struct timer_list mc_ifc_timer ;
   struct timer_list mc_dad_timer ;
   struct ifacaddr6 *ac_list ;
   rwlock_t lock ;
   atomic_t refcnt ;
   __u32 if_flags ;
   int dead ;
   u8 rndid[8U] ;
   struct timer_list regen_timer ;
   struct list_head tempaddr_list ;
   struct in6_addr token ;
   struct neigh_parms *nd_parms ;
   struct ipv6_devconf cnf ;
   struct ipv6_devstat stats ;
   struct timer_list rs_timer ;
   __u8 rs_probes ;
   __u8 addr_gen_mode ;
   unsigned long tstamp ;
   struct callback_head rcu ;
};
union __anonunion____missing_field_name_376 {
   __be32 a4 ;
   __be32 a6[4U] ;
   struct in6_addr in6 ;
};
struct inetpeer_addr_base {
   union __anonunion____missing_field_name_376 __annonCompField109 ;
};
struct inetpeer_addr {
   struct inetpeer_addr_base addr ;
   __u16 family ;
};
union __anonunion____missing_field_name_377 {
   struct list_head gc_list ;
   struct callback_head gc_rcu ;
};
struct __anonstruct____missing_field_name_379 {
   atomic_t rid ;
};
union __anonunion____missing_field_name_378 {
   struct __anonstruct____missing_field_name_379 __annonCompField111 ;
   struct callback_head rcu ;
   struct inet_peer *gc_next ;
};
struct inet_peer {
   struct inet_peer *avl_left ;
   struct inet_peer *avl_right ;
   struct inetpeer_addr daddr ;
   __u32 avl_height ;
   u32 metrics[16U] ;
   u32 rate_tokens ;
   unsigned long rate_last ;
   union __anonunion____missing_field_name_377 __annonCompField110 ;
   union __anonunion____missing_field_name_378 __annonCompField112 ;
   __u32 dtime ;
   atomic_t refcnt ;
};
struct inet_peer_base {
   struct inet_peer *root ;
   seqlock_t lock ;
   int total ;
};
struct uncached_list;
struct rtable {
   struct dst_entry dst ;
   int rt_genid ;
   unsigned int rt_flags ;
   __u16 rt_type ;
   __u8 rt_is_input ;
   __u8 rt_uses_gateway ;
   int rt_iif ;
   __be32 rt_gateway ;
   u32 rt_pmtu ;
   struct list_head rt_uncached ;
   struct uncached_list *rt_uncached_list ;
};
struct inet_ehash_bucket {
   struct hlist_nulls_head chain ;
};
struct inet_bind_hashbucket {
   spinlock_t lock ;
   struct hlist_head chain ;
};
struct inet_listen_hashbucket {
   spinlock_t lock ;
   struct hlist_nulls_head head ;
};
struct inet_hashinfo {
   struct inet_ehash_bucket *ehash ;
   spinlock_t *ehash_locks ;
   unsigned int ehash_mask ;
   unsigned int ehash_locks_mask ;
   struct inet_bind_hashbucket *bhash ;
   unsigned int bhash_size ;
   struct kmem_cache *bind_bucket_cachep ;
   struct inet_listen_hashbucket listening_hash[32U] ;
};
struct hotplug_slot;
struct pci_slot {
   struct pci_bus *bus ;
   struct list_head list ;
   struct hotplug_slot *hotplug ;
   unsigned char number ;
   struct kobject kobj ;
};
typedef int pci_power_t;
typedef unsigned int pci_channel_state_t;
enum pci_channel_state {
    pci_channel_io_normal = 1,
    pci_channel_io_frozen = 2,
    pci_channel_io_perm_failure = 3
} ;
typedef unsigned short pci_dev_flags_t;
typedef unsigned short pci_bus_flags_t;
struct pcie_link_state;
struct pci_vpd;
struct pci_sriov;
struct pci_ats;
struct pci_driver;
union __anonunion____missing_field_name_386 {
   struct pci_sriov *sriov ;
   struct pci_dev *physfn ;
};
struct pci_dev {
   struct list_head bus_list ;
   struct pci_bus *bus ;
   struct pci_bus *subordinate ;
   void *sysdata ;
   struct proc_dir_entry *procent ;
   struct pci_slot *slot ;
   unsigned int devfn ;
   unsigned short vendor ;
   unsigned short device ;
   unsigned short subsystem_vendor ;
   unsigned short subsystem_device ;
   unsigned int class ;
   u8 revision ;
   u8 hdr_type ;
   u8 pcie_cap ;
   u8 msi_cap ;
   u8 msix_cap ;
   unsigned char pcie_mpss : 3 ;
   u8 rom_base_reg ;
   u8 pin ;
   u16 pcie_flags_reg ;
   u8 dma_alias_devfn ;
   struct pci_driver *driver ;
   u64 dma_mask ;
   struct device_dma_parameters dma_parms ;
   pci_power_t current_state ;
   u8 pm_cap ;
   unsigned char pme_support : 5 ;
   unsigned char pme_interrupt : 1 ;
   unsigned char pme_poll : 1 ;
   unsigned char d1_support : 1 ;
   unsigned char d2_support : 1 ;
   unsigned char no_d1d2 : 1 ;
   unsigned char no_d3cold : 1 ;
   unsigned char d3cold_allowed : 1 ;
   unsigned char mmio_always_on : 1 ;
   unsigned char wakeup_prepared : 1 ;
   unsigned char runtime_d3cold : 1 ;
   unsigned char ignore_hotplug : 1 ;
   unsigned int d3_delay ;
   unsigned int d3cold_delay ;
   struct pcie_link_state *link_state ;
   pci_channel_state_t error_state ;
   struct device dev ;
   int cfg_size ;
   unsigned int irq ;
   struct resource resource[17U] ;
   bool match_driver ;
   unsigned char transparent : 1 ;
   unsigned char multifunction : 1 ;
   unsigned char is_added : 1 ;
   unsigned char is_busmaster : 1 ;
   unsigned char no_msi : 1 ;
   unsigned char no_64bit_msi : 1 ;
   unsigned char block_cfg_access : 1 ;
   unsigned char broken_parity_status : 1 ;
   unsigned char irq_reroute_variant : 2 ;
   unsigned char msi_enabled : 1 ;
   unsigned char msix_enabled : 1 ;
   unsigned char ari_enabled : 1 ;
   unsigned char is_managed : 1 ;
   unsigned char needs_freset : 1 ;
   unsigned char state_saved : 1 ;
   unsigned char is_physfn : 1 ;
   unsigned char is_virtfn : 1 ;
   unsigned char reset_fn : 1 ;
   unsigned char is_hotplug_bridge : 1 ;
   unsigned char __aer_firmware_first_valid : 1 ;
   unsigned char __aer_firmware_first : 1 ;
   unsigned char broken_intx_masking : 1 ;
   unsigned char io_window_1k : 1 ;
   unsigned char irq_managed : 1 ;
   unsigned char has_secondary_link : 1 ;
   pci_dev_flags_t dev_flags ;
   atomic_t enable_cnt ;
   u32 saved_config_space[16U] ;
   struct hlist_head saved_cap_space ;
   struct bin_attribute *rom_attr ;
   int rom_attr_enabled ;
   struct bin_attribute *res_attr[17U] ;
   struct bin_attribute *res_attr_wc[17U] ;
   struct list_head msi_list ;
   struct attribute_group const **msi_irq_groups ;
   struct pci_vpd *vpd ;
   union __anonunion____missing_field_name_386 __annonCompField116 ;
   struct pci_ats *ats ;
   phys_addr_t rom ;
   size_t romlen ;
   char *driver_override ;
};
struct pci_ops;
struct msi_controller;
struct pci_bus {
   struct list_head node ;
   struct pci_bus *parent ;
   struct list_head children ;
   struct list_head devices ;
   struct pci_dev *self ;
   struct list_head slots ;
   struct resource *resource[4U] ;
   struct list_head resources ;
   struct resource busn_res ;
   struct pci_ops *ops ;
   struct msi_controller *msi ;
   void *sysdata ;
   struct proc_dir_entry *procdir ;
   unsigned char number ;
   unsigned char primary ;
   unsigned char max_bus_speed ;
   unsigned char cur_bus_speed ;
   char name[48U] ;
   unsigned short bridge_ctl ;
   pci_bus_flags_t bus_flags ;
   struct device *bridge ;
   struct device dev ;
   struct bin_attribute *legacy_io ;
   struct bin_attribute *legacy_mem ;
   unsigned char is_added : 1 ;
};
struct pci_ops {
   void *(*map_bus)(struct pci_bus * , unsigned int , int ) ;
   int (*read)(struct pci_bus * , unsigned int , int , int , u32 * ) ;
   int (*write)(struct pci_bus * , unsigned int , int , int , u32 ) ;
};
struct pci_dynids {
   spinlock_t lock ;
   struct list_head list ;
};
typedef unsigned int pci_ers_result_t;
struct pci_error_handlers {
   pci_ers_result_t (*error_detected)(struct pci_dev * , enum pci_channel_state ) ;
   pci_ers_result_t (*mmio_enabled)(struct pci_dev * ) ;
   pci_ers_result_t (*link_reset)(struct pci_dev * ) ;
   pci_ers_result_t (*slot_reset)(struct pci_dev * ) ;
   void (*reset_notify)(struct pci_dev * , bool ) ;
   void (*resume)(struct pci_dev * ) ;
};
struct pci_driver {
   struct list_head node ;
   char const *name ;
   struct pci_device_id const *id_table ;
   int (*probe)(struct pci_dev * , struct pci_device_id const * ) ;
   void (*remove)(struct pci_dev * ) ;
   int (*suspend)(struct pci_dev * , pm_message_t ) ;
   int (*suspend_late)(struct pci_dev * , pm_message_t ) ;
   int (*resume_early)(struct pci_dev * ) ;
   int (*resume)(struct pci_dev * ) ;
   void (*shutdown)(struct pci_dev * ) ;
   int (*sriov_configure)(struct pci_dev * , int ) ;
   struct pci_error_handlers const *err_handler ;
   struct device_driver driver ;
   struct pci_dynids dynids ;
};
struct msix_entry {
   u32 vector ;
   u16 entry ;
};
enum bfa_status {
    BFA_STATUS_OK = 0,
    BFA_STATUS_FAILED = 1,
    BFA_STATUS_EINVAL = 2,
    BFA_STATUS_ENOMEM = 3,
    BFA_STATUS_ENOSYS = 4,
    BFA_STATUS_ETIMER = 5,
    BFA_STATUS_EPROTOCOL = 6,
    BFA_STATUS_ENOFCPORTS = 7,
    BFA_STATUS_NOFLASH = 8,
    BFA_STATUS_BADFLASH = 9,
    BFA_STATUS_SFP_UNSUPP = 10,
    BFA_STATUS_UNKNOWN_VFID = 11,
    BFA_STATUS_DATACORRUPTED = 12,
    BFA_STATUS_DEVBUSY = 13,
    BFA_STATUS_ABORTED = 14,
    BFA_STATUS_NODEV = 15,
    BFA_STATUS_HDMA_FAILED = 16,
    BFA_STATUS_FLASH_BAD_LEN = 17,
    BFA_STATUS_UNKNOWN_LWWN = 18,
    BFA_STATUS_UNKNOWN_RWWN = 19,
    BFA_STATUS_FCPT_LS_RJT = 20,
    BFA_STATUS_VPORT_EXISTS = 21,
    BFA_STATUS_VPORT_MAX = 22,
    BFA_STATUS_UNSUPP_SPEED = 23,
    BFA_STATUS_INVLD_DFSZ = 24,
    BFA_STATUS_CNFG_FAILED = 25,
    BFA_STATUS_CMD_NOTSUPP = 26,
    BFA_STATUS_NO_ADAPTER = 27,
    BFA_STATUS_LINKDOWN = 28,
    BFA_STATUS_FABRIC_RJT = 29,
    BFA_STATUS_UNKNOWN_VWWN = 30,
    BFA_STATUS_NSLOGIN_FAILED = 31,
    BFA_STATUS_NO_RPORTS = 32,
    BFA_STATUS_NSQUERY_FAILED = 33,
    BFA_STATUS_PORT_OFFLINE = 34,
    BFA_STATUS_RPORT_OFFLINE = 35,
    BFA_STATUS_TGTOPEN_FAILED = 36,
    BFA_STATUS_BAD_LUNS = 37,
    BFA_STATUS_IO_FAILURE = 38,
    BFA_STATUS_NO_FABRIC = 39,
    BFA_STATUS_EBADF = 40,
    BFA_STATUS_EINTR = 41,
    BFA_STATUS_EIO = 42,
    BFA_STATUS_ENOTTY = 43,
    BFA_STATUS_ENXIO = 44,
    BFA_STATUS_EFOPEN = 45,
    BFA_STATUS_VPORT_WWN_BP = 46,
    BFA_STATUS_PORT_NOT_DISABLED = 47,
    BFA_STATUS_BADFRMHDR = 48,
    BFA_STATUS_BADFRMSZ = 49,
    BFA_STATUS_MISSINGFRM = 50,
    BFA_STATUS_LINKTIMEOUT = 51,
    BFA_STATUS_NO_FCPIM_NEXUS = 52,
    BFA_STATUS_CHECKSUM_FAIL = 53,
    BFA_STATUS_GZME_FAILED = 54,
    BFA_STATUS_SCSISTART_REQD = 55,
    BFA_STATUS_IOC_FAILURE = 56,
    BFA_STATUS_INVALID_WWN = 57,
    BFA_STATUS_MISMATCH = 58,
    BFA_STATUS_IOC_ENABLED = 59,
    BFA_STATUS_ADAPTER_ENABLED = 60,
    BFA_STATUS_IOC_NON_OP = 61,
    BFA_STATUS_ADDR_MAP_FAILURE = 62,
    BFA_STATUS_SAME_NAME = 63,
    BFA_STATUS_PENDING = 64,
    BFA_STATUS_8G_SPD = 65,
    BFA_STATUS_4G_SPD = 66,
    BFA_STATUS_AD_IS_ENABLE = 67,
    BFA_STATUS_EINVAL_TOV = 68,
    BFA_STATUS_EINVAL_QDEPTH = 69,
    BFA_STATUS_VERSION_FAIL = 70,
    BFA_STATUS_DIAG_BUSY = 71,
    BFA_STATUS_BEACON_ON = 72,
    BFA_STATUS_BEACON_OFF = 73,
    BFA_STATUS_LBEACON_ON = 74,
    BFA_STATUS_LBEACON_OFF = 75,
    BFA_STATUS_PORT_NOT_INITED = 76,
    BFA_STATUS_RPSC_ENABLED = 77,
    BFA_STATUS_ENOFSAVE = 78,
    BFA_STATUS_BAD_FILE = 79,
    BFA_STATUS_RLIM_EN = 80,
    BFA_STATUS_RLIM_DIS = 81,
    BFA_STATUS_IOC_DISABLED = 82,
    BFA_STATUS_ADAPTER_DISABLED = 83,
    BFA_STATUS_BIOS_DISABLED = 84,
    BFA_STATUS_AUTH_ENABLED = 85,
    BFA_STATUS_AUTH_DISABLED = 86,
    BFA_STATUS_ERROR_TRL_ENABLED = 87,
    BFA_STATUS_ERROR_QOS_ENABLED = 88,
    BFA_STATUS_NO_SFP_DEV = 89,
    BFA_STATUS_MEMTEST_FAILED = 90,
    BFA_STATUS_INVALID_DEVID = 91,
    BFA_STATUS_QOS_ENABLED = 92,
    BFA_STATUS_QOS_DISABLED = 93,
    BFA_STATUS_INCORRECT_DRV_CONFIG = 94,
    BFA_STATUS_REG_FAIL = 95,
    BFA_STATUS_IM_INV_CODE = 96,
    BFA_STATUS_IM_INV_VLAN = 97,
    BFA_STATUS_IM_INV_ADAPT_NAME = 98,
    BFA_STATUS_IM_LOW_RESOURCES = 99,
    BFA_STATUS_IM_VLANID_IS_PVID = 100,
    BFA_STATUS_IM_VLANID_EXISTS = 101,
    BFA_STATUS_IM_FW_UPDATE_FAIL = 102,
    BFA_STATUS_PORTLOG_ENABLED = 103,
    BFA_STATUS_PORTLOG_DISABLED = 104,
    BFA_STATUS_FILE_NOT_FOUND = 105,
    BFA_STATUS_QOS_FC_ONLY = 106,
    BFA_STATUS_RLIM_FC_ONLY = 107,
    BFA_STATUS_CT_SPD = 108,
    BFA_STATUS_LEDTEST_OP = 109,
    BFA_STATUS_CEE_NOT_DN = 110,
    BFA_STATUS_10G_SPD = 111,
    BFA_STATUS_IM_INV_TEAM_NAME = 112,
    BFA_STATUS_IM_DUP_TEAM_NAME = 113,
    BFA_STATUS_IM_ADAPT_ALREADY_IN_TEAM = 114,
    BFA_STATUS_IM_ADAPT_HAS_VLANS = 115,
    BFA_STATUS_IM_PVID_MISMATCH = 116,
    BFA_STATUS_IM_LINK_SPEED_MISMATCH = 117,
    BFA_STATUS_IM_MTU_MISMATCH = 118,
    BFA_STATUS_IM_RSS_MISMATCH = 119,
    BFA_STATUS_IM_HDS_MISMATCH = 120,
    BFA_STATUS_IM_OFFLOAD_MISMATCH = 121,
    BFA_STATUS_IM_PORT_PARAMS = 122,
    BFA_STATUS_IM_PORT_NOT_IN_TEAM = 123,
    BFA_STATUS_IM_CANNOT_REM_PRI = 124,
    BFA_STATUS_IM_MAX_PORTS_REACHED = 125,
    BFA_STATUS_IM_LAST_PORT_DELETE = 126,
    BFA_STATUS_IM_NO_DRIVER = 127,
    BFA_STATUS_IM_MAX_VLANS_REACHED = 128,
    BFA_STATUS_TOMCAT_SPD_NOT_ALLOWED = 129,
    BFA_STATUS_NO_MINPORT_DRIVER = 130,
    BFA_STATUS_CARD_TYPE_MISMATCH = 131,
    BFA_STATUS_BAD_ASICBLK = 132,
    BFA_STATUS_NO_DRIVER = 133,
    BFA_STATUS_INVALID_MAC = 134,
    BFA_STATUS_IM_NO_VLAN = 135,
    BFA_STATUS_IM_ETH_LB_FAILED = 136,
    BFA_STATUS_IM_PVID_REMOVE = 137,
    BFA_STATUS_IM_PVID_EDIT = 138,
    BFA_STATUS_CNA_NO_BOOT = 139,
    BFA_STATUS_IM_PVID_NON_ZERO = 140,
    BFA_STATUS_IM_INETCFG_LOCK_FAILED = 141,
    BFA_STATUS_IM_GET_INETCFG_FAILED = 142,
    BFA_STATUS_IM_NOT_BOUND = 143,
    BFA_STATUS_INSUFFICIENT_PERMS = 144,
    BFA_STATUS_IM_INV_VLAN_NAME = 145,
    BFA_STATUS_CMD_NOTSUPP_CNA = 146,
    BFA_STATUS_IM_PASSTHRU_EDIT = 147,
    BFA_STATUS_IM_BIND_FAILED = 148,
    BFA_STATUS_IM_UNBIND_FAILED = 149,
    BFA_STATUS_IM_PORT_IN_TEAM = 150,
    BFA_STATUS_IM_VLAN_NOT_FOUND = 151,
    BFA_STATUS_IM_TEAM_NOT_FOUND = 152,
    BFA_STATUS_IM_TEAM_CFG_NOT_ALLOWED = 153,
    BFA_STATUS_PBC = 154,
    BFA_STATUS_DEVID_MISSING = 155,
    BFA_STATUS_BAD_FWCFG = 156,
    BFA_STATUS_CREATE_FILE = 157,
    BFA_STATUS_INVALID_VENDOR = 158,
    BFA_STATUS_SFP_NOT_READY = 159,
    BFA_STATUS_FLASH_UNINIT = 160,
    BFA_STATUS_FLASH_EMPTY = 161,
    BFA_STATUS_FLASH_CKFAIL = 162,
    BFA_STATUS_TRUNK_UNSUPP = 163,
    BFA_STATUS_TRUNK_ENABLED = 164,
    BFA_STATUS_TRUNK_DISABLED = 165,
    BFA_STATUS_TRUNK_ERROR_TRL_ENABLED = 166,
    BFA_STATUS_BOOT_CODE_UPDATED = 167,
    BFA_STATUS_BOOT_VERSION = 168,
    BFA_STATUS_CARDTYPE_MISSING = 169,
    BFA_STATUS_INVALID_CARDTYPE = 170,
    BFA_STATUS_NO_TOPOLOGY_FOR_CNA = 171,
    BFA_STATUS_IM_VLAN_OVER_TEAM_DELETE_FAILED = 172,
    BFA_STATUS_ETHBOOT_ENABLED = 173,
    BFA_STATUS_ETHBOOT_DISABLED = 174,
    BFA_STATUS_IOPROFILE_OFF = 175,
    BFA_STATUS_NO_PORT_INSTANCE = 176,
    BFA_STATUS_BOOT_CODE_TIMEDOUT = 177,
    BFA_STATUS_NO_VPORT_LOCK = 178,
    BFA_STATUS_VPORT_NO_CNFG = 179,
    BFA_STATUS_MAX_VAL = 180
} ;
struct bfa_mfg_vpd {
   u8 version ;
   u8 vpd_sig[3U] ;
   u8 chksum ;
   u8 vendor ;
   u8 len ;
   u8 rsv ;
   u8 data[512U] ;
};
struct bfa_ioc_drv_stats {
   u32 ioc_isrs ;
   u32 ioc_enables ;
   u32 ioc_disables ;
   u32 ioc_hbfails ;
   u32 ioc_boots ;
   u32 stats_tmos ;
   u32 hb_count ;
   u32 disable_reqs ;
   u32 enable_reqs ;
   u32 disable_replies ;
   u32 enable_replies ;
   u32 rsvd ;
};
enum bfa_mode {
    BFA_MODE_HBA = 1,
    BFA_MODE_CNA = 2,
    BFA_MODE_NIC = 3
} ;
struct bfa_wc {
   void (*wc_resume)(void * ) ;
   void *wc_cbarg ;
   int wc_count ;
};
struct __anonstruct_h2i_388 {
   u8 qid ;
   u8 fn_lpu ;
};
union __anonunion_mtag_387 {
   struct __anonstruct_h2i_388 h2i ;
   u16 i2htok ;
};
struct bfi_mhdr {
   u8 msg_class ;
   u8 msg_id ;
   union __anonunion_mtag_387 mtag ;
};
struct __anonstruct_a32_389 {
   u32 addr_lo ;
   u32 addr_hi ;
};
union bfi_addr_u {
   struct __anonstruct_a32_389 a32 ;
};
struct bfi_mbmsg {
   struct bfi_mhdr mh ;
   u32 pl[7U] ;
};
enum bfi_pcifn_class {
    BFI_PCIFN_CLASS_FC = 3076,
    BFI_PCIFN_CLASS_ETH = 512
} ;
enum bfi_asic_gen {
    BFI_ASIC_GEN_CB = 1,
    BFI_ASIC_GEN_CT = 2,
    BFI_ASIC_GEN_CT2 = 3
} ;
enum bfi_asic_mode {
    BFI_ASIC_MODE_FC = 1,
    BFI_ASIC_MODE_FC16 = 2,
    BFI_ASIC_MODE_ETH = 3,
    BFI_ASIC_MODE_COMBO = 4
} ;
struct bfi_ioc_attr {
   u64 mfg_pwwn ;
   u64 mfg_nwwn ;
   u8 mfg_mac[6U] ;
   u8 port_mode ;
   u8 rsvd_a ;
   u64 pwwn ;
   u64 nwwn ;
   u8 mac[6U] ;
   u16 rsvd_b ;
   u8 fcoe_mac[6U] ;
   u16 rsvd_c ;
   char brcd_serialnum[12U] ;
   u8 pcie_gen ;
   u8 pcie_lanes_orig ;
   u8 pcie_lanes ;
   u8 rx_bbcredit ;
   u32 adapter_prop ;
   u16 maxfrsize ;
   char asic_rev ;
   u8 rsvd_d ;
   char fw_version[64U] ;
   char optrom_version[64U] ;
   struct bfa_mfg_vpd vpd ;
   u32 card_type ;
};
enum bfi_port_mode {
    BFI_PORT_MODE_FC = 1,
    BFI_PORT_MODE_ETH = 2
} ;
enum bfi_ioc_state {
    BFI_IOC_UNINIT = 0,
    BFI_IOC_INITING = 1,
    BFI_IOC_HWINIT = 2,
    BFI_IOC_CFG = 3,
    BFI_IOC_OP = 4,
    BFI_IOC_DISABLING = 5,
    BFI_IOC_DISABLED = 6,
    BFI_IOC_CFG_DISABLED = 7,
    BFI_IOC_FAIL = 8,
    BFI_IOC_MEMTEST = 9
} ;
struct bfi_msgq_mhdr {
   u8 msg_class ;
   u8 msg_id ;
   u16 msg_token ;
   u16 num_entries ;
   u8 enet_id ;
   u8 rsvd[1U] ;
};
struct bfa_pcidev {
   int pci_slot ;
   u8 pci_func ;
   u16 device_id ;
   u16 ssid ;
   void *pci_bar_kva ;
};
struct bfa_dma {
   void *kva ;
   u64 pa ;
};
struct bfa_ioc_regs {
   void *hfn_mbox_cmd ;
   void *hfn_mbox ;
   void *lpu_mbox_cmd ;
   void *lpu_mbox ;
   void *lpu_read_stat ;
   void *pss_ctl_reg ;
   void *pss_err_status_reg ;
   void *app_pll_fast_ctl_reg ;
   void *app_pll_slow_ctl_reg ;
   void *ioc_sem_reg ;
   void *ioc_usage_sem_reg ;
   void *ioc_init_sem_reg ;
   void *ioc_usage_reg ;
   void *host_page_num_fn ;
   void *heartbeat ;
   void *ioc_fwstate ;
   void *alt_ioc_fwstate ;
   void *ll_halt ;
   void *alt_ll_halt ;
   void *err_set ;
   void *ioc_fail_sync ;
   void *shirq_isr_next ;
   void *shirq_msk_next ;
   void *smem_page_start ;
   u32 smem_pg0 ;
};
struct bfa_mbox_cmd {
   struct list_head qe ;
   void (*cbfn)(void * ) ;
   void *cbarg ;
   u32 msg[8U] ;
};
struct __anonstruct_mbhdlr_392 {
   void (*cbfn)(void * , struct bfi_mbmsg * ) ;
   void *cbarg ;
};
struct bfa_ioc_mbox_mod {
   struct list_head cmd_q ;
   int nmclass ;
   struct __anonstruct_mbhdlr_392 mbhdlr[34U] ;
};
struct bfa_ioc_cbfn {
   void (*enable_cbfn)(void * , enum bfa_status ) ;
   void (*disable_cbfn)(void * ) ;
   void (*hbfail_cbfn)(void * ) ;
   void (*reset_cbfn)(void * ) ;
};
enum bfa_ioc_event {
    BFA_IOC_E_ENABLED = 1,
    BFA_IOC_E_DISABLED = 2,
    BFA_IOC_E_FAILED = 3
} ;
struct bfa_ioc_notify {
   struct list_head qe ;
   void (*cbfn)(void * , enum bfa_ioc_event ) ;
   void *cbarg ;
};
struct bfa_iocpf {
   void (*fsm)(void * , int ) ;
   struct bfa_ioc *ioc ;
   bool fw_mismatch_notified ;
   bool auto_recover ;
   u32 poll_time ;
};
struct bfa;
struct bfa_ioc_hwif;
struct bfa_ioc {
   void (*fsm)(void * , int ) ;
   struct bfa *bfa ;
   struct bfa_pcidev pcidev ;
   struct timer_list ioc_timer ;
   struct timer_list iocpf_timer ;
   struct timer_list sem_timer ;
   struct timer_list hb_timer ;
   u32 hb_count ;
   struct list_head notify_q ;
   void *dbg_fwsave ;
   int dbg_fwsave_len ;
   bool dbg_fwsave_once ;
   enum bfi_pcifn_class clscode ;
   struct bfa_ioc_regs ioc_regs ;
   struct bfa_ioc_drv_stats stats ;
   bool fcmode ;
   bool pllinit ;
   bool stats_busy ;
   u8 port_id ;
   struct bfa_dma attr_dma ;
   struct bfi_ioc_attr *attr ;
   struct bfa_ioc_cbfn *cbfn ;
   struct bfa_ioc_mbox_mod mbox_mod ;
   struct bfa_ioc_hwif const *ioc_hwif ;
   struct bfa_iocpf iocpf ;
   enum bfi_asic_gen asic_gen ;
   enum bfi_asic_mode asic_mode ;
   enum bfi_port_mode port0_mode ;
   enum bfi_port_mode port1_mode ;
   enum bfa_mode port_mode ;
   u8 ad_cap_bm ;
   u8 port_mode_cfg ;
};
struct bfa_ioc_hwif {
   enum bfa_status (*ioc_pll_init)(void * , enum bfi_asic_mode ) ;
   bool (*ioc_firmware_lock)(struct bfa_ioc * ) ;
   void (*ioc_firmware_unlock)(struct bfa_ioc * ) ;
   void (*ioc_reg_init)(struct bfa_ioc * ) ;
   void (*ioc_map_port)(struct bfa_ioc * ) ;
   void (*ioc_isr_mode_set)(struct bfa_ioc * , bool ) ;
   void (*ioc_notify_fail)(struct bfa_ioc * ) ;
   void (*ioc_ownership_reset)(struct bfa_ioc * ) ;
   bool (*ioc_sync_start)(struct bfa_ioc * ) ;
   void (*ioc_sync_join)(struct bfa_ioc * ) ;
   void (*ioc_sync_leave)(struct bfa_ioc * ) ;
   void (*ioc_sync_ack)(struct bfa_ioc * ) ;
   bool (*ioc_sync_complete)(struct bfa_ioc * ) ;
   bool (*ioc_lpu_read_stat)(struct bfa_ioc * ) ;
   void (*ioc_set_fwstate)(struct bfa_ioc * , enum bfi_ioc_state ) ;
   enum bfi_ioc_state (*ioc_get_fwstate)(struct bfa_ioc * ) ;
   void (*ioc_set_alt_fwstate)(struct bfa_ioc * , enum bfi_ioc_state ) ;
   enum bfi_ioc_state (*ioc_get_alt_fwstate)(struct bfa_ioc * ) ;
};
struct bfa_flash {
   struct bfa_ioc *ioc ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 op_busy ;
   u32 residue ;
   u32 offset ;
   enum bfa_status status ;
   u8 *dbuf_kva ;
   u64 dbuf_pa ;
   void (*cbfn)(void * , enum bfa_status ) ;
   void *cbarg ;
   u8 *ubuf ;
   u32 addr_off ;
   struct bfa_mbox_cmd mb ;
   struct bfa_ioc_notify ioc_notify ;
};
struct bfi_enet_q {
   union bfi_addr_u pg_tbl ;
   union bfi_addr_u first_entry ;
   u16 pages ;
   u16 page_sz ;
};
struct bfi_enet_txq {
   struct bfi_enet_q q ;
   u8 priority ;
   u8 rsvd[3U] ;
};
struct bfi_enet_rxq {
   struct bfi_enet_q q ;
   u16 rx_buffer_size ;
   u16 rsvd ;
};
struct bfi_enet_cq {
   struct bfi_enet_q q ;
};
struct bfi_enet_ib_cfg {
   u8 int_pkt_dma ;
   u8 int_enabled ;
   u8 int_pkt_enabled ;
   u8 continuous_coalescing ;
   u8 msix ;
   u8 rsvd[3U] ;
   u32 coalescing_timeout ;
   u32 inter_pkt_timeout ;
   u8 inter_pkt_count ;
   u8 rsvd1[3U] ;
};
union __anonunion_intr_395 {
   u16 msix_index ;
   u16 intx_bitmask ;
};
struct bfi_enet_ib {
   union bfi_addr_u index_addr ;
   union __anonunion_intr_395 intr ;
   u16 rsvd ;
};
struct bfi_enet_req {
   struct bfi_msgq_mhdr mh ;
};
struct bfi_enet_enable_req {
   struct bfi_msgq_mhdr mh ;
   u8 enable ;
   u8 rsvd[3U] ;
};
struct bfi_enet_attr_req {
   struct bfi_msgq_mhdr mh ;
};
struct bfi_enet_tx_cfg {
   u8 vlan_mode ;
   u8 rsvd ;
   u16 vlan_id ;
   u8 admit_tagged_frame ;
   u8 apply_vlan_filter ;
   u8 add_to_vswitch ;
   u8 rsvd1[1U] ;
};
struct __anonstruct_q_cfg_396 {
   struct bfi_enet_txq q ;
   struct bfi_enet_ib ib ;
};
struct bfi_enet_tx_cfg_req {
   struct bfi_msgq_mhdr mh ;
   u8 num_queues ;
   u8 rsvd[3U] ;
   struct __anonstruct_q_cfg_396 q_cfg[8U] ;
   struct bfi_enet_ib_cfg ib_cfg ;
   struct bfi_enet_tx_cfg tx_cfg ;
};
struct __anonstruct_q_handles_397 {
   u32 q_dbell ;
   u32 i_dbell ;
   u8 hw_qid ;
   u8 rsvd[3U] ;
};
struct bfi_enet_tx_cfg_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 hw_id ;
   u8 rsvd[2U] ;
   struct __anonstruct_q_handles_397 q_handles[8U] ;
};
enum bfi_enet_hds_type {
    BFI_ENET_HDS_FORCED = 1,
    BFI_ENET_HDS_IPV6_UDP = 2,
    BFI_ENET_HDS_IPV6_TCP = 4,
    BFI_ENET_HDS_IPV4_TCP = 8,
    BFI_ENET_HDS_IPV4_UDP = 16
} ;
struct __anonstruct_hds_398 {
   u8 max_header_size ;
   u8 force_offset ;
   u8 type ;
   u8 rsvd1 ;
};
struct bfi_enet_rx_cfg {
   u8 rxq_type ;
   u8 rsvd[1U] ;
   u16 frame_size ;
   struct __anonstruct_hds_398 hds ;
   u8 multi_buffer ;
   u8 strip_vlan ;
   u8 drop_untagged ;
   u8 rsvd2 ;
};
struct __anonstruct_q_cfg_399 {
   struct bfi_enet_rxq ql ;
   struct bfi_enet_rxq qs ;
   struct bfi_enet_cq cq ;
   struct bfi_enet_ib ib ;
};
struct bfi_enet_rx_cfg_req {
   struct bfi_msgq_mhdr mh ;
   u8 num_queue_sets ;
   u8 rsvd[3U] ;
   struct __anonstruct_q_cfg_399 q_cfg[16U] ;
   struct bfi_enet_ib_cfg ib_cfg ;
   struct bfi_enet_rx_cfg rx_cfg ;
};
struct __anonstruct_q_handles_400 {
   u32 ql_dbell ;
   u32 qs_dbell ;
   u32 i_dbell ;
   u8 hw_lqid ;
   u8 hw_sqid ;
   u8 hw_cqid ;
   u8 rsvd ;
};
struct bfi_enet_rx_cfg_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 hw_id ;
   u8 rsvd[2U] ;
   struct __anonstruct_q_handles_400 q_handles[16U] ;
};
struct bfi_enet_rit_req {
   struct bfi_msgq_mhdr mh ;
   u16 size ;
   u8 rsvd[2U] ;
   u8 table[64U] ;
};
enum bfi_enet_rss_type {
    BFI_ENET_RSS_IPV6 = 1,
    BFI_ENET_RSS_IPV6_TCP = 2,
    BFI_ENET_RSS_IPV4 = 4,
    BFI_ENET_RSS_IPV4_TCP = 8
} ;
struct bfi_enet_rss_cfg {
   u8 type ;
   u8 mask ;
   u8 rsvd[2U] ;
   u32 key[10U] ;
};
struct bfi_enet_rss_cfg_req {
   struct bfi_msgq_mhdr mh ;
   struct bfi_enet_rss_cfg cfg ;
};
struct bfi_enet_ucast_req {
   struct bfi_msgq_mhdr mh ;
   u8 mac_addr[6U] ;
   u8 rsvd[2U] ;
};
struct bfi_enet_mcast_add_req {
   struct bfi_msgq_mhdr mh ;
   u8 mac_addr[6U] ;
   u8 rsvd[2U] ;
};
struct bfi_enet_mcast_del_req {
   struct bfi_msgq_mhdr mh ;
   u16 handle ;
   u8 rsvd[2U] ;
};
struct bfi_enet_rx_vlan_req {
   struct bfi_msgq_mhdr mh ;
   u8 block_idx ;
   u8 rsvd[3U] ;
   u32 bit_mask[16U] ;
};
struct bfi_enet_set_pause_req {
   struct bfi_msgq_mhdr mh ;
   u8 rsvd[2U] ;
   u8 tx_pause ;
   u8 rx_pause ;
};
struct bfi_enet_diag_lb_req {
   struct bfi_msgq_mhdr mh ;
   u8 rsvd[2U] ;
   u8 mode ;
   u8 enable ;
};
struct bfi_enet_stats_req {
   struct bfi_msgq_mhdr mh ;
   u16 stats_mask ;
   u8 rsvd[2U] ;
   u32 rx_enet_mask ;
   u32 tx_enet_mask ;
   union bfi_addr_u host_buffer ;
};
struct bfi_enet_stats_txf {
   u64 ucast_octets ;
   u64 ucast ;
   u64 ucast_vlan ;
   u64 mcast_octets ;
   u64 mcast ;
   u64 mcast_vlan ;
   u64 bcast_octets ;
   u64 bcast ;
   u64 bcast_vlan ;
   u64 errors ;
   u64 filter_vlan ;
   u64 filter_mac_sa ;
};
struct bfi_enet_stats_rxf {
   u64 ucast_octets ;
   u64 ucast ;
   u64 ucast_vlan ;
   u64 mcast_octets ;
   u64 mcast ;
   u64 mcast_vlan ;
   u64 bcast_octets ;
   u64 bcast ;
   u64 bcast_vlan ;
   u64 frame_drops ;
};
struct bfi_enet_stats_fc_tx {
   u64 txf_ucast_octets ;
   u64 txf_ucast ;
   u64 txf_ucast_vlan ;
   u64 txf_mcast_octets ;
   u64 txf_mcast ;
   u64 txf_mcast_vlan ;
   u64 txf_bcast_octets ;
   u64 txf_bcast ;
   u64 txf_bcast_vlan ;
   u64 txf_parity_errors ;
   u64 txf_timeout ;
   u64 txf_fid_parity_errors ;
};
struct bfi_enet_stats_fc_rx {
   u64 rxf_ucast_octets ;
   u64 rxf_ucast ;
   u64 rxf_ucast_vlan ;
   u64 rxf_mcast_octets ;
   u64 rxf_mcast ;
   u64 rxf_mcast_vlan ;
   u64 rxf_bcast_octets ;
   u64 rxf_bcast ;
   u64 rxf_bcast_vlan ;
};
struct bfi_enet_stats_rad {
   u64 rx_frames ;
   u64 rx_octets ;
   u64 rx_vlan_frames ;
   u64 rx_ucast ;
   u64 rx_ucast_octets ;
   u64 rx_ucast_vlan ;
   u64 rx_mcast ;
   u64 rx_mcast_octets ;
   u64 rx_mcast_vlan ;
   u64 rx_bcast ;
   u64 rx_bcast_octets ;
   u64 rx_bcast_vlan ;
   u64 rx_drops ;
};
struct bfi_enet_stats_bpc {
   u64 tx_pause[8U] ;
   u64 tx_zero_pause[8U] ;
   u64 tx_first_pause[8U] ;
   u64 rx_pause[8U] ;
   u64 rx_zero_pause[8U] ;
   u64 rx_first_pause[8U] ;
};
struct bfi_enet_stats_mac {
   u64 stats_clr_cnt ;
   u64 frame_64 ;
   u64 frame_65_127 ;
   u64 frame_128_255 ;
   u64 frame_256_511 ;
   u64 frame_512_1023 ;
   u64 frame_1024_1518 ;
   u64 frame_1519_1522 ;
   u64 rx_bytes ;
   u64 rx_packets ;
   u64 rx_fcs_error ;
   u64 rx_multicast ;
   u64 rx_broadcast ;
   u64 rx_control_frames ;
   u64 rx_pause ;
   u64 rx_unknown_opcode ;
   u64 rx_alignment_error ;
   u64 rx_frame_length_error ;
   u64 rx_code_error ;
   u64 rx_carrier_sense_error ;
   u64 rx_undersize ;
   u64 rx_oversize ;
   u64 rx_fragments ;
   u64 rx_jabber ;
   u64 rx_drop ;
   u64 tx_bytes ;
   u64 tx_packets ;
   u64 tx_multicast ;
   u64 tx_broadcast ;
   u64 tx_pause ;
   u64 tx_deferral ;
   u64 tx_excessive_deferral ;
   u64 tx_single_collision ;
   u64 tx_muliple_collision ;
   u64 tx_late_collision ;
   u64 tx_excessive_collision ;
   u64 tx_total_collision ;
   u64 tx_pause_honored ;
   u64 tx_drop ;
   u64 tx_jabber ;
   u64 tx_fcs_error ;
   u64 tx_control_frame ;
   u64 tx_oversize ;
   u64 tx_undersize ;
   u64 tx_fragments ;
};
struct bfi_enet_stats {
   struct bfi_enet_stats_mac mac_stats ;
   struct bfi_enet_stats_bpc bpc_stats ;
   struct bfi_enet_stats_rad rad_stats ;
   struct bfi_enet_stats_rad rlb_stats ;
   struct bfi_enet_stats_fc_rx fc_rx_stats ;
   struct bfi_enet_stats_fc_tx fc_tx_stats ;
   struct bfi_enet_stats_rxf rxf_stats[32U] ;
   struct bfi_enet_stats_txf txf_stats[32U] ;
};
struct bna_bit_defn {
   u32 mbox_status_bits ;
   u32 mbox_mask_bits ;
   u32 error_status_bits ;
   u32 error_mask_bits ;
   u32 halt_status_bits ;
   u32 halt_mask_bits ;
};
struct bna_reg {
   void *fn_int_status ;
   void *fn_int_mask ;
};
struct bna_dma_addr {
   u32 msb ;
   u32 lsb ;
};
struct bna_txq_wi_vector {
   u16 reserved ;
   u16 length ;
   struct bna_dma_addr host_addr ;
};
struct __anonstruct_wi_402 {
   u8 reserved ;
   u8 num_vectors ;
   u16 opcode ;
   u16 flags ;
   u16 l4_hdr_size_n_offset ;
   u16 vlan_tag ;
   u16 lso_mss ;
   u32 frame_length ;
};
struct __anonstruct_wi_ext_403 {
   u16 reserved ;
   u16 opcode ;
   u32 reserved2[3U] ;
};
union __anonunion_hdr_401 {
   struct __anonstruct_wi_402 wi ;
   struct __anonstruct_wi_ext_403 wi_ext ;
};
struct bna_txq_entry {
   union __anonunion_hdr_401 hdr ;
   struct bna_txq_wi_vector vector[4U] ;
};
struct bna_rxq_entry {
   struct bna_dma_addr host_addr ;
};
struct bna_cq_entry {
   u32 flags ;
   u16 vlan_tag ;
   u16 length ;
   u32 rss_hash ;
   u8 valid ;
   u8 reserved1 ;
   u8 reserved2 ;
   u8 rxq_id ;
};
struct bfa_cee_lldp_str {
   u8 sub_type ;
   u8 len ;
   u8 rsvd[2U] ;
   u8 value[128U] ;
};
struct bfa_cee_lldp_cfg {
   struct bfa_cee_lldp_str chassis_id ;
   struct bfa_cee_lldp_str port_id ;
   struct bfa_cee_lldp_str port_desc ;
   struct bfa_cee_lldp_str sys_name ;
   struct bfa_cee_lldp_str sys_desc ;
   struct bfa_cee_lldp_str mgmt_addr ;
   u16 time_to_live ;
   u16 enabled_system_cap ;
};
struct bfa_cee_dcbx_cfg {
   u8 pgid[8U] ;
   u8 pg_percentage[8U] ;
   u8 pfc_primap ;
   u8 fcoe_primap ;
   u8 iscsi_primap ;
   u8 dcbx_version ;
   u8 lls_fcoe ;
   u8 lls_lan ;
   u8 rsvd[2U] ;
};
struct bfa_cee_attr {
   u8 cee_status ;
   u8 error_reason ;
   struct bfa_cee_lldp_cfg lldp_remote ;
   struct bfa_cee_dcbx_cfg dcbx_remote ;
   u8 src_mac[6U] ;
   u8 link_speed ;
   u8 nw_priority ;
   u8 filler[2U] ;
};
struct bfa_cee_stats {
   u32 lldp_tx_frames ;
   u32 lldp_rx_frames ;
   u32 lldp_rx_frames_invalid ;
   u32 lldp_rx_frames_new ;
   u32 lldp_tlvs_unrecognized ;
   u32 lldp_rx_shutdown_tlvs ;
   u32 lldp_info_aged_out ;
   u32 dcbx_phylink_ups ;
   u32 dcbx_phylink_downs ;
   u32 dcbx_rx_tlvs ;
   u32 dcbx_rx_tlvs_invalid ;
   u32 dcbx_control_tlv_error ;
   u32 dcbx_feature_tlv_error ;
   u32 dcbx_cee_cfg_new ;
   u32 cee_status_down ;
   u32 cee_status_up ;
   u32 cee_hw_cfg_changed ;
   u32 cee_rx_invalid_cfg ;
};
struct bfa_cee_cbfn {
   void (*get_attr_cbfn)(void * , enum bfa_status ) ;
   void *get_attr_cbarg ;
   void (*get_stats_cbfn)(void * , enum bfa_status ) ;
   void *get_stats_cbarg ;
   void (*reset_stats_cbfn)(void * , enum bfa_status ) ;
   void *reset_stats_cbarg ;
};
struct bfa_cee {
   void *dev ;
   bool get_attr_pending ;
   bool get_stats_pending ;
   bool reset_stats_pending ;
   enum bfa_status get_attr_status ;
   enum bfa_status get_stats_status ;
   enum bfa_status reset_stats_status ;
   struct bfa_cee_cbfn cbfn ;
   struct bfa_ioc_notify ioc_notify ;
   struct bfa_cee_attr *attr ;
   struct bfa_cee_stats *stats ;
   struct bfa_dma attr_dma ;
   struct bfa_dma stats_dma ;
   struct bfa_ioc *ioc ;
   struct bfa_mbox_cmd get_cfg_mb ;
   struct bfa_mbox_cmd get_stats_mb ;
   struct bfa_mbox_cmd reset_stats_mb ;
};
struct bfa_msgq;
struct bfa_msgq_cmd_entry {
   struct list_head qe ;
   void (*cbfn)(void * , enum bfa_status ) ;
   void *cbarg ;
   size_t msg_size ;
   struct bfi_msgq_mhdr *msg_hdr ;
};
enum bfa_msgq_cmdq_flags {
    BFA_MSGQ_CMDQ_F_DB_UPDATE = 1
} ;
struct bfa_msgq_cmdq {
   void (*fsm)(void * , int ) ;
   enum bfa_msgq_cmdq_flags flags ;
   u16 producer_index ;
   u16 consumer_index ;
   u16 depth ;
   struct bfa_dma addr ;
   struct bfa_mbox_cmd dbell_mb ;
   u16 token ;
   int offset ;
   int bytes_to_copy ;
   struct bfa_mbox_cmd copy_mb ;
   struct list_head pending_q ;
   struct bfa_msgq *msgq ;
};
enum bfa_msgq_rspq_flags {
    BFA_MSGQ_RSPQ_F_DB_UPDATE = 1
} ;
struct __anonstruct_rsphdlr_404 {
   void (*cbfn)(void * , struct bfi_msgq_mhdr * ) ;
   void *cbarg ;
};
struct bfa_msgq_rspq {
   void (*fsm)(void * , int ) ;
   enum bfa_msgq_rspq_flags flags ;
   u16 producer_index ;
   u16 consumer_index ;
   u16 depth ;
   struct bfa_dma addr ;
   struct bfa_mbox_cmd dbell_mb ;
   int nmclass ;
   struct __anonstruct_rsphdlr_404 rsphdlr[34U] ;
   struct bfa_msgq *msgq ;
};
struct bfa_msgq {
   struct bfa_msgq_cmdq cmdq ;
   struct bfa_msgq_rspq rspq ;
   struct bfa_wc init_wc ;
   struct bfa_mbox_cmd init_mb ;
   struct bfa_ioc_notify ioc_notify ;
   struct bfa_ioc *ioc ;
};
struct bna_mcam_handle;
struct bna_txq;
struct bna_tx;
struct bna_rxq;
struct bna_cq;
struct bna_rx;
struct bna_rxf;
struct bna_enet;
struct bna;
struct bnad;
enum bna_status {
    BNA_STATUS_T_DISABLED = 0,
    BNA_STATUS_T_ENABLED = 1
} ;
enum bna_cleanup_type {
    BNA_HARD_CLEANUP = 0,
    BNA_SOFT_CLEANUP = 1
} ;
enum bna_cb_status {
    BNA_CB_SUCCESS = 0,
    BNA_CB_FAIL = 1,
    BNA_CB_INTERRUPT = 2,
    BNA_CB_BUSY = 3,
    BNA_CB_INVALID_MAC = 4,
    BNA_CB_MCAST_LIST_FULL = 5,
    BNA_CB_UCAST_CAM_FULL = 6,
    BNA_CB_WAITING = 7,
    BNA_CB_NOT_EXEC = 8
} ;
enum bna_res_type {
    BNA_RES_T_MEM = 1,
    BNA_RES_T_INTR = 2
} ;
enum bna_mem_type {
    BNA_MEM_T_KVA = 1,
    BNA_MEM_T_DMA = 2
} ;
enum bna_intr_type {
    BNA_INTR_T_INTX = 1,
    BNA_INTR_T_MSIX = 2
} ;
enum bna_tx_type {
    BNA_TX_T_REGULAR = 0,
    BNA_TX_T_LOOPBACK = 1
} ;
enum bna_tx_flags {
    BNA_TX_F_ENET_STARTED = 1,
    BNA_TX_F_ENABLED = 2,
    BNA_TX_F_BW_UPDATED = 8
} ;
enum bna_tx_mod_flags {
    BNA_TX_MOD_F_ENET_STARTED = 1,
    BNA_TX_MOD_F_ENET_LOOPBACK = 2
} ;
enum bna_rx_type {
    BNA_RX_T_REGULAR = 0,
    BNA_RX_T_LOOPBACK = 1
} ;
enum bna_rxp_type {
    BNA_RXP_SINGLE = 1,
    BNA_RXP_SLR = 2,
    BNA_RXP_HDS = 3
} ;
enum bna_rxmode {
    BNA_RXMODE_PROMISC = 1,
    BNA_RXMODE_DEFAULT = 2,
    BNA_RXMODE_ALLMULTI = 4
} ;
enum bna_rx_flags {
    BNA_RX_F_ENET_STARTED = 1,
    BNA_RX_F_ENABLED = 2
} ;
enum bna_rx_mod_flags {
    BNA_RX_MOD_F_ENET_STARTED = 1,
    BNA_RX_MOD_F_ENET_LOOPBACK = 2
} ;
enum bna_enet_type {
    BNA_ENET_T_REGULAR = 0,
    BNA_ENET_T_LOOPBACK_INTERNAL = 1,
    BNA_ENET_T_LOOPBACK_EXTERNAL = 2
} ;
enum bna_link_status {
    BNA_LINK_DOWN = 0,
    BNA_LINK_UP = 1,
    BNA_CEE_UP = 2
} ;
enum bna_ethport_flags {
    BNA_ETHPORT_F_ADMIN_UP = 1,
    BNA_ETHPORT_F_PORT_ENABLED = 2,
    BNA_ETHPORT_F_RX_STARTED = 4
} ;
enum bna_enet_flags {
    BNA_ENET_F_IOCETH_READY = 1,
    BNA_ENET_F_ENABLED = 2,
    BNA_ENET_F_PAUSE_CHANGED = 4,
    BNA_ENET_F_MTU_CHANGED = 8
} ;
enum bna_rss_flags {
    BNA_RSS_F_RIT_PENDING = 1,
    BNA_RSS_F_CFG_PENDING = 2,
    BNA_RSS_F_STATUS_PENDING = 4
} ;
enum bna_mod_flags {
    BNA_MOD_F_INIT_DONE = 1
} ;
struct bna_ident {
   int id ;
   char name[64U] ;
};
struct bna_mac {
   struct list_head qe ;
   u8 addr[6U] ;
   struct bna_mcam_handle *handle ;
};
struct bna_mem_descr {
   u32 len ;
   void *kva ;
   struct bna_dma_addr dma ;
};
struct bna_mem_info {
   enum bna_mem_type mem_type ;
   u32 len ;
   u32 num ;
   u32 align_sz ;
   struct bna_mem_descr *mdl ;
   void *cookie ;
};
struct bna_intr_descr {
   int vector ;
};
struct bna_intr_info {
   enum bna_intr_type intr_type ;
   int num ;
   struct bna_intr_descr *idl ;
};
union bna_res_u {
   struct bna_mem_info mem_info ;
   struct bna_intr_info intr_info ;
};
struct bna_res_info {
   enum bna_res_type res_type ;
   union bna_res_u res_u ;
};
struct bna_qpt {
   struct bna_dma_addr hw_qpt_ptr ;
   void *kv_qpt_ptr ;
   u32 page_count ;
   u32 page_size ;
};
struct bna_attr {
   bool fw_query_complete ;
   int num_txq ;
   int num_rxp ;
   int num_ucmac ;
   int num_mcmac ;
   int max_rit_size ;
};
struct bna_ioceth {
   void (*fsm)(void * , int ) ;
   struct bfa_ioc ioc ;
   struct bna_attr attr ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   struct bfi_enet_attr_req attr_req ;
   void (*stop_cbfn)(struct bnad * ) ;
   struct bnad *stop_cbarg ;
   struct bna *bna ;
};
struct bna_pause_config {
   enum bna_status tx_pause ;
   enum bna_status rx_pause ;
};
struct bna_enet {
   void (*fsm)(void * , int ) ;
   enum bna_enet_flags flags ;
   enum bna_enet_type type ;
   struct bna_pause_config pause_config ;
   int mtu ;
   void (*stop_cbfn)(void * ) ;
   void *stop_cbarg ;
   void (*mtu_cbfn)(struct bnad * ) ;
   struct bfa_wc chld_stop_wc ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   struct bfi_enet_set_pause_req pause_req ;
   struct bna *bna ;
};
union __anonunion_bfi_enet_cmd_405 {
   struct bfi_enet_enable_req admin_req ;
   struct bfi_enet_diag_lb_req lpbk_req ;
};
struct bna_ethport {
   void (*fsm)(void * , int ) ;
   enum bna_ethport_flags flags ;
   enum bna_link_status link_status ;
   int rx_started_count ;
   void (*stop_cbfn)(struct bna_enet * ) ;
   void (*adminup_cbfn)(struct bnad * , enum bna_cb_status ) ;
   void (*link_cbfn)(struct bnad * , enum bna_link_status ) ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_405 bfi_enet_cmd ;
   struct bna *bna ;
};
struct bna_ib_dbell {
   void *doorbell_addr ;
   u32 doorbell_ack ;
};
struct bna_ib {
   struct bna_dma_addr ib_seg_host_addr ;
   void *ib_seg_host_addr_kva ;
   struct bna_ib_dbell door_bell ;
   enum bna_intr_type intr_type ;
   int intr_vector ;
   u8 coalescing_timeo ;
   int interpkt_count ;
   int interpkt_timeo ;
};
struct bna_tcb {
   void **sw_qpt ;
   void *sw_q ;
   void *unmap_q ;
   u32 producer_index ;
   u32 consumer_index ;
   u32 volatile *hw_consumer_index ;
   u32 q_depth ;
   void *q_dbell ;
   struct bna_ib_dbell *i_dbell ;
   struct bna_txq *txq ;
   struct bnad *bnad ;
   void *priv ;
   enum bna_intr_type intr_type ;
   int intr_vector ;
   u8 priority ;
   unsigned long flags ;
   int id ;
   char name[16U] ;
};
struct bna_txq {
   struct list_head qe ;
   u8 priority ;
   struct bna_qpt qpt ;
   struct bna_tcb *tcb ;
   struct bna_ib ib ;
   struct bna_tx *tx ;
   int hw_id ;
   u64 tx_packets ;
   u64 tx_bytes ;
};
union __anonunion_bfi_enet_cmd_406 {
   struct bfi_enet_tx_cfg_req cfg_req ;
   struct bfi_enet_req req ;
   struct bfi_enet_tx_cfg_rsp cfg_rsp ;
};
struct bna_tx {
   struct list_head qe ;
   int rid ;
   int hw_id ;
   void (*fsm)(void * , int ) ;
   enum bna_tx_flags flags ;
   enum bna_tx_type type ;
   int num_txq ;
   struct list_head txq_q ;
   u16 txf_vlan_id ;
   void (*tcb_setup_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tcb_destroy_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tx_stall_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_resume_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_cleanup_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*stop_cbfn)(void * , struct bna_tx * ) ;
   void *stop_cbarg ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_406 bfi_enet_cmd ;
   struct bna *bna ;
   void *priv ;
};
struct bna_tx_config {
   int num_txq ;
   int txq_depth ;
   int coalescing_timeo ;
   enum bna_tx_type tx_type ;
};
struct bna_tx_event_cbfn {
   void (*tcb_setup_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tcb_destroy_cbfn)(struct bnad * , struct bna_tcb * ) ;
   void (*tx_stall_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_resume_cbfn)(struct bnad * , struct bna_tx * ) ;
   void (*tx_cleanup_cbfn)(struct bnad * , struct bna_tx * ) ;
};
struct bna_tx_mod {
   struct bna_tx *tx ;
   struct bna_txq *txq ;
   struct list_head tx_free_q ;
   struct list_head tx_active_q ;
   struct list_head txq_free_q ;
   void (*stop_cbfn)(struct bna_enet * ) ;
   struct bfa_wc tx_stop_wc ;
   enum bna_tx_mod_flags flags ;
   u8 prio_map ;
   int default_prio ;
   int iscsi_over_cee ;
   int iscsi_prio ;
   int prio_reconfigured ;
   u32 rid_mask ;
   struct bna *bna ;
};
struct bna_ccb;
struct bna_rcb {
   void **sw_qpt ;
   void *sw_q ;
   void *unmap_q ;
   u32 producer_index ;
   u32 consumer_index ;
   u32 q_depth ;
   void *q_dbell ;
   struct bna_rxq *rxq ;
   struct bna_ccb *ccb ;
   struct bnad *bnad ;
   void *priv ;
   unsigned long flags ;
   int id ;
};
struct bna_rxp;
struct bna_rxq {
   struct list_head qe ;
   int buffer_size ;
   int q_depth ;
   u32 num_vecs ;
   enum bna_status multi_buffer ;
   struct bna_qpt qpt ;
   struct bna_rcb *rcb ;
   struct bna_rxp *rxp ;
   struct bna_rx *rx ;
   int hw_id ;
   u64 rx_packets ;
   u64 rx_bytes ;
   u64 rx_packets_with_error ;
   u64 rxbuf_alloc_failed ;
};
struct __anonstruct_hds_407 {
   struct bna_rxq *hdr ;
   struct bna_rxq *data ;
};
struct __anonstruct_slr_408 {
   struct bna_rxq *small ;
   struct bna_rxq *large ;
};
struct __anonstruct_single_409 {
   struct bna_rxq *only ;
   struct bna_rxq *reserved ;
};
union bna_rxq_u {
   struct __anonstruct_hds_407 hds ;
   struct __anonstruct_slr_408 slr ;
   struct __anonstruct_single_409 single ;
};
struct bna_pkt_rate {
   u32 small_pkt_cnt ;
   u32 large_pkt_cnt ;
};
struct bna_ccb {
   void **sw_qpt ;
   void *sw_q ;
   u32 producer_index ;
   u32 volatile *hw_producer_index ;
   u32 q_depth ;
   struct bna_ib_dbell *i_dbell ;
   struct bna_rcb *rcb[2U] ;
   void *ctrl ;
   struct bna_pkt_rate pkt_rate ;
   u32 pkts_una ;
   u32 bytes_per_intr ;
   struct bna_cq *cq ;
   struct bnad *bnad ;
   void *priv ;
   enum bna_intr_type intr_type ;
   int intr_vector ;
   u8 rx_coalescing_timeo ;
   int id ;
   char name[16U] ;
};
struct bna_cq {
   struct bna_qpt qpt ;
   struct bna_ccb *ccb ;
   struct bna_ib ib ;
   struct bna_rx *rx ;
};
struct bna_rss_config {
   enum bfi_enet_rss_type hash_type ;
   u8 hash_mask ;
   u32 toeplitz_hash_key[10U] ;
};
struct bna_hds_config {
   enum bfi_enet_hds_type hdr_type ;
   int forced_offset ;
};
struct bna_rx_config {
   enum bna_rx_type rx_type ;
   int num_paths ;
   enum bna_rxp_type rxp_type ;
   int coalescing_timeo ;
   u32 frame_size ;
   u32 q1_depth ;
   u32 q1_buf_size ;
   u32 q0_depth ;
   u32 q0_buf_size ;
   u32 q0_num_vecs ;
   enum bna_status q0_multi_buf ;
   enum bna_status rss_status ;
   struct bna_rss_config rss_config ;
   struct bna_hds_config hds_config ;
   enum bna_status vlan_strip_status ;
};
struct bna_rxp {
   struct list_head qe ;
   enum bna_rxp_type type ;
   union bna_rxq_u rxq ;
   struct bna_cq cq ;
   struct bna_rx *rx ;
   int vector ;
   int hw_id ;
};
union __anonunion_bfi_enet_cmd_410 {
   struct bfi_enet_enable_req req ;
   struct bfi_enet_rss_cfg_req rss_req ;
   struct bfi_enet_rit_req rit_req ;
   struct bfi_enet_rx_vlan_req vlan_req ;
   struct bfi_enet_mcast_add_req mcast_add_req ;
   struct bfi_enet_mcast_del_req mcast_del_req ;
   struct bfi_enet_ucast_req ucast_req ;
};
struct bna_rxf {
   void (*fsm)(void * , int ) ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_410 bfi_enet_cmd ;
   void (*start_cbfn)(struct bna_rx * ) ;
   struct bna_rx *start_cbarg ;
   void (*stop_cbfn)(struct bna_rx * ) ;
   struct bna_rx *stop_cbarg ;
   void (*cam_fltr_cbfn)(struct bnad * , struct bna_rx * ) ;
   struct bnad *cam_fltr_cbarg ;
   struct list_head ucast_pending_add_q ;
   struct list_head ucast_pending_del_q ;
   struct bna_mac *ucast_pending_mac ;
   int ucast_pending_set ;
   struct list_head ucast_active_q ;
   struct bna_mac ucast_active_mac ;
   int ucast_active_set ;
   struct list_head mcast_pending_add_q ;
   struct list_head mcast_pending_del_q ;
   struct list_head mcast_active_q ;
   struct list_head mcast_handle_q ;
   enum bna_rxmode rxmode_pending ;
   enum bna_rxmode rxmode_pending_bitmask ;
   enum bna_rxmode rxmode_active ;
   u8 vlan_pending_bitmask ;
   enum bna_status vlan_filter_status ;
   u32 vlan_filter_table[128U] ;
   bool vlan_strip_pending ;
   enum bna_status vlan_strip_status ;
   enum bna_rss_flags rss_pending ;
   enum bna_status rss_status ;
   struct bna_rss_config rss_cfg ;
   u8 *rit ;
   int rit_size ;
   struct bna_rx *rx ;
};
union __anonunion_bfi_enet_cmd_411 {
   struct bfi_enet_rx_cfg_req cfg_req ;
   struct bfi_enet_req req ;
   struct bfi_enet_rx_cfg_rsp cfg_rsp ;
};
struct bna_rx {
   struct list_head qe ;
   int rid ;
   int hw_id ;
   void (*fsm)(void * , int ) ;
   enum bna_rx_type type ;
   int num_paths ;
   struct list_head rxp_q ;
   struct bna_hds_config hds_cfg ;
   struct bna_rxf rxf ;
   enum bna_rx_flags rx_flags ;
   struct bfa_msgq_cmd_entry msgq_cmd ;
   union __anonunion_bfi_enet_cmd_411 bfi_enet_cmd ;
   void (*rcb_setup_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*rcb_destroy_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*ccb_setup_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*ccb_destroy_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*rx_stall_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_cleanup_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_post_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*stop_cbfn)(void * , struct bna_rx * ) ;
   void *stop_cbarg ;
   struct bna *bna ;
   void *priv ;
};
struct bna_rx_event_cbfn {
   void (*rcb_setup_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*rcb_destroy_cbfn)(struct bnad * , struct bna_rcb * ) ;
   void (*ccb_setup_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*ccb_destroy_cbfn)(struct bnad * , struct bna_ccb * ) ;
   void (*rx_stall_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_cleanup_cbfn)(struct bnad * , struct bna_rx * ) ;
   void (*rx_post_cbfn)(struct bnad * , struct bna_rx * ) ;
};
struct bna_rx_mod {
   struct bna *bna ;
   struct bna_rx *rx ;
   struct bna_rxp *rxp ;
   struct bna_rxq *rxq ;
   struct list_head rx_free_q ;
   struct list_head rx_active_q ;
   int rx_free_count ;
   struct list_head rxp_free_q ;
   int rxp_free_count ;
   struct list_head rxq_free_q ;
   int rxq_free_count ;
   enum bna_rx_mod_flags flags ;
   void (*stop_cbfn)(struct bna_enet * ) ;
   struct bfa_wc rx_stop_wc ;
   u32 dim_vector[8U][2U] ;
   u32 rid_mask ;
};
struct bna_ucam_mod {
   struct bna_mac *ucmac ;
   struct list_head free_q ;
   struct list_head del_q ;
   struct bna *bna ;
};
struct bna_mcam_handle {
   struct list_head qe ;
   int handle ;
   int refcnt ;
};
struct bna_mcam_mod {
   struct bna_mac *mcmac ;
   struct bna_mcam_handle *mchandle ;
   struct list_head free_q ;
   struct list_head del_q ;
   struct list_head free_handle_q ;
   struct bna *bna ;
};
struct bna_stats {
   struct bna_dma_addr hw_stats_dma ;
   struct bfi_enet_stats *hw_stats_kva ;
   struct bfi_enet_stats hw_stats ;
};
struct bna_stats_mod {
   bool ioc_ready ;
   bool stats_get_busy ;
   bool stats_clr_busy ;
   struct bfa_msgq_cmd_entry stats_get_cmd ;
   struct bfa_msgq_cmd_entry stats_clr_cmd ;
   struct bfi_enet_stats_req stats_get ;
   struct bfi_enet_stats_req stats_clr ;
};
struct bna {
   struct bna_ident ident ;
   struct bfa_pcidev pcidev ;
   struct bna_reg regs ;
   struct bna_bit_defn bits ;
   struct bna_stats stats ;
   struct bna_ioceth ioceth ;
   struct bfa_cee cee ;
   struct bfa_flash flash ;
   struct bfa_msgq msgq ;
   struct bna_ethport ethport ;
   struct bna_enet enet ;
   struct bna_stats_mod stats_mod ;
   struct bna_tx_mod tx_mod ;
   struct bna_rx_mod rx_mod ;
   struct bna_ucam_mod ucam_mod ;
   struct bna_mcam_mod mcam_mod ;
   enum bna_mod_flags mod_flags ;
   int default_mode_rid ;
   int promisc_rid ;
   struct bnad *bnad ;
};
struct bnad_rx_ctrl {
   struct bna_ccb *ccb ;
   struct bnad *bnad ;
   unsigned long flags ;
   struct napi_struct napi ;
   u64 rx_intr_ctr ;
   u64 rx_poll_ctr ;
   u64 rx_schedule ;
   u64 rx_keep_poll ;
   u64 rx_complete ;
};
enum bnad_intr_source {
    BNAD_INTR_TX = 1,
    BNAD_INTR_RX = 2
} ;
struct bnad_iocmd_comp {
   struct bnad *bnad ;
   struct completion comp ;
   int comp_status ;
};
struct bnad_completion {
   struct completion ioc_comp ;
   struct completion ucast_comp ;
   struct completion mcast_comp ;
   struct completion tx_comp ;
   struct completion rx_comp ;
   struct completion stats_comp ;
   struct completion enet_comp ;
   struct completion mtu_comp ;
   u8 ioc_comp_status ;
   u8 ucast_comp_status ;
   u8 mcast_comp_status ;
   u8 tx_comp_status ;
   u8 rx_comp_status ;
   u8 stats_comp_status ;
   u8 port_comp_status ;
   u8 mtu_comp_status ;
};
struct bnad_drv_stats {
   u64 netif_queue_stop ;
   u64 netif_queue_wakeup ;
   u64 netif_queue_stopped ;
   u64 tso4 ;
   u64 tso6 ;
   u64 tso_err ;
   u64 tcpcsum_offload ;
   u64 udpcsum_offload ;
   u64 csum_help ;
   u64 tx_skb_too_short ;
   u64 tx_skb_stopping ;
   u64 tx_skb_max_vectors ;
   u64 tx_skb_mss_too_long ;
   u64 tx_skb_tso_too_short ;
   u64 tx_skb_tso_prepare ;
   u64 tx_skb_non_tso_too_long ;
   u64 tx_skb_tcp_hdr ;
   u64 tx_skb_udp_hdr ;
   u64 tx_skb_csum_err ;
   u64 tx_skb_headlen_too_long ;
   u64 tx_skb_headlen_zero ;
   u64 tx_skb_frag_zero ;
   u64 tx_skb_len_mismatch ;
   u64 hw_stats_updates ;
   u64 netif_rx_dropped ;
   u64 link_toggle ;
   u64 cee_toggle ;
   u64 rxp_info_alloc_failed ;
   u64 mbox_intr_disabled ;
   u64 mbox_intr_enabled ;
   u64 tx_unmap_q_alloc_failed ;
   u64 rx_unmap_q_alloc_failed ;
   u64 rxbuf_alloc_failed ;
};
struct bnad_stats {
   struct bnad_drv_stats drv_stats ;
   struct bna_stats *bna_stats ;
};
struct bnad_tx_res_info {
   struct bna_res_info res_info[7U] ;
};
struct bnad_rx_res_info {
   struct bna_res_info res_info[16U] ;
};
struct bnad_tx_info {
   struct bna_tx *tx ;
   struct bna_tcb *tcb[8U] ;
   u32 tx_id ;
   struct delayed_work tx_cleanup_work ;
};
struct bnad_rx_info {
   struct bna_rx *rx ;
   struct bnad_rx_ctrl rx_ctrl[16U] ;
   u32 rx_id ;
   struct work_struct rx_cleanup_work ;
};
struct bnad_tx_vector {
   dma_addr_t dma_addr ;
   __u32 dma_len ;
};
struct bnad_tx_unmap {
   struct sk_buff *skb ;
   u32 nvecs ;
   struct bnad_tx_vector vectors[4U] ;
};
struct bnad_rx_vector {
   dma_addr_t dma_addr ;
   u32 len ;
};
struct bnad_rx_unmap {
   struct page *page ;
   struct sk_buff *skb ;
   struct bnad_rx_vector vector ;
   u32 page_offset ;
};
enum bnad_rxbuf_type {
    BNAD_RXBUF_NONE = 0,
    BNAD_RXBUF_SK_BUFF = 1,
    BNAD_RXBUF_PAGE = 2,
    BNAD_RXBUF_MULTI_BUFF = 3
} ;
struct bnad_rx_unmap_q {
   int reuse_pi ;
   int alloc_order ;
   u32 map_size ;
   enum bnad_rxbuf_type type ;
   struct bnad_rx_unmap unmap[0U] ;
};
struct bnad_diag;
struct bnad {
   struct net_device *netdev ;
   u32 id ;
   struct list_head list_entry ;
   struct bnad_tx_info tx_info[1U] ;
   struct bnad_rx_info rx_info[1U] ;
   unsigned long active_vlans[64U] ;
   u32 num_tx ;
   u32 num_rx ;
   u32 num_txq_per_tx ;
   u32 num_rxp_per_rx ;
   u32 txq_depth ;
   u32 rxq_depth ;
   u8 tx_coalescing_timeo ;
   u8 rx_coalescing_timeo ;
   struct bna_rx_config rx_config[1U] ;
   struct bna_tx_config tx_config[1U] ;
   void *bar0 ;
   struct bna bna ;
   u32 cfg_flags ;
   unsigned long run_flags ;
   struct pci_dev *pcidev ;
   u64 mmio_start ;
   u64 mmio_len ;
   u32 msix_num ;
   struct msix_entry *msix_table ;
   struct mutex conf_mutex ;
   spinlock_t bna_lock ;
   struct timer_list ioc_timer ;
   struct timer_list dim_timer ;
   struct timer_list stats_timer ;
   struct bna_res_info res_info[4U] ;
   struct bna_res_info mod_res_info[8U] ;
   struct bnad_tx_res_info tx_res_info[1U] ;
   struct bnad_rx_res_info rx_res_info[1U] ;
   struct bnad_completion bnad_completions ;
   u8 perm_addr[6U] ;
   struct workqueue_struct *work_q ;
   struct bnad_stats stats ;
   struct bnad_diag *diag ;
   char adapter_name[64U] ;
   char port_name[64U] ;
   char mbox_irq_name[64U] ;
   char wq_name[64U] ;
   char *regdata ;
   u32 reglen ;
   struct dentry *bnad_dentry_files[5U] ;
   struct dentry *port_debugfs_root ;
};
typedef bool ldv_func_ret_type___2;
typedef bool ldv_func_ret_type___3;
typedef bool ldv_func_ret_type___4;
typedef bool ldv_func_ret_type___5;
typedef int ldv_func_ret_type___6;
typedef int ldv_func_ret_type___7;
typedef int ldv_func_ret_type___8;
typedef int ldv_func_ret_type___9;
typedef int ldv_func_ret_type___10;
typedef int ldv_func_ret_type___11;
typedef int ldv_func_ret_type___12;
typedef int ldv_func_ret_type___13;
typedef int ldv_func_ret_type___14;
typedef int ldv_func_ret_type___15;
typedef int ldv_func_ret_type___16;
typedef int ldv_func_ret_type___17;
typedef int ldv_func_ret_type___18;
typedef int ldv_func_ret_type___19;
typedef int ldv_func_ret_type___20;
typedef int ldv_func_ret_type___21;
typedef int ldv_func_ret_type___22;
enum hrtimer_restart;
struct bfa_adapter_attr {
   char manufacturer[8U] ;
   char serial_num[12U] ;
   u32 card_type ;
   char model[16U] ;
   char model_descr[128U] ;
   u64 pwwn ;
   char node_symname[256U] ;
   char hw_ver[64U] ;
   char fw_ver[64U] ;
   char optrom_ver[64U] ;
   char os_type[64U] ;
   struct bfa_mfg_vpd vpd ;
   u8 mac[6U] ;
   u8 nports ;
   u8 max_speed ;
   u8 prototype ;
   char asic_rev ;
   u8 pcie_gen ;
   u8 pcie_lanes_orig ;
   u8 pcie_lanes ;
   u8 cna_capable ;
   u8 is_mezz ;
   u8 trunk_capable ;
};
struct bfa_ioc_driver_attr {
   char driver[16U] ;
   char driver_ver[64U] ;
   char fw_ver[64U] ;
   char bios_ver[64U] ;
   char efi_ver[64U] ;
   char ob_ver[64U] ;
};
struct bfa_ioc_pci_attr {
   u16 vendor_id ;
   u16 device_id ;
   u16 ssid ;
   u16 ssvid ;
   u32 pcifn ;
   u32 rsvd ;
   char chip_rev[8U] ;
};
enum bfa_ioc_state {
    BFA_IOC_UNINIT = 1,
    BFA_IOC_RESET = 2,
    BFA_IOC_SEMWAIT = 3,
    BFA_IOC_HWINIT = 4,
    BFA_IOC_GETATTR = 5,
    BFA_IOC_OPERATIONAL = 6,
    BFA_IOC_INITFAIL = 7,
    BFA_IOC_FAIL = 8,
    BFA_IOC_DISABLING = 9,
    BFA_IOC_DISABLED = 10,
    BFA_IOC_FWMISMATCH = 11,
    BFA_IOC_ENABLING = 12,
    BFA_IOC_HWFAIL = 13
} ;
enum bfa_ioc_type {
    BFA_IOC_TYPE_FC = 1,
    BFA_IOC_TYPE_FCoE = 2,
    BFA_IOC_TYPE_LL = 3
} ;
struct bfa_ioc_attr {
   enum bfa_ioc_type ioc_type ;
   enum bfa_ioc_state state ;
   struct bfa_adapter_attr adapter_attr ;
   struct bfa_ioc_driver_attr driver_attr ;
   struct bfa_ioc_pci_attr pci_attr ;
   u8 port_id ;
   u8 port_mode ;
   u8 cap_bm ;
   u8 port_mode_cfg ;
   u8 def_fn ;
   u8 rsvd[3U] ;
};
struct bfa_flash_part_attr {
   u32 part_type ;
   u32 part_instance ;
   u32 part_off ;
   u32 part_size ;
   u32 part_len ;
   u32 part_status ;
   char rsv[8U] ;
};
struct bfa_flash_attr {
   u32 status ;
   u32 npart ;
   struct bfa_flash_part_attr part[32U] ;
};
enum hrtimer_restart;
struct bnad_drvinfo {
   struct bfa_ioc_attr ioc_attr ;
   struct bfa_cee_attr cee_attr ;
   struct bfa_flash_attr flash_attr ;
   u32 cee_status ;
   u32 flash_status ;
};
struct bnad_debug_info {
   char *debug_buffer ;
   void *i_private ;
   int buffer_len ;
};
struct bnad_debugfs_entry {
   char const *name ;
   umode_t mode ;
   struct file_operations const *fops ;
};
enum hrtimer_restart;
enum bfi_mclass {
    BFI_MC_IOC = 1,
    BFI_MC_DIAG = 2,
    BFI_MC_FLASH = 3,
    BFI_MC_CEE = 4,
    BFI_MC_FCPORT = 5,
    BFI_MC_IOCFC = 6,
    BFI_MC_LL = 7,
    BFI_MC_UF = 8,
    BFI_MC_FCXP = 9,
    BFI_MC_LPS = 10,
    BFI_MC_RPORT = 11,
    BFI_MC_ITNIM = 12,
    BFI_MC_IOIM_READ = 13,
    BFI_MC_IOIM_WRITE = 14,
    BFI_MC_IOIM_IO = 15,
    BFI_MC_IOIM = 16,
    BFI_MC_IOIM_IOCOM = 17,
    BFI_MC_TSKIM = 18,
    BFI_MC_SBOOT = 19,
    BFI_MC_IPFC = 20,
    BFI_MC_PORT = 21,
    BFI_MC_SFP = 22,
    BFI_MC_MSGQ = 23,
    BFI_MC_ENET = 24,
    BFI_MC_PHY = 25,
    BFI_MC_NBOOT = 26,
    BFI_MC_TIO_READ = 27,
    BFI_MC_TIO_WRITE = 28,
    BFI_MC_TIO_DATA_XFERED = 29,
    BFI_MC_TIO_IO = 30,
    BFI_MC_TIO = 31,
    BFI_MC_MFG = 32,
    BFI_MC_EDMA = 33,
    BFI_MC_MAX = 34
} ;
struct bfi_enet_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 rsvd ;
   u16 cmd_offset ;
};
struct bfi_enet_attr_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 rsvd ;
   u16 cmd_offset ;
   u32 max_cfg ;
   u32 max_ucmac ;
   u32 rit_size ;
};
struct bna_reg_offset {
   u32 fn_int_status ;
   u32 fn_int_mask ;
};
enum bna_ethport_event {
    ETHPORT_E_START = 1,
    ETHPORT_E_STOP = 2,
    ETHPORT_E_FAIL = 3,
    ETHPORT_E_UP = 4,
    ETHPORT_E_DOWN = 5,
    ETHPORT_E_FWRESP_UP_OK = 6,
    ETHPORT_E_FWRESP_DOWN = 7,
    ETHPORT_E_FWRESP_UP_FAIL = 8
} ;
enum bna_enet_event {
    ENET_E_START = 1,
    ENET_E_STOP = 2,
    ENET_E_FAIL = 3,
    ENET_E_PAUSE_CFG = 4,
    ENET_E_MTU_CFG = 5,
    ENET_E_FWRESP_PAUSE = 6,
    ENET_E_CHLD_STOPPED = 7
} ;
enum bna_ioceth_event {
    IOCETH_E_ENABLE = 1,
    IOCETH_E_DISABLE = 2,
    IOCETH_E_IOC_RESET = 3,
    IOCETH_E_IOC_FAILED = 4,
    IOCETH_E_IOC_READY = 5,
    IOCETH_E_ENET_ATTR_RESP = 6,
    IOCETH_E_ENET_STOPPED = 7,
    IOCETH_E_IOC_DISABLED = 8
} ;
enum hrtimer_restart;
enum bfi_enet_h2i_msgs {
    BFI_ENET_H2I_RX_CFG_SET_REQ = 1,
    BFI_ENET_H2I_RX_CFG_CLR_REQ = 2,
    BFI_ENET_H2I_RIT_CFG_REQ = 3,
    BFI_ENET_H2I_RSS_CFG_REQ = 4,
    BFI_ENET_H2I_RSS_ENABLE_REQ = 5,
    BFI_ENET_H2I_RX_PROMISCUOUS_REQ = 6,
    BFI_ENET_H2I_RX_DEFAULT_REQ = 7,
    BFI_ENET_H2I_MAC_UCAST_SET_REQ = 8,
    BFI_ENET_H2I_MAC_UCAST_CLR_REQ = 9,
    BFI_ENET_H2I_MAC_UCAST_ADD_REQ = 10,
    BFI_ENET_H2I_MAC_UCAST_DEL_REQ = 11,
    BFI_ENET_H2I_MAC_MCAST_ADD_REQ = 12,
    BFI_ENET_H2I_MAC_MCAST_DEL_REQ = 13,
    BFI_ENET_H2I_MAC_MCAST_FILTER_REQ = 14,
    BFI_ENET_H2I_RX_VLAN_SET_REQ = 15,
    BFI_ENET_H2I_RX_VLAN_STRIP_ENABLE_REQ = 16,
    BFI_ENET_H2I_TX_CFG_SET_REQ = 17,
    BFI_ENET_H2I_TX_CFG_CLR_REQ = 18,
    BFI_ENET_H2I_PORT_ADMIN_UP_REQ = 19,
    BFI_ENET_H2I_SET_PAUSE_REQ = 20,
    BFI_ENET_H2I_DIAG_LOOPBACK_REQ = 21,
    BFI_ENET_H2I_GET_ATTR_REQ = 22,
    BFI_ENET_H2I_STATS_GET_REQ = 23,
    BFI_ENET_H2I_STATS_CLR_REQ = 24,
    BFI_ENET_H2I_WOL_MAGIC_REQ = 25,
    BFI_ENET_H2I_WOL_FRAME_REQ = 26,
    BFI_ENET_H2I_MAX = 27
} ;
struct bfi_enet_mcast_add_rsp {
   struct bfi_msgq_mhdr mh ;
   u8 error ;
   u8 rsvd ;
   u16 cmd_offset ;
   u16 handle ;
   u8 rsvd1[2U] ;
};
enum bna_rx_event {
    RX_E_START = 1,
    RX_E_STOP = 2,
    RX_E_FAIL = 3,
    RX_E_STARTED = 4,
    RX_E_STOPPED = 5,
    RX_E_RXF_STARTED = 6,
    RX_E_RXF_STOPPED = 7,
    RX_E_CLEANUP_DONE = 8
} ;
enum bna_rxf_event {
    RXF_E_START = 1,
    RXF_E_STOP = 2,
    RXF_E_FAIL = 3,
    RXF_E_CONFIG = 4,
    RXF_E_FW_RESP = 7
} ;
enum bna_tx_event {
    TX_E_START = 1,
    TX_E_STOP = 2,
    TX_E_FAIL = 3,
    TX_E_STARTED = 4,
    TX_E_STOPPED = 5,
    TX_E_CLEANUP_DONE = 7,
    TX_E_BW_UPDATE = 8
} ;
enum hrtimer_restart;
struct bfi_msgq {
   union bfi_addr_u addr ;
   u16 q_depth ;
   u8 rsvd[2U] ;
};
struct bfi_msgq_cfg_req {
   struct bfi_mhdr mh ;
   struct bfi_msgq cmdq ;
   struct bfi_msgq rspq ;
};
union __anonunion_idx_334 {
   u16 cmdq_pi ;
   u16 rspq_ci ;
};
struct bfi_msgq_h2i_db {
   struct bfi_mhdr mh ;
   union __anonunion_idx_334 idx ;
};
union __anonunion_idx_335 {
   u16 rspq_pi ;
   u16 cmdq_ci ;
};
struct bfi_msgq_i2h_db {
   struct bfi_mhdr mh ;
   union __anonunion_idx_335 idx ;
};
struct bfi_msgq_h2i_cmdq_copy_rsp {
   struct bfi_mhdr mh ;
   u8 data[28U] ;
};
struct bfi_msgq_i2h_cmdq_copy_req {
   struct bfi_mhdr mh ;
   u16 offset ;
   u16 len ;
};
enum cmdq_event {
    CMDQ_E_START = 1,
    CMDQ_E_STOP = 2,
    CMDQ_E_FAIL = 3,
    CMDQ_E_POST = 4,
    CMDQ_E_INIT_RESP = 5,
    CMDQ_E_DB_READY = 6
} ;
enum rspq_event {
    RSPQ_E_START = 1,
    RSPQ_E_STOP = 2,
    RSPQ_E_FAIL = 3,
    RSPQ_E_RESP = 4,
    RSPQ_E_INIT_RESP = 5,
    RSPQ_E_DB_READY = 6
} ;
typedef __kernel_long_t __kernel_suseconds_t;
struct timeval {
   __kernel_time_t tv_sec ;
   __kernel_suseconds_t tv_usec ;
};
enum hrtimer_restart;
struct bfa_sm_table {
   void (*sm)(void * , int ) ;
   int state ;
   char *name ;
};
struct bfi_alen {
   union bfi_addr_u al_addr ;
   u32 al_len ;
};
struct bfi_ioc_getattr_req {
   struct bfi_mhdr mh ;
   union bfi_addr_u attr_addr ;
};
struct bfi_ioc_fwver {
   u8 major ;
   u8 minor ;
   u8 maint ;
   u8 patch ;
   u8 phase ;
   u8 build ;
   u8 rsvd[2U] ;
};
struct bfi_ioc_image_hdr {
   u32 signature ;
   u8 asic_gen ;
   u8 asic_mode ;
   u8 port0_mode ;
   u8 port1_mode ;
   u32 exec ;
   u32 bootenv ;
   u32 rsvd_b[2U] ;
   struct bfi_ioc_fwver fwver ;
   u32 md5sum[4U] ;
};
enum bfi_ioc_img_ver_cmp {
    BFI_IOC_IMG_VER_INCOMP = 0,
    BFI_IOC_IMG_VER_OLD = 1,
    BFI_IOC_IMG_VER_SAME = 2,
    BFI_IOC_IMG_VER_BETTER = 3
} ;
enum bfi_fwboot_type {
    BFI_FWBOOT_TYPE_NORMAL = 0,
    BFI_FWBOOT_TYPE_FLASH = 1,
    BFI_FWBOOT_TYPE_MEMTEST = 2
} ;
struct bfi_ioc_ctrl_req {
   struct bfi_mhdr mh ;
   u16 clscode ;
   u16 rsvd ;
   u32 tv_sec ;
};
struct bfi_ioc_ctrl_reply {
   struct bfi_mhdr mh ;
   u8 status ;
   u8 port_mode ;
   u8 cap_bm ;
   u8 rsvd ;
};
union bfi_ioc_i2h_msg_u {
   struct bfi_mhdr mh ;
   struct bfi_ioc_ctrl_reply fw_event ;
   u32 mboxmsg[8U] ;
};
struct bfi_flash_query_req {
   struct bfi_mhdr mh ;
   struct bfi_alen alen ;
};
struct bfi_flash_write_req {
   struct bfi_mhdr mh ;
   struct bfi_alen alen ;
   u32 type ;
   u8 instance ;
   u8 last ;
   u8 rsv[2U] ;
   u32 offset ;
   u32 length ;
};
struct bfi_flash_read_req {
   struct bfi_mhdr mh ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 offset ;
   u32 length ;
   struct bfi_alen alen ;
};
struct bfi_flash_query_rsp {
   struct bfi_mhdr mh ;
   u32 status ;
};
struct bfi_flash_read_rsp {
   struct bfi_mhdr mh ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 status ;
   u32 length ;
};
struct bfi_flash_write_rsp {
   struct bfi_mhdr mh ;
   u32 type ;
   u8 instance ;
   u8 rsv[3U] ;
   u32 status ;
   u32 length ;
};
enum ioc_event {
    IOC_E_RESET = 1,
    IOC_E_ENABLE = 2,
    IOC_E_DISABLE = 3,
    IOC_E_DETACH = 4,
    IOC_E_ENABLED = 5,
    IOC_E_FWRSP_GETATTR = 6,
    IOC_E_DISABLED = 7,
    IOC_E_PFFAILED = 8,
    IOC_E_HBFAIL = 9,
    IOC_E_HWERROR = 10,
    IOC_E_TIMEOUT = 11,
    IOC_E_HWFAILED = 12
} ;
enum iocpf_event {
    IOCPF_E_ENABLE = 1,
    IOCPF_E_DISABLE = 2,
    IOCPF_E_STOP = 3,
    IOCPF_E_FWREADY = 4,
    IOCPF_E_FWRSP_ENABLE = 5,
    IOCPF_E_FWRSP_DISABLE = 6,
    IOCPF_E_FAIL = 7,
    IOCPF_E_INITFAIL = 8,
    IOCPF_E_GETATTRFAIL = 9,
    IOCPF_E_SEMLOCKED = 10,
    IOCPF_E_TIMEOUT = 11,
    IOCPF_E_SEM_ERROR = 12
} ;
enum bfa_iocpf_state {
    BFA_IOCPF_RESET = 1,
    BFA_IOCPF_SEMWAIT = 2,
    BFA_IOCPF_HWINIT = 3,
    BFA_IOCPF_READY = 4,
    BFA_IOCPF_INITFAIL = 5,
    BFA_IOCPF_FAIL = 6,
    BFA_IOCPF_DISABLING = 7,
    BFA_IOCPF_DISABLED = 8,
    BFA_IOCPF_FWMISMATCH = 9
} ;
struct __anonstruct_r_337 {
   unsigned char cmd ;
   unsigned char addr_cnt : 4 ;
   unsigned short read_cnt : 9 ;
   unsigned short write_cnt : 9 ;
   unsigned char rsv : 1 ;
   unsigned char act : 1 ;
};
union bfa_flash_cmd_reg {
   struct __anonstruct_r_337 r ;
   u32 i ;
};
struct __anonstruct_r_338 {
   unsigned char good : 1 ;
   unsigned char bad : 1 ;
   unsigned char present : 1 ;
   unsigned char init_status : 1 ;
   unsigned char busy : 1 ;
   unsigned char fifo_cnt : 6 ;
   unsigned int rsv : 21 ;
};
union bfa_flash_dev_status_reg {
   struct __anonstruct_r_338 r ;
   u32 i ;
};
struct __anonstruct_r_339 {
   unsigned char dummy ;
   unsigned int addr : 24 ;
};
union bfa_flash_addr_reg {
   struct __anonstruct_r_339 r ;
   u32 i ;
};
union __anonunion_m_341 {
   struct bfi_flash_query_rsp *query ;
   struct bfi_flash_write_rsp *write ;
   struct bfi_flash_read_rsp *read ;
   struct bfi_mbmsg *msg ;
};
typedef int ldv_func_ret_type___23;
typedef int ldv_func_ret_type___24;
typedef int ldv_func_ret_type___25;
typedef int ldv_func_ret_type___26;
typedef int ldv_func_ret_type___27;
typedef int ldv_func_ret_type___28;
enum hrtimer_restart;
struct __anonstruct_ct_fnreg_337 {
   u32 hfn_mbox ;
   u32 lpu_mbox ;
   u32 hfn_pgn ;
};
struct __anonstruct_ct_p0reg_338 {
   u32 hfn ;
   u32 lpu ;
};
struct __anonstruct_ct_p1reg_339 {
   u32 hfn ;
   u32 lpu ;
};
struct __anonstruct_ct2_reg_340 {
   u32 hfn_mbox ;
   u32 lpu_mbox ;
   u32 hfn_pgn ;
   u32 hfn ;
   u32 lpu ;
   u32 lpu_read ;
};
enum hrtimer_restart;
struct bfi_cee_get_req {
   struct bfi_mhdr mh ;
   union bfi_addr_u dma_addr ;
};
struct bfi_cee_get_rsp {
   struct bfi_mhdr mh ;
   u8 cmd_status ;
   u8 rsvd[3U] ;
};
struct bfi_cee_stats_rsp {
   struct bfi_mhdr mh ;
   u8 cmd_status ;
   u8 rsvd[3U] ;
};
union bfi_cee_i2h_msg_u {
   struct bfi_mhdr mh ;
   struct bfi_cee_get_rsp get_rsp ;
   struct bfi_cee_stats_rsp stats_rsp ;
};
enum hrtimer_restart;
void __builtin_prefetch(void const * , ...) ;
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern struct module __this_module ;
__inline static void set_bit(long nr , unsigned long volatile *addr )
{
  {
  __asm__ volatile (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %1,%0": "+m" (*((long volatile *)addr)): "Ir" (nr): "memory");
  return;
}
}
__inline static void clear_bit(long nr , unsigned long volatile *addr )
{
  {
  __asm__ volatile (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %1,%0": "+m" (*((long volatile *)addr)): "Ir" (nr));
  return;
}
}
__inline static int test_and_set_bit(long nr , unsigned long volatile *addr )
{
  char c ;
  {
  __asm__ volatile (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
__inline static int test_and_clear_bit(long nr , unsigned long volatile *addr )
{
  char c ;
  {
  __asm__ volatile (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %2, %0; setc %1": "+m" (*addr),
                       "=qm" (c): "Ir" (nr): "memory");
  return ((int )((signed char )c) != 0);
}
}
__inline static int constant_test_bit(long nr , unsigned long const volatile *addr )
{
  {
  return ((int )((unsigned long )*(addr + (unsigned long )(nr >> 6)) >> ((int )nr & 63)) & 1);
}
}
__inline static int fls64(__u64 x )
{
  int bitpos ;
  {
  bitpos = -1;
  __asm__ ("bsrq %1,%q0": "+r" (bitpos): "rm" (x));
  return (bitpos + 1);
}
}
extern unsigned long find_next_bit(unsigned long const * , unsigned long , unsigned long ) ;
extern unsigned long find_first_bit(unsigned long const * , unsigned long ) ;
__inline static __u32 __arch_swab32(__u32 val )
{
  {
  __asm__ ("bswapl %0": "=r" (val): "0" (val));
  return (val);
}
}
__inline static __u64 __arch_swab64(__u64 val )
{
  {
  __asm__ ("bswapq %0": "=r" (val): "0" (val));
  return (val);
}
}
__inline static __u16 __fswab16(__u16 val )
{
  {
  return ((__u16 )((int )((short )((int )val << 8)) | (int )((short )((int )val >> 8))));
}
}
__inline static __u32 __fswab32(__u32 val )
{
  __u32 tmp ;
  {
  tmp = __arch_swab32(val);
  return (tmp);
}
}
__inline static __u64 __fswab64(__u64 val )
{
  __u64 tmp ;
  {
  tmp = __arch_swab64(val);
  return (tmp);
}
}
extern int printk(char const * , ...) ;
extern int sprintf(char * , char const * , ...) ;
void ldv_spin_lock(void) ;
void ldv_spin_unlock(void) ;
extern void *malloc(size_t ) ;
extern void *calloc(size_t , size_t ) ;
extern void *memset(void * , int , size_t ) ;
extern void *memmove(void * , void const * , size_t ) ;
extern int __VERIFIER_nondet_int(void) ;
extern unsigned long __VERIFIER_nondet_ulong(void) ;
extern void *__VERIFIER_nondet_pointer(void) ;
extern void __VERIFIER_assume(int ) ;
void *ldv_malloc(size_t size )
{
  void *p ;
  void *tmp ;
  int tmp___0 ;
  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = malloc(size);
    p = tmp;
    __VERIFIER_assume((unsigned long )p != (unsigned long )((void *)0));
    return (p);
  }
}
}
void *ldv_zalloc(size_t size )
{
  void *p ;
  void *tmp ;
  int tmp___0 ;
  {
  tmp___0 = __VERIFIER_nondet_int();
  if (tmp___0 != 0) {
    return ((void *)0);
  } else {
    tmp = calloc(1UL, size);
    p = tmp;
    __VERIFIER_assume((unsigned long )p != (unsigned long )((void *)0));
    return (p);
  }
}
}
void *ldv_init_zalloc(size_t size )
{
  void *p ;
  void *tmp ;
  {
  tmp = calloc(1UL, size);
  p = tmp;
  __VERIFIER_assume((unsigned long )p != (unsigned long )((void *)0));
  return (p);
}
}
void *ldv_memset(void *s , int c , size_t n )
{
  void *tmp ;
  {
  tmp = memset(s, c, n);
  return (tmp);
}
}
int ldv_undef_int(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  return (tmp);
}
}
void *ldv_undef_ptr(void)
{
  void *tmp ;
  {
  tmp = __VERIFIER_nondet_pointer();
  return (tmp);
}
}
unsigned long ldv_undef_ulong(void)
{
  unsigned long tmp ;
  {
  tmp = __VERIFIER_nondet_ulong();
  return (tmp);
}
}
__inline static void ldv_error(void)
{
  {
  ERROR: ;
  __VERIFIER_error();
}
}
__inline static void ldv_stop(void)
{
  {
  LDV_STOP: ;
  goto LDV_STOP;
}
}
__inline static long ldv__builtin_expect(long exp , long c )
{
  {
  return (exp);
}
}
__inline static void ldv__builtin_trap(void)
{
  {
  ldv_error();
  return;
}
}
__inline static void INIT_LIST_HEAD(struct list_head *list )
{
  {
  list->next = list;
  list->prev = list;
  return;
}
}
extern void __list_add(struct list_head * , struct list_head * , struct list_head * ) ;
__inline static void list_add_tail(struct list_head *new , struct list_head *head )
{
  {
  __list_add(new, head->prev, head);
  return;
}
}
extern void list_del(struct list_head * ) ;
extern void warn_slowpath_null(char const * , int const ) ;
extern unsigned long __phys_addr(unsigned long ) ;
__inline static int __get_order(unsigned long size )
{
  int order ;
  {
  size = size - 1UL;
  size = size >> 12;
  order = fls64((__u64 )size);
  return (order);
}
}
extern void *memset(void * , int , size_t ) ;
extern int __bitmap_weight(unsigned long const * , unsigned int ) ;
__inline static int bitmap_weight(unsigned long const *src , unsigned int nbits )
{
  int tmp___0 ;
  {
  tmp___0 = __bitmap_weight(src, nbits);
  return (tmp___0);
}
}
extern int nr_cpu_ids ;
extern struct cpumask const * const cpu_online_mask ;
__inline static unsigned int cpumask_weight(struct cpumask const *srcp )
{
  int tmp ;
  {
  tmp = bitmap_weight((unsigned long const *)(& srcp->bits), (unsigned int )nr_cpu_ids);
  return ((unsigned int )tmp);
}
}
__inline static int atomic_read(atomic_t const *v )
{
  int __var ;
  {
  __var = 0;
  return ((int )*((int const volatile *)(& v->counter)));
}
}
__inline static void atomic_inc(atomic_t *v )
{
  {
  __asm__ volatile (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; incl %0": "+m" (v->counter));
  return;
}
}
extern void lockdep_init_map(struct lockdep_map * , char const * , struct lock_class_key * ,
                             int ) ;
extern void __raw_spin_lock_init(raw_spinlock_t * , char const * , struct lock_class_key * ) ;
extern void _raw_spin_unlock_irqrestore(raw_spinlock_t * , unsigned long ) ;
__inline static raw_spinlock_t *spinlock_check(spinlock_t *lock )
{
  {
  return (& lock->__annonCompField18.rlock);
}
}
__inline static void ldv_spin_unlock_irqrestore_12(spinlock_t *lock , unsigned long flags )
{
  {
  _raw_spin_unlock_irqrestore(& lock->__annonCompField18.rlock, flags);
  return;
}
}
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) ;
extern void dump_page(struct page * , char const * ) ;
extern void __init_waitqueue_head(wait_queue_head_t * , char const * , struct lock_class_key * ) ;
extern void mutex_destroy(struct mutex * ) ;
extern void __mutex_init(struct mutex * , char const * , struct lock_class_key * ) ;
extern void mutex_lock_nested(struct mutex * , unsigned int ) ;
extern void mutex_unlock(struct mutex * ) ;
__inline static void init_completion(struct completion *x )
{
  struct lock_class_key __key ;
  {
  x->done = 0U;
  __init_waitqueue_head(& x->wait, "&x->wait", & __key);
  return;
}
}
extern void wait_for_completion(struct completion * ) ;
extern unsigned long wait_for_completion_timeout(struct completion * , unsigned long ) ;
extern void complete(struct completion * ) ;
extern unsigned long volatile jiffies ;
extern unsigned long __msecs_to_jiffies(unsigned int const ) ;
__inline static unsigned long msecs_to_jiffies(unsigned int const m )
{
  unsigned long tmp___0 ;
  {
  tmp___0 = __msecs_to_jiffies(m);
  return (tmp___0);
}
}
extern void init_timer_key(struct timer_list * , unsigned int , char const * ,
                           struct lock_class_key * ) ;
extern int mod_timer(struct timer_list * , unsigned long ) ;
int ldv_mod_timer_43(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_50(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_51(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_52(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
extern int del_timer_sync(struct timer_list * ) ;
int ldv_del_timer_sync_53(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_54(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_58(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_59(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_60(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_63(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_64(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_sync_65(struct timer_list *ldv_func_arg1 ) ;
extern void delayed_work_timer_fn(unsigned long ) ;
extern void __init_work(struct work_struct * , int ) ;
extern struct workqueue_struct *__alloc_workqueue_key(char const * , unsigned int ,
                                                      int , struct lock_class_key * ,
                                                      char const * , ...) ;
extern void destroy_workqueue(struct workqueue_struct * ) ;
void ldv_destroy_workqueue_56(struct workqueue_struct *ldv_func_arg1 ) ;
extern bool queue_work_on(int , struct workqueue_struct * , struct work_struct * ) ;
bool ldv_queue_work_on_15(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_17(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
extern bool queue_delayed_work_on(int , struct workqueue_struct * , struct delayed_work * ,
                                  unsigned long ) ;
bool ldv_queue_delayed_work_on_16(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_19(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
extern void flush_workqueue(struct workqueue_struct * ) ;
void ldv_flush_workqueue_18(struct workqueue_struct *ldv_func_arg1 ) ;
void ldv_flush_workqueue_55(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static bool queue_work(struct workqueue_struct *wq , struct work_struct *work )
{
  bool tmp ;
  {
  tmp = ldv_queue_work_on_15(8192, wq, work);
  return (tmp);
}
}
__inline static bool queue_delayed_work(struct workqueue_struct *wq , struct delayed_work *dwork ,
                                        unsigned long delay )
{
  bool tmp ;
  {
  tmp = ldv_queue_delayed_work_on_16(8192, wq, dwork, delay);
  return (tmp);
}
}
__inline static unsigned int readl(void const volatile *addr )
{
  unsigned int ret ;
  {
  __asm__ volatile ("movl %1,%0": "=r" (ret): "m" (*((unsigned int volatile *)addr)): "memory");
  return (ret);
}
}
__inline static void writel(unsigned int val , void volatile *addr )
{
  {
  __asm__ volatile ("movl %0,%1": : "r" (val), "m" (*((unsigned int volatile *)addr)): "memory");
  return;
}
}
extern void *ioremap_nocache(resource_size_t , unsigned long ) ;
extern void iounmap(void volatile * ) ;
__inline static struct page *alloc_pages(gfp_t flags , unsigned int order ) ;
extern void kfree(void const * ) ;
void *ldv_kmem_cache_alloc_25(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
void *ldv_kmem_cache_alloc_42(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) ;
void ldv_check_alloc_flags(gfp_t flags ) ;
struct timer_list *ldv_timer_list_7_1 ;
int ldv_state_variable_20 ;
int pci_counter ;
struct work_struct *ldv_work_struct_3_1 ;
int ldv_state_variable_0 ;
struct timer_list *ldv_timer_list_9_3 ;
struct timer_list *ldv_timer_list_10_2 ;
struct timer_list *ldv_timer_list_8_1 ;
int ldv_timer_5_2 ;
int ldv_irq_2_0 = 0;
int ldv_state_variable_12 ;
struct pci_dev *bnad_pci_driver_group1 ;
struct timer_list *ldv_timer_list_5_0 ;
int ldv_state_variable_14 ;
int ldv_timer_9_1 ;
int ldv_timer_6_2 ;
int ldv_timer_9_0 ;
struct timer_list *ldv_timer_list_5_3 ;
int ldv_state_variable_17 ;
int ldv_timer_9_3 ;
struct inode *bnad_debugfs_op_fwtrc_group1 ;
void *ldv_irq_data_2_3 ;
int ldv_state_variable_19 ;
struct work_struct *ldv_work_struct_4_3 ;
int ldv_state_variable_9 ;
struct file *bnad_debugfs_op_regwr_group2 ;
int ldv_timer_6_0 ;
struct timer_list *ldv_timer_list_5_1 ;
struct file *bnad_debugfs_op_regrd_group2 ;
int ref_cnt ;
int ldv_irq_line_1_1 ;
void *ldv_irq_data_2_2 ;
int ldv_work_3_3 ;
struct work_struct *ldv_work_struct_4_0 ;
int ldv_state_variable_7 ;
struct work_struct *ldv_work_struct_3_3 ;
struct timer_list *ldv_timer_list_10_0 ;
struct timer_list *ldv_timer_list_6_3 ;
int ldv_irq_2_1 = 0;
int ldv_timer_8_2 ;
void *ldv_irq_data_2_1 ;
struct timer_list *ldv_timer_list_6_2 ;
int ldv_irq_1_3 = 0;
struct timer_list *ldv_timer_list_9_2 ;
int ldv_irq_line_2_2 ;
int ldv_timer_9_2 ;
struct timer_list *ldv_timer_list_7_3 ;
int ldv_work_4_0 ;
struct work_struct *ldv_work_struct_3_2 ;
int ldv_state_variable_6 ;
void *ldv_irq_data_1_0 ;
void *ldv_irq_data_1_3 ;
struct work_struct *ldv_work_struct_4_2 ;
struct timer_list *ldv_timer_list_6_0 ;
struct net_device *bnad_ethtool_ops_group5 ;
struct timer_list *ldv_timer_list_8_3 ;
int ldv_timer_7_1 ;
int ldv_timer_10_2 ;
int LDV_IN_INTERRUPT = 1;
int ldv_irq_1_1 = 0;
struct inode *bnad_debugfs_op_drvinfo_group1 ;
int ldv_timer_5_3 ;
struct timer_list *ldv_timer_list_7_0 ;
struct ethtool_cmd *bnad_ethtool_ops_group1 ;
struct timer_list *ldv_timer_list_10_1 ;
struct ethtool_pauseparam *bnad_ethtool_ops_group3 ;
int ldv_state_variable_3 ;
int ldv_irq_line_1_0 ;
struct timer_list *ldv_timer_list_9_0 ;
int ldv_timer_8_3 ;
int ldv_state_variable_4 ;
int ldv_timer_7_3 ;
int ldv_state_variable_8 ;
struct inode *bnad_debugfs_op_regwr_group1 ;
int ldv_state_variable_15 ;
struct ethtool_eeprom *bnad_ethtool_ops_group2 ;
struct timer_list *ldv_timer_list_5_2 ;
int ldv_state_variable_21 ;
int ldv_state_variable_5 ;
struct net_device *bnad_netdev_ops_group1 ;
int ldv_state_variable_13 ;
int ldv_work_3_2 ;
int ldv_timer_5_1 ;
struct timer_list *ldv_timer_list_7_2 ;
struct file *bnad_debugfs_op_fwtrc_group2 ;
int ldv_work_3_0 ;
struct file *bnad_debugfs_op_fwsave_group2 ;
struct timer_list *ldv_timer_list_6_1 ;
struct inode *bnad_debugfs_op_regrd_group1 ;
int ldv_irq_2_2 = 0;
int ldv_timer_7_0 ;
struct bfa_ioc *nw_hwif_ct2_group0 ;
int ldv_irq_line_2_0 ;
struct ethtool_ringparam *bnad_ethtool_ops_group0 ;
int ldv_state_variable_1 ;
int ldv_irq_line_1_2 ;
int ldv_timer_6_3 ;
int ldv_timer_8_0 ;
int ldv_irq_line_2_3 ;
int ldv_timer_10_0 ;
struct ethtool_coalesce *bnad_ethtool_ops_group4 ;
void *ldv_irq_data_1_1 ;
struct bfa_ioc *nw_hwif_ct_group0 ;
int ldv_state_variable_10 ;
int ldv_irq_1_0 = 0;
int ldv_work_4_1 ;
int ldv_work_4_3 ;
int ldv_timer_8_1 ;
int ldv_state_variable_16 ;
int ldv_work_3_1 ;
int ldv_irq_line_2_1 ;
int ldv_state_variable_2 ;
int ldv_timer_10_1 ;
int ldv_timer_5_0 ;
void *ldv_irq_data_1_2 ;
void *ldv_irq_data_2_0 ;
struct work_struct *ldv_work_struct_3_0 ;
int ldv_work_4_2 ;
int ldv_state_variable_11 ;
int ldv_timer_7_2 ;
int ldv_irq_1_2 = 0;
int ldv_state_variable_18 ;
int ldv_irq_2_3 = 0;
struct timer_list *ldv_timer_list_8_0 ;
struct timer_list *ldv_timer_list_10_3 ;
int ldv_irq_line_1_3 ;
int ldv_timer_6_1 ;
struct work_struct *ldv_work_struct_4_1 ;
struct inode *bnad_debugfs_op_fwsave_group1 ;
int ldv_timer_10_3 ;
struct timer_list *ldv_timer_list_8_2 ;
struct timer_list *ldv_timer_list_9_1 ;
struct file *bnad_debugfs_op_drvinfo_group2 ;
void work_init_3(void) ;
void activate_suitable_timer_6(struct timer_list *timer , unsigned long data ) ;
void disable_suitable_irq_2(int line , void *data ) ;
int reg_timer_7(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data ) ;
void ldv_timer_5(int state , struct timer_list *timer ) ;
void choose_timer_5(void) ;
void activate_pending_timer_9(struct timer_list *timer , unsigned long data , int pending_flag ) ;
int reg_check_1(irqreturn_t (*handler)(int , void * ) ) ;
void ldv_file_operations_15(void) ;
void disable_suitable_timer_8(struct timer_list *timer ) ;
void activate_work_3(struct work_struct *work , int state ) ;
void activate_pending_timer_10(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void ldv_file_operations_14(void) ;
void call_and_disable_all_4(int state ) ;
void ldv_initialize_bfa_ioc_hwif_11(void) ;
int reg_timer_10(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data ) ;
void call_and_disable_work_3(struct work_struct *work ) ;
void ldv_file_operations_16(void) ;
void timer_init_6(void) ;
void ldv_initialize_ethtool_ops_19(void) ;
void disable_work_3(struct work_struct *work ) ;
void ldv_timer_9(int state , struct timer_list *timer ) ;
void activate_pending_timer_8(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void ldv_timer_7(int state , struct timer_list *timer ) ;
void timer_init_5(void) ;
void disable_suitable_irq_1(int line , void *data ) ;
void activate_suitable_irq_1(int line , void *data ) ;
void invoke_work_4(void) ;
void timer_init_9(void) ;
void ldv_pci_driver_20(void) ;
void disable_suitable_timer_6(struct timer_list *timer ) ;
void ldv_file_operations_17(void) ;
void disable_suitable_timer_5(struct timer_list *timer ) ;
void ldv_timer_10(int state , struct timer_list *timer ) ;
int ldv_irq_2(int state , int line , void *data ) ;
void ldv_net_device_ops_21(void) ;
void activate_pending_timer_6(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void activate_suitable_timer_9(struct timer_list *timer , unsigned long data ) ;
void choose_interrupt_2(void) ;
void disable_suitable_timer_10(struct timer_list *timer ) ;
void activate_work_4(struct work_struct *work , int state ) ;
void choose_timer_8(void) ;
void disable_suitable_timer_7(struct timer_list *timer ) ;
int reg_timer_9(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data ) ;
void ldv_initialize_bfa_ioc_hwif_12(void) ;
void activate_suitable_irq_2(int line , void *data ) ;
int reg_timer_8(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data ) ;
void disable_suitable_timer_9(struct timer_list *timer ) ;
void choose_timer_6(void) ;
int reg_timer_6(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data ) ;
void activate_suitable_timer_10(struct timer_list *timer , unsigned long data ) ;
void ldv_timer_6(int state , struct timer_list *timer ) ;
void timer_init_7(void) ;
void choose_interrupt_1(void) ;
int reg_check_2(irqreturn_t (*handler)(int , void * ) ) ;
void ldv_file_operations_18(void) ;
void choose_timer_9(void) ;
void timer_init_10(void) ;
void disable_work_4(struct work_struct *work ) ;
void work_init_4(void) ;
void invoke_work_3(void) ;
int ldv_irq_1(int state , int line , void *data ) ;
void ldv_timer_8(int state , struct timer_list *timer ) ;
void activate_pending_timer_5(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void choose_timer_7(void) ;
void timer_init_8(void) ;
void call_and_disable_all_3(int state ) ;
void activate_suitable_timer_8(struct timer_list *timer , unsigned long data ) ;
void choose_timer_10(void) ;
int reg_timer_5(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data ) ;
void call_and_disable_work_4(struct work_struct *work ) ;
void activate_suitable_timer_5(struct timer_list *timer , unsigned long data ) ;
void activate_pending_timer_7(struct timer_list *timer , unsigned long data , int pending_flag ) ;
void activate_suitable_timer_7(struct timer_list *timer , unsigned long data ) ;
__inline static void *dev_get_drvdata(struct device const *dev )
{
  {
  return ((void *)dev->driver_data);
}
}
__inline static void dev_set_drvdata(struct device *dev , void *data )
{
  {
  dev->driver_data = data;
  return;
}
}
extern void dev_err(struct device const * , char const * , ...) ;
extern void dev_warn(struct device const * , char const * , ...) ;
extern void _dev_info(struct device const * , char const * , ...) ;
__inline static int PageTail(struct page const *page )
{
  int tmp ;
  {
  tmp = constant_test_bit(15L, (unsigned long const volatile *)(& page->flags));
  return (tmp);
}
}
__inline static struct page *compound_head_by_tail(struct page *tail )
{
  struct page *head ;
  int tmp ;
  long tmp___0 ;
  {
  head = tail->__annonCompField46.first_page;
  __asm__ volatile ("": : : "memory");
  tmp = PageTail((struct page const *)tail);
  tmp___0 = ldv__builtin_expect(tmp != 0, 1L);
  if (tmp___0 != 0L) {
    return (head);
  } else {
  }
  return (tail);
}
}
__inline static struct page *compound_head(struct page *page )
{
  struct page *tmp ;
  int tmp___0 ;
  long tmp___1 ;
  {
  tmp___0 = PageTail((struct page const *)page);
  tmp___1 = ldv__builtin_expect(tmp___0 != 0, 0L);
  if (tmp___1 != 0L) {
    tmp = compound_head_by_tail(page);
    return (tmp);
  } else {
  }
  return (page);
}
}
extern bool __get_page_tail(struct page * ) ;
__inline static void get_page(struct page *page )
{
  bool tmp ;
  long tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;
  {
  tmp___1 = PageTail((struct page const *)page);
  tmp___2 = ldv__builtin_expect(tmp___1 != 0, 0L);
  if (tmp___2 != 0L) {
    tmp = __get_page_tail(page);
    tmp___0 = ldv__builtin_expect((long )tmp, 1L);
    if (tmp___0 != 0L) {
      return;
    } else {
    }
  } else {
  }
  tmp___3 = atomic_read((atomic_t const *)(& page->__annonCompField42.__annonCompField41.__annonCompField40._count));
  tmp___4 = ldv__builtin_expect(tmp___3 <= 0, 0L);
  if (tmp___4 != 0L) {
    dump_page(page, "VM_BUG_ON_PAGE(atomic_read(&page->_count) <= 0)");
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/mm.h"),
                         "i" (543), "i" (12UL));
    ldv_23242: ;
    goto ldv_23242;
  } else {
  }
  atomic_inc(& page->__annonCompField42.__annonCompField41.__annonCompField40._count);
  return;
}
}
extern void put_page(struct page * ) ;
__inline static void *lowmem_page_address(struct page const *page )
{
  {
  return ((void *)((unsigned long )((unsigned long long )(((long )page + 24189255811072L) / 64L) << 12) + 0xffff880000000000UL));
}
}
__inline static void kmemcheck_mark_initialized(void *address , unsigned int n )
{
  {
  return;
}
}
__inline static __sum16 csum_fold(__wsum sum )
{
  {
  __asm__ ("  addl %1,%0\n  adcl $0xffff,%0": "=r" (sum): "r" (sum << 16), "0" (sum & 4294901760U));
  return ((__sum16 )(~ sum >> 16));
}
}
__inline static __wsum csum_tcpudp_nofold(__be32 saddr , __be32 daddr , unsigned short len ,
                                          unsigned short proto , __wsum sum )
{
  {
  __asm__ ("  addl %1, %0\n  adcl %2, %0\n  adcl %3, %0\n  adcl $0, %0\n": "=r" (sum): "g" (daddr),
            "g" (saddr), "g" (((int )len + (int )proto) << 8), "0" (sum));
  return (sum);
}
}
__inline static __sum16 csum_tcpudp_magic(__be32 saddr , __be32 daddr , unsigned short len ,
                                          unsigned short proto , __wsum sum )
{
  __wsum tmp ;
  __sum16 tmp___0 ;
  {
  tmp = csum_tcpudp_nofold(saddr, daddr, (int )len, (int )proto, sum);
  tmp___0 = csum_fold(tmp);
  return (tmp___0);
}
}
extern __sum16 csum_ipv6_magic(struct in6_addr const * , struct in6_addr const * ,
                               __u32 , unsigned short , __wsum ) ;
__inline static int valid_dma_direction(int dma_direction )
{
  {
  return ((dma_direction == 0 || dma_direction == 1) || dma_direction == 2);
}
}
extern void debug_dma_map_page(struct device * , struct page * , size_t , size_t ,
                               int , dma_addr_t , bool ) ;
extern void debug_dma_unmap_page(struct device * , dma_addr_t , size_t , int ,
                                 bool ) ;
extern struct dma_map_ops *dma_ops ;
__inline static struct dma_map_ops *get_dma_ops(struct device *dev )
{
  long tmp ;
  {
  tmp = ldv__builtin_expect((unsigned long )dev == (unsigned long )((struct device *)0),
                         0L);
  if (tmp != 0L || (unsigned long )dev->archdata.dma_ops == (unsigned long )((struct dma_map_ops *)0)) {
    return (dma_ops);
  } else {
    return (dev->archdata.dma_ops);
  }
}
}
__inline static dma_addr_t dma_map_single_attrs(struct device *dev , void *ptr , size_t size ,
                                                enum dma_data_direction dir , struct dma_attrs *attrs )
{
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  int tmp___0 ;
  long tmp___1 ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;
  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  kmemcheck_mark_initialized(ptr, (unsigned int )size);
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (19), "i" (12UL));
    ldv_31784: ;
    goto ldv_31784;
  } else {
  }
  tmp___2 = __phys_addr((unsigned long )ptr);
  addr = (*(ops->map_page))(dev, (struct page *)-24189255811072L + (tmp___2 >> 12),
                            (unsigned long )ptr & 4095UL, size, dir, attrs);
  tmp___3 = __phys_addr((unsigned long )ptr);
  debug_dma_map_page(dev, (struct page *)-24189255811072L + (tmp___3 >> 12), (unsigned long )ptr & 4095UL,
                     size, (int )dir, addr, 1);
  return (addr);
}
}
__inline static void dma_unmap_single_attrs(struct device *dev , dma_addr_t addr ,
                                            size_t size , enum dma_data_direction dir ,
                                            struct dma_attrs *attrs )
{
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;
  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (36), "i" (12UL));
    ldv_31793: ;
    goto ldv_31793;
  } else {
  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t ,
                                                                    size_t , enum dma_data_direction ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, attrs);
  } else {
  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 1);
  return;
}
}
__inline static dma_addr_t dma_map_page(struct device *dev , struct page *page , size_t offset ,
                                        size_t size , enum dma_data_direction dir )
{
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  void *tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = lowmem_page_address((struct page const *)page);
  kmemcheck_mark_initialized(tmp___0 + offset, (unsigned int )size);
  tmp___1 = valid_dma_direction((int )dir);
  tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
  if (tmp___2 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (84), "i" (12UL));
    ldv_31828: ;
    goto ldv_31828;
  } else {
  }
  addr = (*(ops->map_page))(dev, page, offset, size, dir, (struct dma_attrs *)0);
  debug_dma_map_page(dev, page, offset, size, (int )dir, addr, 0);
  return (addr);
}
}
__inline static void dma_unmap_page(struct device *dev , dma_addr_t addr , size_t size ,
                                    enum dma_data_direction dir )
{
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;
  {
  tmp = get_dma_ops(dev);
  ops = tmp;
  tmp___0 = valid_dma_direction((int )dir);
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
  if (tmp___1 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (96), "i" (12UL));
    ldv_31836: ;
    goto ldv_31836;
  } else {
  }
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t ,
                                                                    size_t , enum dma_data_direction ,
                                                                    struct dma_attrs * ))0)) {
    (*(ops->unmap_page))(dev, addr, size, dir, (struct dma_attrs *)0);
  } else {
  }
  debug_dma_unmap_page(dev, addr, size, (int )dir, 0);
  return;
}
}
extern int dma_supported(struct device * , u64 ) ;
extern int dma_set_mask(struct device * , u64 ) ;
extern void *dma_alloc_attrs(struct device * , size_t , dma_addr_t * , gfp_t , struct dma_attrs * ) ;
extern void dma_free_attrs(struct device * , size_t , void * , dma_addr_t , struct dma_attrs * ) ;
__inline static int dma_set_coherent_mask(struct device *dev , u64 mask )
{
  int tmp ;
  {
  tmp = dma_supported(dev, mask);
  if (tmp == 0) {
    return (-5);
  } else {
  }
  dev->coherent_dma_mask = mask;
  return (0);
}
}
__inline static int dma_set_mask_and_coherent(struct device *dev , u64 mask )
{
  int rc ;
  int tmp ;
  {
  tmp = dma_set_mask(dev, mask);
  rc = tmp;
  if (rc == 0) {
    dma_set_coherent_mask(dev, mask);
  } else {
  }
  return (rc);
}
}
__inline static unsigned int skb_frag_size(skb_frag_t const *frag )
{
  {
  return ((unsigned int )frag->size);
}
}
__inline static void skb_frag_size_set(skb_frag_t *frag , unsigned int size )
{
  {
  frag->size = size;
  return;
}
}
struct sk_buff *ldv_skb_clone_33(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_41(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_35(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_31(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) ;
int ldv_pskb_expand_head_39(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) ;
int ldv_pskb_expand_head_40(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags ) ;
__inline static unsigned char *skb_end_pointer(struct sk_buff const *skb )
{
  {
  return ((unsigned char *)skb->head + (unsigned long )skb->end);
}
}
__inline static int skb_header_cloned(struct sk_buff const *skb )
{
  int dataref ;
  unsigned char *tmp ;
  {
  if ((unsigned int )*((unsigned char *)skb + 142UL) == 0U) {
    return (0);
  } else {
  }
  tmp = skb_end_pointer(skb);
  dataref = atomic_read((atomic_t const *)(& ((struct skb_shared_info *)tmp)->dataref));
  dataref = (dataref & 65535) - (dataref >> 16);
  return (dataref != 1);
}
}
__inline static unsigned int skb_headlen(struct sk_buff const *skb )
{
  {
  return ((unsigned int )skb->len - (unsigned int )skb->data_len);
}
}
__inline static void __skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                          int off , int size )
{
  skb_frag_t *frag ;
  unsigned char *tmp ;
  {
  tmp = skb_end_pointer((struct sk_buff const *)skb);
  frag = (skb_frag_t *)(& ((struct skb_shared_info *)tmp)->frags) + (unsigned long )i;
  frag->page.p = page;
  frag->page_offset = (__u32 )off;
  skb_frag_size_set(frag, (unsigned int )size);
  page = compound_head(page);
  if ((int )page->__annonCompField42.__annonCompField37.pfmemalloc && (unsigned long )page->__annonCompField36.mapping == (unsigned long )((struct address_space *)0)) {
    skb->pfmemalloc = 1U;
  } else {
  }
  return;
}
}
__inline static void skb_fill_page_desc(struct sk_buff *skb , int i , struct page *page ,
                                        int off , int size )
{
  unsigned char *tmp ;
  {
  __skb_fill_page_desc(skb, i, page, off, size);
  tmp = skb_end_pointer((struct sk_buff const *)skb);
  ((struct skb_shared_info *)tmp)->nr_frags = (unsigned int )((unsigned char )i) + 1U;
  return;
}
}
extern unsigned char *skb_put(struct sk_buff * , unsigned int ) ;
extern unsigned char *__pskb_pull_tail(struct sk_buff * , int ) ;
__inline static int pskb_may_pull(struct sk_buff *skb , unsigned int len )
{
  unsigned int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  unsigned int tmp___2 ;
  unsigned char *tmp___3 ;
  {
  tmp = skb_headlen((struct sk_buff const *)skb);
  tmp___0 = ldv__builtin_expect(tmp >= len, 1L);
  if (tmp___0 != 0L) {
    return (1);
  } else {
  }
  tmp___1 = ldv__builtin_expect(skb->len < len, 0L);
  if (tmp___1 != 0L) {
    return (0);
  } else {
  }
  tmp___2 = skb_headlen((struct sk_buff const *)skb);
  tmp___3 = __pskb_pull_tail(skb, (int )(len - tmp___2));
  return ((unsigned long )tmp___3 != (unsigned long )((unsigned char *)0U));
}
}
__inline static unsigned int skb_headroom(struct sk_buff const *skb )
{
  {
  return ((unsigned int )((long )skb->data) - (unsigned int )((long )skb->head));
}
}
__inline static unsigned char *skb_transport_header(struct sk_buff const *skb )
{
  {
  return ((unsigned char *)skb->head + (unsigned long )skb->transport_header);
}
}
__inline static unsigned char *skb_network_header(struct sk_buff const *skb )
{
  {
  return ((unsigned char *)skb->head + (unsigned long )skb->network_header);
}
}
__inline static int skb_transport_offset(struct sk_buff const *skb )
{
  unsigned char *tmp ;
  {
  tmp = skb_transport_header(skb);
  return ((int )((unsigned int )((long )tmp) - (unsigned int )((long )skb->data)));
}
}
struct sk_buff *ldv___netdev_alloc_skb_36(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_37(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_38(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags ) ;
__inline static struct sk_buff *__netdev_alloc_skb_ip_align(struct net_device *dev ,
                                                            unsigned int length ,
                                                            gfp_t gfp )
{
  struct sk_buff *skb ;
  struct sk_buff *tmp ;
  {
  tmp = ldv___netdev_alloc_skb_38(dev, length, gfp);
  skb = tmp;
  return (skb);
}
}
__inline static struct sk_buff *netdev_alloc_skb_ip_align(struct net_device *dev ,
                                                          unsigned int length )
{
  struct sk_buff *tmp ;
  {
  tmp = __netdev_alloc_skb_ip_align(dev, length, 32U);
  return (tmp);
}
}
__inline static struct page *skb_frag_page(skb_frag_t const *frag )
{
  {
  return ((struct page *)frag->page.p);
}
}
__inline static dma_addr_t skb_frag_dma_map(struct device *dev , skb_frag_t const *frag ,
                                            size_t offset , size_t size , enum dma_data_direction dir )
{
  struct page *tmp ;
  dma_addr_t tmp___0 ;
  {
  tmp = skb_frag_page(frag);
  tmp___0 = dma_map_page(dev, tmp, (size_t )frag->page_offset + offset, size, dir);
  return (tmp___0);
}
}
__inline static int __skb_cow(struct sk_buff *skb , unsigned int headroom , int cloned )
{
  int delta ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  int _max1 ;
  int _max2 ;
  int _max1___0 ;
  int _max2___0 ;
  int tmp___1 ;
  {
  delta = 0;
  tmp___0 = skb_headroom((struct sk_buff const *)skb);
  if (tmp___0 < headroom) {
    tmp = skb_headroom((struct sk_buff const *)skb);
    delta = (int )(headroom - tmp);
  } else {
  }
  if (delta != 0 || cloned != 0) {
    _max1 = 32;
    _max2 = 64;
    _max1___0 = 32;
    _max2___0 = 64;
    tmp___1 = ldv_pskb_expand_head_39(skb, (((_max1 > _max2 ? _max1 : _max2) + -1) + delta) & - (_max1___0 > _max2___0 ? _max1___0 : _max2___0),
                                      0, 32U);
    return (tmp___1);
  } else {
  }
  return (0);
}
}
__inline static int skb_cow_head(struct sk_buff *skb , unsigned int headroom )
{
  int tmp ;
  int tmp___0 ;
  {
  tmp = skb_header_cloned((struct sk_buff const *)skb);
  tmp___0 = __skb_cow(skb, headroom, tmp);
  return (tmp___0);
}
}
extern void skb_clone_tx_timestamp(struct sk_buff * ) ;
extern void skb_tstamp_tx(struct sk_buff * , struct skb_shared_hwtstamps * ) ;
__inline static void sw_tx_timestamp(struct sk_buff *skb )
{
  unsigned char *tmp ;
  unsigned char *tmp___0 ;
  {
  tmp = skb_end_pointer((struct sk_buff const *)skb);
  if (((int )((struct skb_shared_info *)tmp)->tx_flags & 2) != 0) {
    tmp___0 = skb_end_pointer((struct sk_buff const *)skb);
    if (((int )((struct skb_shared_info *)tmp___0)->tx_flags & 4) == 0) {
      skb_tstamp_tx(skb, (struct skb_shared_hwtstamps *)0);
    } else {
    }
  } else {
  }
  return;
}
}
__inline static void skb_tx_timestamp(struct sk_buff *skb )
{
  {
  skb_clone_tx_timestamp(skb);
  sw_tx_timestamp(skb);
  return;
}
}
__inline static bool skb_is_gso(struct sk_buff const *skb )
{
  unsigned char *tmp ;
  {
  tmp = skb_end_pointer(skb);
  return ((unsigned int )((struct skb_shared_info *)tmp)->gso_size != 0U);
}
}
__inline static void skb_checksum_none_assert(struct sk_buff const *skb )
{
  {
  return;
}
}
extern void synchronize_irq(unsigned int ) ;
extern int request_threaded_irq(unsigned int , irqreturn_t (*)(int , void * ) ,
                                irqreturn_t (*)(int , void * ) , unsigned long ,
                                char const * , void * ) ;
__inline static int request_irq(unsigned int irq , irqreturn_t (*handler)(int , void * ) ,
                                unsigned long flags , char const *name , void *dev )
{
  int tmp ;
  {
  tmp = request_threaded_irq(irq, handler, (irqreturn_t (*)(int , void * ))0, flags,
                             name, dev);
  return (tmp);
}
}
__inline static int ldv_request_irq_45(unsigned int irq , irqreturn_t (*handler)(int ,
                                                                                 void * ) ,
                                       unsigned long flags , char const *name ,
                                       void *dev ) ;
__inline static int ldv_request_irq_47(unsigned int irq , irqreturn_t (*handler)(int ,
                                                                                 void * ) ,
                                       unsigned long flags , char const *name ,
                                       void *dev ) ;
__inline static int ldv_request_irq_49(unsigned int irq , irqreturn_t (*handler)(int ,
                                                                                 void * ) ,
                                       unsigned long flags , char const *name ,
                                       void *dev ) ;
extern void free_irq(unsigned int , void * ) ;
void ldv_free_irq_44(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
void ldv_free_irq_46(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
void ldv_free_irq_48(unsigned int ldv_func_arg1 , void *ldv_func_arg2 ) ;
extern void __napi_schedule(struct napi_struct * ) ;
__inline static bool napi_disable_pending(struct napi_struct *n )
{
  int tmp ;
  {
  tmp = constant_test_bit(1L, (unsigned long const volatile *)(& n->state));
  return (tmp != 0);
}
}
__inline static bool napi_schedule_prep(struct napi_struct *n )
{
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  {
  tmp = napi_disable_pending(n);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = test_and_set_bit(0L, (unsigned long volatile *)(& n->state));
    if (tmp___1 == 0) {
      tmp___2 = 1;
    } else {
      tmp___2 = 0;
    }
  } else {
    tmp___2 = 0;
  }
  return ((bool )tmp___2);
}
}
__inline static void napi_complete(struct napi_struct *n )
{
  {
  return;
}
}
extern void napi_disable(struct napi_struct * ) ;
__inline static void napi_enable(struct napi_struct *n )
{
  int tmp ;
  long tmp___0 ;
  {
  tmp = constant_test_bit(0L, (unsigned long const volatile *)(& n->state));
  tmp___0 = ldv__builtin_expect(tmp == 0, 0L);
  if (tmp___0 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/linux/netdevice.h"),
                         "i" (507), "i" (12UL));
    ldv_42066: ;
    goto ldv_42066;
  } else {
  }
  __asm__ volatile ("": : : "memory");
  clear_bit(0L, (unsigned long volatile *)(& n->state));
  return;
}
}
__inline static struct netdev_queue *netdev_get_tx_queue(struct net_device const *dev ,
                                                         unsigned int index )
{
  {
  return ((struct netdev_queue *)dev->_tx + (unsigned long )index);
}
}
__inline static void *netdev_priv(struct net_device const *dev )
{
  {
  return ((void *)dev + 3008U);
}
}
extern void netif_napi_add(struct net_device * , struct napi_struct * , int (*)(struct napi_struct * ,
                                                                                int ) ,
                           int ) ;
extern void netif_napi_del(struct napi_struct * ) ;
extern void free_netdev(struct net_device * ) ;
void ldv_free_netdev_61(struct net_device *dev ) ;
void ldv_free_netdev_66(struct net_device *dev ) ;
extern void netif_tx_wake_queue(struct netdev_queue * ) ;
__inline static void netif_wake_queue(struct net_device *dev )
{
  struct netdev_queue *tmp ;
  {
  tmp = netdev_get_tx_queue((struct net_device const *)dev, 0U);
  netif_tx_wake_queue(tmp);
  return;
}
}
__inline static void netif_tx_stop_queue(struct netdev_queue *dev_queue )
{
  {
  set_bit(0L, (unsigned long volatile *)(& dev_queue->state));
  return;
}
}
__inline static void netif_stop_queue(struct net_device *dev )
{
  struct netdev_queue *tmp ;
  {
  tmp = netdev_get_tx_queue((struct net_device const *)dev, 0U);
  netif_tx_stop_queue(tmp);
  return;
}
}
__inline static bool netif_tx_queue_stopped(struct netdev_queue const *dev_queue )
{
  int tmp ;
  {
  tmp = constant_test_bit(0L, (unsigned long const volatile *)(& dev_queue->state));
  return (tmp != 0);
}
}
__inline static bool netif_queue_stopped(struct net_device const *dev )
{
  struct netdev_queue *tmp ;
  bool tmp___0 ;
  {
  tmp = netdev_get_tx_queue(dev, 0U);
  tmp___0 = netif_tx_queue_stopped((struct netdev_queue const *)tmp);
  return (tmp___0);
}
}
__inline static bool netif_running(struct net_device const *dev )
{
  int tmp ;
  {
  tmp = constant_test_bit(0L, (unsigned long const volatile *)(& dev->state));
  return (tmp != 0);
}
}
__inline static void netif_stop_subqueue(struct net_device *dev , u16 queue_index )
{
  struct netdev_queue *txq ;
  struct netdev_queue *tmp ;
  {
  tmp = netdev_get_tx_queue((struct net_device const *)dev, (unsigned int )queue_index);
  txq = tmp;
  netif_tx_stop_queue(txq);
  return;
}
}
extern void netif_wake_subqueue(struct net_device * , u16 ) ;
extern void __dev_kfree_skb_any(struct sk_buff * , enum skb_free_reason ) ;
__inline static void dev_kfree_skb_any(struct sk_buff *skb )
{
  {
  __dev_kfree_skb_any(skb, 1);
  return;
}
}
extern int netif_receive_skb_sk(struct sock * , struct sk_buff * ) ;
__inline static int netif_receive_skb(struct sk_buff *skb )
{
  int tmp ;
  {
  tmp = netif_receive_skb_sk(skb->sk, skb);
  return (tmp);
}
}
extern void napi_gro_flush(struct napi_struct * , bool ) ;
extern struct sk_buff *napi_get_frags(struct napi_struct * ) ;
extern gro_result_t napi_gro_frags(struct napi_struct * ) ;
__inline static bool netif_carrier_ok(struct net_device const *dev )
{
  int tmp ;
  {
  tmp = constant_test_bit(2L, (unsigned long const volatile *)(& dev->state));
  return (tmp == 0);
}
}
extern void netif_carrier_on(struct net_device * ) ;
extern void netif_carrier_off(struct net_device * ) ;
extern int register_netdev(struct net_device * ) ;
int ldv_register_netdev_57(struct net_device *dev ) ;
extern void unregister_netdev(struct net_device * ) ;
void ldv_unregister_netdev_62(struct net_device *dev ) ;
extern void netdev_rss_key_fill(void * , size_t ) ;
extern void netdev_err(struct net_device const * , char const * , ...) ;
extern void netdev_info(struct net_device const * , char const * , ...) ;
extern __be16 eth_type_trans(struct sk_buff * , struct net_device * ) ;
extern int eth_validate_addr(struct net_device * ) ;
extern struct net_device *alloc_etherdev_mqs(int , unsigned int , unsigned int ) ;
__inline static bool is_zero_ether_addr(u8 const *addr )
{
  {
  return (((unsigned int )*((u32 const *)addr) | (unsigned int )*((u16 const *)addr + 4U)) == 0U);
}
}
__inline static bool is_multicast_ether_addr(u8 const *addr )
{
  u32 a ;
  {
  a = *((u32 const *)addr);
  return ((a & 1U) != 0U);
}
}
__inline static bool is_valid_ether_addr(u8 const *addr )
{
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  {
  tmp = is_multicast_ether_addr(addr);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    tmp___1 = is_zero_ether_addr(addr);
    if (tmp___1) {
      tmp___2 = 0;
    } else {
      tmp___2 = 1;
    }
    if (tmp___2) {
      tmp___3 = 1;
    } else {
      tmp___3 = 0;
    }
  } else {
    tmp___3 = 0;
  }
  return ((bool )tmp___3);
}
}
__inline static void ether_addr_copy(u8 *dst , u8 const *src )
{
  {
  *((u32 *)dst) = *((u32 const *)src);
  *((u16 *)dst + 4U) = *((u16 const *)src + 4U);
  return;
}
}
__inline static void __vlan_hwaccel_put_tag(struct sk_buff *skb , __be16 vlan_proto ,
                                            u16 vlan_tci )
{
  {
  skb->vlan_proto = vlan_proto;
  skb->vlan_tci = (__u16 )((unsigned int )vlan_tci | 4096U);
  return;
}
}
__inline static __be16 __vlan_get_protocol(struct sk_buff *skb , __be16 type , int *depth )
{
  unsigned int vlan_depth ;
  int __ret_warn_on ;
  long tmp ;
  long tmp___0 ;
  struct vlan_hdr *vh ;
  int tmp___1 ;
  long tmp___2 ;
  {
  vlan_depth = (unsigned int )skb->mac_len;
  if ((unsigned int )type == 129U || (unsigned int )type == 43144U) {
    if (vlan_depth != 0U) {
      __ret_warn_on = vlan_depth <= 3U;
      tmp = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp != 0L) {
        warn_slowpath_null("include/linux/if_vlan.h", 492);
      } else {
      }
      tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
      if (tmp___0 != 0L) {
        return (0U);
      } else {
      }
      vlan_depth = vlan_depth - 4U;
    } else {
      vlan_depth = 14U;
    }
    ldv_44952:
    tmp___1 = pskb_may_pull(skb, vlan_depth + 4U);
    tmp___2 = ldv__builtin_expect(tmp___1 == 0, 0L);
    if (tmp___2 != 0L) {
      return (0U);
    } else {
    }
    vh = (struct vlan_hdr *)skb->data + (unsigned long )vlan_depth;
    type = vh->h_vlan_encapsulated_proto;
    vlan_depth = vlan_depth + 4U;
    if ((unsigned int )type == 129U || (unsigned int )type == 43144U) {
      goto ldv_44952;
    } else {
    }
  } else {
  }
  if ((unsigned long )depth != (unsigned long )((int *)0)) {
    *depth = (int )vlan_depth;
  } else {
  }
  return (type);
}
}
__inline static __be16 vlan_get_protocol(struct sk_buff *skb )
{
  __be16 tmp ;
  {
  tmp = __vlan_get_protocol(skb, (int )skb->protocol, (int *)0);
  return (tmp);
}
}
__inline static struct iphdr *ip_hdr(struct sk_buff const *skb )
{
  unsigned char *tmp ;
  {
  tmp = skb_network_header(skb);
  return ((struct iphdr *)tmp);
}
}
__inline static struct tcphdr *tcp_hdr(struct sk_buff const *skb )
{
  unsigned char *tmp ;
  {
  tmp = skb_transport_header(skb);
  return ((struct tcphdr *)tmp);
}
}
__inline static unsigned int tcp_hdrlen(struct sk_buff const *skb )
{
  struct tcphdr *tmp ;
  {
  tmp = tcp_hdr(skb);
  return ((unsigned int )((int )tmp->doff * 4));
}
}
__inline static struct ipv6hdr *ipv6_hdr(struct sk_buff const *skb )
{
  unsigned char *tmp ;
  {
  tmp = skb_network_header(skb);
  return ((struct ipv6hdr *)tmp);
}
}
extern void release_firmware(struct firmware const * ) ;
extern int pci_enable_device(struct pci_dev * ) ;
extern void pci_disable_device(struct pci_dev * ) ;
extern void pci_set_master(struct pci_dev * ) ;
extern void pci_intx(struct pci_dev * , int ) ;
extern int pci_request_regions(struct pci_dev * , char const * ) ;
extern void pci_release_regions(struct pci_dev * ) ;
extern int __pci_register_driver(struct pci_driver * , struct module * , char const * ) ;
int ldv___pci_register_driver_67(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const *ldv_func_arg3 ) ;
extern void pci_unregister_driver(struct pci_driver * ) ;
void ldv_pci_unregister_driver_68(struct pci_driver *ldv_func_arg1 ) ;
extern void pci_disable_msix(struct pci_dev * ) ;
extern int pci_enable_msix_range(struct pci_dev * , struct msix_entry * , int , int ) ;
__inline static void *pci_get_drvdata(struct pci_dev *pdev )
{
  void *tmp ;
  {
  tmp = dev_get_drvdata((struct device const *)(& pdev->dev));
  return (tmp);
}
}
__inline static void pci_set_drvdata(struct pci_dev *pdev , void *data )
{
  {
  dev_set_drvdata(& pdev->dev, data);
  return;
}
}
void bfa_nw_ioc_auto_recover(bool auto_recover ) ;
void bfa_nw_ioc_timeout(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_hb_check(struct bfa_ioc *ioc ) ;
void bfa_nw_iocpf_timeout(struct bfa_ioc *ioc ) ;
void bfa_nw_iocpf_sem_timeout(struct bfa_ioc *ioc ) ;
u32 const bna_napi_dim_vector[8U][2U] ;
void bna_res_req(struct bna_res_info *res_info ) ;
void bna_mod_res_req(struct bna *bna , struct bna_res_info *res_info ) ;
void bna_init(struct bna *bna , struct bnad *bnad , struct bfa_pcidev *pcidev , struct bna_res_info *res_info ) ;
void bna_mod_init(struct bna *bna , struct bna_res_info *res_info ) ;
void bna_uninit(struct bna *bna ) ;
int bna_num_txq_set(struct bna *bna , int num_txq ) ;
int bna_num_rxp_set(struct bna *bna , int num_rxp ) ;
void bna_hw_stats_get(struct bna *bna ) ;
void bna_mbox_handler(struct bna *bna , u32 intr_status ) ;
void bna_tx_res_req(int num_txq , int txq_depth , struct bna_res_info *res_info ) ;
struct bna_tx *bna_tx_create(struct bna *bna , struct bnad *bnad , struct bna_tx_config *tx_cfg ,
                             struct bna_tx_event_cbfn const *tx_cbfn , struct bna_res_info *res_info ,
                             void *priv ) ;
void bna_tx_destroy(struct bna_tx *tx ) ;
void bna_tx_enable(struct bna_tx *tx ) ;
void bna_tx_disable(struct bna_tx *tx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_tx * ) ) ;
void bna_tx_cleanup_complete(struct bna_tx *tx ) ;
void bna_tx_coalescing_timeo_set(struct bna_tx *tx , int coalescing_timeo ) ;
void bna_rx_res_req(struct bna_rx_config *q_cfg , struct bna_res_info *res_info ) ;
struct bna_rx *bna_rx_create(struct bna *bna , struct bnad *bnad , struct bna_rx_config *rx_cfg ,
                             struct bna_rx_event_cbfn const *rx_cbfn , struct bna_res_info *res_info ,
                             void *priv ) ;
void bna_rx_destroy(struct bna_rx *rx ) ;
void bna_rx_enable(struct bna_rx *rx ) ;
void bna_rx_disable(struct bna_rx *rx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_rx * ) ) ;
void bna_rx_cleanup_complete(struct bna_rx *rx ) ;
void bna_rx_coalescing_timeo_set(struct bna_rx *rx , int coalescing_timeo ) ;
void bna_rx_dim_reconfig(struct bna *bna , u32 const (*vector)[2] ) ;
void bna_rx_dim_update(struct bna_ccb *ccb ) ;
enum bna_cb_status bna_rx_ucast_set(struct bna_rx *rx , u8 const *ucmac ) ;
enum bna_cb_status bna_rx_ucast_listset(struct bna_rx *rx , int count , u8 const *uclist ) ;
enum bna_cb_status bna_rx_mcast_add(struct bna_rx *rx , u8 const *addr , void (*cbfn)(struct bnad * ,
                                                                                        struct bna_rx * ) ) ;
enum bna_cb_status bna_rx_mcast_listset(struct bna_rx *rx , int count , u8 const *mclist ) ;
void bna_rx_mcast_delall(struct bna_rx *rx ) ;
enum bna_cb_status bna_rx_mode_set(struct bna_rx *rx , enum bna_rxmode new_mode ,
                                   enum bna_rxmode bitmask ) ;
void bna_rx_vlan_add(struct bna_rx *rx , int vlan_id ) ;
void bna_rx_vlan_del(struct bna_rx *rx , int vlan_id ) ;
void bna_rx_vlanfilter_enable(struct bna_rx *rx ) ;
void bna_rx_vlan_strip_enable(struct bna_rx *rx ) ;
void bna_rx_vlan_strip_disable(struct bna_rx *rx ) ;
void bna_enet_enable(struct bna_enet *enet ) ;
void bna_enet_disable(struct bna_enet *enet , enum bna_cleanup_type type , void (*cbfn)(void * ) ) ;
void bna_enet_pause_config(struct bna_enet *enet , struct bna_pause_config *pause_config ) ;
void bna_enet_mtu_set(struct bna_enet *enet , int mtu , void (*cbfn)(struct bnad * ) ) ;
void bna_enet_perm_mac_get(struct bna_enet *enet , u8 *mac ) ;
void bna_ioceth_enable(struct bna_ioceth *ioceth ) ;
void bna_ioceth_disable(struct bna_ioceth *ioceth , enum bna_cleanup_type type ) ;
void bnad_cb_ethport_link_status(struct bnad *bnad , enum bna_link_status link_status ) ;
void bnad_cb_ioceth_ready(struct bnad *bnad ) ;
void bnad_cb_ioceth_failed(struct bnad *bnad ) ;
void bnad_cb_ioceth_disabled(struct bnad *bnad ) ;
void bnad_cb_mbox_intr_enable(struct bnad *bnad ) ;
void bnad_cb_mbox_intr_disable(struct bnad *bnad ) ;
void bnad_cb_stats_get(struct bnad *bnad , enum bna_cb_status status , struct bna_stats *stats ) ;
struct firmware const *bfi_fw ;
u32 *cna_get_firmware_buf(struct pci_dev *pdev ) ;
void bnad_set_rx_mode(struct net_device *netdev ) ;
int bnad_mac_addr_set_locked(struct bnad *bnad , u8 const *mac_addr ) ;
int bnad_enable_default_bcast(struct bnad *bnad ) ;
void bnad_restore_vlans(struct bnad *bnad , u32 rx_id ) ;
void bnad_set_ethtool_ops(struct net_device *netdev ) ;
void bnad_cb_completion(void *arg , enum bfa_status status ) ;
void bnad_tx_coalescing_timeo_set(struct bnad *bnad ) ;
void bnad_rx_coalescing_timeo_set(struct bnad *bnad ) ;
int bnad_setup_rx(struct bnad *bnad , u32 rx_id ) ;
int bnad_setup_tx(struct bnad *bnad , u32 tx_id ) ;
void bnad_destroy_tx(struct bnad *bnad , u32 tx_id ) ;
void bnad_destroy_rx(struct bnad *bnad , u32 rx_id ) ;
void bnad_dim_timer_start(struct bnad *bnad ) ;
void bnad_netdev_qstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats ) ;
void bnad_netdev_hwstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats ) ;
void bnad_debugfs_init(struct bnad *bnad ) ;
void bnad_debugfs_uninit(struct bnad *bnad ) ;
static struct mutex bnad_fwimg_mutex = {{1}, {{{{{0}}, 3735899821U, 4294967295U, (void *)-1, {0, {0, 0}, "bnad_fwimg_mutex.wait_lock",
                                                          0, 0UL}}}}, {& bnad_fwimg_mutex.wait_list,
                                                                       & bnad_fwimg_mutex.wait_list},
    0, (void *)(& bnad_fwimg_mutex), {0, {0, 0}, "bnad_fwimg_mutex", 0, 0UL}};
static uint bnad_msix_disable ;
static uint bnad_ioc_auto_recover = 1U;
static uint bna_debugfs_enable = 1U;
static u32 bnad_rxqs_per_cq = 2U;
static u32 bna_id ;
static struct mutex bnad_list_mutex ;
static struct list_head bnad_list = {& bnad_list, & bnad_list};
static u8 const bnad_bcast_addr[6U] = { 255U, 255U, 255U, 255U,
        255U, 255U};
static void bnad_add_to_list(struct bnad *bnad )
{
  u32 tmp ;
  {
  mutex_lock_nested(& bnad_list_mutex, 0U);
  list_add_tail(& bnad->list_entry, & bnad_list);
  tmp = bna_id;
  bna_id = bna_id + 1U;
  bnad->id = tmp;
  mutex_unlock(& bnad_list_mutex);
  return;
}
}
static void bnad_remove_from_list(struct bnad *bnad )
{
  {
  mutex_lock_nested(& bnad_list_mutex, 0U);
  list_del(& bnad->list_entry);
  mutex_unlock(& bnad_list_mutex);
  return;
}
}
static void bnad_cq_cleanup(struct bnad *bnad , struct bna_ccb *ccb )
{
  struct bna_cq_entry *cmpl ;
  int i ;
  {
  i = 0;
  goto ldv_58411;
  ldv_58410:
  cmpl = (struct bna_cq_entry *)ccb->sw_q + (unsigned long )i;
  cmpl->valid = 0U;
  i = i + 1;
  ldv_58411: ;
  if ((u32 )i < ccb->q_depth) {
    goto ldv_58410;
  } else {
  }
  return;
}
}
static u32 bnad_tx_buff_unmap(struct bnad *bnad , struct bnad_tx_unmap *unmap_q ,
                              u32 q_depth , u32 index )
{
  struct bnad_tx_unmap *unmap ;
  struct sk_buff *skb ;
  int vector ;
  int nvecs ;
  unsigned int tmp ;
  {
  unmap = unmap_q + (unsigned long )index;
  nvecs = (int )unmap->nvecs;
  skb = unmap->skb;
  unmap->skb = (struct sk_buff *)0;
  unmap->nvecs = 0U;
  tmp = skb_headlen((struct sk_buff const *)skb);
  dma_unmap_single_attrs(& (bnad->pcidev)->dev, ((struct bnad_tx_vector *)(& unmap->vectors))->dma_addr,
                         (size_t )tmp, 1, (struct dma_attrs *)0);
  ((struct bnad_tx_vector *)(& unmap->vectors))->dma_addr = 0ULL;
  nvecs = nvecs - 1;
  vector = 0;
  goto ldv_58424;
  ldv_58423:
  vector = vector + 1;
  if (vector == 4) {
    vector = 0;
    index = (index + 1U) & (q_depth - 1U);
    unmap = unmap_q + (unsigned long )index;
  } else {
  }
  dma_unmap_page(& (bnad->pcidev)->dev, ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vector)->dma_addr,
                 (size_t )((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vector)->dma_len,
                 1);
  ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vector)->dma_addr = 0ULL;
  nvecs = nvecs - 1;
  ldv_58424: ;
  if (nvecs != 0) {
    goto ldv_58423;
  } else {
  }
  index = (index + 1U) & (q_depth - 1U);
  return (index);
}
}
static void bnad_txq_cleanup(struct bnad *bnad , struct bna_tcb *tcb )
{
  struct bnad_tx_unmap *unmap_q ;
  struct sk_buff *skb ;
  int i ;
  {
  unmap_q = (struct bnad_tx_unmap *)tcb->unmap_q;
  i = 0;
  goto ldv_58435;
  ldv_58434:
  skb = (unmap_q + (unsigned long )i)->skb;
  if ((unsigned long )skb == (unsigned long )((struct sk_buff *)0)) {
    goto ldv_58433;
  } else {
  }
  bnad_tx_buff_unmap(bnad, unmap_q, tcb->q_depth, (u32 )i);
  dev_kfree_skb_any(skb);
  ldv_58433:
  i = i + 1;
  ldv_58435: ;
  if ((u32 )i < tcb->q_depth) {
    goto ldv_58434;
  } else {
  }
  return;
}
}
static u32 bnad_txcmpl_process(struct bnad *bnad , struct bna_tcb *tcb )
{
  u32 sent_packets ;
  u32 sent_bytes ;
  u32 wis ;
  u32 unmap_wis ;
  u32 hw_cons ;
  u32 cons ;
  u32 q_depth ;
  struct bnad_tx_unmap *unmap_q ;
  struct bnad_tx_unmap *unmap ;
  struct sk_buff *skb ;
  int tmp ;
  long tmp___0 ;
  {
  sent_packets = 0U;
  sent_bytes = 0U;
  unmap_q = (struct bnad_tx_unmap *)tcb->unmap_q;
  tmp = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
  if (tmp == 0) {
    return (0U);
  } else {
  }
  hw_cons = *(tcb->hw_consumer_index);
  cons = tcb->consumer_index;
  q_depth = tcb->q_depth;
  wis = (hw_cons - cons) & (q_depth - 1U);
  tmp___0 = ldv__builtin_expect(((tcb->producer_index - tcb->consumer_index) & (tcb->q_depth - 1U)) < wis,
                             0L);
  if (tmp___0 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (203), "i" (12UL));
    ldv_58451: ;
    goto ldv_58451;
  } else {
  }
  goto ldv_58453;
  ldv_58452:
  unmap = unmap_q + (unsigned long )cons;
  skb = unmap->skb;
  sent_packets = sent_packets + 1U;
  sent_bytes = skb->len + sent_bytes;
  unmap_wis = (unmap->nvecs + 3U) >> 2;
  wis = wis - unmap_wis;
  cons = bnad_tx_buff_unmap(bnad, unmap_q, q_depth, cons);
  dev_kfree_skb_any(skb);
  ldv_58453: ;
  if (wis != 0U) {
    goto ldv_58452;
  } else {
  }
  tcb->consumer_index = hw_cons;
  (tcb->txq)->tx_packets = (tcb->txq)->tx_packets + (u64 )sent_packets;
  (tcb->txq)->tx_bytes = (tcb->txq)->tx_bytes + (u64 )sent_bytes;
  return (sent_packets);
}
}
static u32 bnad_tx_complete(struct bnad *bnad , struct bna_tcb *tcb )
{
  struct net_device *netdev ;
  u32 sent ;
  int tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;
  {
  netdev = bnad->netdev;
  sent = 0U;
  tmp = test_and_set_bit(0L, (unsigned long volatile *)(& tcb->flags));
  if (tmp != 0) {
    return (0U);
  } else {
  }
  sent = bnad_txcmpl_process(bnad, tcb);
  if (sent != 0U) {
    tmp___1 = netif_queue_stopped((struct net_device const *)netdev);
    if ((int )tmp___1) {
      tmp___2 = netif_carrier_ok((struct net_device const *)netdev);
      if ((int )tmp___2) {
        if ((((tcb->consumer_index - tcb->producer_index) - 1U) & (tcb->q_depth - 1U)) > 7U) {
          tmp___0 = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
          if (tmp___0 != 0) {
            netif_wake_queue(netdev);
            bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
          } else {
          }
        } else {
        }
      } else {
      }
    } else {
    }
  } else {
  }
  tmp___3 = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
  tmp___4 = ldv__builtin_expect(tmp___3 != 0, 1L);
  if (tmp___4 != 0L) {
    writel((tcb->i_dbell)->doorbell_ack | sent, (void volatile *)(tcb->i_dbell)->doorbell_addr);
  } else {
  }
  __asm__ volatile ("": : : "memory");
  clear_bit(0L, (unsigned long volatile *)(& tcb->flags));
  return (sent);
}
}
static irqreturn_t bnad_msix_tx(int irq , void *data )
{
  struct bna_tcb *tcb ;
  struct bnad *bnad ;
  {
  tcb = (struct bna_tcb *)data;
  bnad = tcb->bnad;
  bnad_tx_complete(bnad, tcb);
  return (1);
}
}
__inline static void bnad_rxq_alloc_uninit(struct bnad *bnad , struct bna_rcb *rcb )
{
  struct bnad_rx_unmap_q *unmap_q ;
  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  unmap_q->reuse_pi = -1;
  unmap_q->alloc_order = -1;
  unmap_q->map_size = 0U;
  unmap_q->type = 0;
  return;
}
}
static int bnad_rxq_alloc_init(struct bnad *bnad , struct bna_rcb *rcb )
{
  struct bnad_rx_unmap_q *unmap_q ;
  int order ;
  long tmp ;
  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  bnad_rxq_alloc_uninit(bnad, rcb);
  order = __get_order((unsigned long )(rcb->rxq)->buffer_size);
  unmap_q->type = 2;
  if (rcb->id & 1) {
    unmap_q->alloc_order = 0;
    unmap_q->map_size = (u32 )(rcb->rxq)->buffer_size;
  } else
  if ((unsigned int )(rcb->rxq)->multi_buffer != 0U) {
    unmap_q->alloc_order = 0;
    unmap_q->map_size = (u32 )(rcb->rxq)->buffer_size;
    unmap_q->type = 3;
  } else {
    unmap_q->alloc_order = order;
    unmap_q->map_size = (rcb->rxq)->buffer_size > 2048 ? (u32 )(4096UL << order) : 2048U;
  }
  tmp = ldv__builtin_expect((4096UL << order) % (unsigned long )unmap_q->map_size != 0UL,
                         0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (312), "i" (12UL));
    ldv_58478: ;
    goto ldv_58478;
  } else {
  }
  return (0);
}
}
__inline static void bnad_rxq_cleanup_page(struct bnad *bnad , struct bnad_rx_unmap *unmap )
{
  {
  if ((unsigned long )unmap->page == (unsigned long )((struct page *)0)) {
    return;
  } else {
  }
  dma_unmap_page(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                 2);
  put_page(unmap->page);
  unmap->page = (struct page *)0;
  unmap->vector.dma_addr = 0ULL;
  unmap->vector.len = 0U;
  return;
}
}
__inline static void bnad_rxq_cleanup_skb(struct bnad *bnad , struct bnad_rx_unmap *unmap )
{
  {
  if ((unsigned long )unmap->skb == (unsigned long )((struct sk_buff *)0)) {
    return;
  } else {
  }
  dma_unmap_single_attrs(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                         2, (struct dma_attrs *)0);
  dev_kfree_skb_any(unmap->skb);
  unmap->skb = (struct sk_buff *)0;
  unmap->vector.dma_addr = 0ULL;
  unmap->vector.len = 0U;
  return;
}
}
static void bnad_rxq_cleanup(struct bnad *bnad , struct bna_rcb *rcb )
{
  struct bnad_rx_unmap_q *unmap_q ;
  int i ;
  struct bnad_rx_unmap *unmap ;
  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  i = 0;
  goto ldv_58495;
  ldv_58494:
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )i;
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_rxq_cleanup_skb(bnad, unmap);
  } else {
    bnad_rxq_cleanup_page(bnad, unmap);
  }
  i = i + 1;
  ldv_58495: ;
  if ((u32 )i < rcb->q_depth) {
    goto ldv_58494;
  } else {
  }
  bnad_rxq_alloc_uninit(bnad, rcb);
  return;
}
}
static u32 bnad_rxq_refill_page(struct bnad *bnad , struct bna_rcb *rcb , u32 nalloc )
{
  u32 alloced ;
  u32 prod ;
  u32 q_depth ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  struct bnad_rx_unmap *prev ;
  struct bna_rxq_entry *rxent ;
  struct page *page ;
  u32 page_offset ;
  u32 alloc_size ;
  dma_addr_t dma_addr ;
  long tmp ;
  u64 tmp_addr ;
  __u64 tmp___0 ;
  u32 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;
  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  prod = rcb->producer_index;
  q_depth = rcb->q_depth;
  alloc_size = (u32 )(4096UL << unmap_q->alloc_order);
  alloced = 0U;
  goto ldv_58516;
  ldv_58515:
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )prod;
  if (unmap_q->reuse_pi < 0) {
    page = alloc_pages(16416U, (unsigned int )unmap_q->alloc_order);
    page_offset = 0U;
  } else {
    prev = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )unmap_q->reuse_pi;
    page = prev->page;
    page_offset = prev->page_offset + unmap_q->map_size;
    get_page(page);
  }
  tmp = ldv__builtin_expect((unsigned long )page == (unsigned long )((struct page *)0),
                         0L);
  if (tmp != 0L) {
    bnad->stats.drv_stats.rxbuf_alloc_failed = bnad->stats.drv_stats.rxbuf_alloc_failed + 1ULL;
    (rcb->rxq)->rxbuf_alloc_failed = (rcb->rxq)->rxbuf_alloc_failed + 1ULL;
    goto finishing;
  } else {
  }
  dma_addr = dma_map_page(& (bnad->pcidev)->dev, page, (size_t )page_offset, (size_t )unmap_q->map_size,
                          2);
  unmap->page = page;
  unmap->page_offset = page_offset;
  unmap->vector.dma_addr = dma_addr;
  unmap->vector.len = unmap_q->map_size;
  page_offset = unmap_q->map_size + page_offset;
  if (page_offset < alloc_size) {
    unmap_q->reuse_pi = (int )prod;
  } else {
    unmap_q->reuse_pi = -1;
  }
  rxent = (struct bna_rxq_entry *)rcb->sw_q + (unsigned long )prod;
  tmp___0 = __fswab64(dma_addr);
  tmp_addr = tmp___0;
  rxent->host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  rxent->host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  prod = (prod + 1U) & (q_depth - 1U);
  alloced = alloced + 1U;
  ldv_58516:
  tmp___1 = nalloc;
  nalloc = nalloc - 1U;
  if (tmp___1 != 0U) {
    goto ldv_58515;
  } else {
  }
  finishing:
  tmp___4 = ldv__builtin_expect(alloced != 0U, 1L);
  if (tmp___4 != 0L) {
    rcb->producer_index = prod;
    __asm__ volatile ("mfence": : : "memory");
    tmp___2 = constant_test_bit(1L, (unsigned long const volatile *)(& rcb->flags));
    tmp___3 = ldv__builtin_expect(tmp___2 != 0, 1L);
    if (tmp___3 != 0L) {
      writel(rcb->producer_index | 2147483648U, (void volatile *)rcb->q_dbell);
    } else {
    }
  } else {
  }
  return (alloced);
}
}
static u32 bnad_rxq_refill_skb(struct bnad *bnad , struct bna_rcb *rcb , u32 nalloc )
{
  u32 alloced ;
  u32 prod ;
  u32 q_depth ;
  u32 buff_sz ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  struct bna_rxq_entry *rxent ;
  struct sk_buff *skb ;
  dma_addr_t dma_addr ;
  long tmp ;
  u64 tmp_addr ;
  __u64 tmp___0 ;
  u32 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;
  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  buff_sz = (u32 )(rcb->rxq)->buffer_size;
  prod = rcb->producer_index;
  q_depth = rcb->q_depth;
  alloced = 0U;
  goto ldv_58535;
  ldv_58534:
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )prod;
  skb = netdev_alloc_skb_ip_align(bnad->netdev, buff_sz);
  tmp = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                         0L);
  if (tmp != 0L) {
    bnad->stats.drv_stats.rxbuf_alloc_failed = bnad->stats.drv_stats.rxbuf_alloc_failed + 1ULL;
    (rcb->rxq)->rxbuf_alloc_failed = (rcb->rxq)->rxbuf_alloc_failed + 1ULL;
    goto finishing;
  } else {
  }
  dma_addr = dma_map_single_attrs(& (bnad->pcidev)->dev, (void *)skb->data, (size_t )buff_sz,
                                  2, (struct dma_attrs *)0);
  unmap->skb = skb;
  unmap->vector.dma_addr = dma_addr;
  unmap->vector.len = buff_sz;
  rxent = (struct bna_rxq_entry *)rcb->sw_q + (unsigned long )prod;
  tmp___0 = __fswab64(dma_addr);
  tmp_addr = tmp___0;
  rxent->host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  rxent->host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  prod = (prod + 1U) & (q_depth - 1U);
  alloced = alloced + 1U;
  ldv_58535:
  tmp___1 = nalloc;
  nalloc = nalloc - 1U;
  if (tmp___1 != 0U) {
    goto ldv_58534;
  } else {
  }
  finishing:
  tmp___4 = ldv__builtin_expect(alloced != 0U, 1L);
  if (tmp___4 != 0L) {
    rcb->producer_index = prod;
    __asm__ volatile ("mfence": : : "memory");
    tmp___2 = constant_test_bit(1L, (unsigned long const volatile *)(& rcb->flags));
    tmp___3 = ldv__builtin_expect(tmp___2 != 0, 1L);
    if (tmp___3 != 0L) {
      writel(rcb->producer_index | 2147483648U, (void volatile *)rcb->q_dbell);
    } else {
    }
  } else {
  }
  return (alloced);
}
}
__inline static void bnad_rxq_post(struct bnad *bnad , struct bna_rcb *rcb )
{
  struct bnad_rx_unmap_q *unmap_q ;
  u32 to_alloc ;
  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  to_alloc = ((rcb->consumer_index - rcb->producer_index) - 1U) & (rcb->q_depth - 1U);
  if (to_alloc >> 3 == 0U) {
    return;
  } else {
  }
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_rxq_refill_skb(bnad, rcb, to_alloc);
  } else {
    bnad_rxq_refill_page(bnad, rcb, to_alloc);
  }
  return;
}
}
static void bnad_cq_drop_packet(struct bnad *bnad , struct bna_rcb *rcb , u32 sop_ci ,
                                u32 nvecs )
{
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  u32 ci ;
  u32 vec ;
  {
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  vec = 0U;
  ci = sop_ci;
  goto ldv_58554;
  ldv_58553:
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )ci;
  ci = (ci + 1U) & (rcb->q_depth - 1U);
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_rxq_cleanup_skb(bnad, unmap);
  } else {
    bnad_rxq_cleanup_page(bnad, unmap);
  }
  vec = vec + 1U;
  ldv_58554: ;
  if (vec < nvecs) {
    goto ldv_58553;
  } else {
  }
  return;
}
}
static void bnad_cq_setup_skb_frags(struct bna_rcb *rcb , struct sk_buff *skb , u32 sop_ci ,
                                    u32 nvecs , u32 last_fraglen )
{
  struct bnad *bnad ;
  u32 ci ;
  u32 vec ;
  u32 len ;
  u32 totlen ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  void *tmp ;
  unsigned char *tmp___0 ;
  {
  totlen = 0U;
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  bnad = rcb->bnad;
  tmp = lowmem_page_address((struct page const *)unmap_q->unmap[sop_ci].page);
  __builtin_prefetch((void const *)tmp + (unsigned long )unmap_q->unmap[sop_ci].page_offset);
  vec = 1U;
  ci = sop_ci;
  goto ldv_58571;
  ldv_58570:
  unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )ci;
  ci = (ci + 1U) & (rcb->q_depth - 1U);
  dma_unmap_page(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                 2);
  len = vec != nvecs ? unmap->vector.len : last_fraglen;
  skb->truesize = skb->truesize + unmap->vector.len;
  totlen = totlen + len;
  tmp___0 = skb_end_pointer((struct sk_buff const *)skb);
  skb_fill_page_desc(skb, (int )((struct skb_shared_info *)tmp___0)->nr_frags, unmap->page,
                     (int )unmap->page_offset, (int )len);
  unmap->page = (struct page *)0;
  unmap->vector.len = 0U;
  vec = vec + 1U;
  ldv_58571: ;
  if (vec <= nvecs) {
    goto ldv_58570;
  } else {
  }
  skb->len = skb->len + totlen;
  skb->data_len = skb->data_len + totlen;
  return;
}
}
__inline static void bnad_cq_setup_skb(struct bnad *bnad , struct sk_buff *skb , struct bnad_rx_unmap *unmap ,
                                       u32 len )
{
  {
  __builtin_prefetch((void const *)skb->data);
  dma_unmap_single_attrs(& (bnad->pcidev)->dev, unmap->vector.dma_addr, (size_t )unmap->vector.len,
                         2, (struct dma_attrs *)0);
  skb_put(skb, len);
  skb->protocol = eth_type_trans(skb, bnad->netdev);
  unmap->skb = (struct sk_buff *)0;
  unmap->vector.len = 0U;
  return;
}
}
static u32 bnad_cq_process(struct bnad *bnad , struct bna_ccb *ccb , int budget )
{
  struct bna_cq_entry *cq ;
  struct bna_cq_entry *cmpl ;
  struct bna_cq_entry *next_cmpl ;
  struct bna_rcb *rcb ;
  struct bnad_rx_unmap_q *unmap_q ;
  struct bnad_rx_unmap *unmap ;
  struct sk_buff *skb ;
  struct bna_pkt_rate *pkt_rt ;
  struct bnad_rx_ctrl *rx_ctrl ;
  u32 packets ;
  u32 len ;
  u32 totlen ;
  u32 pi ;
  u32 vec ;
  u32 sop_ci ;
  u32 nvecs ;
  u32 flags ;
  u32 masked_flags ;
  __u16 tmp ;
  long tmp___0 ;
  __u32 tmp___1 ;
  __u16 tmp___2 ;
  __u16 tmp___3 ;
  __u32 tmp___4 ;
  long tmp___5 ;
  long tmp___6 ;
  __u16 tmp___7 ;
  int tmp___8 ;
  long tmp___9 ;
  {
  rcb = (struct bna_rcb *)0;
  unmap = (struct bnad_rx_unmap *)0;
  skb = (struct sk_buff *)0;
  pkt_rt = & ccb->pkt_rate;
  rx_ctrl = (struct bnad_rx_ctrl *)ccb->ctrl;
  packets = 0U;
  len = 0U;
  totlen = 0U;
  sop_ci = 0U;
  nvecs = 0U;
  __builtin_prefetch((void const *)bnad->netdev);
  cq = (struct bna_cq_entry *)ccb->sw_q;
  goto ldv_58610;
  ldv_58609:
  cmpl = cq + (unsigned long )ccb->producer_index;
  if ((unsigned int )cmpl->valid == 0U) {
    goto ldv_58602;
  } else {
  }
  __asm__ volatile ("lfence": : : "memory");
  tmp = __fswab16((int )cmpl->length);
  if ((unsigned int )tmp > 1000U) {
    pkt_rt->large_pkt_cnt = pkt_rt->large_pkt_cnt + 1U;
  } else {
    pkt_rt->small_pkt_cnt = pkt_rt->small_pkt_cnt + 1U;
  }
  if ((int )cmpl->rxq_id & 1) {
    rcb = ccb->rcb[1];
  } else {
    rcb = ccb->rcb[0];
  }
  unmap_q = (struct bnad_rx_unmap_q *)rcb->unmap_q;
  sop_ci = rcb->consumer_index;
  if ((unsigned int )unmap_q->type == 1U) {
    unmap = (struct bnad_rx_unmap *)(& unmap_q->unmap) + (unsigned long )sop_ci;
    skb = unmap->skb;
  } else {
    skb = napi_get_frags(& rx_ctrl->napi);
    tmp___0 = ldv__builtin_expect((unsigned long )skb == (unsigned long )((struct sk_buff *)0),
                               0L);
    if (tmp___0 != 0L) {
      goto ldv_58602;
    } else {
    }
  }
  __builtin_prefetch((void const *)skb);
  tmp___1 = __fswab32(cmpl->flags);
  flags = tmp___1;
  tmp___2 = __fswab16((int )cmpl->length);
  len = (u32 )tmp___2;
  totlen = len;
  nvecs = 1U;
  if ((unsigned int )unmap_q->type == 3U && (int )flags >= 0) {
    pi = ccb->producer_index;
    ldv_58604:
    pi = (pi + 1U) & (ccb->q_depth - 1U);
    next_cmpl = cq + (unsigned long )pi;
    if ((unsigned int )next_cmpl->valid == 0U) {
      goto ldv_58603;
    } else {
    }
    __asm__ volatile ("lfence": : : "memory");
    tmp___3 = __fswab16((int )next_cmpl->length);
    len = (u32 )tmp___3;
    tmp___4 = __fswab32(next_cmpl->flags);
    flags = tmp___4;
    nvecs = nvecs + 1U;
    totlen = totlen + len;
    if ((int )flags >= 0) {
      goto ldv_58604;
    } else {
    }
    ldv_58603: ;
    if ((unsigned int )next_cmpl->valid == 0U) {
      goto ldv_58602;
    } else {
    }
  } else {
  }
  tmp___5 = ldv__builtin_expect(((unsigned long )flags & 7UL) != 0UL, 0L);
  if (tmp___5 != 0L) {
    bnad_cq_drop_packet(bnad, rcb, sop_ci, nvecs);
    (rcb->rxq)->rx_packets_with_error = (rcb->rxq)->rx_packets_with_error + 1ULL;
    goto next;
  } else {
  }
  if ((unsigned int )unmap_q->type == 1U) {
    bnad_cq_setup_skb(bnad, skb, unmap, len);
  } else {
    bnad_cq_setup_skb_frags(rcb, skb, sop_ci, nvecs, len);
  }
  packets = packets + 1U;
  (rcb->rxq)->rx_packets = (rcb->rxq)->rx_packets + 1ULL;
  (rcb->rxq)->rx_bytes = (rcb->rxq)->rx_bytes + (u64 )totlen;
  ccb->bytes_per_intr = ccb->bytes_per_intr + totlen;
  masked_flags = flags & 7008U;
  tmp___6 = ldv__builtin_expect((long )(((bnad->netdev)->features & 17179869184ULL) != 0ULL && (((masked_flags == 4704U || masked_flags == 4448U) || masked_flags == 2592U) || masked_flags == 2336U)),
                             1L);
  if (tmp___6 != 0L) {
    skb->ip_summed = 1U;
  } else {
    skb_checksum_none_assert((struct sk_buff const *)skb);
  }
  if (((unsigned long )flags & 8192UL) != 0UL && ((bnad->netdev)->features & 256ULL) != 0ULL) {
    tmp___7 = __fswab16((int )cmpl->vlan_tag);
    __vlan_hwaccel_put_tag(skb, 129, (int )tmp___7);
  } else {
  }
  if ((unsigned int )unmap_q->type == 1U) {
    netif_receive_skb(skb);
  } else {
    napi_gro_frags(& rx_ctrl->napi);
  }
  next:
  rcb->consumer_index = (rcb->consumer_index + nvecs) & (rcb->q_depth - 1U);
  vec = 0U;
  goto ldv_58607;
  ldv_58606:
  cmpl = cq + (unsigned long )ccb->producer_index;
  cmpl->valid = 0U;
  ccb->producer_index = (ccb->producer_index + 1U) & (ccb->q_depth - 1U);
  vec = vec + 1U;
  ldv_58607: ;
  if (vec < nvecs) {
    goto ldv_58606;
  } else {
  }
  ldv_58610: ;
  if ((u32 )budget > packets) {
    goto ldv_58609;
  } else {
  }
  ldv_58602:
  napi_gro_flush(& rx_ctrl->napi, 0);
  tmp___8 = constant_test_bit(0L, (unsigned long const volatile *)(& (ccb->rcb[0])->flags));
  tmp___9 = ldv__builtin_expect(tmp___8 != 0, 1L);
  if (tmp___9 != 0L) {
    writel(packets | 2147483648U, (void volatile *)(ccb->i_dbell)->doorbell_addr);
  } else {
  }
  bnad_rxq_post(bnad, ccb->rcb[0]);
  if ((unsigned long )ccb->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    bnad_rxq_post(bnad, ccb->rcb[1]);
  } else {
  }
  return (packets);
}
}
static void bnad_netif_rx_schedule_poll(struct bnad *bnad , struct bna_ccb *ccb )
{
  struct bnad_rx_ctrl *rx_ctrl ;
  struct napi_struct *napi ;
  bool tmp ;
  long tmp___0 ;
  {
  rx_ctrl = (struct bnad_rx_ctrl *)ccb->ctrl;
  napi = & rx_ctrl->napi;
  tmp = napi_schedule_prep(napi);
  tmp___0 = ldv__builtin_expect((long )tmp, 1L);
  if (tmp___0 != 0L) {
    __napi_schedule(napi);
    rx_ctrl->rx_schedule = rx_ctrl->rx_schedule + 1ULL;
  } else {
  }
  return;
}
}
static irqreturn_t bnad_msix_rx(int irq , void *data )
{
  struct bna_ccb *ccb ;
  {
  ccb = (struct bna_ccb *)data;
  if ((unsigned long )ccb != (unsigned long )((struct bna_ccb *)0)) {
    ((struct bnad_rx_ctrl *)ccb->ctrl)->rx_intr_ctr = ((struct bnad_rx_ctrl *)ccb->ctrl)->rx_intr_ctr + 1ULL;
    bnad_netif_rx_schedule_poll(ccb->bnad, ccb);
  } else {
  }
  return (1);
}
}
static irqreturn_t bnad_msix_mbox_handler(int irq , void *data )
{
  u32 intr_status ;
  unsigned long flags ;
  struct bnad *bnad ;
  int tmp ;
  long tmp___0 ;
  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  tmp = constant_test_bit(2L, (unsigned long const volatile *)(& bnad->run_flags));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return (1);
  } else {
  }
  intr_status = readl((void const volatile *)bnad->bna.regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ bnad->bna.bits.mbox_status_bits & intr_status, (void volatile *)bnad->bna.regs.fn_int_status);
  } else {
  }
  if (((bnad->bna.bits.mbox_status_bits | bnad->bna.bits.error_status_bits) & intr_status) != 0U) {
    bna_mbox_handler(& bnad->bna, intr_status);
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (1);
}
}
static irqreturn_t bnad_isr(int irq , void *data )
{
  int i ;
  int j ;
  u32 intr_status ;
  unsigned long flags ;
  struct bnad *bnad ;
  struct bnad_rx_info *rx_info ;
  struct bnad_rx_ctrl *rx_ctrl ;
  struct bna_tcb *tcb ;
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  int tmp___2 ;
  {
  bnad = (struct bnad *)data;
  tcb = (struct bna_tcb *)0;
  ldv_spin_lock();
  tmp = constant_test_bit(2L, (unsigned long const volatile *)(& bnad->run_flags));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return (0);
  } else {
  }
  intr_status = readl((void const volatile *)bnad->bna.regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ bnad->bna.bits.mbox_status_bits & intr_status, (void volatile *)bnad->bna.regs.fn_int_status);
  } else {
  }
  tmp___1 = ldv__builtin_expect(intr_status == 0U, 0L);
  if (tmp___1 != 0L) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return (0);
  } else {
  }
  if (((bnad->bna.bits.mbox_status_bits | bnad->bna.bits.error_status_bits) & intr_status) != 0U) {
    bna_mbox_handler(& bnad->bna, intr_status);
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((intr_status & 65535U) == 0U) {
    return (1);
  } else {
  }
  i = 0;
  goto ldv_58645;
  ldv_58644:
  j = 0;
  goto ldv_58642;
  ldv_58641:
  tcb = bnad->tx_info[i].tcb[j];
  if ((unsigned long )tcb != (unsigned long )((struct bna_tcb *)0)) {
    tmp___2 = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
    if (tmp___2 != 0) {
      bnad_tx_complete(bnad, bnad->tx_info[i].tcb[j]);
    } else {
    }
  } else {
  }
  j = j + 1;
  ldv_58642: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_58641;
  } else {
  }
  i = i + 1;
  ldv_58645: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58644;
  } else {
  }
  i = 0;
  goto ldv_58652;
  ldv_58651:
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58647;
  } else {
  }
  j = 0;
  goto ldv_58649;
  ldv_58648:
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )j;
  if ((unsigned long )rx_ctrl->ccb != (unsigned long )((struct bna_ccb *)0)) {
    bnad_netif_rx_schedule_poll(bnad, rx_ctrl->ccb);
  } else {
  }
  j = j + 1;
  ldv_58649: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58648;
  } else {
  }
  ldv_58647:
  i = i + 1;
  ldv_58652: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58651;
  } else {
  }
  return (1);
}
}
static void bnad_enable_mbox_irq(struct bnad *bnad )
{
  {
  clear_bit(2L, (unsigned long volatile *)(& bnad->run_flags));
  bnad->stats.drv_stats.mbox_intr_enabled = bnad->stats.drv_stats.mbox_intr_enabled + 1ULL;
  return;
}
}
static void bnad_disable_mbox_irq(struct bnad *bnad )
{
  {
  set_bit(2L, (unsigned long volatile *)(& bnad->run_flags));
  bnad->stats.drv_stats.mbox_intr_disabled = bnad->stats.drv_stats.mbox_intr_disabled + 1ULL;
  return;
}
}
static void bnad_set_netdev_perm_addr(struct bnad *bnad )
{
  struct net_device *netdev ;
  bool tmp ;
  {
  netdev = bnad->netdev;
  ether_addr_copy((u8 *)(& netdev->perm_addr), (u8 const *)(& bnad->perm_addr));
  tmp = is_zero_ether_addr((u8 const *)netdev->dev_addr);
  if ((int )tmp) {
    ether_addr_copy(netdev->dev_addr, (u8 const *)(& bnad->perm_addr));
  } else {
  }
  return;
}
}
void bnad_cb_mbox_intr_enable(struct bnad *bnad )
{
  {
  bnad_enable_mbox_irq(bnad);
  return;
}
}
void bnad_cb_mbox_intr_disable(struct bnad *bnad )
{
  {
  bnad_disable_mbox_irq(bnad);
  return;
}
}
void bnad_cb_ioceth_ready(struct bnad *bnad )
{
  {
  bnad->bnad_completions.ioc_comp_status = 0U;
  complete(& bnad->bnad_completions.ioc_comp);
  return;
}
}
void bnad_cb_ioceth_failed(struct bnad *bnad )
{
  {
  bnad->bnad_completions.ioc_comp_status = 1U;
  complete(& bnad->bnad_completions.ioc_comp);
  return;
}
}
void bnad_cb_ioceth_disabled(struct bnad *bnad )
{
  {
  bnad->bnad_completions.ioc_comp_status = 0U;
  complete(& bnad->bnad_completions.ioc_comp);
  return;
}
}
static void bnad_cb_enet_disabled(void *arg )
{
  struct bnad *bnad ;
  {
  bnad = (struct bnad *)arg;
  netif_carrier_off(bnad->netdev);
  complete(& bnad->bnad_completions.enet_comp);
  return;
}
}
void bnad_cb_ethport_link_status(struct bnad *bnad , enum bna_link_status link_status )
{
  bool link_up ;
  int tmp ;
  int tmp___0 ;
  uint tx_id ;
  uint tcb_id ;
  struct bna_tcb *tcb ;
  u32 txq_id ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  bool tmp___4 ;
  {
  link_up = 0;
  link_up = (bool )((unsigned int )link_status == 1U || (unsigned int )link_status == 2U);
  if ((unsigned int )link_status == 2U) {
    tmp = constant_test_bit(0L, (unsigned long const volatile *)(& bnad->run_flags));
    if (tmp == 0) {
      bnad->stats.drv_stats.cee_toggle = bnad->stats.drv_stats.cee_toggle + 1ULL;
    } else {
    }
    set_bit(0L, (unsigned long volatile *)(& bnad->run_flags));
  } else {
    tmp___0 = constant_test_bit(0L, (unsigned long const volatile *)(& bnad->run_flags));
    if (tmp___0 != 0) {
      bnad->stats.drv_stats.cee_toggle = bnad->stats.drv_stats.cee_toggle + 1ULL;
    } else {
    }
    clear_bit(0L, (unsigned long volatile *)(& bnad->run_flags));
  }
  if ((int )link_up) {
    tmp___2 = netif_carrier_ok((struct net_device const *)bnad->netdev);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {
      netdev_info((struct net_device const *)bnad->netdev, "link up\n");
      netif_carrier_on(bnad->netdev);
      bnad->stats.drv_stats.link_toggle = bnad->stats.drv_stats.link_toggle + 1ULL;
      tx_id = 0U;
      goto ldv_58697;
      ldv_58696:
      tcb_id = 0U;
      goto ldv_58694;
      ldv_58693:
      tcb = bnad->tx_info[tx_id].tcb[tcb_id];
      if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
        goto ldv_58692;
      } else {
      }
      txq_id = (u32 )tcb->id;
      tmp___1 = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
      if (tmp___1 != 0) {
        netif_wake_subqueue(bnad->netdev, (int )((u16 )txq_id));
        bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
      } else {
        netif_stop_subqueue(bnad->netdev, (int )((u16 )txq_id));
        bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
      }
      ldv_58692:
      tcb_id = tcb_id + 1U;
      ldv_58694: ;
      if (bnad->num_txq_per_tx > tcb_id) {
        goto ldv_58693;
      } else {
      }
      tx_id = tx_id + 1U;
      ldv_58697: ;
      if (bnad->num_tx > tx_id) {
        goto ldv_58696;
      } else {
      }
    } else {
    }
  } else {
    tmp___4 = netif_carrier_ok((struct net_device const *)bnad->netdev);
    if ((int )tmp___4) {
      netdev_info((struct net_device const *)bnad->netdev, "link down\n");
      netif_carrier_off(bnad->netdev);
      bnad->stats.drv_stats.link_toggle = bnad->stats.drv_stats.link_toggle + 1ULL;
    } else {
    }
  }
  return;
}
}
static void bnad_cb_tx_disabled(void *arg , struct bna_tx *tx )
{
  struct bnad *bnad ;
  {
  bnad = (struct bnad *)arg;
  complete(& bnad->bnad_completions.tx_comp);
  return;
}
}
static void bnad_cb_tcb_setup(struct bnad *bnad , struct bna_tcb *tcb )
{
  struct bnad_tx_info *tx_info ;
  {
  tx_info = (struct bnad_tx_info *)((tcb->txq)->tx)->priv;
  tcb->priv = (void *)tcb;
  tx_info->tcb[tcb->id] = tcb;
  return;
}
}
static void bnad_cb_tcb_destroy(struct bnad *bnad , struct bna_tcb *tcb )
{
  struct bnad_tx_info *tx_info ;
  {
  tx_info = (struct bnad_tx_info *)((tcb->txq)->tx)->priv;
  tx_info->tcb[tcb->id] = (struct bna_tcb *)0;
  tcb->priv = (void *)0;
  return;
}
}
static void bnad_cb_ccb_setup(struct bnad *bnad , struct bna_ccb *ccb )
{
  struct bnad_rx_info *rx_info ;
  {
  rx_info = (struct bnad_rx_info *)((ccb->cq)->rx)->priv;
  rx_info->rx_ctrl[ccb->id].ccb = ccb;
  ccb->ctrl = (void *)(& rx_info->rx_ctrl) + (unsigned long )ccb->id;
  return;
}
}
static void bnad_cb_ccb_destroy(struct bnad *bnad , struct bna_ccb *ccb )
{
  struct bnad_rx_info *rx_info ;
  {
  rx_info = (struct bnad_rx_info *)((ccb->cq)->rx)->priv;
  rx_info->rx_ctrl[ccb->id].ccb = (struct bna_ccb *)0;
  return;
}
}
static void bnad_cb_tx_stall(struct bnad *bnad , struct bna_tx *tx )
{
  struct bnad_tx_info *tx_info ;
  struct bna_tcb *tcb ;
  u32 txq_id ;
  int i ;
  {
  tx_info = (struct bnad_tx_info *)tx->priv;
  i = 0;
  goto ldv_58734;
  ldv_58733:
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58732;
  } else {
  }
  txq_id = (u32 )tcb->id;
  clear_bit(1L, (unsigned long volatile *)(& tcb->flags));
  netif_stop_subqueue(bnad->netdev, (int )((u16 )txq_id));
  ldv_58732:
  i = i + 1;
  ldv_58734: ;
  if (i <= 7) {
    goto ldv_58733;
  } else {
  }
  return;
}
}
static void bnad_cb_tx_resume(struct bnad *bnad , struct bna_tx *tx )
{
  struct bnad_tx_info *tx_info ;
  struct bna_tcb *tcb ;
  u32 txq_id ;
  int i ;
  int tmp ;
  long tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  bool tmp___3 ;
  {
  tx_info = (struct bnad_tx_info *)tx->priv;
  i = 0;
  goto ldv_58748;
  ldv_58747:
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58744;
  } else {
  }
  txq_id = (u32 )tcb->id;
  tmp = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (1072), "i" (12UL));
    ldv_58745: ;
    goto ldv_58745;
  } else {
  }
  set_bit(1L, (unsigned long volatile *)(& tcb->flags));
  tmp___1 = ldv__builtin_expect((unsigned int )*(tcb->hw_consumer_index) != 0U, 0L);
  if (tmp___1 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (1074), "i" (12UL));
    ldv_58746: ;
    goto ldv_58746;
  } else {
  }
  tmp___2 = netif_carrier_ok((struct net_device const *)bnad->netdev);
  if ((int )tmp___2) {
    netif_wake_subqueue(bnad->netdev, (int )((u16 )txq_id));
    bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
  } else {
  }
  ldv_58744:
  i = i + 1;
  ldv_58748: ;
  if (i <= 7) {
    goto ldv_58747;
  } else {
  }
  tmp___3 = is_zero_ether_addr((u8 const *)(& bnad->perm_addr));
  if ((int )tmp___3) {
    bna_enet_perm_mac_get(& bnad->bna.enet, (u8 *)(& bnad->perm_addr));
    bnad_set_netdev_perm_addr(bnad);
  } else {
  }
  return;
}
}
static void bnad_tx_cleanup(struct delayed_work *work )
{
  struct bnad_tx_info *tx_info ;
  struct delayed_work const *__mptr ;
  struct bnad *bnad ;
  struct bna_tcb *tcb ;
  unsigned long flags ;
  u32 i ;
  u32 pending ;
  int tmp ;
  unsigned long tmp___0 ;
  {
  __mptr = (struct delayed_work const *)work;
  tx_info = (struct bnad_tx_info *)__mptr + 0xffffffffffffffb0UL;
  bnad = (struct bnad *)0;
  pending = 0U;
  i = 0U;
  goto ldv_58763;
  ldv_58762:
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58761;
  } else {
  }
  bnad = tcb->bnad;
  tmp = test_and_set_bit(0L, (unsigned long volatile *)(& tcb->flags));
  if (tmp != 0) {
    pending = pending + 1U;
    goto ldv_58761;
  } else {
  }
  bnad_txq_cleanup(bnad, tcb);
  __asm__ volatile ("": : : "memory");
  clear_bit(0L, (unsigned long volatile *)(& tcb->flags));
  ldv_58761:
  i = i + 1U;
  ldv_58763: ;
  if (i <= 7U) {
    goto ldv_58762;
  } else {
  }
  if (pending != 0U) {
    tmp___0 = msecs_to_jiffies(1U);
    queue_delayed_work(bnad->work_q, & tx_info->tx_cleanup_work, tmp___0);
    return;
  } else {
  }
  ldv_spin_lock();
  bna_tx_cleanup_complete(tx_info->tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_cb_tx_cleanup(struct bnad *bnad , struct bna_tx *tx )
{
  struct bnad_tx_info *tx_info ;
  struct bna_tcb *tcb ;
  int i ;
  {
  tx_info = (struct bnad_tx_info *)tx->priv;
  i = 0;
  goto ldv_58774;
  ldv_58773:
  tcb = tx_info->tcb[i];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
  } else {
  }
  i = i + 1;
  ldv_58774: ;
  if (i <= 7) {
    goto ldv_58773;
  } else {
  }
  queue_delayed_work(bnad->work_q, & tx_info->tx_cleanup_work, 0UL);
  return;
}
}
static void bnad_cb_rx_stall(struct bnad *bnad , struct bna_rx *rx )
{
  struct bnad_rx_info *rx_info ;
  struct bna_ccb *ccb ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;
  {
  rx_info = (struct bnad_rx_info *)rx->priv;
  i = 0;
  goto ldv_58786;
  ldv_58785:
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  ccb = rx_ctrl->ccb;
  if ((unsigned long )ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58784;
  } else {
  }
  clear_bit(1L, (unsigned long volatile *)(& (ccb->rcb[0])->flags));
  if ((unsigned long )ccb->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    clear_bit(1L, (unsigned long volatile *)(& (ccb->rcb[1])->flags));
  } else {
  }
  ldv_58784:
  i = i + 1;
  ldv_58786: ;
  if (i <= 15) {
    goto ldv_58785;
  } else {
  }
  return;
}
}
static void bnad_rx_cleanup(void *work )
{
  struct bnad_rx_info *rx_info ;
  struct work_struct const *__mptr ;
  struct bnad_rx_ctrl *rx_ctrl ;
  struct bnad *bnad ;
  unsigned long flags ;
  u32 i ;
  {
  __mptr = (struct work_struct const *)work;
  rx_info = (struct bnad_rx_info *)__mptr + 0xffffffffffffea70UL;
  bnad = (struct bnad *)0;
  i = 0U;
  goto ldv_58800;
  ldv_58799:
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  if ((unsigned long )rx_ctrl->ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58798;
  } else {
  }
  bnad = (rx_ctrl->ccb)->bnad;
  napi_disable(& rx_ctrl->napi);
  bnad_cq_cleanup(bnad, rx_ctrl->ccb);
  bnad_rxq_cleanup(bnad, (rx_ctrl->ccb)->rcb[0]);
  if ((unsigned long )(rx_ctrl->ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    bnad_rxq_cleanup(bnad, (rx_ctrl->ccb)->rcb[1]);
  } else {
  }
  ldv_58798:
  i = i + 1U;
  ldv_58800: ;
  if (i <= 15U) {
    goto ldv_58799;
  } else {
  }
  ldv_spin_lock();
  bna_rx_cleanup_complete(rx_info->rx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_cb_rx_cleanup(struct bnad *bnad , struct bna_rx *rx )
{
  struct bnad_rx_info *rx_info ;
  struct bna_ccb *ccb ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;
  {
  rx_info = (struct bnad_rx_info *)rx->priv;
  i = 0;
  goto ldv_58812;
  ldv_58811:
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  ccb = rx_ctrl->ccb;
  if ((unsigned long )ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58810;
  } else {
  }
  clear_bit(0L, (unsigned long volatile *)(& (ccb->rcb[0])->flags));
  if ((unsigned long )ccb->rcb[1] != (unsigned long )((struct bna_rcb *)0)) {
    clear_bit(0L, (unsigned long volatile *)(& (ccb->rcb[1])->flags));
  } else {
  }
  ldv_58810:
  i = i + 1;
  ldv_58812: ;
  if (i <= 15) {
    goto ldv_58811;
  } else {
  }
  queue_work(bnad->work_q, & rx_info->rx_cleanup_work);
  return;
}
}
static void bnad_cb_rx_post(struct bnad *bnad , struct bna_rx *rx )
{
  struct bnad_rx_info *rx_info ;
  struct bna_ccb *ccb ;
  struct bna_rcb *rcb ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;
  int j ;
  {
  rx_info = (struct bnad_rx_info *)rx->priv;
  i = 0;
  goto ldv_58830;
  ldv_58829:
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )i;
  ccb = rx_ctrl->ccb;
  if ((unsigned long )ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58824;
  } else {
  }
  napi_enable(& rx_ctrl->napi);
  j = 0;
  goto ldv_58827;
  ldv_58826:
  rcb = ccb->rcb[j];
  if ((unsigned long )rcb == (unsigned long )((struct bna_rcb *)0)) {
    goto ldv_58825;
  } else {
  }
  bnad_rxq_alloc_init(bnad, rcb);
  set_bit(0L, (unsigned long volatile *)(& rcb->flags));
  set_bit(1L, (unsigned long volatile *)(& rcb->flags));
  bnad_rxq_post(bnad, rcb);
  ldv_58825:
  j = j + 1;
  ldv_58827: ;
  if (j <= 1) {
    goto ldv_58826;
  } else {
  }
  ldv_58824:
  i = i + 1;
  ldv_58830: ;
  if (i <= 15) {
    goto ldv_58829;
  } else {
  }
  return;
}
}
static void bnad_cb_rx_disabled(void *arg , struct bna_rx *rx )
{
  struct bnad *bnad ;
  {
  bnad = (struct bnad *)arg;
  complete(& bnad->bnad_completions.rx_comp);
  return;
}
}
static void bnad_cb_rx_mcast_add(struct bnad *bnad , struct bna_rx *rx )
{
  {
  bnad->bnad_completions.mcast_comp_status = 0U;
  complete(& bnad->bnad_completions.mcast_comp);
  return;
}
}
void bnad_cb_stats_get(struct bnad *bnad , enum bna_cb_status status , struct bna_stats *stats )
{
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  unsigned long tmp___2 ;
  {
  if ((unsigned int )status == 0U) {
    bnad->stats.drv_stats.hw_stats_updates = bnad->stats.drv_stats.hw_stats_updates + 1ULL;
  } else {
  }
  tmp = netif_running((struct net_device const *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {
    tmp___1 = constant_test_bit(5L, (unsigned long const volatile *)(& bnad->run_flags));
    if (tmp___1 == 0) {
      return;
    } else {
    }
  }
  tmp___2 = msecs_to_jiffies(1000U);
  ldv_mod_timer_43(& bnad->stats_timer, tmp___2 + (unsigned long )jiffies);
  return;
}
}
static void bnad_cb_enet_mtu_set(struct bnad *bnad )
{
  {
  bnad->bnad_completions.mtu_comp_status = 0U;
  complete(& bnad->bnad_completions.mtu_comp);
  return;
}
}
void bnad_cb_completion(void *arg , enum bfa_status status )
{
  struct bnad_iocmd_comp *iocmd_comp ;
  {
  iocmd_comp = (struct bnad_iocmd_comp *)arg;
  iocmd_comp->comp_status = (int )status;
  complete(& iocmd_comp->comp);
  return;
}
}
static void bnad_mem_free(struct bnad *bnad , struct bna_mem_info *mem_info )
{
  int i ;
  dma_addr_t dma_pa ;
  __u32 tmp ;
  __u32 tmp___0 ;
  {
  if ((unsigned long )mem_info->mdl == (unsigned long )((struct bna_mem_descr *)0)) {
    return;
  } else {
  }
  i = 0;
  goto ldv_58861;
  ldv_58860: ;
  if ((unsigned long )(mem_info->mdl + (unsigned long )i)->kva != (unsigned long )((void *)0)) {
    if ((unsigned int )mem_info->mem_type == 2U) {
      tmp = __fswab32((mem_info->mdl + (unsigned long )i)->dma.msb);
      tmp___0 = __fswab32((mem_info->mdl + (unsigned long )i)->dma.lsb);
      dma_pa = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
      dma_free_attrs(& (bnad->pcidev)->dev, (size_t )(mem_info->mdl + (unsigned long )i)->len,
                     (mem_info->mdl + (unsigned long )i)->kva, dma_pa, (struct dma_attrs *)0);
    } else {
      kfree((void const *)(mem_info->mdl + (unsigned long )i)->kva);
    }
  } else {
  }
  i = i + 1;
  ldv_58861: ;
  if ((u32 )i < mem_info->num) {
    goto ldv_58860;
  } else {
  }
  kfree((void const *)mem_info->mdl);
  mem_info->mdl = (struct bna_mem_descr *)0;
  return;
}
}
static int bnad_mem_alloc(struct bnad *bnad , struct bna_mem_info *mem_info )
{
  int i ;
  dma_addr_t dma_pa ;
  void *tmp ;
  u64 tmp_addr ;
  __u64 tmp___0 ;
  {
  if (mem_info->num == 0U || mem_info->len == 0U) {
    mem_info->mdl = (struct bna_mem_descr *)0;
    return (0);
  } else {
  }
  tmp = kcalloc((size_t )mem_info->num, 24UL, 208U);
  mem_info->mdl = (struct bna_mem_descr *)tmp;
  if ((unsigned long )mem_info->mdl == (unsigned long )((struct bna_mem_descr *)0)) {
    return (-12);
  } else {
  }
  if ((unsigned int )mem_info->mem_type == 2U) {
    i = 0;
    goto ldv_58872;
    ldv_58871:
    (mem_info->mdl + (unsigned long )i)->len = mem_info->len;
    (mem_info->mdl + (unsigned long )i)->kva = dma_alloc_attrs(& (bnad->pcidev)->dev,
                                                               (size_t )mem_info->len,
                                                               & dma_pa, 208U, (struct dma_attrs *)0);
    if ((unsigned long )(mem_info->mdl + (unsigned long )i)->kva == (unsigned long )((void *)0)) {
      goto err_return;
    } else {
    }
    tmp___0 = __fswab64(dma_pa);
    tmp_addr = tmp___0;
    (mem_info->mdl + (unsigned long )i)->dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
    (mem_info->mdl + (unsigned long )i)->dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
    i = i + 1;
    ldv_58872: ;
    if ((u32 )i < mem_info->num) {
      goto ldv_58871;
    } else {
    }
  } else {
    i = 0;
    goto ldv_58875;
    ldv_58874:
    (mem_info->mdl + (unsigned long )i)->len = mem_info->len;
    (mem_info->mdl + (unsigned long )i)->kva = kzalloc((size_t )mem_info->len, 208U);
    if ((unsigned long )(mem_info->mdl + (unsigned long )i)->kva == (unsigned long )((void *)0)) {
      goto err_return;
    } else {
    }
    i = i + 1;
    ldv_58875: ;
    if ((u32 )i < mem_info->num) {
      goto ldv_58874;
    } else {
    }
  }
  return (0);
  err_return:
  bnad_mem_free(bnad, mem_info);
  return (-12);
}
}
static void bnad_mbox_irq_free(struct bnad *bnad )
{
  int irq ;
  unsigned long flags ;
  {
  ldv_spin_lock();
  bnad_disable_mbox_irq(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  irq = (bnad->cfg_flags & 16U) != 0U ? (int )(bnad->msix_table)->vector : (int )(bnad->pcidev)->irq;
  ldv_free_irq_44((unsigned int )irq, (void *)bnad);
  return;
}
}
static int bnad_mbox_irq_alloc(struct bnad *bnad )
{
  int err ;
  unsigned long irq_flags ;
  unsigned long flags ;
  u32 irq ;
  irqreturn_t (*irq_handler)(int , void * ) ;
  {
  err = 0;
  ldv_spin_lock();
  if ((bnad->cfg_flags & 16U) != 0U) {
    irq_handler = & bnad_msix_mbox_handler;
    irq = (bnad->msix_table)->vector;
    irq_flags = 0UL;
  } else {
    irq_handler = & bnad_isr;
    irq = (bnad->pcidev)->irq;
    irq_flags = 128UL;
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  sprintf((char *)(& bnad->mbox_irq_name), "%s", (char *)"bna");
  set_bit(2L, (unsigned long volatile *)(& bnad->run_flags));
  bnad->stats.drv_stats.mbox_intr_disabled = bnad->stats.drv_stats.mbox_intr_disabled + 1ULL;
  err = ldv_request_irq_45(irq, irq_handler, irq_flags, (char const *)(& bnad->mbox_irq_name),
                           (void *)bnad);
  return (err);
}
}
static void bnad_txrx_irq_free(struct bnad *bnad , struct bna_intr_info *intr_info )
{
  {
  kfree((void const *)intr_info->idl);
  intr_info->idl = (struct bna_intr_descr *)0;
  return;
}
}
static int bnad_txrx_irq_alloc(struct bnad *bnad , enum bnad_intr_source src , u32 txrx_id ,
                               struct bna_intr_info *intr_info )
{
  int i ;
  int vector_start ;
  u32 cfg_flags ;
  unsigned long flags ;
  void *tmp ;
  void *tmp___0 ;
  {
  vector_start = 0;
  ldv_spin_lock();
  cfg_flags = bnad->cfg_flags;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((cfg_flags & 16U) != 0U) {
    intr_info->intr_type = 2;
    tmp = kcalloc((size_t )intr_info->num, 4UL, 208U);
    intr_info->idl = (struct bna_intr_descr *)tmp;
    if ((unsigned long )intr_info->idl == (unsigned long )((struct bna_intr_descr *)0)) {
      return (-12);
    } else {
    }
    switch ((unsigned int )src) {
    case 1U:
    vector_start = (int )(txrx_id + 1U);
    goto ldv_58905;
    case 2U:
    vector_start = (int )((bnad->num_tx * bnad->num_txq_per_tx + txrx_id) + 1U);
    goto ldv_58905;
    default:
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad.c"),
                         "i" (1481), "i" (12UL));
    ldv_58908: ;
    goto ldv_58908;
    }
    ldv_58905:
    i = 0;
    goto ldv_58910;
    ldv_58909:
    (intr_info->idl + (unsigned long )i)->vector = vector_start + i;
    i = i + 1;
    ldv_58910: ;
    if (intr_info->num > i) {
      goto ldv_58909;
    } else {
    }
  } else {
    intr_info->intr_type = 1;
    intr_info->num = 1;
    tmp___0 = kcalloc((size_t )intr_info->num, 4UL, 208U);
    intr_info->idl = (struct bna_intr_descr *)tmp___0;
    if ((unsigned long )intr_info->idl == (unsigned long )((struct bna_intr_descr *)0)) {
      return (-12);
    } else {
    }
    switch ((unsigned int )src) {
    case 1U:
    (intr_info->idl)->vector = 1;
    goto ldv_58913;
    case 2U:
    (intr_info->idl)->vector = 2;
    goto ldv_58913;
    }
    ldv_58913: ;
  }
  return (0);
}
}
static void bnad_tx_msix_unregister(struct bnad *bnad , struct bnad_tx_info *tx_info ,
                                    int num_txqs )
{
  int i ;
  int vector_num ;
  {
  i = 0;
  goto ldv_58924;
  ldv_58923: ;
  if ((unsigned long )tx_info->tcb[i] == (unsigned long )((struct bna_tcb *)0)) {
    goto ldv_58922;
  } else {
  }
  vector_num = (tx_info->tcb[i])->intr_vector;
  ldv_free_irq_46((bnad->msix_table + (unsigned long )vector_num)->vector, (void *)tx_info->tcb[i]);
  ldv_58922:
  i = i + 1;
  ldv_58924: ;
  if (i < num_txqs) {
    goto ldv_58923;
  } else {
  }
  return;
}
}
static int bnad_tx_msix_register(struct bnad *bnad , struct bnad_tx_info *tx_info ,
                                 u32 tx_id , int num_txqs )
{
  int i ;
  int err ;
  int vector_num ;
  {
  i = 0;
  goto ldv_58937;
  ldv_58936:
  vector_num = (tx_info->tcb[i])->intr_vector;
  sprintf((char *)(& (tx_info->tcb[i])->name), "%s TXQ %d", (char *)(& (bnad->netdev)->name),
          (u32 )(tx_info->tcb[i])->id + tx_id);
  err = ldv_request_irq_47((bnad->msix_table + (unsigned long )vector_num)->vector,
                           & bnad_msix_tx, 0UL, (char const *)(& (tx_info->tcb[i])->name),
                           (void *)tx_info->tcb[i]);
  if (err != 0) {
    goto err_return;
  } else {
  }
  i = i + 1;
  ldv_58937: ;
  if (i < num_txqs) {
    goto ldv_58936;
  } else {
  }
  return (0);
  err_return: ;
  if (i > 0) {
    bnad_tx_msix_unregister(bnad, tx_info, i + -1);
  } else {
  }
  return (-1);
}
}
static void bnad_rx_msix_unregister(struct bnad *bnad , struct bnad_rx_info *rx_info ,
                                    int num_rxps )
{
  int i ;
  int vector_num ;
  {
  i = 0;
  goto ldv_58948;
  ldv_58947: ;
  if ((unsigned long )rx_info->rx_ctrl[i].ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_58946;
  } else {
  }
  vector_num = (rx_info->rx_ctrl[i].ccb)->intr_vector;
  ldv_free_irq_48((bnad->msix_table + (unsigned long )vector_num)->vector, (void *)rx_info->rx_ctrl[i].ccb);
  ldv_58946:
  i = i + 1;
  ldv_58948: ;
  if (i < num_rxps) {
    goto ldv_58947;
  } else {
  }
  return;
}
}
static int bnad_rx_msix_register(struct bnad *bnad , struct bnad_rx_info *rx_info ,
                                 u32 rx_id , int num_rxps )
{
  int i ;
  int err ;
  int vector_num ;
  {
  i = 0;
  goto ldv_58961;
  ldv_58960:
  vector_num = (rx_info->rx_ctrl[i].ccb)->intr_vector;
  sprintf((char *)(& (rx_info->rx_ctrl[i].ccb)->name), "%s CQ %d", (char *)(& (bnad->netdev)->name),
          (u32 )(rx_info->rx_ctrl[i].ccb)->id + rx_id);
  err = ldv_request_irq_49((bnad->msix_table + (unsigned long )vector_num)->vector,
                           & bnad_msix_rx, 0UL, (char const *)(& (rx_info->rx_ctrl[i].ccb)->name),
                           (void *)rx_info->rx_ctrl[i].ccb);
  if (err != 0) {
    goto err_return;
  } else {
  }
  i = i + 1;
  ldv_58961: ;
  if (i < num_rxps) {
    goto ldv_58960;
  } else {
  }
  return (0);
  err_return: ;
  if (i > 0) {
    bnad_rx_msix_unregister(bnad, rx_info, i + -1);
  } else {
  }
  return (-1);
}
}
static void bnad_tx_res_free(struct bnad *bnad , struct bna_res_info *res_info )
{
  int i ;
  {
  i = 0;
  goto ldv_58969;
  ldv_58968: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    bnad_mem_free(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    bnad_txrx_irq_free(bnad, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {
  }
  i = i + 1;
  ldv_58969: ;
  if (i <= 6) {
    goto ldv_58968;
  } else {
  }
  return;
}
}
static int bnad_tx_res_alloc(struct bnad *bnad , struct bna_res_info *res_info , u32 tx_id )
{
  int i ;
  int err ;
  {
  err = 0;
  i = 0;
  goto ldv_58980;
  ldv_58979: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    err = bnad_mem_alloc(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    err = bnad_txrx_irq_alloc(bnad, 1, tx_id, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {
  }
  if (err != 0) {
    goto err_return;
  } else {
  }
  i = i + 1;
  ldv_58980: ;
  if (i <= 6) {
    goto ldv_58979;
  } else {
  }
  return (0);
  err_return:
  bnad_tx_res_free(bnad, res_info);
  return (err);
}
}
static void bnad_rx_res_free(struct bnad *bnad , struct bna_res_info *res_info )
{
  int i ;
  {
  i = 0;
  goto ldv_58988;
  ldv_58987: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    bnad_mem_free(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    bnad_txrx_irq_free(bnad, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {
  }
  i = i + 1;
  ldv_58988: ;
  if (i <= 15) {
    goto ldv_58987;
  } else {
  }
  return;
}
}
static int bnad_rx_res_alloc(struct bnad *bnad , struct bna_res_info *res_info , uint rx_id )
{
  int i ;
  int err ;
  {
  err = 0;
  i = 0;
  goto ldv_58999;
  ldv_58998: ;
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 1U) {
    err = bnad_mem_alloc(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  } else
  if ((unsigned int )(res_info + (unsigned long )i)->res_type == 2U) {
    err = bnad_txrx_irq_alloc(bnad, 2, rx_id, & (res_info + (unsigned long )i)->res_u.intr_info);
  } else {
  }
  if (err != 0) {
    goto err_return;
  } else {
  }
  i = i + 1;
  ldv_58999: ;
  if (i <= 15) {
    goto ldv_58998;
  } else {
  }
  return (0);
  err_return:
  bnad_rx_res_free(bnad, res_info);
  return (err);
}
}
static void bnad_ioc_timeout(unsigned long data )
{
  struct bnad *bnad ;
  unsigned long flags ;
  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_ioc_timeout(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_ioc_hb_check(unsigned long data )
{
  struct bnad *bnad ;
  unsigned long flags ;
  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_ioc_hb_check(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_iocpf_timeout(unsigned long data )
{
  struct bnad *bnad ;
  unsigned long flags ;
  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_iocpf_timeout(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_iocpf_sem_timeout(unsigned long data )
{
  struct bnad *bnad ;
  unsigned long flags ;
  {
  bnad = (struct bnad *)data;
  ldv_spin_lock();
  bfa_nw_iocpf_sem_timeout(& bnad->bna.ioceth.ioc);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_dim_timeout(unsigned long data )
{
  struct bnad *bnad ;
  struct bnad_rx_info *rx_info ;
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;
  int j ;
  unsigned long flags ;
  bool tmp ;
  int tmp___0 ;
  unsigned long tmp___1 ;
  int tmp___2 ;
  {
  bnad = (struct bnad *)data;
  tmp = netif_carrier_ok((struct net_device const *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {
  }
  ldv_spin_lock();
  i = 0;
  goto ldv_59036;
  ldv_59035:
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_59030;
  } else {
  }
  j = 0;
  goto ldv_59033;
  ldv_59032:
  rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )j;
  if ((unsigned long )rx_ctrl->ccb == (unsigned long )((struct bna_ccb *)0)) {
    goto ldv_59031;
  } else {
  }
  bna_rx_dim_update(rx_ctrl->ccb);
  ldv_59031:
  j = j + 1;
  ldv_59033: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_59032;
  } else {
  }
  ldv_59030:
  i = i + 1;
  ldv_59036: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_59035;
  } else {
  }
  tmp___2 = constant_test_bit(4L, (unsigned long const volatile *)(& bnad->run_flags));
  if (tmp___2 != 0) {
    tmp___1 = msecs_to_jiffies(1000U);
    ldv_mod_timer_50(& bnad->dim_timer, tmp___1 + (unsigned long )jiffies);
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_stats_timeout(unsigned long data )
{
  struct bnad *bnad ;
  unsigned long flags ;
  bool tmp ;
  int tmp___0 ;
  int tmp___1 ;
  {
  bnad = (struct bnad *)data;
  tmp = netif_running((struct net_device const *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return;
  } else {
    tmp___1 = constant_test_bit(5L, (unsigned long const volatile *)(& bnad->run_flags));
    if (tmp___1 == 0) {
      return;
    } else {
    }
  }
  ldv_spin_lock();
  bna_hw_stats_get(& bnad->bna);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
void bnad_dim_timer_start(struct bnad *bnad )
{
  unsigned long tmp ;
  int tmp___0 ;
  {
  if ((int )bnad->cfg_flags & 1) {
    tmp___0 = constant_test_bit(4L, (unsigned long const volatile *)(& bnad->run_flags));
    if (tmp___0 == 0) {
      reg_timer_7(& bnad->dim_timer, & bnad_dim_timeout, (unsigned long )bnad);
      set_bit(4L, (unsigned long volatile *)(& bnad->run_flags));
      tmp = msecs_to_jiffies(1000U);
      ldv_mod_timer_51(& bnad->dim_timer, tmp + (unsigned long )jiffies);
    } else {
    }
  } else {
  }
  return;
}
}
static void bnad_stats_timer_start(struct bnad *bnad )
{
  unsigned long flags ;
  unsigned long tmp ;
  int tmp___0 ;
  {
  ldv_spin_lock();
  tmp___0 = test_and_set_bit(5L, (unsigned long volatile *)(& bnad->run_flags));
  if (tmp___0 == 0) {
    reg_timer_7(& bnad->stats_timer, & bnad_stats_timeout, (unsigned long )bnad);
    tmp = msecs_to_jiffies(1000U);
    ldv_mod_timer_52(& bnad->stats_timer, tmp + (unsigned long )jiffies);
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_stats_timer_stop(struct bnad *bnad )
{
  int to_del ;
  unsigned long flags ;
  int tmp ;
  {
  to_del = 0;
  ldv_spin_lock();
  tmp = test_and_clear_bit(5L, (unsigned long volatile *)(& bnad->run_flags));
  if (tmp != 0) {
    to_del = 1;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (to_del != 0) {
    ldv_del_timer_sync_53(& bnad->stats_timer);
  } else {
  }
  return;
}
}
static void bnad_netdev_mc_list_get(struct net_device *netdev , u8 *mc_list )
{
  int i ;
  struct netdev_hw_addr *mc_addr ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  i = 1;
  __mptr = (struct list_head const *)netdev->mc.list.next;
  mc_addr = (struct netdev_hw_addr *)__mptr;
  goto ldv_59066;
  ldv_59065:
  ether_addr_copy(mc_list + (unsigned long )(i * 6), (u8 const *)(& mc_addr->addr));
  i = i + 1;
  __mptr___0 = (struct list_head const *)mc_addr->list.next;
  mc_addr = (struct netdev_hw_addr *)__mptr___0;
  ldv_59066: ;
  if ((unsigned long )(& mc_addr->list) != (unsigned long )(& netdev->mc.list)) {
    goto ldv_59065;
  } else {
  }
  return;
}
}
static int bnad_napi_poll_rx(struct napi_struct *napi , int budget )
{
  struct bnad_rx_ctrl *rx_ctrl ;
  struct napi_struct const *__mptr ;
  struct bnad *bnad ;
  int rcvd ;
  bool tmp ;
  int tmp___0 ;
  u32 tmp___1 ;
  int tmp___2 ;
  long tmp___3 ;
  {
  __mptr = (struct napi_struct const *)napi;
  rx_ctrl = (struct bnad_rx_ctrl *)__mptr + 0xffffffffffffffe8UL;
  bnad = rx_ctrl->bnad;
  rcvd = 0;
  rx_ctrl->rx_poll_ctr = rx_ctrl->rx_poll_ctr + 1ULL;
  tmp = netif_carrier_ok((struct net_device const *)bnad->netdev);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    goto poll_exit;
  } else {
  }
  tmp___1 = bnad_cq_process(bnad, rx_ctrl->ccb, budget);
  rcvd = (int )tmp___1;
  if (rcvd >= budget) {
    return (rcvd);
  } else {
  }
  poll_exit:
  napi_complete(napi);
  rx_ctrl->rx_complete = rx_ctrl->rx_complete + 1ULL;
  if ((unsigned long )rx_ctrl->ccb != (unsigned long )((struct bna_ccb *)0)) {
    tmp___2 = constant_test_bit(0L, (unsigned long const volatile *)(& ((rx_ctrl->ccb)->rcb[0])->flags));
    tmp___3 = ldv__builtin_expect(tmp___2 != 0, 1L);
    if (tmp___3 != 0L) {
      ((rx_ctrl->ccb)->i_dbell)->doorbell_ack = (unsigned int )((int )(rx_ctrl->ccb)->rx_coalescing_timeo << 16) | 2147483648U;
      writel(((rx_ctrl->ccb)->i_dbell)->doorbell_ack, (void volatile *)((rx_ctrl->ccb)->i_dbell)->doorbell_addr);
    } else {
    }
  } else {
  }
  return (rcvd);
}
}
static void bnad_napi_add(struct bnad *bnad , u32 rx_id )
{
  struct bnad_rx_ctrl *rx_ctrl ;
  int i ;
  {
  i = 0;
  goto ldv_59085;
  ldv_59084:
  rx_ctrl = (struct bnad_rx_ctrl *)(& bnad->rx_info[rx_id].rx_ctrl) + (unsigned long )i;
  netif_napi_add(bnad->netdev, & rx_ctrl->napi, & bnad_napi_poll_rx, 64);
  i = i + 1;
  ldv_59085: ;
  if ((u32 )i < bnad->num_rxp_per_rx) {
    goto ldv_59084;
  } else {
  }
  return;
}
}
static void bnad_napi_delete(struct bnad *bnad , u32 rx_id )
{
  int i ;
  {
  i = 0;
  goto ldv_59093;
  ldv_59092:
  netif_napi_del(& bnad->rx_info[rx_id].rx_ctrl[i].napi);
  i = i + 1;
  ldv_59093: ;
  if ((u32 )i < bnad->num_rxp_per_rx) {
    goto ldv_59092;
  } else {
  }
  return;
}
}
void bnad_destroy_tx(struct bnad *bnad , u32 tx_id )
{
  struct bnad_tx_info *tx_info ;
  struct bna_res_info *res_info ;
  unsigned long flags ;
  {
  tx_info = (struct bnad_tx_info *)(& bnad->tx_info) + (unsigned long )tx_id;
  res_info = (struct bna_res_info *)(& bnad->tx_res_info[tx_id].res_info);
  if ((unsigned long )tx_info->tx == (unsigned long )((struct bna_tx *)0)) {
    return;
  } else {
  }
  init_completion(& bnad->bnad_completions.tx_comp);
  ldv_spin_lock();
  bna_tx_disable(tx_info->tx, 0, & bnad_cb_tx_disabled);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.tx_comp);
  if ((unsigned int )(tx_info->tcb[0])->intr_type == 2U) {
    bnad_tx_msix_unregister(bnad, tx_info, (int )bnad->num_txq_per_tx);
  } else {
  }
  ldv_spin_lock();
  bna_tx_destroy(tx_info->tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tx_info->tx = (struct bna_tx *)0;
  tx_info->tx_id = 0U;
  bnad_tx_res_free(bnad, res_info);
  return;
}
}
int bnad_setup_tx(struct bnad *bnad , u32 tx_id )
{
  int err ;
  struct bnad_tx_info *tx_info ;
  struct bna_res_info *res_info ;
  struct bna_intr_info *intr_info ;
  struct bna_tx_config *tx_config ;
  struct bna_tx_event_cbfn tx_cbfn ;
  struct bna_tx *tx ;
  unsigned long flags ;
  struct lock_class_key __key ;
  atomic_long_t __constr_expr_0 ;
  struct lock_class_key __key___0 ;
  {
  tx_info = (struct bnad_tx_info *)(& bnad->tx_info) + (unsigned long )tx_id;
  res_info = (struct bna_res_info *)(& bnad->tx_res_info[tx_id].res_info);
  intr_info = & (res_info + 6UL)->res_u.intr_info;
  tx_config = (struct bna_tx_config *)(& bnad->tx_config) + (unsigned long )tx_id;
  tx_cbfn.tcb_setup_cbfn = & bnad_cb_tcb_setup;
  tx_cbfn.tcb_destroy_cbfn = & bnad_cb_tcb_destroy;
  tx_cbfn.tx_stall_cbfn = & bnad_cb_tx_stall;
  tx_cbfn.tx_resume_cbfn = & bnad_cb_tx_resume;
  tx_cbfn.tx_cleanup_cbfn = & bnad_cb_tx_cleanup;
  tx_info->tx_id = tx_id;
  tx_config->num_txq = (int )bnad->num_txq_per_tx;
  tx_config->txq_depth = (int )bnad->txq_depth;
  tx_config->tx_type = 0;
  tx_config->coalescing_timeo = (int )bnad->tx_coalescing_timeo;
  ldv_spin_lock();
  bna_tx_res_req((int )bnad->num_txq_per_tx, (int )bnad->txq_depth, res_info);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  (res_info + 1UL)->res_type = 1;
  (res_info + 1UL)->res_u.mem_info.mem_type = 1;
  (res_info + 1UL)->res_u.mem_info.num = bnad->num_txq_per_tx;
  (res_info + 1UL)->res_u.mem_info.len = bnad->txq_depth * 80U;
  err = bnad_tx_res_alloc(bnad, res_info, tx_id);
  if (err != 0) {
    return (err);
  } else {
  }
  ldv_spin_lock();
  tx = bna_tx_create(& bnad->bna, bnad, tx_config, & tx_cbfn, res_info, (void *)tx_info);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((unsigned long )tx == (unsigned long )((struct bna_tx *)0)) {
    err = -12;
    goto err_return;
  } else {
  }
  tx_info->tx = tx;
  __init_work(& tx_info->tx_cleanup_work.work, 0);
  __constr_expr_0.counter = 137438953408L;
  tx_info->tx_cleanup_work.work.data = __constr_expr_0;
  lockdep_init_map(& tx_info->tx_cleanup_work.work.lockdep_map, "(&(&tx_info->tx_cleanup_work)->work)",
                   & __key, 0);
  INIT_LIST_HEAD(& tx_info->tx_cleanup_work.work.entry);
  tx_info->tx_cleanup_work.work.func = (void (*)(struct work_struct * ))(& bnad_tx_cleanup);
  init_timer_key(& tx_info->tx_cleanup_work.timer, 2097152U, "(&(&tx_info->tx_cleanup_work)->timer)",
                 & __key___0);
  tx_info->tx_cleanup_work.timer.function = & delayed_work_timer_fn;
  tx_info->tx_cleanup_work.timer.data = (unsigned long )(& tx_info->tx_cleanup_work);
  if ((unsigned int )intr_info->intr_type == 2U) {
    err = bnad_tx_msix_register(bnad, tx_info, tx_id, (int )bnad->num_txq_per_tx);
    if (err != 0) {
      goto cleanup_tx;
    } else {
    }
  } else {
  }
  ldv_spin_lock();
  bna_tx_enable(tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (0);
  cleanup_tx:
  ldv_spin_lock();
  bna_tx_destroy(tx_info->tx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tx_info->tx = (struct bna_tx *)0;
  tx_info->tx_id = 0U;
  err_return:
  bnad_tx_res_free(bnad, res_info);
  return (err);
}
}
static void bnad_init_rx_config(struct bnad *bnad , struct bna_rx_config *rx_config )
{
  {
  memset((void *)rx_config, 0, 108UL);
  rx_config->rx_type = 0;
  rx_config->num_paths = (int )bnad->num_rxp_per_rx;
  rx_config->coalescing_timeo = (int )bnad->rx_coalescing_timeo;
  if (bnad->num_rxp_per_rx > 1U) {
    rx_config->rss_status = 1;
    rx_config->rss_config.hash_type = 15;
    rx_config->rss_config.hash_mask = (unsigned int )((u8 )bnad->num_rxp_per_rx) - 1U;
    netdev_rss_key_fill((void *)(& rx_config->rss_config.toeplitz_hash_key), 40UL);
  } else {
    rx_config->rss_status = 0;
    memset((void *)(& rx_config->rss_config), 0, 48UL);
  }
  rx_config->frame_size = (bnad->netdev)->mtu + 22U;
  rx_config->q0_multi_buf = 0;
  rx_config->rxp_type = 2;
  if ((unsigned int )(bnad->pcidev)->device == 34U && rx_config->frame_size > 4096U) {
    rx_config->q0_buf_size = 2048U;
    rx_config->q0_num_vecs = 4U;
    rx_config->q0_depth = bnad->rxq_depth * rx_config->q0_num_vecs;
    rx_config->q0_multi_buf = 1;
  } else {
    rx_config->q0_buf_size = rx_config->frame_size;
    rx_config->q0_num_vecs = 1U;
    rx_config->q0_depth = bnad->rxq_depth;
  }
  if ((unsigned int )rx_config->rxp_type == 2U) {
    rx_config->q1_depth = bnad->rxq_depth;
    rx_config->q1_buf_size = 128U;
  } else {
  }
  rx_config->vlan_strip_status = ((bnad->netdev)->features & 256ULL) != 0ULL;
  return;
}
}
static void bnad_rx_ctrl_init(struct bnad *bnad , u32 rx_id )
{
  struct bnad_rx_info *rx_info ;
  int i ;
  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )rx_id;
  i = 0;
  goto ldv_59130;
  ldv_59129:
  rx_info->rx_ctrl[i].bnad = bnad;
  i = i + 1;
  ldv_59130: ;
  if ((u32 )i < bnad->num_rxp_per_rx) {
    goto ldv_59129;
  } else {
  }
  return;
}
}
static u32 bnad_reinit_rx(struct bnad *bnad )
{
  struct net_device *netdev ;
  u32 err ;
  u32 current_err ;
  u32 rx_id ;
  u32 count ;
  unsigned long flags ;
  int tmp ;
  {
  netdev = bnad->netdev;
  err = 0U;
  current_err = 0U;
  rx_id = 0U;
  count = 0U;
  rx_id = 0U;
  goto ldv_59143;
  ldv_59142: ;
  if ((unsigned long )bnad->rx_info[rx_id].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_59141;
  } else {
  }
  bnad_destroy_rx(bnad, rx_id);
  ldv_59141:
  rx_id = rx_id + 1U;
  ldv_59143: ;
  if (bnad->num_rx > rx_id) {
    goto ldv_59142;
  } else {
  }
  ldv_spin_lock();
  bna_enet_mtu_set(& bnad->bna.enet, (int )((bnad->netdev)->mtu + 22U), (void (*)(struct bnad * ))0);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  rx_id = 0U;
  goto ldv_59146;
  ldv_59145:
  count = count + 1U;
  tmp = bnad_setup_rx(bnad, rx_id);
  current_err = (u32 )tmp;
  if (current_err != 0U && err == 0U) {
    err = current_err;
    netdev_err((struct net_device const *)netdev, "RXQ:%u setup failed\n", rx_id);
  } else {
  }
  rx_id = rx_id + 1U;
  ldv_59146: ;
  if (bnad->num_rx > rx_id) {
    goto ldv_59145;
  } else {
  }
  if ((unsigned long )bnad->rx_info[0].rx != (unsigned long )((struct bna_rx *)0) && err == 0U) {
    bnad_restore_vlans(bnad, 0U);
    bnad_enable_default_bcast(bnad);
    ldv_spin_lock();
    bnad_mac_addr_set_locked(bnad, (u8 const *)netdev->dev_addr);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    bnad_set_rx_mode(netdev);
  } else {
  }
  return (count);
}
}
void bnad_destroy_rx(struct bnad *bnad , u32 rx_id )
{
  struct bnad_rx_info *rx_info ;
  struct bna_rx_config *rx_config ;
  struct bna_res_info *res_info ;
  unsigned long flags ;
  int to_del ;
  int tmp ;
  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )rx_id;
  rx_config = (struct bna_rx_config *)(& bnad->rx_config) + (unsigned long )rx_id;
  res_info = (struct bna_res_info *)(& bnad->rx_res_info[rx_id].res_info);
  to_del = 0;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    return;
  } else {
  }
  if (rx_id == 0U) {
    ldv_spin_lock();
    if ((int )bnad->cfg_flags & 1) {
      tmp = constant_test_bit(4L, (unsigned long const volatile *)(& bnad->run_flags));
      if (tmp != 0) {
        clear_bit(4L, (unsigned long volatile *)(& bnad->run_flags));
        to_del = 1;
      } else {
      }
    } else {
    }
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    if (to_del != 0) {
      ldv_del_timer_sync_54(& bnad->dim_timer);
    } else {
    }
  } else {
  }
  init_completion(& bnad->bnad_completions.rx_comp);
  ldv_spin_lock();
  bna_rx_disable(rx_info->rx, 0, & bnad_cb_rx_disabled);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.rx_comp);
  if ((unsigned int )(rx_info->rx_ctrl[0].ccb)->intr_type == 2U) {
    bnad_rx_msix_unregister(bnad, rx_info, rx_config->num_paths);
  } else {
  }
  bnad_napi_delete(bnad, rx_id);
  ldv_spin_lock();
  bna_rx_destroy(rx_info->rx);
  rx_info->rx = (struct bna_rx *)0;
  rx_info->rx_id = 0U;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_rx_res_free(bnad, res_info);
  return;
}
}
int bnad_setup_rx(struct bnad *bnad , u32 rx_id )
{
  int err ;
  struct bnad_rx_info *rx_info ;
  struct bna_res_info *res_info ;
  struct bna_intr_info *intr_info ;
  struct bna_rx_config *rx_config ;
  struct bna_rx_event_cbfn rx_cbfn ;
  struct bna_rx *rx ;
  unsigned long flags ;
  struct lock_class_key __key ;
  atomic_long_t __constr_expr_0 ;
  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )rx_id;
  res_info = (struct bna_res_info *)(& bnad->rx_res_info[rx_id].res_info);
  intr_info = & (res_info + 15UL)->res_u.intr_info;
  rx_config = (struct bna_rx_config *)(& bnad->rx_config) + (unsigned long )rx_id;
  rx_cbfn.rcb_setup_cbfn = (void (*)(struct bnad * , struct bna_rcb * ))0;
  rx_cbfn.rcb_destroy_cbfn = (void (*)(struct bnad * , struct bna_rcb * ))0;
  rx_cbfn.ccb_setup_cbfn = & bnad_cb_ccb_setup;
  rx_cbfn.ccb_destroy_cbfn = & bnad_cb_ccb_destroy;
  rx_cbfn.rx_stall_cbfn = & bnad_cb_rx_stall;
  rx_cbfn.rx_cleanup_cbfn = & bnad_cb_rx_cleanup;
  rx_cbfn.rx_post_cbfn = & bnad_cb_rx_post;
  rx_info->rx_id = rx_id;
  bnad_init_rx_config(bnad, rx_config);
  ldv_spin_lock();
  bna_rx_res_req(rx_config, res_info);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  (res_info + 3UL)->res_type = 1;
  (res_info + 3UL)->res_u.mem_info.mem_type = 1;
  (res_info + 3UL)->res_u.mem_info.num = (u32 )rx_config->num_paths;
  (res_info + 3UL)->res_u.mem_info.len = rx_config->q0_depth * 40U + 64U;
  if ((unsigned int )rx_config->rxp_type != 1U) {
    (res_info + 2UL)->res_type = 1;
    (res_info + 2UL)->res_u.mem_info.mem_type = 1;
    (res_info + 2UL)->res_u.mem_info.num = (u32 )rx_config->num_paths;
    (res_info + 2UL)->res_u.mem_info.len = rx_config->q1_depth * 40U + 64U;
  } else {
  }
  err = bnad_rx_res_alloc(bnad, res_info, rx_id);
  if (err != 0) {
    return (err);
  } else {
  }
  bnad_rx_ctrl_init(bnad, rx_id);
  ldv_spin_lock();
  rx = bna_rx_create(& bnad->bna, bnad, rx_config, & rx_cbfn, res_info, (void *)rx_info);
  if ((unsigned long )rx == (unsigned long )((struct bna_rx *)0)) {
    err = -12;
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto err_return;
  } else {
  }
  rx_info->rx = rx;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  __init_work(& rx_info->rx_cleanup_work, 0);
  __constr_expr_0.counter = 137438953408L;
  rx_info->rx_cleanup_work.data = __constr_expr_0;
  lockdep_init_map(& rx_info->rx_cleanup_work.lockdep_map, "(&rx_info->rx_cleanup_work)",
                   & __key, 0);
  INIT_LIST_HEAD(& rx_info->rx_cleanup_work.entry);
  rx_info->rx_cleanup_work.func = (void (*)(struct work_struct * ))(& bnad_rx_cleanup);
  bnad_napi_add(bnad, rx_id);
  if ((unsigned int )intr_info->intr_type == 2U) {
    err = bnad_rx_msix_register(bnad, rx_info, rx_id, rx_config->num_paths);
    if (err != 0) {
      goto err_return;
    } else {
    }
  } else {
  }
  ldv_spin_lock();
  if (rx_id == 0U) {
    if ((int )bnad->cfg_flags & 1) {
      bna_rx_dim_reconfig(& bnad->bna, (u32 const (*)[2])(& bna_napi_dim_vector));
    } else {
    }
    bna_rx_vlanfilter_enable(rx);
    bnad_dim_timer_start(bnad);
  } else {
  }
  bna_rx_enable(rx);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (0);
  err_return:
  bnad_destroy_rx(bnad, rx_id);
  return (err);
}
}
void bnad_tx_coalescing_timeo_set(struct bnad *bnad )
{
  struct bnad_tx_info *tx_info ;
  {
  tx_info = (struct bnad_tx_info *)(& bnad->tx_info);
  if ((unsigned long )tx_info->tx == (unsigned long )((struct bna_tx *)0)) {
    return;
  } else {
  }
  bna_tx_coalescing_timeo_set(tx_info->tx, (int )bnad->tx_coalescing_timeo);
  return;
}
}
void bnad_rx_coalescing_timeo_set(struct bnad *bnad )
{
  struct bnad_rx_info *rx_info ;
  int i ;
  {
  i = 0;
  goto ldv_59183;
  ldv_59182:
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
  if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_59181;
  } else {
  }
  bna_rx_coalescing_timeo_set(rx_info->rx, (int )bnad->rx_coalescing_timeo);
  ldv_59181:
  i = i + 1;
  ldv_59183: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_59182;
  } else {
  }
  return;
}
}
int bnad_mac_addr_set_locked(struct bnad *bnad , u8 const *mac_addr )
{
  int ret ;
  bool tmp ;
  int tmp___0 ;
  enum bna_cb_status tmp___1 ;
  {
  tmp = is_valid_ether_addr(mac_addr);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (-99);
  } else {
  }
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    return (0);
  } else {
  }
  tmp___1 = bna_rx_ucast_set(bnad->rx_info[0].rx, mac_addr);
  ret = (int )tmp___1;
  if (ret != 0) {
    return (-99);
  } else {
  }
  return (0);
}
}
int bnad_enable_default_bcast(struct bnad *bnad )
{
  struct bnad_rx_info *rx_info ;
  int ret ;
  unsigned long flags ;
  enum bna_cb_status tmp ;
  {
  rx_info = (struct bnad_rx_info *)(& bnad->rx_info);
  init_completion(& bnad->bnad_completions.mcast_comp);
  ldv_spin_lock();
  tmp = bna_rx_mcast_add(rx_info->rx, (u8 const *)(& bnad_bcast_addr), & bnad_cb_rx_mcast_add);
  ret = (int )tmp;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (ret == 0) {
    wait_for_completion(& bnad->bnad_completions.mcast_comp);
  } else {
    return (-19);
  }
  if ((unsigned int )bnad->bnad_completions.mcast_comp_status != 0U) {
    return (-19);
  } else {
  }
  return (0);
}
}
void bnad_restore_vlans(struct bnad *bnad , u32 rx_id )
{
  u16 vid ;
  unsigned long flags ;
  unsigned long tmp ;
  unsigned long tmp___0 ;
  {
  tmp = find_first_bit((unsigned long const *)(& bnad->active_vlans), 4096UL);
  vid = (u16 )tmp;
  goto ldv_59203;
  ldv_59202:
  ldv_spin_lock();
  bna_rx_vlan_add(bnad->rx_info[rx_id].rx, (int )vid);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tmp___0 = find_next_bit((unsigned long const *)(& bnad->active_vlans), 4096UL,
                          (unsigned long )((int )vid + 1));
  vid = (u16 )tmp___0;
  ldv_59203: ;
  if ((unsigned int )vid <= 4095U) {
    goto ldv_59202;
  } else {
  }
  return;
}
}
void bnad_netdev_qstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats )
{
  int i ;
  int j ;
  {
  i = 0;
  goto ldv_59215;
  ldv_59214:
  j = 0;
  goto ldv_59212;
  ldv_59211: ;
  if ((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0)) {
    stats->rx_packets = stats->rx_packets + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq)->rx_packets;
    stats->rx_bytes = stats->rx_bytes + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq)->rx_bytes;
    if ((unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
      stats->rx_packets = stats->rx_packets + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq)->rx_packets;
      stats->rx_bytes = stats->rx_bytes + (((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq)->rx_bytes;
    } else {
    }
  } else {
  }
  j = j + 1;
  ldv_59212: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_59211;
  } else {
  }
  i = i + 1;
  ldv_59215: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_59214;
  } else {
  }
  i = 0;
  goto ldv_59221;
  ldv_59220:
  j = 0;
  goto ldv_59218;
  ldv_59217: ;
  if ((unsigned long )bnad->tx_info[i].tcb[j] != (unsigned long )((struct bna_tcb *)0)) {
    stats->tx_packets = stats->tx_packets + ((bnad->tx_info[i].tcb[j])->txq)->tx_packets;
    stats->tx_bytes = stats->tx_bytes + ((bnad->tx_info[i].tcb[j])->txq)->tx_bytes;
  } else {
  }
  j = j + 1;
  ldv_59218: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_59217;
  } else {
  }
  i = i + 1;
  ldv_59221: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_59220;
  } else {
  }
  return;
}
}
void bnad_netdev_hwstats_fill(struct bnad *bnad , struct rtnl_link_stats64 *stats )
{
  struct bfi_enet_stats_mac *mac_stats ;
  u32 bmap___0 ;
  int i ;
  {
  mac_stats = & (bnad->stats.bna_stats)->hw_stats.mac_stats;
  stats->rx_errors = (((mac_stats->rx_fcs_error + mac_stats->rx_alignment_error) + mac_stats->rx_frame_length_error) + mac_stats->rx_code_error) + mac_stats->rx_undersize;
  stats->tx_errors = mac_stats->tx_fcs_error + mac_stats->tx_undersize;
  stats->rx_dropped = mac_stats->rx_drop;
  stats->tx_dropped = mac_stats->tx_drop;
  stats->multicast = mac_stats->rx_multicast;
  stats->collisions = mac_stats->tx_total_collision;
  stats->rx_length_errors = mac_stats->rx_frame_length_error;
  stats->rx_crc_errors = mac_stats->rx_fcs_error;
  stats->rx_frame_errors = mac_stats->rx_alignment_error;
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_59232;
  ldv_59231: ;
  if ((int )bmap___0 & 1) {
    stats->rx_fifo_errors = stats->rx_fifo_errors + (bnad->stats.bna_stats)->hw_stats.rxf_stats[i].frame_drops;
    goto ldv_59230;
  } else {
  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_59232: ;
  if (bmap___0 != 0U) {
    goto ldv_59231;
  } else {
  }
  ldv_59230: ;
  return;
}
}
static void bnad_mbox_irq_sync(struct bnad *bnad )
{
  u32 irq ;
  unsigned long flags ;
  {
  ldv_spin_lock();
  if ((bnad->cfg_flags & 16U) != 0U) {
    irq = (bnad->msix_table)->vector;
  } else {
    irq = (bnad->pcidev)->irq;
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  synchronize_irq(irq);
  return;
}
}
static int bnad_tso_prepare(struct bnad *bnad , struct sk_buff *skb )
{
  int err ;
  struct iphdr *iph ;
  struct iphdr *tmp ;
  struct tcphdr *tmp___0 ;
  __sum16 tmp___1 ;
  struct ipv6hdr *ipv6h ;
  struct ipv6hdr *tmp___2 ;
  struct tcphdr *tmp___3 ;
  __sum16 tmp___4 ;
  __be16 tmp___5 ;
  {
  err = skb_cow_head(skb, 0U);
  if (err < 0) {
    bnad->stats.drv_stats.tso_err = bnad->stats.drv_stats.tso_err + 1ULL;
    return (err);
  } else {
  }
  tmp___5 = vlan_get_protocol(skb);
  if ((unsigned int )tmp___5 == 8U) {
    tmp = ip_hdr((struct sk_buff const *)skb);
    iph = tmp;
    iph->tot_len = 0U;
    iph->check = 0U;
    tmp___0 = tcp_hdr((struct sk_buff const *)skb);
    tmp___1 = csum_tcpudp_magic(iph->saddr, iph->daddr, 0, 6, 0U);
    tmp___0->check = ~ ((int )tmp___1);
    bnad->stats.drv_stats.tso4 = bnad->stats.drv_stats.tso4 + 1ULL;
  } else {
    tmp___2 = ipv6_hdr((struct sk_buff const *)skb);
    ipv6h = tmp___2;
    ipv6h->payload_len = 0U;
    tmp___3 = tcp_hdr((struct sk_buff const *)skb);
    tmp___4 = csum_ipv6_magic((struct in6_addr const *)(& ipv6h->saddr), (struct in6_addr const *)(& ipv6h->daddr),
                              0U, 6, 0U);
    tmp___3->check = ~ ((int )tmp___4);
    bnad->stats.drv_stats.tso6 = bnad->stats.drv_stats.tso6 + 1ULL;
  }
  return (0);
}
}
static void bnad_q_num_init(struct bnad *bnad )
{
  int rxps ;
  unsigned int _min1 ;
  unsigned int tmp ;
  unsigned int _min2 ;
  {
  tmp = cpumask_weight(cpu_online_mask);
  _min1 = tmp;
  _min2 = 16U;
  rxps = (int )(_min1 < _min2 ? _min1 : _min2);
  if ((bnad->cfg_flags & 16U) == 0U) {
    rxps = 1;
  } else {
  }
  bnad->num_rx = 1U;
  bnad->num_tx = 1U;
  bnad->num_rxp_per_rx = (u32 )rxps;
  bnad->num_txq_per_tx = 1U;
  return;
}
}
static void bnad_q_num_adjust(struct bnad *bnad , int msix_vectors , int temp )
{
  {
  bnad->num_txq_per_tx = 1U;
  if ((u32 )msix_vectors >= (bnad->num_tx * bnad->num_txq_per_tx + bnad_rxqs_per_cq) + 1U && (bnad->cfg_flags & 16U) != 0U) {
    bnad->num_rxp_per_rx = ((u32 )msix_vectors - bnad->num_tx * bnad->num_txq_per_tx) - 1U;
  } else {
    bnad->num_rxp_per_rx = 1U;
  }
  return;
}
}
static int bnad_ioceth_disable(struct bnad *bnad )
{
  unsigned long flags ;
  int err ;
  unsigned long tmp ;
  {
  err = 0;
  ldv_spin_lock();
  init_completion(& bnad->bnad_completions.ioc_comp);
  bna_ioceth_disable(& bnad->bna.ioceth, 0);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tmp = msecs_to_jiffies(10000U);
  wait_for_completion_timeout(& bnad->bnad_completions.ioc_comp, tmp);
  err = (int )bnad->bnad_completions.ioc_comp_status;
  return (err);
}
}
static int bnad_ioceth_enable(struct bnad *bnad )
{
  int err ;
  unsigned long flags ;
  unsigned long tmp ;
  {
  err = 0;
  ldv_spin_lock();
  init_completion(& bnad->bnad_completions.ioc_comp);
  bnad->bnad_completions.ioc_comp_status = 7U;
  bna_ioceth_enable(& bnad->bna.ioceth);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  tmp = msecs_to_jiffies(10000U);
  wait_for_completion_timeout(& bnad->bnad_completions.ioc_comp, tmp);
  err = (int )bnad->bnad_completions.ioc_comp_status;
  return (err);
}
}
static void bnad_res_free(struct bnad *bnad , struct bna_res_info *res_info , u32 res_val_max )
{
  int i ;
  {
  i = 0;
  goto ldv_59274;
  ldv_59273:
  bnad_mem_free(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  i = i + 1;
  ldv_59274: ;
  if ((u32 )i < res_val_max) {
    goto ldv_59273;
  } else {
  }
  return;
}
}
static int bnad_res_alloc(struct bnad *bnad , struct bna_res_info *res_info , u32 res_val_max )
{
  int i ;
  int err ;
  {
  i = 0;
  goto ldv_59285;
  ldv_59284:
  err = bnad_mem_alloc(bnad, & (res_info + (unsigned long )i)->res_u.mem_info);
  if (err != 0) {
    goto err_return;
  } else {
  }
  i = i + 1;
  ldv_59285: ;
  if ((u32 )i < res_val_max) {
    goto ldv_59284;
  } else {
  }
  return (0);
  err_return:
  bnad_res_free(bnad, res_info, res_val_max);
  return (err);
}
}
static void bnad_enable_msix(struct bnad *bnad )
{
  int i ;
  int ret ;
  unsigned long flags ;
  void *tmp ;
  {
  ldv_spin_lock();
  if ((bnad->cfg_flags & 16U) == 0U) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((unsigned long )bnad->msix_table != (unsigned long )((struct msix_entry *)0)) {
    return;
  } else {
  }
  tmp = kcalloc((size_t )bnad->msix_num, 8UL, 208U);
  bnad->msix_table = (struct msix_entry *)tmp;
  if ((unsigned long )bnad->msix_table == (unsigned long )((struct msix_entry *)0)) {
    goto intx_mode;
  } else {
  }
  i = 0;
  goto ldv_59295;
  ldv_59294:
  (bnad->msix_table + (unsigned long )i)->entry = (u16 )i;
  i = i + 1;
  ldv_59295: ;
  if ((u32 )i < bnad->msix_num) {
    goto ldv_59294;
  } else {
  }
  ret = pci_enable_msix_range(bnad->pcidev, bnad->msix_table, 1, (int )bnad->msix_num);
  if (ret < 0) {
    goto intx_mode;
  } else
  if ((u32 )ret < bnad->msix_num) {
    dev_warn((struct device const *)(& (bnad->pcidev)->dev), "%d MSI-X vectors allocated < %d requested\n",
             ret, bnad->msix_num);
    ldv_spin_lock();
    bnad_q_num_adjust(bnad, (ret + -1) / 2, (ret + -1) / 2);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    bnad->msix_num = (bnad->num_tx * bnad->num_txq_per_tx + bnad->num_rx * bnad->num_rxp_per_rx) + 1U;
    if (bnad->msix_num > (u32 )ret) {
      pci_disable_msix(bnad->pcidev);
      goto intx_mode;
    } else {
    }
  } else {
  }
  pci_intx(bnad->pcidev, 0);
  return;
  intx_mode:
  dev_warn((struct device const *)(& (bnad->pcidev)->dev), "MSI-X enable failed - operating in INTx mode\n");
  kfree((void const *)bnad->msix_table);
  bnad->msix_table = (struct msix_entry *)0;
  bnad->msix_num = 0U;
  ldv_spin_lock();
  bnad->cfg_flags = bnad->cfg_flags & 4294967279U;
  bnad_q_num_init(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static void bnad_disable_msix(struct bnad *bnad )
{
  u32 cfg_flags ;
  unsigned long flags ;
  {
  ldv_spin_lock();
  cfg_flags = bnad->cfg_flags;
  if ((bnad->cfg_flags & 16U) != 0U) {
    bnad->cfg_flags = bnad->cfg_flags & 4294967279U;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if ((cfg_flags & 16U) != 0U) {
    pci_disable_msix(bnad->pcidev);
    kfree((void const *)bnad->msix_table);
    bnad->msix_table = (struct msix_entry *)0;
  } else {
  }
  return;
}
}
static int bnad_open(struct net_device *netdev )
{
  int err ;
  struct bnad *bnad ;
  void *tmp ;
  struct bna_pause_config pause_config ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  err = bnad_setup_tx(bnad, 0U);
  if (err != 0) {
    goto err_return;
  } else {
  }
  err = bnad_setup_rx(bnad, 0U);
  if (err != 0) {
    goto cleanup_tx;
  } else {
  }
  pause_config.tx_pause = 0;
  pause_config.rx_pause = 0;
  ldv_spin_lock();
  bna_enet_mtu_set(& bnad->bna.enet, (int )((bnad->netdev)->mtu + 22U), (void (*)(struct bnad * ))0);
  bna_enet_pause_config(& bnad->bna.enet, & pause_config);
  bna_enet_enable(& bnad->bna.enet);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_enable_default_bcast(bnad);
  bnad_restore_vlans(bnad, 0U);
  ldv_spin_lock();
  bnad_mac_addr_set_locked(bnad, (u8 const *)netdev->dev_addr);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_stats_timer_start(bnad);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
  cleanup_tx:
  bnad_destroy_tx(bnad, 0U);
  err_return:
  mutex_unlock(& bnad->conf_mutex);
  return (err);
}
}
static int bnad_stop(struct net_device *netdev )
{
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  bnad_stats_timer_stop(bnad);
  init_completion(& bnad->bnad_completions.enet_comp);
  ldv_spin_lock();
  bna_enet_disable(& bnad->bna.enet, 0, & bnad_cb_enet_disabled);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.enet_comp);
  bnad_destroy_tx(bnad, 0U);
  bnad_destroy_rx(bnad, 0U);
  bnad_mbox_irq_sync(bnad);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static int bnad_txq_wi_prepare(struct bnad *bnad , struct bna_tcb *tcb , struct sk_buff *skb ,
                               struct bna_txq_entry *txqent )
{
  u16 flags ;
  u32 gso_size ;
  u16 vlan_tag ;
  int tmp ;
  __u16 tmp___0 ;
  unsigned char *tmp___1 ;
  long tmp___2 ;
  __u16 tmp___3 ;
  int tmp___4 ;
  unsigned int tmp___5 ;
  long tmp___6 ;
  int tmp___7 ;
  unsigned int tmp___8 ;
  int tmp___9 ;
  __u16 tmp___10 ;
  long tmp___11 ;
  __be16 net_proto ;
  __be16 tmp___12 ;
  u8 proto ;
  struct iphdr *tmp___13 ;
  struct ipv6hdr *tmp___14 ;
  int tmp___15 ;
  __u16 tmp___16 ;
  unsigned int tmp___17 ;
  int tmp___18 ;
  unsigned int tmp___19 ;
  long tmp___20 ;
  int tmp___21 ;
  __u16 tmp___22 ;
  unsigned int tmp___23 ;
  int tmp___24 ;
  long tmp___25 ;
  bool tmp___26 ;
  __u16 tmp___27 ;
  __u32 tmp___28 ;
  {
  flags = 0U;
  vlan_tag = 0U;
  if (((int )skb->vlan_tci & 4096) != 0) {
    vlan_tag = (unsigned int )skb->vlan_tci & 61439U;
    flags = (u16 )((unsigned int )flags | 24U);
  } else {
  }
  tmp = constant_test_bit(0L, (unsigned long const volatile *)(& bnad->run_flags));
  if (tmp != 0) {
    vlan_tag = (u16 )((int )((short )((int )tcb->priority << 13)) | ((int )((short )vlan_tag) & 8191));
    flags = (u16 )((unsigned int )flags | 24U);
  } else {
  }
  tmp___0 = __fswab16((int )vlan_tag);
  txqent->hdr.wi.vlan_tag = tmp___0;
  tmp___26 = skb_is_gso((struct sk_buff const *)skb);
  if ((int )tmp___26) {
    tmp___1 = skb_end_pointer((struct sk_buff const *)skb);
    gso_size = (u32 )((struct skb_shared_info *)tmp___1)->gso_size;
    tmp___2 = ldv__builtin_expect((bnad->netdev)->mtu < gso_size, 0L);
    if (tmp___2 != 0L) {
      bnad->stats.drv_stats.tx_skb_mss_too_long = bnad->stats.drv_stats.tx_skb_mss_too_long + 1ULL;
      return (-22);
    } else {
    }
    tmp___4 = skb_transport_offset((struct sk_buff const *)skb);
    tmp___5 = tcp_hdrlen((struct sk_buff const *)skb);
    tmp___6 = ldv__builtin_expect(((u32 )tmp___4 + gso_size) + tmp___5 >= skb->len, 0L);
    if (tmp___6 != 0L) {
      txqent->hdr.wi.opcode = 516U;
      txqent->hdr.wi.lso_mss = 0U;
      bnad->stats.drv_stats.tx_skb_tso_too_short = bnad->stats.drv_stats.tx_skb_tso_too_short + 1ULL;
    } else {
      txqent->hdr.wi.opcode = 772U;
      tmp___3 = __fswab16((int )((__u16 )gso_size));
      txqent->hdr.wi.lso_mss = tmp___3;
    }
    tmp___7 = bnad_tso_prepare(bnad, skb);
    if (tmp___7 != 0) {
      bnad->stats.drv_stats.tx_skb_tso_prepare = bnad->stats.drv_stats.tx_skb_tso_prepare + 1ULL;
      return (-22);
    } else {
    }
    flags = (u16 )((unsigned int )flags | 3U);
    tmp___8 = tcp_hdrlen((struct sk_buff const *)skb);
    tmp___9 = skb_transport_offset((struct sk_buff const *)skb);
    tmp___10 = __fswab16((int )((unsigned int )((int )((__u16 )(tmp___8 >> 2)) << 10U) | ((unsigned int )((__u16 )tmp___9) & 1023U)));
    txqent->hdr.wi.l4_hdr_size_n_offset = tmp___10;
  } else {
    txqent->hdr.wi.opcode = 516U;
    txqent->hdr.wi.lso_mss = 0U;
    tmp___11 = ldv__builtin_expect(skb->len > (bnad->netdev)->mtu + 18U, 0L);
    if (tmp___11 != 0L) {
      bnad->stats.drv_stats.tx_skb_non_tso_too_long = bnad->stats.drv_stats.tx_skb_non_tso_too_long + 1ULL;
      return (-22);
    } else {
    }
    if ((unsigned int )*((unsigned char *)skb + 145UL) == 6U) {
      tmp___12 = vlan_get_protocol(skb);
      net_proto = tmp___12;
      proto = 0U;
      if ((unsigned int )net_proto == 8U) {
        tmp___13 = ip_hdr((struct sk_buff const *)skb);
        proto = tmp___13->protocol;
      } else
      if ((unsigned int )net_proto == 56710U) {
        tmp___14 = ipv6_hdr((struct sk_buff const *)skb);
        proto = tmp___14->nexthdr;
      } else {
      }
      if ((unsigned int )proto == 6U) {
        flags = (u16 )((unsigned int )flags | 2U);
        tmp___15 = skb_transport_offset((struct sk_buff const *)skb);
        tmp___16 = __fswab16((int )((__u16 )tmp___15) & 1023);
        txqent->hdr.wi.l4_hdr_size_n_offset = tmp___16;
        bnad->stats.drv_stats.tcpcsum_offload = bnad->stats.drv_stats.tcpcsum_offload + 1ULL;
        tmp___17 = skb_headlen((struct sk_buff const *)skb);
        tmp___18 = skb_transport_offset((struct sk_buff const *)skb);
        tmp___19 = tcp_hdrlen((struct sk_buff const *)skb);
        tmp___20 = ldv__builtin_expect(tmp___17 < (unsigned int )tmp___18 + tmp___19,
                                    0L);
        if (tmp___20 != 0L) {
          bnad->stats.drv_stats.tx_skb_tcp_hdr = bnad->stats.drv_stats.tx_skb_tcp_hdr + 1ULL;
          return (-22);
        } else {
        }
      } else
      if ((unsigned int )proto == 17U) {
        flags = (u16 )((unsigned int )flags | 4U);
        tmp___21 = skb_transport_offset((struct sk_buff const *)skb);
        tmp___22 = __fswab16((int )((__u16 )tmp___21) & 1023);
        txqent->hdr.wi.l4_hdr_size_n_offset = tmp___22;
        bnad->stats.drv_stats.udpcsum_offload = bnad->stats.drv_stats.udpcsum_offload + 1ULL;
        tmp___23 = skb_headlen((struct sk_buff const *)skb);
        tmp___24 = skb_transport_offset((struct sk_buff const *)skb);
        tmp___25 = ldv__builtin_expect((unsigned long )tmp___23 < (unsigned long )tmp___24 + 8UL,
                                    0L);
        if (tmp___25 != 0L) {
          bnad->stats.drv_stats.tx_skb_udp_hdr = bnad->stats.drv_stats.tx_skb_udp_hdr + 1ULL;
          return (-22);
        } else {
        }
      } else {
        bnad->stats.drv_stats.tx_skb_csum_err = bnad->stats.drv_stats.tx_skb_csum_err + 1ULL;
        return (-22);
      }
    } else {
      txqent->hdr.wi.l4_hdr_size_n_offset = 0U;
    }
  }
  tmp___27 = __fswab16((int )flags);
  txqent->hdr.wi.flags = tmp___27;
  tmp___28 = __fswab32(skb->len);
  txqent->hdr.wi.frame_length = tmp___28;
  return (0);
}
}
static netdev_tx_t bnad_start_xmit(struct sk_buff *skb , struct net_device *netdev )
{
  struct bnad *bnad ;
  void *tmp ;
  u32 txq_id ;
  struct bna_tcb *tcb ;
  struct bnad_tx_unmap *unmap_q ;
  struct bnad_tx_unmap *unmap ;
  struct bnad_tx_unmap *head_unmap ;
  u32 prod ;
  u32 q_depth ;
  u32 vect_id ;
  u32 wis ;
  u32 vectors ;
  u32 len ;
  int i ;
  dma_addr_t dma_addr ;
  struct bna_txq_entry *txqent ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  long tmp___5 ;
  unsigned char *tmp___6 ;
  long tmp___7 ;
  u32 sent ;
  int tmp___8 ;
  long tmp___9 ;
  int tmp___10 ;
  long tmp___11 ;
  long tmp___12 ;
  int tmp___13 ;
  u64 tmp_addr ;
  __u64 tmp___14 ;
  __u16 tmp___15 ;
  struct skb_frag_struct const *frag ;
  unsigned char *tmp___16 ;
  u32 size ;
  unsigned int tmp___17 ;
  long tmp___18 ;
  u64 tmp_addr___0 ;
  __u64 tmp___19 ;
  __u16 tmp___20 ;
  long tmp___21 ;
  int tmp___22 ;
  long tmp___23 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  txq_id = 0U;
  tcb = (struct bna_tcb *)0;
  len = skb_headlen((struct sk_buff const *)skb);
  tmp___0 = ldv__builtin_expect(skb->len <= 14U, 0L);
  if (tmp___0 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_too_short = bnad->stats.drv_stats.tx_skb_too_short + 1ULL;
    return (0);
  } else {
  }
  tmp___1 = ldv__builtin_expect(len > 65535U, 0L);
  if (tmp___1 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_headlen_zero = bnad->stats.drv_stats.tx_skb_headlen_zero + 1ULL;
    return (0);
  } else {
  }
  tmp___2 = ldv__builtin_expect(len == 0U, 0L);
  if (tmp___2 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_headlen_zero = bnad->stats.drv_stats.tx_skb_headlen_zero + 1ULL;
    return (0);
  } else {
  }
  tcb = bnad->tx_info[0].tcb[txq_id];
  if ((unsigned long )tcb == (unsigned long )((struct bna_tcb *)0)) {
    tmp___4 = 1;
  } else {
    tmp___3 = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
    if (tmp___3 == 0) {
      tmp___4 = 1;
    } else {
      tmp___4 = 0;
    }
  }
  tmp___5 = ldv__builtin_expect((long )tmp___4, 0L);
  if (tmp___5 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_stopping = bnad->stats.drv_stats.tx_skb_stopping + 1ULL;
    return (0);
  } else {
  }
  q_depth = tcb->q_depth;
  prod = tcb->producer_index;
  unmap_q = (struct bnad_tx_unmap *)tcb->unmap_q;
  tmp___6 = skb_end_pointer((struct sk_buff const *)skb);
  vectors = (u32 )((int )((struct skb_shared_info *)tmp___6)->nr_frags + 1);
  wis = (vectors + 3U) >> 2;
  tmp___7 = ldv__builtin_expect(vectors > 255U, 0L);
  if (tmp___7 != 0L) {
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_max_vectors = bnad->stats.drv_stats.tx_skb_max_vectors + 1ULL;
    return (0);
  } else {
  }
  tmp___12 = ldv__builtin_expect((((tcb->consumer_index - tcb->producer_index) - 1U) & (q_depth - 1U)) < wis,
                              0L);
  if (tmp___12 != 0L) {
    if ((unsigned int )*(tcb->hw_consumer_index) != tcb->consumer_index) {
      tmp___10 = test_and_set_bit(0L, (unsigned long volatile *)(& tcb->flags));
      if (tmp___10 == 0) {
        sent = bnad_txcmpl_process(bnad, tcb);
        tmp___8 = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
        tmp___9 = ldv__builtin_expect(tmp___8 != 0, 1L);
        if (tmp___9 != 0L) {
          writel((tcb->i_dbell)->doorbell_ack | sent, (void volatile *)(tcb->i_dbell)->doorbell_addr);
        } else {
        }
        __asm__ volatile ("": : : "memory");
        clear_bit(0L, (unsigned long volatile *)(& tcb->flags));
      } else {
        netif_stop_queue(netdev);
        bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
      }
    } else {
      netif_stop_queue(netdev);
      bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
    }
    __asm__ volatile ("mfence": : : "memory");
    tmp___11 = ldv__builtin_expect((((tcb->consumer_index - tcb->producer_index) - 1U) & (q_depth - 1U)) < wis,
                                1L);
    if (tmp___11 != 0L) {
      bnad->stats.drv_stats.netif_queue_stop = bnad->stats.drv_stats.netif_queue_stop + 1ULL;
      return (16);
    } else {
      netif_wake_queue(netdev);
      bnad->stats.drv_stats.netif_queue_wakeup = bnad->stats.drv_stats.netif_queue_wakeup + 1ULL;
    }
  } else {
  }
  txqent = (struct bna_txq_entry *)tcb->sw_q + (unsigned long )prod;
  head_unmap = unmap_q + (unsigned long )prod;
  tmp___13 = bnad_txq_wi_prepare(bnad, tcb, skb, txqent);
  if (tmp___13 != 0) {
    dev_kfree_skb_any(skb);
    return (0);
  } else {
  }
  txqent->hdr.wi.reserved = 0U;
  txqent->hdr.wi.num_vectors = (u8 )vectors;
  head_unmap->skb = skb;
  head_unmap->nvecs = 0U;
  unmap = head_unmap;
  dma_addr = dma_map_single_attrs(& (bnad->pcidev)->dev, (void *)skb->data, (size_t )len,
                                  1, (struct dma_attrs *)0);
  tmp___14 = __fswab64(dma_addr);
  tmp_addr = tmp___14;
  txqent->vector[0].host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  txqent->vector[0].host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  tmp___15 = __fswab16((int )((__u16 )len));
  txqent->vector[0].length = tmp___15;
  ((struct bnad_tx_vector *)(& unmap->vectors))->dma_addr = dma_addr;
  head_unmap->nvecs = head_unmap->nvecs + 1U;
  i = 0;
  vect_id = 0U;
  goto ldv_59352;
  ldv_59351:
  tmp___16 = skb_end_pointer((struct sk_buff const *)skb);
  frag = (struct skb_frag_struct const *)(& ((struct skb_shared_info *)tmp___16)->frags) + (unsigned long )i;
  tmp___17 = skb_frag_size(frag);
  size = tmp___17;
  tmp___18 = ldv__builtin_expect(size == 0U, 0L);
  if (tmp___18 != 0L) {
    bnad_tx_buff_unmap(bnad, unmap_q, q_depth, tcb->producer_index);
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_frag_zero = bnad->stats.drv_stats.tx_skb_frag_zero + 1ULL;
    return (0);
  } else {
  }
  len = len + size;
  vect_id = vect_id + 1U;
  if (vect_id == 4U) {
    vect_id = 0U;
    prod = (prod + 1U) & (q_depth - 1U);
    txqent = (struct bna_txq_entry *)tcb->sw_q + (unsigned long )prod;
    txqent->hdr.wi_ext.opcode = 1025U;
    unmap = unmap_q + (unsigned long )prod;
  } else {
  }
  dma_addr = skb_frag_dma_map(& (bnad->pcidev)->dev, frag, 0UL, (size_t )size, 1);
  ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vect_id)->dma_len = size;
  tmp___19 = __fswab64(dma_addr);
  tmp_addr___0 = tmp___19;
  txqent->vector[vect_id].host_addr.msb = ((struct bna_dma_addr *)(& tmp_addr___0))->msb;
  txqent->vector[vect_id].host_addr.lsb = ((struct bna_dma_addr *)(& tmp_addr___0))->lsb;
  tmp___20 = __fswab16((int )((__u16 )size));
  txqent->vector[vect_id].length = tmp___20;
  ((struct bnad_tx_vector *)(& unmap->vectors) + (unsigned long )vect_id)->dma_addr = dma_addr;
  head_unmap->nvecs = head_unmap->nvecs + 1U;
  i = i + 1;
  ldv_59352: ;
  if ((u32 )i < vectors - 1U) {
    goto ldv_59351;
  } else {
  }
  tmp___21 = ldv__builtin_expect(skb->len != len, 0L);
  if (tmp___21 != 0L) {
    bnad_tx_buff_unmap(bnad, unmap_q, q_depth, tcb->producer_index);
    dev_kfree_skb_any(skb);
    bnad->stats.drv_stats.tx_skb_len_mismatch = bnad->stats.drv_stats.tx_skb_len_mismatch + 1ULL;
    return (0);
  } else {
  }
  prod = (prod + 1U) & (q_depth - 1U);
  tcb->producer_index = prod;
  __asm__ volatile ("mfence": : : "memory");
  tmp___22 = constant_test_bit(1L, (unsigned long const volatile *)(& tcb->flags));
  tmp___23 = ldv__builtin_expect(tmp___22 == 0, 0L);
  if (tmp___23 != 0L) {
    return (0);
  } else {
  }
  skb_tx_timestamp(skb);
  writel(tcb->producer_index | 2147483648U, (void volatile *)tcb->q_dbell);
  __asm__ volatile ("mfence": : : "memory");
  return (0);
}
}
static struct rtnl_link_stats64 *bnad_get_stats64(struct net_device *netdev , struct rtnl_link_stats64 *stats )
{
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  ldv_spin_lock();
  bnad_netdev_qstats_fill(bnad, stats);
  bnad_netdev_hwstats_fill(bnad, stats);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (stats);
}
}
static void bnad_set_rx_ucast_fltr(struct bnad *bnad )
{
  struct net_device *netdev ;
  int uc_count ;
  enum bna_cb_status ret ;
  u8 *mac_list ;
  struct netdev_hw_addr *ha ;
  int entry ;
  void *tmp ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  netdev = bnad->netdev;
  uc_count = netdev->uc.count;
  if ((bnad->netdev)->uc.count == 0) {
    bna_rx_ucast_listset(bnad->rx_info[0].rx, 0, (u8 const *)0U);
    return;
  } else {
  }
  if (bnad->bna.ioceth.attr.num_ucmac < uc_count) {
    goto mode_default;
  } else {
  }
  tmp = kzalloc((size_t )(uc_count * 6), 32U);
  mac_list = (u8 *)tmp;
  if ((unsigned long )mac_list == (unsigned long )((u8 *)0U)) {
    goto mode_default;
  } else {
  }
  entry = 0;
  __mptr = (struct list_head const *)netdev->uc.list.next;
  ha = (struct netdev_hw_addr *)__mptr;
  goto ldv_59375;
  ldv_59374:
  ether_addr_copy(mac_list + (unsigned long )(entry * 6), (u8 const *)(& ha->addr));
  entry = entry + 1;
  __mptr___0 = (struct list_head const *)ha->list.next;
  ha = (struct netdev_hw_addr *)__mptr___0;
  ldv_59375: ;
  if ((unsigned long )(& ha->list) != (unsigned long )(& netdev->uc.list)) {
    goto ldv_59374;
  } else {
  }
  ret = bna_rx_ucast_listset(bnad->rx_info[0].rx, entry, (u8 const *)mac_list);
  kfree((void const *)mac_list);
  if ((unsigned int )ret != 0U) {
    goto mode_default;
  } else {
  }
  return;
  mode_default:
  bnad->cfg_flags = bnad->cfg_flags | 8U;
  bna_rx_ucast_listset(bnad->rx_info[0].rx, 0, (u8 const *)0U);
  return;
}
}
static void bnad_set_rx_mcast_fltr(struct bnad *bnad )
{
  struct net_device *netdev ;
  int mc_count ;
  enum bna_cb_status ret ;
  u8 *mac_list ;
  void *tmp ;
  {
  netdev = bnad->netdev;
  mc_count = netdev->mc.count;
  if ((netdev->flags & 512U) != 0U) {
    goto mode_allmulti;
  } else {
  }
  if (netdev->mc.count == 0) {
    return;
  } else {
  }
  if (bnad->bna.ioceth.attr.num_mcmac < mc_count) {
    goto mode_allmulti;
  } else {
  }
  tmp = kzalloc((size_t )((mc_count + 1) * 6), 32U);
  mac_list = (u8 *)tmp;
  if ((unsigned long )mac_list == (unsigned long )((u8 *)0U)) {
    goto mode_allmulti;
  } else {
  }
  ether_addr_copy(mac_list, (u8 const *)(& bnad_bcast_addr));
  bnad_netdev_mc_list_get(netdev, mac_list);
  ret = bna_rx_mcast_listset(bnad->rx_info[0].rx, mc_count + 1, (u8 const *)mac_list);
  kfree((void const *)mac_list);
  if ((unsigned int )ret != 0U) {
    goto mode_allmulti;
  } else {
  }
  return;
  mode_allmulti:
  bnad->cfg_flags = bnad->cfg_flags | 4U;
  bna_rx_mcast_delall(bnad->rx_info[0].rx);
  return;
}
}
void bnad_set_rx_mode(struct net_device *netdev )
{
  struct bnad *bnad ;
  void *tmp ;
  enum bna_rxmode new_mode ;
  enum bna_rxmode mode_mask ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  ldv_spin_lock();
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    return;
  } else {
  }
  bnad->cfg_flags = bnad->cfg_flags & 4294967281U;
  new_mode = 0;
  if ((netdev->flags & 256U) != 0U) {
    new_mode = (enum bna_rxmode )((unsigned int )new_mode | 1U);
    bnad->cfg_flags = bnad->cfg_flags | 2U;
  } else {
    bnad_set_rx_mcast_fltr(bnad);
    if ((bnad->cfg_flags & 4U) != 0U) {
      new_mode = (enum bna_rxmode )((unsigned int )new_mode | 4U);
    } else {
    }
    bnad_set_rx_ucast_fltr(bnad);
    if ((bnad->cfg_flags & 8U) != 0U) {
      new_mode = (enum bna_rxmode )((unsigned int )new_mode | 2U);
    } else {
    }
  }
  mode_mask = 7;
  bna_rx_mode_set(bnad->rx_info[0].rx, new_mode, mode_mask);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return;
}
}
static int bnad_set_mac_address(struct net_device *netdev , void *addr )
{
  int err ;
  struct bnad *bnad ;
  void *tmp ;
  struct sockaddr *sa ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  sa = (struct sockaddr *)addr;
  ldv_spin_lock();
  err = bnad_mac_addr_set_locked(bnad, (u8 const *)(& sa->sa_data));
  if (err == 0) {
    ether_addr_copy(netdev->dev_addr, (u8 const *)(& sa->sa_data));
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return (err);
}
}
static int bnad_mtu_set(struct bnad *bnad , int frame_size )
{
  unsigned long flags ;
  {
  init_completion(& bnad->bnad_completions.mtu_comp);
  ldv_spin_lock();
  bna_enet_mtu_set(& bnad->bna.enet, frame_size, & bnad_cb_enet_mtu_set);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& bnad->bnad_completions.mtu_comp);
  return ((int )bnad->bnad_completions.mtu_comp_status);
}
}
static int bnad_change_mtu(struct net_device *netdev , int new_mtu )
{
  int err ;
  int mtu ;
  struct bnad *bnad ;
  void *tmp ;
  u32 rx_count ;
  u32 frame ;
  u32 new_frame ;
  bool tmp___0 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  rx_count = 0U;
  if (new_mtu + 14 <= 59 || new_mtu > 9000) {
    return (-22);
  } else {
  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  mtu = (int )netdev->mtu;
  netdev->mtu = (unsigned int )new_mtu;
  frame = (u32 )(mtu + 22);
  new_frame = (u32 )(new_mtu + 22);
  if ((unsigned int )(bnad->pcidev)->device == 34U) {
    tmp___0 = netif_running((struct net_device const *)bnad->netdev);
    if ((int )tmp___0) {
      if ((frame <= 4096U && new_frame > 4096U) || (frame > 4096U && new_frame <= 4096U)) {
        rx_count = bnad_reinit_rx(bnad);
      } else {
      }
    } else {
    }
  } else {
  }
  err = bnad_mtu_set(bnad, (int )new_frame);
  if (err != 0) {
    err = -16;
  } else {
  }
  mutex_unlock(& bnad->conf_mutex);
  return (err);
}
}
static int bnad_vlan_rx_add_vid(struct net_device *netdev , __be16 proto , u16 vid )
{
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    return (0);
  } else {
  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  ldv_spin_lock();
  bna_rx_vlan_add(bnad->rx_info[0].rx, (int )vid);
  set_bit((long )vid, (unsigned long volatile *)(& bnad->active_vlans));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static int bnad_vlan_rx_kill_vid(struct net_device *netdev , __be16 proto , u16 vid )
{
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  if ((unsigned long )bnad->rx_info[0].rx == (unsigned long )((struct bna_rx *)0)) {
    return (0);
  } else {
  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  ldv_spin_lock();
  clear_bit((long )vid, (unsigned long volatile *)(& bnad->active_vlans));
  bna_rx_vlan_del(bnad->rx_info[0].rx, (int )vid);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static int bnad_set_features(struct net_device *dev , netdev_features_t features )
{
  struct bnad *bnad ;
  void *tmp ;
  netdev_features_t changed ;
  unsigned long flags ;
  bool tmp___0 ;
  {
  tmp = netdev_priv((struct net_device const *)dev);
  bnad = (struct bnad *)tmp;
  changed = dev->features ^ features;
  if ((changed & 256ULL) != 0ULL) {
    tmp___0 = netif_running((struct net_device const *)dev);
    if ((int )tmp___0) {
      ldv_spin_lock();
      if ((features & 256ULL) != 0ULL) {
        bna_rx_vlan_strip_enable(bnad->rx_info[0].rx);
      } else {
        bna_rx_vlan_strip_disable(bnad->rx_info[0].rx);
      }
      spin_unlock_irqrestore(& bnad->bna_lock, flags);
    } else {
    }
  } else {
  }
  return (0);
}
}
static void bnad_netpoll(struct net_device *netdev )
{
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_rx_info *rx_info ;
  struct bnad_rx_ctrl *rx_ctrl ;
  u32 curr_mask ;
  int i ;
  int j ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  if ((bnad->cfg_flags & 16U) == 0U) {
    curr_mask = readl((void const volatile *)bnad->bna.regs.fn_int_mask);
    writel(4294967295U, (void volatile *)bnad->bna.regs.fn_int_mask);
    bnad_isr((int )(bnad->pcidev)->irq, (void *)netdev);
    writel(curr_mask, (void volatile *)bnad->bna.regs.fn_int_mask);
  } else {
    i = 0;
    goto ldv_59450;
    ldv_59449:
    rx_info = (struct bnad_rx_info *)(& bnad->rx_info) + (unsigned long )i;
    if ((unsigned long )rx_info->rx == (unsigned long )((struct bna_rx *)0)) {
      goto ldv_59445;
    } else {
    }
    j = 0;
    goto ldv_59447;
    ldv_59446:
    rx_ctrl = (struct bnad_rx_ctrl *)(& rx_info->rx_ctrl) + (unsigned long )j;
    if ((unsigned long )rx_ctrl->ccb != (unsigned long )((struct bna_ccb *)0)) {
      bnad_netif_rx_schedule_poll(bnad, rx_ctrl->ccb);
    } else {
    }
    j = j + 1;
    ldv_59447: ;
    if ((u32 )j < bnad->num_rxp_per_rx) {
      goto ldv_59446;
    } else {
    }
    ldv_59445:
    i = i + 1;
    ldv_59450: ;
    if ((u32 )i < bnad->num_rx) {
      goto ldv_59449;
    } else {
    }
  }
  return;
}
}
static struct net_device_ops const bnad_netdev_ops =
     {0, 0, & bnad_open, & bnad_stop, & bnad_start_xmit, 0, 0, & bnad_set_rx_mode, & bnad_set_mac_address,
    & eth_validate_addr, 0, 0, & bnad_change_mtu, 0, 0, & bnad_get_stats64, 0, & bnad_vlan_rx_add_vid,
    & bnad_vlan_rx_kill_vid, & bnad_netpoll, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, & bnad_set_features, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static void bnad_netdev_init(struct bnad *bnad , bool using_dac )
{
  struct net_device *netdev ;
  {
  netdev = bnad->netdev;
  netdev->hw_features = 17180983699ULL;
  netdev->vlan_features = 1114163ULL;
  netdev->features = (netdev->features | netdev->hw_features) | 512ULL;
  if ((int )using_dac) {
    netdev->features = netdev->features | 32ULL;
  } else {
  }
  netdev->mem_start = (unsigned long )bnad->mmio_start;
  netdev->mem_end = (unsigned long )((bnad->mmio_start + bnad->mmio_len) - 1ULL);
  netdev->netdev_ops = & bnad_netdev_ops;
  bnad_set_ethtool_ops(netdev);
  return;
}
}
static int bnad_init(struct bnad *bnad , struct pci_dev *pdev , struct net_device *netdev )
{
  unsigned long flags ;
  struct lock_class_key __key ;
  char const *__lock_name ;
  struct workqueue_struct *tmp ;
  {
  netdev->dev.parent = & pdev->dev;
  pci_set_drvdata(pdev, (void *)netdev);
  bnad->netdev = netdev;
  bnad->pcidev = pdev;
  bnad->mmio_start = pdev->resource[0].start;
  bnad->mmio_len = pdev->resource[0].start != 0ULL || pdev->resource[0].end != pdev->resource[0].start ? (pdev->resource[0].end - pdev->resource[0].start) + 1ULL : 0ULL;
  bnad->bar0 = ioremap_nocache(bnad->mmio_start, (unsigned long )bnad->mmio_len);
  if ((unsigned long )bnad->bar0 == (unsigned long )((void *)0)) {
    dev_err((struct device const *)(& pdev->dev), "ioremap for bar0 failed\n");
    return (-12);
  } else {
  }
  _dev_info((struct device const *)(& pdev->dev), "bar0 mapped to %p, len %llu\n",
            bnad->bar0, bnad->mmio_len);
  ldv_spin_lock();
  if (bnad_msix_disable == 0U) {
    bnad->cfg_flags = 16U;
  } else {
  }
  bnad->cfg_flags = bnad->cfg_flags | 1U;
  bnad_q_num_init(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad->msix_num = (bnad->num_tx * bnad->num_txq_per_tx + bnad->num_rx * bnad->num_rxp_per_rx) + 1U;
  bnad->txq_depth = 2048U;
  bnad->rxq_depth = 2048U;
  bnad->tx_coalescing_timeo = 20U;
  bnad->rx_coalescing_timeo = 12U;
  sprintf((char *)(& bnad->wq_name), "%s_wq_%d", (char *)"bna", bnad->id);
  __lock_name = "\"%s\"bnad->wq_name";
  tmp = __alloc_workqueue_key("%s", 131082U, 1, & __key, __lock_name, (char *)(& bnad->wq_name));
  bnad->work_q = tmp;
  if ((unsigned long )bnad->work_q == (unsigned long )((struct workqueue_struct *)0)) {
    iounmap((void volatile *)bnad->bar0);
    return (-12);
  } else {
  }
  return (0);
}
}
static void bnad_uninit(struct bnad *bnad )
{
  {
  if ((unsigned long )bnad->work_q != (unsigned long )((struct workqueue_struct *)0)) {
    ldv_flush_workqueue_55(bnad->work_q);
    ldv_destroy_workqueue_56(bnad->work_q);
    bnad->work_q = (struct workqueue_struct *)0;
  } else {
  }
  if ((unsigned long )bnad->bar0 != (unsigned long )((void *)0)) {
    iounmap((void volatile *)bnad->bar0);
  } else {
  }
  return;
}
}
static void bnad_lock_init(struct bnad *bnad )
{
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;
  {
  spinlock_check(& bnad->bna_lock);
  __raw_spin_lock_init(& bnad->bna_lock.__annonCompField18.rlock, "&(&bnad->bna_lock)->rlock",
                       & __key);
  __mutex_init(& bnad->conf_mutex, "&bnad->conf_mutex", & __key___0);
  __mutex_init(& bnad_list_mutex, "&bnad_list_mutex", & __key___1);
  return;
}
}
static void bnad_lock_uninit(struct bnad *bnad )
{
  {
  mutex_destroy(& bnad->conf_mutex);
  mutex_destroy(& bnad_list_mutex);
  return;
}
}
static int bnad_pci_init(struct bnad *bnad , struct pci_dev *pdev , bool *using_dac )
{
  int err ;
  int tmp ;
  {
  err = pci_enable_device(pdev);
  if (err != 0) {
    return (err);
  } else {
  }
  err = pci_request_regions(pdev, "bna");
  if (err != 0) {
    goto disable_device;
  } else {
  }
  tmp = dma_set_mask_and_coherent(& pdev->dev, 0xffffffffffffffffULL);
  if (tmp == 0) {
    *using_dac = 1;
  } else {
    err = dma_set_mask_and_coherent(& pdev->dev, 4294967295ULL);
    if (err != 0) {
      goto release_regions;
    } else {
    }
    *using_dac = 0;
  }
  pci_set_master(pdev);
  return (0);
  release_regions:
  pci_release_regions(pdev);
  disable_device:
  pci_disable_device(pdev);
  return (err);
}
}
static void bnad_pci_uninit(struct pci_dev *pdev )
{
  {
  pci_release_regions(pdev);
  pci_disable_device(pdev);
  return;
}
}
static int bnad_pci_probe(struct pci_dev *pdev , struct pci_device_id const *pcidev_id )
{
  bool using_dac ;
  int err ;
  struct bnad *bnad ;
  struct bna *bna ;
  struct net_device *netdev ;
  struct bfa_pcidev pcidev_info ;
  unsigned long flags ;
  u32 *tmp ;
  void *tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  {
  mutex_lock_nested(& bnad_fwimg_mutex, 0U);
  tmp = cna_get_firmware_buf(pdev);
  if ((unsigned long )tmp == (unsigned long )((u32 *)0U)) {
    mutex_unlock(& bnad_fwimg_mutex);
    dev_err((struct device const *)(& pdev->dev), "failed to load firmware image!\n");
    return (-19);
  } else {
  }
  mutex_unlock(& bnad_fwimg_mutex);
  netdev = alloc_etherdev_mqs(21248, 1U, 1U);
  if ((unsigned long )netdev == (unsigned long )((struct net_device *)0)) {
    err = -12;
    return (err);
  } else {
  }
  tmp___0 = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp___0;
  bnad_lock_init(bnad);
  bnad_add_to_list(bnad);
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  using_dac = 0;
  err = bnad_pci_init(bnad, pdev, & using_dac);
  if (err != 0) {
    goto unlock_mutex;
  } else {
  }
  err = bnad_init(bnad, pdev, netdev);
  if (err != 0) {
    goto pci_uninit;
  } else {
  }
  bnad_netdev_init(bnad, (int )using_dac);
  netif_carrier_off(netdev);
  if (bna_debugfs_enable != 0U) {
    bnad_debugfs_init(bnad);
  } else {
  }
  ldv_spin_lock();
  bna_res_req((struct bna_res_info *)(& bnad->res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  err = bnad_res_alloc(bnad, (struct bna_res_info *)(& bnad->res_info), 4U);
  if (err != 0) {
    goto drv_uninit;
  } else {
  }
  bna = & bnad->bna;
  pcidev_info.pci_slot = (int )((bnad->pcidev)->devfn >> 3) & 31;
  pcidev_info.pci_func = (unsigned int )((u8 )(bnad->pcidev)->devfn) & 7U;
  pcidev_info.device_id = (bnad->pcidev)->device;
  pcidev_info.pci_bar_kva = bnad->bar0;
  ldv_spin_lock();
  bna_init(bna, bnad, & pcidev_info, (struct bna_res_info *)(& bnad->res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad->stats.bna_stats = & bna->stats;
  bnad_enable_msix(bnad);
  err = bnad_mbox_irq_alloc(bnad);
  if (err != 0) {
    goto res_free;
  } else {
  }
  reg_timer_7(& bnad->bna.ioceth.ioc.ioc_timer, & bnad_ioc_timeout, (unsigned long )bnad);
  reg_timer_7(& bnad->bna.ioceth.ioc.hb_timer, & bnad_ioc_hb_check, (unsigned long )bnad);
  reg_timer_7(& bnad->bna.ioceth.ioc.iocpf_timer, & bnad_iocpf_timeout, (unsigned long )bnad);
  reg_timer_7(& bnad->bna.ioceth.ioc.sem_timer, & bnad_iocpf_sem_timeout, (unsigned long )bnad);
  err = bnad_ioceth_enable(bnad);
  if (err != 0) {
    dev_err((struct device const *)(& pdev->dev), "initialization failed err=%d\n",
            err);
    goto probe_success;
  } else {
  }
  ldv_spin_lock();
  tmp___3 = bna_num_txq_set(bna, (int )(bnad->num_tx * bnad->num_txq_per_tx + 1U));
  if (tmp___3 != 0) {
    goto _L;
  } else {
    tmp___4 = bna_num_rxp_set(bna, (int )(bnad->num_rx * bnad->num_rxp_per_rx + 1U));
    if (tmp___4 != 0) {
      _L:
      bnad_q_num_adjust(bnad, bna->ioceth.attr.num_txq + -1, bna->ioceth.attr.num_rxp + -1);
      tmp___1 = bna_num_txq_set(bna, (int )(bnad->num_tx * bnad->num_txq_per_tx + 1U));
      if (tmp___1 != 0) {
        err = -5;
      } else {
        tmp___2 = bna_num_rxp_set(bna, (int )(bnad->num_rx * bnad->num_rxp_per_rx + 1U));
        if (tmp___2 != 0) {
          err = -5;
        } else {
        }
      }
    } else {
    }
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (err != 0) {
    goto disable_ioceth;
  } else {
  }
  ldv_spin_lock();
  bna_mod_res_req(& bnad->bna, (struct bna_res_info *)(& bnad->mod_res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  err = bnad_res_alloc(bnad, (struct bna_res_info *)(& bnad->mod_res_info), 8U);
  if (err != 0) {
    err = -5;
    goto disable_ioceth;
  } else {
  }
  ldv_spin_lock();
  bna_mod_init(& bnad->bna, (struct bna_res_info *)(& bnad->mod_res_info));
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  ldv_spin_lock();
  bna_enet_perm_mac_get(& bna->enet, (u8 *)(& bnad->perm_addr));
  bnad_set_netdev_perm_addr(bnad);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  err = ldv_register_netdev_57(netdev);
  if (err != 0) {
    dev_err((struct device const *)(& pdev->dev), "registering net device failed\n");
    goto probe_uninit;
  } else {
  }
  set_bit(3L, (unsigned long volatile *)(& bnad->run_flags));
  return (0);
  probe_success:
  mutex_unlock(& bnad->conf_mutex);
  return (0);
  probe_uninit:
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->mod_res_info), 8U);
  disable_ioceth:
  bnad_ioceth_disable(bnad);
  ldv_del_timer_sync_58(& bnad->bna.ioceth.ioc.ioc_timer);
  ldv_del_timer_sync_59(& bnad->bna.ioceth.ioc.sem_timer);
  ldv_del_timer_sync_60(& bnad->bna.ioceth.ioc.hb_timer);
  ldv_spin_lock();
  bna_uninit(bna);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_mbox_irq_free(bnad);
  bnad_disable_msix(bnad);
  res_free:
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->res_info), 4U);
  drv_uninit:
  kfree((void const *)bnad->regdata);
  bnad_debugfs_uninit(bnad);
  bnad_uninit(bnad);
  pci_uninit:
  bnad_pci_uninit(pdev);
  unlock_mutex:
  mutex_unlock(& bnad->conf_mutex);
  bnad_remove_from_list(bnad);
  bnad_lock_uninit(bnad);
  ldv_free_netdev_61(netdev);
  return (err);
}
}
static void bnad_pci_remove(struct pci_dev *pdev )
{
  struct net_device *netdev ;
  void *tmp ;
  struct bnad *bnad ;
  struct bna *bna ;
  unsigned long flags ;
  void *tmp___0 ;
  int tmp___1 ;
  {
  tmp = pci_get_drvdata(pdev);
  netdev = (struct net_device *)tmp;
  if ((unsigned long )netdev == (unsigned long )((struct net_device *)0)) {
    return;
  } else {
  }
  tmp___0 = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp___0;
  bna = & bnad->bna;
  tmp___1 = test_and_clear_bit(3L, (unsigned long volatile *)(& bnad->run_flags));
  if (tmp___1 != 0) {
    ldv_unregister_netdev_62(netdev);
  } else {
  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  bnad_ioceth_disable(bnad);
  ldv_del_timer_sync_63(& bnad->bna.ioceth.ioc.ioc_timer);
  ldv_del_timer_sync_64(& bnad->bna.ioceth.ioc.sem_timer);
  ldv_del_timer_sync_65(& bnad->bna.ioceth.ioc.hb_timer);
  ldv_spin_lock();
  bna_uninit(bna);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->mod_res_info), 8U);
  bnad_res_free(bnad, (struct bna_res_info *)(& bnad->res_info), 4U);
  bnad_mbox_irq_free(bnad);
  bnad_disable_msix(bnad);
  bnad_pci_uninit(pdev);
  mutex_unlock(& bnad->conf_mutex);
  bnad_remove_from_list(bnad);
  bnad_lock_uninit(bnad);
  kfree((void const *)bnad->regdata);
  bnad_debugfs_uninit(bnad);
  bnad_uninit(bnad);
  ldv_free_netdev_66(netdev);
  return;
}
}
static struct pci_device_id const bnad_pci_id_table[3U] = { {5719U, 20U, 4294967295U, 4294967295U, 131072U, 16776960U, 0UL},
        {5719U, 34U, 4294967295U, 4294967295U, 131072U, 16776960U, 0UL},
        {0U, 0U, 0U, 0U, 0U, 0U, 0UL}};
struct pci_device_id const __mod_pci__bnad_pci_id_table_device_table[3U] ;
static struct pci_driver bnad_pci_driver =
     {{0, 0}, "bna", (struct pci_device_id const *)(& bnad_pci_id_table), & bnad_pci_probe,
    & bnad_pci_remove, 0, 0, 0, 0, 0, 0, 0, {0, 0, 0, 0, (_Bool)0, 0, 0, 0, 0, 0,
                                             0, 0, 0, 0, 0, 0}, {{{{{{0}}, 0U, 0U,
                                                                    0, {0, {0, 0},
                                                                        0, 0, 0UL}}}},
                                                                 {0, 0}}};
static int bnad_module_init(void)
{
  int err ;
  {
  printk("\016bna: QLogic BR-series 10G Ethernet driver - version: %s\n", (char *)"3.2.25.1");
  bfa_nw_ioc_auto_recover(bnad_ioc_auto_recover != 0U);
  err = ldv___pci_register_driver_67(& bnad_pci_driver, & __this_module, "bna");
  if (err < 0) {
    printk("\vbna: PCI driver registration failed err=%d\n", err);
    return (err);
  } else {
  }
  return (0);
}
}
static void bnad_module_exit(void)
{
  {
  ldv_pci_unregister_driver_68(& bnad_pci_driver);
  release_firmware(bfi_fw);
  return;
}
}
extern int ldv_shutdown_20(void) ;
int ldv_retval_0 ;
int ldv_retval_4 ;
int ldv_retval_6 ;
extern int ldv_ndo_init_21(void) ;
extern void ldv_initialize(void) ;
int ldv_retval_1 ;
extern void ldv_check_final_state(void) ;
extern int ldv_ndo_uninit_21(void) ;
void work_init_3(void)
{
  {
  ldv_work_3_0 = 0;
  ldv_work_3_1 = 0;
  ldv_work_3_2 = 0;
  ldv_work_3_3 = 0;
  return;
}
}
void activate_suitable_timer_6(struct timer_list *timer , unsigned long data )
{
  {
  if (ldv_timer_6_0 == 0 || ldv_timer_6_0 == 2) {
    ldv_timer_list_6_0 = timer;
    ldv_timer_list_6_0->data = data;
    ldv_timer_6_0 = 1;
    return;
  } else {
  }
  if (ldv_timer_6_1 == 0 || ldv_timer_6_1 == 2) {
    ldv_timer_list_6_1 = timer;
    ldv_timer_list_6_1->data = data;
    ldv_timer_6_1 = 1;
    return;
  } else {
  }
  if (ldv_timer_6_2 == 0 || ldv_timer_6_2 == 2) {
    ldv_timer_list_6_2 = timer;
    ldv_timer_list_6_2->data = data;
    ldv_timer_6_2 = 1;
    return;
  } else {
  }
  if (ldv_timer_6_3 == 0 || ldv_timer_6_3 == 2) {
    ldv_timer_list_6_3 = timer;
    ldv_timer_list_6_3->data = data;
    ldv_timer_6_3 = 1;
    return;
  } else {
  }
  return;
}
}
void disable_suitable_irq_2(int line , void *data )
{
  {
  if (ldv_irq_2_0 != 0 && line == ldv_irq_line_2_0) {
    ldv_irq_2_0 = 0;
    return;
  } else {
  }
  if (ldv_irq_2_1 != 0 && line == ldv_irq_line_2_1) {
    ldv_irq_2_1 = 0;
    return;
  } else {
  }
  if (ldv_irq_2_2 != 0 && line == ldv_irq_line_2_2) {
    ldv_irq_2_2 = 0;
    return;
  } else {
  }
  if (ldv_irq_2_3 != 0 && line == ldv_irq_line_2_3) {
    ldv_irq_2_3 = 0;
    return;
  } else {
  }
  return;
}
}
int reg_timer_7(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data )
{
  {
  if ((unsigned long )function == (unsigned long )(& bnad_ioc_timeout)) {
    activate_suitable_timer_7(timer, data);
  } else {
  }
  return (0);
}
}
void ldv_timer_5(int state , struct timer_list *timer )
{
  {
  LDV_IN_INTERRUPT = 2;
  bnad_dim_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void choose_timer_5(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_5_0 == 1) {
    ldv_timer_5_0 = 2;
    ldv_timer_5(ldv_timer_5_0, ldv_timer_list_5_0);
  } else {
  }
  goto ldv_59580;
  case 1: ;
  if (ldv_timer_5_1 == 1) {
    ldv_timer_5_1 = 2;
    ldv_timer_5(ldv_timer_5_1, ldv_timer_list_5_1);
  } else {
  }
  goto ldv_59580;
  case 2: ;
  if (ldv_timer_5_2 == 1) {
    ldv_timer_5_2 = 2;
    ldv_timer_5(ldv_timer_5_2, ldv_timer_list_5_2);
  } else {
  }
  goto ldv_59580;
  case 3: ;
  if (ldv_timer_5_3 == 1) {
    ldv_timer_5_3 = 2;
    ldv_timer_5(ldv_timer_5_3, ldv_timer_list_5_3);
  } else {
  }
  goto ldv_59580;
  default:
  ldv_stop();
  }
  ldv_59580: ;
  return;
}
}
void activate_pending_timer_9(struct timer_list *timer , unsigned long data , int pending_flag )
{
  {
  if ((unsigned long )ldv_timer_list_9_0 == (unsigned long )timer) {
    if (ldv_timer_9_0 == 2 || pending_flag != 0) {
      ldv_timer_list_9_0 = timer;
      ldv_timer_list_9_0->data = data;
      ldv_timer_9_0 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_9_1 == (unsigned long )timer) {
    if (ldv_timer_9_1 == 2 || pending_flag != 0) {
      ldv_timer_list_9_1 = timer;
      ldv_timer_list_9_1->data = data;
      ldv_timer_9_1 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_9_2 == (unsigned long )timer) {
    if (ldv_timer_9_2 == 2 || pending_flag != 0) {
      ldv_timer_list_9_2 = timer;
      ldv_timer_list_9_2->data = data;
      ldv_timer_9_2 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_9_3 == (unsigned long )timer) {
    if (ldv_timer_9_3 == 2 || pending_flag != 0) {
      ldv_timer_list_9_3 = timer;
      ldv_timer_list_9_3->data = data;
      ldv_timer_9_3 = 1;
    } else {
    }
    return;
  } else {
  }
  activate_suitable_timer_9(timer, data);
  return;
}
}
int reg_check_1(irqreturn_t (*handler)(int , void * ) )
{
  {
  if ((unsigned long )handler == (unsigned long )(& bnad_msix_tx)) {
    return (1);
  } else {
  }
  return (0);
}
}
void disable_suitable_timer_8(struct timer_list *timer )
{
  {
  if (ldv_timer_8_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_0) {
    ldv_timer_8_0 = 0;
    return;
  } else {
  }
  if (ldv_timer_8_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_1) {
    ldv_timer_8_1 = 0;
    return;
  } else {
  }
  if (ldv_timer_8_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_2) {
    ldv_timer_8_2 = 0;
    return;
  } else {
  }
  if (ldv_timer_8_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_8_3) {
    ldv_timer_8_3 = 0;
    return;
  } else {
  }
  return;
}
}
void activate_work_3(struct work_struct *work , int state )
{
  {
  if (ldv_work_3_0 == 0) {
    ldv_work_struct_3_0 = work;
    ldv_work_3_0 = state;
    return;
  } else {
  }
  if (ldv_work_3_1 == 0) {
    ldv_work_struct_3_1 = work;
    ldv_work_3_1 = state;
    return;
  } else {
  }
  if (ldv_work_3_2 == 0) {
    ldv_work_struct_3_2 = work;
    ldv_work_3_2 = state;
    return;
  } else {
  }
  if (ldv_work_3_3 == 0) {
    ldv_work_struct_3_3 = work;
    ldv_work_3_3 = state;
    return;
  } else {
  }
  return;
}
}
void activate_pending_timer_10(struct timer_list *timer , unsigned long data , int pending_flag )
{
  {
  if ((unsigned long )ldv_timer_list_10_0 == (unsigned long )timer) {
    if (ldv_timer_10_0 == 2 || pending_flag != 0) {
      ldv_timer_list_10_0 = timer;
      ldv_timer_list_10_0->data = data;
      ldv_timer_10_0 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_10_1 == (unsigned long )timer) {
    if (ldv_timer_10_1 == 2 || pending_flag != 0) {
      ldv_timer_list_10_1 = timer;
      ldv_timer_list_10_1->data = data;
      ldv_timer_10_1 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_10_2 == (unsigned long )timer) {
    if (ldv_timer_10_2 == 2 || pending_flag != 0) {
      ldv_timer_list_10_2 = timer;
      ldv_timer_list_10_2->data = data;
      ldv_timer_10_2 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_10_3 == (unsigned long )timer) {
    if (ldv_timer_10_3 == 2 || pending_flag != 0) {
      ldv_timer_list_10_3 = timer;
      ldv_timer_list_10_3->data = data;
      ldv_timer_10_3 = 1;
    } else {
    }
    return;
  } else {
  }
  activate_suitable_timer_10(timer, data);
  return;
}
}
void call_and_disable_all_4(int state )
{
  {
  if (ldv_work_4_0 == state) {
    call_and_disable_work_4(ldv_work_struct_4_0);
  } else {
  }
  if (ldv_work_4_1 == state) {
    call_and_disable_work_4(ldv_work_struct_4_1);
  } else {
  }
  if (ldv_work_4_2 == state) {
    call_and_disable_work_4(ldv_work_struct_4_2);
  } else {
  }
  if (ldv_work_4_3 == state) {
    call_and_disable_work_4(ldv_work_struct_4_3);
  } else {
  }
  return;
}
}
int reg_timer_10(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data )
{
  {
  if ((unsigned long )function == (unsigned long )(& bnad_iocpf_sem_timeout)) {
    activate_suitable_timer_10(timer, data);
  } else {
  }
  return (0);
}
}
void call_and_disable_work_3(struct work_struct *work )
{
  {
  if ((ldv_work_3_0 == 2 || ldv_work_3_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_0) {
    ldv__builtin_trap();
    ldv_work_3_0 = 1;
    return;
  } else {
  }
  if ((ldv_work_3_1 == 2 || ldv_work_3_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_1) {
    ldv__builtin_trap();
    ldv_work_3_1 = 1;
    return;
  } else {
  }
  if ((ldv_work_3_2 == 2 || ldv_work_3_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_2) {
    ldv__builtin_trap();
    ldv_work_3_2 = 1;
    return;
  } else {
  }
  if ((ldv_work_3_3 == 2 || ldv_work_3_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_3) {
    ldv__builtin_trap();
    ldv_work_3_3 = 1;
    return;
  } else {
  }
  return;
}
}
void timer_init_6(void)
{
  {
  ldv_timer_6_0 = 0;
  ldv_timer_6_1 = 0;
  ldv_timer_6_2 = 0;
  ldv_timer_6_3 = 0;
  return;
}
}
void disable_work_3(struct work_struct *work )
{
  {
  if ((ldv_work_3_0 == 3 || ldv_work_3_0 == 2) && (unsigned long )ldv_work_struct_3_0 == (unsigned long )work) {
    ldv_work_3_0 = 1;
  } else {
  }
  if ((ldv_work_3_1 == 3 || ldv_work_3_1 == 2) && (unsigned long )ldv_work_struct_3_1 == (unsigned long )work) {
    ldv_work_3_1 = 1;
  } else {
  }
  if ((ldv_work_3_2 == 3 || ldv_work_3_2 == 2) && (unsigned long )ldv_work_struct_3_2 == (unsigned long )work) {
    ldv_work_3_2 = 1;
  } else {
  }
  if ((ldv_work_3_3 == 3 || ldv_work_3_3 == 2) && (unsigned long )ldv_work_struct_3_3 == (unsigned long )work) {
    ldv_work_3_3 = 1;
  } else {
  }
  return;
}
}
void ldv_timer_9(int state , struct timer_list *timer )
{
  {
  LDV_IN_INTERRUPT = 2;
  bnad_iocpf_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void activate_pending_timer_8(struct timer_list *timer , unsigned long data , int pending_flag )
{
  {
  if ((unsigned long )ldv_timer_list_8_0 == (unsigned long )timer) {
    if (ldv_timer_8_0 == 2 || pending_flag != 0) {
      ldv_timer_list_8_0 = timer;
      ldv_timer_list_8_0->data = data;
      ldv_timer_8_0 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_8_1 == (unsigned long )timer) {
    if (ldv_timer_8_1 == 2 || pending_flag != 0) {
      ldv_timer_list_8_1 = timer;
      ldv_timer_list_8_1->data = data;
      ldv_timer_8_1 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_8_2 == (unsigned long )timer) {
    if (ldv_timer_8_2 == 2 || pending_flag != 0) {
      ldv_timer_list_8_2 = timer;
      ldv_timer_list_8_2->data = data;
      ldv_timer_8_2 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_8_3 == (unsigned long )timer) {
    if (ldv_timer_8_3 == 2 || pending_flag != 0) {
      ldv_timer_list_8_3 = timer;
      ldv_timer_list_8_3->data = data;
      ldv_timer_8_3 = 1;
    } else {
    }
    return;
  } else {
  }
  activate_suitable_timer_8(timer, data);
  return;
}
}
void ldv_timer_7(int state , struct timer_list *timer )
{
  {
  LDV_IN_INTERRUPT = 2;
  bnad_ioc_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void timer_init_5(void)
{
  {
  ldv_timer_5_0 = 0;
  ldv_timer_5_1 = 0;
  ldv_timer_5_2 = 0;
  ldv_timer_5_3 = 0;
  return;
}
}
void disable_suitable_irq_1(int line , void *data )
{
  {
  if (ldv_irq_1_0 != 0 && line == ldv_irq_line_1_0) {
    ldv_irq_1_0 = 0;
    return;
  } else {
  }
  if (ldv_irq_1_1 != 0 && line == ldv_irq_line_1_1) {
    ldv_irq_1_1 = 0;
    return;
  } else {
  }
  if (ldv_irq_1_2 != 0 && line == ldv_irq_line_1_2) {
    ldv_irq_1_2 = 0;
    return;
  } else {
  }
  if (ldv_irq_1_3 != 0 && line == ldv_irq_line_1_3) {
    ldv_irq_1_3 = 0;
    return;
  } else {
  }
  return;
}
}
void activate_suitable_irq_1(int line , void *data )
{
  {
  if (ldv_irq_1_0 == 0) {
    ldv_irq_line_1_0 = line;
    ldv_irq_data_1_0 = data;
    ldv_irq_1_0 = 1;
    return;
  } else {
  }
  if (ldv_irq_1_1 == 0) {
    ldv_irq_line_1_1 = line;
    ldv_irq_data_1_1 = data;
    ldv_irq_1_1 = 1;
    return;
  } else {
  }
  if (ldv_irq_1_2 == 0) {
    ldv_irq_line_1_2 = line;
    ldv_irq_data_1_2 = data;
    ldv_irq_1_2 = 1;
    return;
  } else {
  }
  if (ldv_irq_1_3 == 0) {
    ldv_irq_line_1_3 = line;
    ldv_irq_data_1_3 = data;
    ldv_irq_1_3 = 1;
    return;
  } else {
  }
  return;
}
}
void invoke_work_4(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_4_0 == 2 || ldv_work_4_0 == 3) {
    ldv_work_4_0 = 4;
    ldv__builtin_trap();
    ldv_work_4_0 = 1;
  } else {
  }
  goto ldv_59657;
  case 1: ;
  if (ldv_work_4_1 == 2 || ldv_work_4_1 == 3) {
    ldv_work_4_1 = 4;
    ldv__builtin_trap();
    ldv_work_4_1 = 1;
  } else {
  }
  goto ldv_59657;
  case 2: ;
  if (ldv_work_4_2 == 2 || ldv_work_4_2 == 3) {
    ldv_work_4_2 = 4;
    ldv__builtin_trap();
    ldv_work_4_2 = 1;
  } else {
  }
  goto ldv_59657;
  case 3: ;
  if (ldv_work_4_3 == 2 || ldv_work_4_3 == 3) {
    ldv_work_4_3 = 4;
    ldv__builtin_trap();
    ldv_work_4_3 = 1;
  } else {
  }
  goto ldv_59657;
  default:
  ldv_stop();
  }
  ldv_59657: ;
  return;
}
}
void timer_init_9(void)
{
  {
  ldv_timer_9_0 = 0;
  ldv_timer_9_1 = 0;
  ldv_timer_9_2 = 0;
  ldv_timer_9_3 = 0;
  return;
}
}
void ldv_pci_driver_20(void)
{
  void *tmp ;
  {
  tmp = ldv_init_zalloc(2976UL);
  bnad_pci_driver_group1 = (struct pci_dev *)tmp;
  return;
}
}
void disable_suitable_timer_6(struct timer_list *timer )
{
  {
  if (ldv_timer_6_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_0) {
    ldv_timer_6_0 = 0;
    return;
  } else {
  }
  if (ldv_timer_6_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_1) {
    ldv_timer_6_1 = 0;
    return;
  } else {
  }
  if (ldv_timer_6_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_2) {
    ldv_timer_6_2 = 0;
    return;
  } else {
  }
  if (ldv_timer_6_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_6_3) {
    ldv_timer_6_3 = 0;
    return;
  } else {
  }
  return;
}
}
void disable_suitable_timer_5(struct timer_list *timer )
{
  {
  if (ldv_timer_5_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_0) {
    ldv_timer_5_0 = 0;
    return;
  } else {
  }
  if (ldv_timer_5_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_1) {
    ldv_timer_5_1 = 0;
    return;
  } else {
  }
  if (ldv_timer_5_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_2) {
    ldv_timer_5_2 = 0;
    return;
  } else {
  }
  if (ldv_timer_5_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_5_3) {
    ldv_timer_5_3 = 0;
    return;
  } else {
  }
  return;
}
}
void ldv_timer_10(int state , struct timer_list *timer )
{
  {
  LDV_IN_INTERRUPT = 2;
  bnad_iocpf_sem_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
int ldv_irq_2(int state , int line , void *data )
{
  irqreturn_t irq_retval ;
  int tmp ;
  int tmp___0 ;
  {
  tmp = __VERIFIER_nondet_int();
  irq_retval = (irqreturn_t )tmp;
  if (state != 0) {
    tmp___0 = __VERIFIER_nondet_int();
    switch (tmp___0) {
    case 0: ;
    if (state == 1) {
      LDV_IN_INTERRUPT = 2;
      irq_retval = bnad_msix_rx(line, data);
      LDV_IN_INTERRUPT = 1;
      return (state);
    } else {
    }
    goto ldv_59685;
    default:
    ldv_stop();
    }
    ldv_59685: ;
  } else {
  }
  return (state);
}
}
void ldv_net_device_ops_21(void)
{
  void *tmp ;
  {
  tmp = ldv_init_zalloc(3008UL);
  bnad_netdev_ops_group1 = (struct net_device *)tmp;
  return;
}
}
void activate_pending_timer_6(struct timer_list *timer , unsigned long data , int pending_flag )
{
  {
  if ((unsigned long )ldv_timer_list_6_0 == (unsigned long )timer) {
    if (ldv_timer_6_0 == 2 || pending_flag != 0) {
      ldv_timer_list_6_0 = timer;
      ldv_timer_list_6_0->data = data;
      ldv_timer_6_0 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_6_1 == (unsigned long )timer) {
    if (ldv_timer_6_1 == 2 || pending_flag != 0) {
      ldv_timer_list_6_1 = timer;
      ldv_timer_list_6_1->data = data;
      ldv_timer_6_1 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_6_2 == (unsigned long )timer) {
    if (ldv_timer_6_2 == 2 || pending_flag != 0) {
      ldv_timer_list_6_2 = timer;
      ldv_timer_list_6_2->data = data;
      ldv_timer_6_2 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_6_3 == (unsigned long )timer) {
    if (ldv_timer_6_3 == 2 || pending_flag != 0) {
      ldv_timer_list_6_3 = timer;
      ldv_timer_list_6_3->data = data;
      ldv_timer_6_3 = 1;
    } else {
    }
    return;
  } else {
  }
  activate_suitable_timer_6(timer, data);
  return;
}
}
void activate_suitable_timer_9(struct timer_list *timer , unsigned long data )
{
  {
  if (ldv_timer_9_0 == 0 || ldv_timer_9_0 == 2) {
    ldv_timer_list_9_0 = timer;
    ldv_timer_list_9_0->data = data;
    ldv_timer_9_0 = 1;
    return;
  } else {
  }
  if (ldv_timer_9_1 == 0 || ldv_timer_9_1 == 2) {
    ldv_timer_list_9_1 = timer;
    ldv_timer_list_9_1->data = data;
    ldv_timer_9_1 = 1;
    return;
  } else {
  }
  if (ldv_timer_9_2 == 0 || ldv_timer_9_2 == 2) {
    ldv_timer_list_9_2 = timer;
    ldv_timer_list_9_2->data = data;
    ldv_timer_9_2 = 1;
    return;
  } else {
  }
  if (ldv_timer_9_3 == 0 || ldv_timer_9_3 == 2) {
    ldv_timer_list_9_3 = timer;
    ldv_timer_list_9_3->data = data;
    ldv_timer_9_3 = 1;
    return;
  } else {
  }
  return;
}
}
void choose_interrupt_2(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0:
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_0, ldv_irq_line_2_0, ldv_irq_data_2_0);
  goto ldv_59703;
  case 1:
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_1, ldv_irq_line_2_1, ldv_irq_data_2_1);
  goto ldv_59703;
  case 2:
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_2, ldv_irq_line_2_2, ldv_irq_data_2_2);
  goto ldv_59703;
  case 3:
  ldv_irq_2_0 = ldv_irq_2(ldv_irq_2_3, ldv_irq_line_2_3, ldv_irq_data_2_3);
  goto ldv_59703;
  default:
  ldv_stop();
  }
  ldv_59703: ;
  return;
}
}
void disable_suitable_timer_10(struct timer_list *timer )
{
  {
  if (ldv_timer_10_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_0) {
    ldv_timer_10_0 = 0;
    return;
  } else {
  }
  if (ldv_timer_10_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_1) {
    ldv_timer_10_1 = 0;
    return;
  } else {
  }
  if (ldv_timer_10_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_2) {
    ldv_timer_10_2 = 0;
    return;
  } else {
  }
  if (ldv_timer_10_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_10_3) {
    ldv_timer_10_3 = 0;
    return;
  } else {
  }
  return;
}
}
void activate_work_4(struct work_struct *work , int state )
{
  {
  if (ldv_work_4_0 == 0) {
    ldv_work_struct_4_0 = work;
    ldv_work_4_0 = state;
    return;
  } else {
  }
  if (ldv_work_4_1 == 0) {
    ldv_work_struct_4_1 = work;
    ldv_work_4_1 = state;
    return;
  } else {
  }
  if (ldv_work_4_2 == 0) {
    ldv_work_struct_4_2 = work;
    ldv_work_4_2 = state;
    return;
  } else {
  }
  if (ldv_work_4_3 == 0) {
    ldv_work_struct_4_3 = work;
    ldv_work_4_3 = state;
    return;
  } else {
  }
  return;
}
}
void choose_timer_8(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_8_0 == 1) {
    ldv_timer_8_0 = 2;
    ldv_timer_8(ldv_timer_8_0, ldv_timer_list_8_0);
  } else {
  }
  goto ldv_59719;
  case 1: ;
  if (ldv_timer_8_1 == 1) {
    ldv_timer_8_1 = 2;
    ldv_timer_8(ldv_timer_8_1, ldv_timer_list_8_1);
  } else {
  }
  goto ldv_59719;
  case 2: ;
  if (ldv_timer_8_2 == 1) {
    ldv_timer_8_2 = 2;
    ldv_timer_8(ldv_timer_8_2, ldv_timer_list_8_2);
  } else {
  }
  goto ldv_59719;
  case 3: ;
  if (ldv_timer_8_3 == 1) {
    ldv_timer_8_3 = 2;
    ldv_timer_8(ldv_timer_8_3, ldv_timer_list_8_3);
  } else {
  }
  goto ldv_59719;
  default:
  ldv_stop();
  }
  ldv_59719: ;
  return;
}
}
void disable_suitable_timer_7(struct timer_list *timer )
{
  {
  if (ldv_timer_7_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_0) {
    ldv_timer_7_0 = 0;
    return;
  } else {
  }
  if (ldv_timer_7_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_1) {
    ldv_timer_7_1 = 0;
    return;
  } else {
  }
  if (ldv_timer_7_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_2) {
    ldv_timer_7_2 = 0;
    return;
  } else {
  }
  if (ldv_timer_7_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_7_3) {
    ldv_timer_7_3 = 0;
    return;
  } else {
  }
  return;
}
}
int reg_timer_9(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data )
{
  {
  if ((unsigned long )function == (unsigned long )(& bnad_iocpf_timeout)) {
    activate_suitable_timer_9(timer, data);
  } else {
  }
  return (0);
}
}
void activate_suitable_irq_2(int line , void *data )
{
  {
  if (ldv_irq_2_0 == 0) {
    ldv_irq_line_2_0 = line;
    ldv_irq_data_2_0 = data;
    ldv_irq_2_0 = 1;
    return;
  } else {
  }
  if (ldv_irq_2_1 == 0) {
    ldv_irq_line_2_1 = line;
    ldv_irq_data_2_1 = data;
    ldv_irq_2_1 = 1;
    return;
  } else {
  }
  if (ldv_irq_2_2 == 0) {
    ldv_irq_line_2_2 = line;
    ldv_irq_data_2_2 = data;
    ldv_irq_2_2 = 1;
    return;
  } else {
  }
  if (ldv_irq_2_3 == 0) {
    ldv_irq_line_2_3 = line;
    ldv_irq_data_2_3 = data;
    ldv_irq_2_3 = 1;
    return;
  } else {
  }
  return;
}
}
int reg_timer_8(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data )
{
  {
  if ((unsigned long )function == (unsigned long )(& bnad_ioc_hb_check)) {
    activate_suitable_timer_8(timer, data);
  } else {
  }
  return (0);
}
}
void disable_suitable_timer_9(struct timer_list *timer )
{
  {
  if (ldv_timer_9_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_0) {
    ldv_timer_9_0 = 0;
    return;
  } else {
  }
  if (ldv_timer_9_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_1) {
    ldv_timer_9_1 = 0;
    return;
  } else {
  }
  if (ldv_timer_9_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_2) {
    ldv_timer_9_2 = 0;
    return;
  } else {
  }
  if (ldv_timer_9_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_9_3) {
    ldv_timer_9_3 = 0;
    return;
  } else {
  }
  return;
}
}
void choose_timer_6(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_6_0 == 1) {
    ldv_timer_6_0 = 2;
    ldv_timer_6(ldv_timer_6_0, ldv_timer_list_6_0);
  } else {
  }
  goto ldv_59750;
  case 1: ;
  if (ldv_timer_6_1 == 1) {
    ldv_timer_6_1 = 2;
    ldv_timer_6(ldv_timer_6_1, ldv_timer_list_6_1);
  } else {
  }
  goto ldv_59750;
  case 2: ;
  if (ldv_timer_6_2 == 1) {
    ldv_timer_6_2 = 2;
    ldv_timer_6(ldv_timer_6_2, ldv_timer_list_6_2);
  } else {
  }
  goto ldv_59750;
  case 3: ;
  if (ldv_timer_6_3 == 1) {
    ldv_timer_6_3 = 2;
    ldv_timer_6(ldv_timer_6_3, ldv_timer_list_6_3);
  } else {
  }
  goto ldv_59750;
  default:
  ldv_stop();
  }
  ldv_59750: ;
  return;
}
}
int reg_timer_6(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data )
{
  {
  if ((unsigned long )function == (unsigned long )(& bnad_stats_timeout)) {
    activate_suitable_timer_6(timer, data);
  } else {
  }
  return (0);
}
}
void activate_suitable_timer_10(struct timer_list *timer , unsigned long data )
{
  {
  if (ldv_timer_10_0 == 0 || ldv_timer_10_0 == 2) {
    ldv_timer_list_10_0 = timer;
    ldv_timer_list_10_0->data = data;
    ldv_timer_10_0 = 1;
    return;
  } else {
  }
  if (ldv_timer_10_1 == 0 || ldv_timer_10_1 == 2) {
    ldv_timer_list_10_1 = timer;
    ldv_timer_list_10_1->data = data;
    ldv_timer_10_1 = 1;
    return;
  } else {
  }
  if (ldv_timer_10_2 == 0 || ldv_timer_10_2 == 2) {
    ldv_timer_list_10_2 = timer;
    ldv_timer_list_10_2->data = data;
    ldv_timer_10_2 = 1;
    return;
  } else {
  }
  if (ldv_timer_10_3 == 0 || ldv_timer_10_3 == 2) {
    ldv_timer_list_10_3 = timer;
    ldv_timer_list_10_3->data = data;
    ldv_timer_10_3 = 1;
    return;
  } else {
  }
  return;
}
}
void ldv_timer_6(int state , struct timer_list *timer )
{
  {
  LDV_IN_INTERRUPT = 2;
  bnad_stats_timeout(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void timer_init_7(void)
{
  {
  ldv_timer_7_0 = 0;
  ldv_timer_7_1 = 0;
  ldv_timer_7_2 = 0;
  ldv_timer_7_3 = 0;
  return;
}
}
void choose_interrupt_1(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0:
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_0, ldv_irq_line_1_0, ldv_irq_data_1_0);
  goto ldv_59776;
  case 1:
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_1, ldv_irq_line_1_1, ldv_irq_data_1_1);
  goto ldv_59776;
  case 2:
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_2, ldv_irq_line_1_2, ldv_irq_data_1_2);
  goto ldv_59776;
  case 3:
  ldv_irq_1_0 = ldv_irq_1(ldv_irq_1_3, ldv_irq_line_1_3, ldv_irq_data_1_3);
  goto ldv_59776;
  default:
  ldv_stop();
  }
  ldv_59776: ;
  return;
}
}
int reg_check_2(irqreturn_t (*handler)(int , void * ) )
{
  {
  if ((unsigned long )handler == (unsigned long )(& bnad_msix_rx)) {
    return (1);
  } else {
  }
  return (0);
}
}
void choose_timer_9(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_9_0 == 1) {
    ldv_timer_9_0 = 2;
    ldv_timer_9(ldv_timer_9_0, ldv_timer_list_9_0);
  } else {
  }
  goto ldv_59790;
  case 1: ;
  if (ldv_timer_9_1 == 1) {
    ldv_timer_9_1 = 2;
    ldv_timer_9(ldv_timer_9_1, ldv_timer_list_9_1);
  } else {
  }
  goto ldv_59790;
  case 2: ;
  if (ldv_timer_9_2 == 1) {
    ldv_timer_9_2 = 2;
    ldv_timer_9(ldv_timer_9_2, ldv_timer_list_9_2);
  } else {
  }
  goto ldv_59790;
  case 3: ;
  if (ldv_timer_9_3 == 1) {
    ldv_timer_9_3 = 2;
    ldv_timer_9(ldv_timer_9_3, ldv_timer_list_9_3);
  } else {
  }
  goto ldv_59790;
  default:
  ldv_stop();
  }
  ldv_59790: ;
  return;
}
}
void timer_init_10(void)
{
  {
  ldv_timer_10_0 = 0;
  ldv_timer_10_1 = 0;
  ldv_timer_10_2 = 0;
  ldv_timer_10_3 = 0;
  return;
}
}
void disable_work_4(struct work_struct *work )
{
  {
  if ((ldv_work_4_0 == 3 || ldv_work_4_0 == 2) && (unsigned long )ldv_work_struct_4_0 == (unsigned long )work) {
    ldv_work_4_0 = 1;
  } else {
  }
  if ((ldv_work_4_1 == 3 || ldv_work_4_1 == 2) && (unsigned long )ldv_work_struct_4_1 == (unsigned long )work) {
    ldv_work_4_1 = 1;
  } else {
  }
  if ((ldv_work_4_2 == 3 || ldv_work_4_2 == 2) && (unsigned long )ldv_work_struct_4_2 == (unsigned long )work) {
    ldv_work_4_2 = 1;
  } else {
  }
  if ((ldv_work_4_3 == 3 || ldv_work_4_3 == 2) && (unsigned long )ldv_work_struct_4_3 == (unsigned long )work) {
    ldv_work_4_3 = 1;
  } else {
  }
  return;
}
}
void work_init_4(void)
{
  {
  ldv_work_4_0 = 0;
  ldv_work_4_1 = 0;
  ldv_work_4_2 = 0;
  ldv_work_4_3 = 0;
  return;
}
}
void invoke_work_3(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_work_3_0 == 2 || ldv_work_3_0 == 3) {
    ldv_work_3_0 = 4;
    ldv__builtin_trap();
    ldv_work_3_0 = 1;
  } else {
  }
  goto ldv_59810;
  case 1: ;
  if (ldv_work_3_1 == 2 || ldv_work_3_1 == 3) {
    ldv_work_3_1 = 4;
    ldv__builtin_trap();
    ldv_work_3_1 = 1;
  } else {
  }
  goto ldv_59810;
  case 2: ;
  if (ldv_work_3_2 == 2 || ldv_work_3_2 == 3) {
    ldv_work_3_2 = 4;
    ldv__builtin_trap();
    ldv_work_3_2 = 1;
  } else {
  }
  goto ldv_59810;
  case 3: ;
  if (ldv_work_3_3 == 2 || ldv_work_3_3 == 3) {
    ldv_work_3_3 = 4;
    ldv__builtin_trap();
    ldv_work_3_3 = 1;
  } else {
  }
  goto ldv_59810;
  default:
  ldv_stop();
  }
  ldv_59810: ;
  return;
}
}
int ldv_irq_1(int state , int line , void *data )
{
  irqreturn_t irq_retval ;
  int tmp ;
  int tmp___0 ;
  {
  tmp = __VERIFIER_nondet_int();
  irq_retval = (irqreturn_t )tmp;
  if (state != 0) {
    tmp___0 = __VERIFIER_nondet_int();
    switch (tmp___0) {
    case 0: ;
    if (state == 1) {
      LDV_IN_INTERRUPT = 2;
      irq_retval = bnad_msix_tx(line, data);
      LDV_IN_INTERRUPT = 1;
      return (state);
    } else {
    }
    goto ldv_59822;
    default:
    ldv_stop();
    }
    ldv_59822: ;
  } else {
  }
  return (state);
}
}
void ldv_timer_8(int state , struct timer_list *timer )
{
  {
  LDV_IN_INTERRUPT = 2;
  bnad_ioc_hb_check(timer->data);
  LDV_IN_INTERRUPT = 1;
  return;
}
}
void activate_pending_timer_5(struct timer_list *timer , unsigned long data , int pending_flag )
{
  {
  if ((unsigned long )ldv_timer_list_5_0 == (unsigned long )timer) {
    if (ldv_timer_5_0 == 2 || pending_flag != 0) {
      ldv_timer_list_5_0 = timer;
      ldv_timer_list_5_0->data = data;
      ldv_timer_5_0 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_5_1 == (unsigned long )timer) {
    if (ldv_timer_5_1 == 2 || pending_flag != 0) {
      ldv_timer_list_5_1 = timer;
      ldv_timer_list_5_1->data = data;
      ldv_timer_5_1 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_5_2 == (unsigned long )timer) {
    if (ldv_timer_5_2 == 2 || pending_flag != 0) {
      ldv_timer_list_5_2 = timer;
      ldv_timer_list_5_2->data = data;
      ldv_timer_5_2 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_5_3 == (unsigned long )timer) {
    if (ldv_timer_5_3 == 2 || pending_flag != 0) {
      ldv_timer_list_5_3 = timer;
      ldv_timer_list_5_3->data = data;
      ldv_timer_5_3 = 1;
    } else {
    }
    return;
  } else {
  }
  activate_suitable_timer_5(timer, data);
  return;
}
}
void choose_timer_7(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_7_0 == 1) {
    ldv_timer_7_0 = 2;
    ldv_timer_7(ldv_timer_7_0, ldv_timer_list_7_0);
  } else {
  }
  goto ldv_59839;
  case 1: ;
  if (ldv_timer_7_1 == 1) {
    ldv_timer_7_1 = 2;
    ldv_timer_7(ldv_timer_7_1, ldv_timer_list_7_1);
  } else {
  }
  goto ldv_59839;
  case 2: ;
  if (ldv_timer_7_2 == 1) {
    ldv_timer_7_2 = 2;
    ldv_timer_7(ldv_timer_7_2, ldv_timer_list_7_2);
  } else {
  }
  goto ldv_59839;
  case 3: ;
  if (ldv_timer_7_3 == 1) {
    ldv_timer_7_3 = 2;
    ldv_timer_7(ldv_timer_7_3, ldv_timer_list_7_3);
  } else {
  }
  goto ldv_59839;
  default:
  ldv_stop();
  }
  ldv_59839: ;
  return;
}
}
void timer_init_8(void)
{
  {
  ldv_timer_8_0 = 0;
  ldv_timer_8_1 = 0;
  ldv_timer_8_2 = 0;
  ldv_timer_8_3 = 0;
  return;
}
}
void call_and_disable_all_3(int state )
{
  {
  if (ldv_work_3_0 == state) {
    call_and_disable_work_3(ldv_work_struct_3_0);
  } else {
  }
  if (ldv_work_3_1 == state) {
    call_and_disable_work_3(ldv_work_struct_3_1);
  } else {
  }
  if (ldv_work_3_2 == state) {
    call_and_disable_work_3(ldv_work_struct_3_2);
  } else {
  }
  if (ldv_work_3_3 == state) {
    call_and_disable_work_3(ldv_work_struct_3_3);
  } else {
  }
  return;
}
}
void activate_suitable_timer_8(struct timer_list *timer , unsigned long data )
{
  {
  if (ldv_timer_8_0 == 0 || ldv_timer_8_0 == 2) {
    ldv_timer_list_8_0 = timer;
    ldv_timer_list_8_0->data = data;
    ldv_timer_8_0 = 1;
    return;
  } else {
  }
  if (ldv_timer_8_1 == 0 || ldv_timer_8_1 == 2) {
    ldv_timer_list_8_1 = timer;
    ldv_timer_list_8_1->data = data;
    ldv_timer_8_1 = 1;
    return;
  } else {
  }
  if (ldv_timer_8_2 == 0 || ldv_timer_8_2 == 2) {
    ldv_timer_list_8_2 = timer;
    ldv_timer_list_8_2->data = data;
    ldv_timer_8_2 = 1;
    return;
  } else {
  }
  if (ldv_timer_8_3 == 0 || ldv_timer_8_3 == 2) {
    ldv_timer_list_8_3 = timer;
    ldv_timer_list_8_3->data = data;
    ldv_timer_8_3 = 1;
    return;
  } else {
  }
  return;
}
}
void choose_timer_10(void)
{
  int tmp ;
  {
  tmp = __VERIFIER_nondet_int();
  switch (tmp) {
  case 0: ;
  if (ldv_timer_10_0 == 1) {
    ldv_timer_10_0 = 2;
    ldv_timer_10(ldv_timer_10_0, ldv_timer_list_10_0);
  } else {
  }
  goto ldv_59858;
  case 1: ;
  if (ldv_timer_10_1 == 1) {
    ldv_timer_10_1 = 2;
    ldv_timer_10(ldv_timer_10_1, ldv_timer_list_10_1);
  } else {
  }
  goto ldv_59858;
  case 2: ;
  if (ldv_timer_10_2 == 1) {
    ldv_timer_10_2 = 2;
    ldv_timer_10(ldv_timer_10_2, ldv_timer_list_10_2);
  } else {
  }
  goto ldv_59858;
  case 3: ;
  if (ldv_timer_10_3 == 1) {
    ldv_timer_10_3 = 2;
    ldv_timer_10(ldv_timer_10_3, ldv_timer_list_10_3);
  } else {
  }
  goto ldv_59858;
  default:
  ldv_stop();
  }
  ldv_59858: ;
  return;
}
}
int reg_timer_5(struct timer_list *timer , void (*function)(unsigned long ) , unsigned long data )
{
  {
  if ((unsigned long )function == (unsigned long )(& bnad_dim_timeout)) {
    activate_suitable_timer_5(timer, data);
  } else {
  }
  return (0);
}
}
void call_and_disable_work_4(struct work_struct *work )
{
  {
  if ((ldv_work_4_0 == 2 || ldv_work_4_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_0) {
    ldv__builtin_trap();
    ldv_work_4_0 = 1;
    return;
  } else {
  }
  if ((ldv_work_4_1 == 2 || ldv_work_4_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_1) {
    ldv__builtin_trap();
    ldv_work_4_1 = 1;
    return;
  } else {
  }
  if ((ldv_work_4_2 == 2 || ldv_work_4_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_2) {
    ldv__builtin_trap();
    ldv_work_4_2 = 1;
    return;
  } else {
  }
  if ((ldv_work_4_3 == 2 || ldv_work_4_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_4_3) {
    ldv__builtin_trap();
    ldv_work_4_3 = 1;
    return;
  } else {
  }
  return;
}
}
void activate_suitable_timer_5(struct timer_list *timer , unsigned long data )
{
  {
  if (ldv_timer_5_0 == 0 || ldv_timer_5_0 == 2) {
    ldv_timer_list_5_0 = timer;
    ldv_timer_list_5_0->data = data;
    ldv_timer_5_0 = 1;
    return;
  } else {
  }
  if (ldv_timer_5_1 == 0 || ldv_timer_5_1 == 2) {
    ldv_timer_list_5_1 = timer;
    ldv_timer_list_5_1->data = data;
    ldv_timer_5_1 = 1;
    return;
  } else {
  }
  if (ldv_timer_5_2 == 0 || ldv_timer_5_2 == 2) {
    ldv_timer_list_5_2 = timer;
    ldv_timer_list_5_2->data = data;
    ldv_timer_5_2 = 1;
    return;
  } else {
  }
  if (ldv_timer_5_3 == 0 || ldv_timer_5_3 == 2) {
    ldv_timer_list_5_3 = timer;
    ldv_timer_list_5_3->data = data;
    ldv_timer_5_3 = 1;
    return;
  } else {
  }
  return;
}
}
void activate_pending_timer_7(struct timer_list *timer , unsigned long data , int pending_flag )
{
  {
  if ((unsigned long )ldv_timer_list_7_0 == (unsigned long )timer) {
    if (ldv_timer_7_0 == 2 || pending_flag != 0) {
      ldv_timer_list_7_0 = timer;
      ldv_timer_list_7_0->data = data;
      ldv_timer_7_0 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_7_1 == (unsigned long )timer) {
    if (ldv_timer_7_1 == 2 || pending_flag != 0) {
      ldv_timer_list_7_1 = timer;
      ldv_timer_list_7_1->data = data;
      ldv_timer_7_1 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_7_2 == (unsigned long )timer) {
    if (ldv_timer_7_2 == 2 || pending_flag != 0) {
      ldv_timer_list_7_2 = timer;
      ldv_timer_list_7_2->data = data;
      ldv_timer_7_2 = 1;
    } else {
    }
    return;
  } else {
  }
  if ((unsigned long )ldv_timer_list_7_3 == (unsigned long )timer) {
    if (ldv_timer_7_3 == 2 || pending_flag != 0) {
      ldv_timer_list_7_3 = timer;
      ldv_timer_list_7_3->data = data;
      ldv_timer_7_3 = 1;
    } else {
    }
    return;
  } else {
  }
  activate_suitable_timer_7(timer, data);
  return;
}
}
void activate_suitable_timer_7(struct timer_list *timer , unsigned long data )
{
  {
  if (ldv_timer_7_0 == 0 || ldv_timer_7_0 == 2) {
    ldv_timer_list_7_0 = timer;
    ldv_timer_list_7_0->data = data;
    ldv_timer_7_0 = 1;
    return;
  } else {
  }
  if (ldv_timer_7_1 == 0 || ldv_timer_7_1 == 2) {
    ldv_timer_list_7_1 = timer;
    ldv_timer_list_7_1->data = data;
    ldv_timer_7_1 = 1;
    return;
  } else {
  }
  if (ldv_timer_7_2 == 0 || ldv_timer_7_2 == 2) {
    ldv_timer_list_7_2 = timer;
    ldv_timer_list_7_2->data = data;
    ldv_timer_7_2 = 1;
    return;
  } else {
  }
  if (ldv_timer_7_3 == 0 || ldv_timer_7_3 == 2) {
    ldv_timer_list_7_3 = timer;
    ldv_timer_list_7_3->data = data;
    ldv_timer_7_3 = 1;
    return;
  } else {
  }
  return;
}
}
void ldv_main_exported_13(void) ;
void ldv_main_exported_19(void) ;
void ldv_main_exported_18(void) ;
void ldv_main_exported_16(void) ;
void ldv_main_exported_17(void) ;
void ldv_main_exported_15(void) ;
void ldv_main_exported_14(void) ;
void ldv_main_exported_11(void) ;
void ldv_main_exported_12(void) ;
int main(void)
{
  u16 ldvarg11 ;
  int ldvarg7 ;
  __be16 ldvarg12 ;
  void *ldvarg5 ;
  void *tmp ;
  struct sk_buff *ldvarg6 ;
  void *tmp___0 ;
  netdev_features_t ldvarg8 ;
  struct rtnl_link_stats64 *ldvarg4 ;
  void *tmp___1 ;
  __be16 ldvarg10 ;
  u16 ldvarg9 ;
  struct pci_device_id *ldvarg41 ;
  void *tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg5 = tmp;
  tmp___0 = ldv_init_zalloc(232UL);
  ldvarg6 = (struct sk_buff *)tmp___0;
  tmp___1 = ldv_init_zalloc(184UL);
  ldvarg4 = (struct rtnl_link_stats64 *)tmp___1;
  tmp___2 = ldv_init_zalloc(32UL);
  ldvarg41 = (struct pci_device_id *)tmp___2;
  ldv_initialize();
  ldv_memset((void *)(& ldvarg11), 0, 2UL);
  ldv_memset((void *)(& ldvarg7), 0, 4UL);
  ldv_memset((void *)(& ldvarg12), 0, 2UL);
  ldv_memset((void *)(& ldvarg8), 0, 8UL);
  ldv_memset((void *)(& ldvarg10), 0, 2UL);
  ldv_memset((void *)(& ldvarg9), 0, 2UL);
  ldv_state_variable_11 = 0;
  ldv_state_variable_21 = 0;
  timer_init_7();
  ldv_state_variable_7 = 1;
  ldv_state_variable_17 = 0;
  ldv_state_variable_2 = 1;
  ldv_state_variable_1 = 1;
  ldv_state_variable_18 = 0;
  ref_cnt = 0;
  ldv_state_variable_0 = 1;
  ldv_state_variable_16 = 0;
  ldv_state_variable_13 = 0;
  timer_init_6();
  ldv_state_variable_6 = 1;
  work_init_3();
  ldv_state_variable_3 = 1;
  timer_init_9();
  ldv_state_variable_9 = 1;
  ldv_state_variable_12 = 0;
  ldv_state_variable_20 = 0;
  ldv_state_variable_14 = 0;
  ldv_state_variable_15 = 0;
  timer_init_8();
  ldv_state_variable_8 = 1;
  work_init_4();
  ldv_state_variable_4 = 1;
  ldv_state_variable_19 = 0;
  timer_init_10();
  ldv_state_variable_10 = 1;
  timer_init_5();
  ldv_state_variable_5 = 1;
  ldv_59974:
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_11 != 0) {
    ldv_main_exported_11();
  } else {
  }
  goto ldv_59925;
  case 1: ;
  if (ldv_state_variable_21 != 0) {
    tmp___4 = __VERIFIER_nondet_int();
    switch (tmp___4) {
    case 0: ;
    if (ldv_state_variable_21 == 3) {
      bnad_stop(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 1: ;
    if (ldv_state_variable_21 == 1) {
      bnad_set_rx_mode(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      bnad_set_rx_mode(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_set_rx_mode(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 2: ;
    if (ldv_state_variable_21 == 1) {
      eth_validate_addr(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      eth_validate_addr(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      eth_validate_addr(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 3: ;
    if (ldv_state_variable_21 == 1) {
      bnad_vlan_rx_kill_vid(bnad_netdev_ops_group1, (int )ldvarg12, (int )ldvarg11);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      bnad_vlan_rx_kill_vid(bnad_netdev_ops_group1, (int )ldvarg12, (int )ldvarg11);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_vlan_rx_kill_vid(bnad_netdev_ops_group1, (int )ldvarg12, (int )ldvarg11);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 4: ;
    if (ldv_state_variable_21 == 1) {
      bnad_vlan_rx_add_vid(bnad_netdev_ops_group1, (int )ldvarg10, (int )ldvarg9);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      bnad_vlan_rx_add_vid(bnad_netdev_ops_group1, (int )ldvarg10, (int )ldvarg9);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_vlan_rx_add_vid(bnad_netdev_ops_group1, (int )ldvarg10, (int )ldvarg9);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 5: ;
    if (ldv_state_variable_21 == 1) {
      bnad_netpoll(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      bnad_netpoll(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_netpoll(bnad_netdev_ops_group1);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 6: ;
    if (ldv_state_variable_21 == 1) {
      bnad_set_features(bnad_netdev_ops_group1, ldvarg8);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      bnad_set_features(bnad_netdev_ops_group1, ldvarg8);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_set_features(bnad_netdev_ops_group1, ldvarg8);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 7: ;
    if (ldv_state_variable_21 == 3) {
      bnad_change_mtu(bnad_netdev_ops_group1, ldvarg7);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_change_mtu(bnad_netdev_ops_group1, ldvarg7);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 8: ;
    if (ldv_state_variable_21 == 2) {
      ldv_retval_1 = bnad_open(bnad_netdev_ops_group1);
      if (ldv_retval_1 == 0) {
        ldv_state_variable_21 = 3;
      } else {
      }
    } else {
    }
    goto ldv_59928;
    case 9: ;
    if (ldv_state_variable_21 == 3) {
      bnad_start_xmit(ldvarg6, bnad_netdev_ops_group1);
      ldv_state_variable_21 = 3;
    } else {
    }
    goto ldv_59928;
    case 10: ;
    if (ldv_state_variable_21 == 1) {
      bnad_set_mac_address(bnad_netdev_ops_group1, ldvarg5);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      bnad_set_mac_address(bnad_netdev_ops_group1, ldvarg5);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_set_mac_address(bnad_netdev_ops_group1, ldvarg5);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 11: ;
    if (ldv_state_variable_21 == 1) {
      bnad_get_stats64(bnad_netdev_ops_group1, ldvarg4);
      ldv_state_variable_21 = 1;
    } else {
    }
    if (ldv_state_variable_21 == 3) {
      bnad_get_stats64(bnad_netdev_ops_group1, ldvarg4);
      ldv_state_variable_21 = 3;
    } else {
    }
    if (ldv_state_variable_21 == 2) {
      bnad_get_stats64(bnad_netdev_ops_group1, ldvarg4);
      ldv_state_variable_21 = 2;
    } else {
    }
    goto ldv_59928;
    case 12: ;
    if (ldv_state_variable_21 == 1) {
      ldv_retval_0 = ldv_ndo_init_21();
      if (ldv_retval_0 == 0) {
        ldv_state_variable_21 = 2;
        ref_cnt = ref_cnt + 1;
      } else {
      }
    } else {
    }
    goto ldv_59928;
    case 13: ;
    if (ldv_state_variable_21 == 2) {
      ldv_ndo_uninit_21();
      ldv_state_variable_21 = 1;
      ref_cnt = ref_cnt - 1;
    } else {
    }
    goto ldv_59928;
    default:
    ldv_stop();
    }
    ldv_59928: ;
  } else {
  }
  goto ldv_59925;
  case 2: ;
  if (ldv_state_variable_7 != 0) {
    choose_timer_7();
  } else {
  }
  goto ldv_59925;
  case 3: ;
  if (ldv_state_variable_17 != 0) {
    ldv_main_exported_17();
  } else {
  }
  goto ldv_59925;
  case 4: ;
  if (ldv_state_variable_2 != 0) {
    choose_interrupt_2();
  } else {
  }
  goto ldv_59925;
  case 5: ;
  if (ldv_state_variable_1 != 0) {
    choose_interrupt_1();
  } else {
  }
  goto ldv_59925;
  case 6: ;
  if (ldv_state_variable_18 != 0) {
    ldv_main_exported_18();
  } else {
  }
  goto ldv_59925;
  case 7: ;
  if (ldv_state_variable_0 != 0) {
    tmp___5 = __VERIFIER_nondet_int();
    switch (tmp___5) {
    case 0: ;
    if (ldv_state_variable_0 == 3 && ref_cnt == 0) {
      bnad_module_exit();
      ldv_state_variable_0 = 2;
      goto ldv_final;
    } else {
    }
    goto ldv_59951;
    case 1: ;
    if (ldv_state_variable_0 == 1) {
      ldv_retval_4 = bnad_module_init();
      if (ldv_retval_4 == 0) {
        ldv_state_variable_0 = 3;
        ldv_state_variable_16 = 1;
        ldv_file_operations_16();
        ldv_state_variable_13 = 1;
        ldv_state_variable_19 = 1;
        ldv_initialize_ethtool_ops_19();
        ldv_state_variable_18 = 1;
        ldv_file_operations_18();
        ldv_state_variable_14 = 1;
        ldv_file_operations_14();
        ldv_state_variable_15 = 1;
        ldv_file_operations_15();
        ldv_state_variable_12 = 1;
        ldv_initialize_bfa_ioc_hwif_12();
        ldv_state_variable_17 = 1;
        ldv_file_operations_17();
        ldv_state_variable_11 = 1;
        ldv_initialize_bfa_ioc_hwif_11();
      } else {
      }
      if (ldv_retval_4 != 0) {
        ldv_state_variable_0 = 2;
        goto ldv_final;
      } else {
      }
    } else {
    }
    goto ldv_59951;
    default:
    ldv_stop();
    }
    ldv_59951: ;
  } else {
  }
  goto ldv_59925;
  case 8: ;
  if (ldv_state_variable_16 != 0) {
    ldv_main_exported_16();
  } else {
  }
  goto ldv_59925;
  case 9: ;
  if (ldv_state_variable_13 != 0) {
    ldv_main_exported_13();
  } else {
  }
  goto ldv_59925;
  case 10: ;
  if (ldv_state_variable_6 != 0) {
    choose_timer_6();
  } else {
  }
  goto ldv_59925;
  case 11: ;
  if (ldv_state_variable_3 != 0) {
    invoke_work_3();
  } else {
  }
  goto ldv_59925;
  case 12: ;
  if (ldv_state_variable_9 != 0) {
    choose_timer_9();
  } else {
  }
  goto ldv_59925;
  case 13: ;
  if (ldv_state_variable_12 != 0) {
    ldv_main_exported_12();
  } else {
  }
  goto ldv_59925;
  case 14: ;
  if (ldv_state_variable_20 != 0) {
    tmp___6 = __VERIFIER_nondet_int();
    switch (tmp___6) {
    case 0: ;
    if (ldv_state_variable_20 == 1) {
      ldv_retval_6 = bnad_pci_probe(bnad_pci_driver_group1, (struct pci_device_id const *)ldvarg41);
      if (ldv_retval_6 == 0) {
        ldv_state_variable_20 = 2;
        ref_cnt = ref_cnt + 1;
      } else {
      }
    } else {
    }
    goto ldv_59962;
    case 1: ;
    if (ldv_state_variable_20 == 2) {
      bnad_pci_remove(bnad_pci_driver_group1);
      ldv_state_variable_20 = 1;
    } else {
    }
    goto ldv_59962;
    case 2: ;
    if (ldv_state_variable_20 == 2) {
      ldv_shutdown_20();
      ldv_state_variable_20 = 2;
    } else {
    }
    goto ldv_59962;
    default:
    ldv_stop();
    }
    ldv_59962: ;
  } else {
  }
  goto ldv_59925;
  case 15: ;
  if (ldv_state_variable_14 != 0) {
    ldv_main_exported_14();
  } else {
  }
  goto ldv_59925;
  case 16: ;
  if (ldv_state_variable_15 != 0) {
    ldv_main_exported_15();
  } else {
  }
  goto ldv_59925;
  case 17: ;
  if (ldv_state_variable_8 != 0) {
    choose_timer_8();
  } else {
  }
  goto ldv_59925;
  case 18: ;
  if (ldv_state_variable_4 != 0) {
    invoke_work_4();
  } else {
  }
  goto ldv_59925;
  case 19: ;
  if (ldv_state_variable_19 != 0) {
    ldv_main_exported_19();
  } else {
  }
  goto ldv_59925;
  case 20: ;
  if (ldv_state_variable_10 != 0) {
    choose_timer_10();
  } else {
  }
  goto ldv_59925;
  case 21: ;
  if (ldv_state_variable_5 != 0) {
    choose_timer_5();
  } else {
  }
  goto ldv_59925;
  default:
  ldv_stop();
  }
  ldv_59925: ;
  goto ldv_59974;
  ldv_final:
  ldv_check_final_state();
  return 0;
}
}
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags )
{
  {
  ldv_spin_unlock();
  ldv_spin_unlock_irqrestore_12(lock, flags);
  return;
}
}
bool ldv_queue_work_on_15(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_16(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_17(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_18(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_19(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
__inline static struct page *alloc_pages(gfp_t flags , unsigned int order )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct page *)tmp);
}
}
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
void *ldv_kmem_cache_alloc_25(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
__inline static void *kzalloc(size_t size , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_31(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_33(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_35(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_36(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_37(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_38(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                          gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_39(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_40(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                            gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_41(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
void *ldv_kmem_cache_alloc_42(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_mod_timer_43(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
void ldv_free_irq_44(unsigned int ldv_func_arg1 , void *ldv_func_arg2 )
{
  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_2((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
__inline static int ldv_request_irq_45(unsigned int irq , irqreturn_t (*handler)(int ,
                                                                                 void * ) ,
                                       unsigned long flags , char const *name ,
                                       void *dev )
{
  ldv_func_ret_type___7 ldv_func_res ;
  int tmp ;
  int tmp___0 ;
  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_2(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_2((int )irq, dev);
  } else {
  }
  return (ldv_func_res);
}
}
void ldv_free_irq_46(unsigned int ldv_func_arg1 , void *ldv_func_arg2 )
{
  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_2((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
__inline static int ldv_request_irq_47(unsigned int irq , irqreturn_t (*handler)(int ,
                                                                                 void * ) ,
                                       unsigned long flags , char const *name ,
                                       void *dev )
{
  ldv_func_ret_type___8 ldv_func_res ;
  int tmp ;
  int tmp___0 ;
  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_2(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_2((int )irq, dev);
  } else {
  }
  return (ldv_func_res);
}
}
void ldv_free_irq_48(unsigned int ldv_func_arg1 , void *ldv_func_arg2 )
{
  {
  free_irq(ldv_func_arg1, ldv_func_arg2);
  disable_suitable_irq_2((int )ldv_func_arg1, ldv_func_arg2);
  return;
}
}
__inline static int ldv_request_irq_49(unsigned int irq , irqreturn_t (*handler)(int ,
                                                                                 void * ) ,
                                       unsigned long flags , char const *name ,
                                       void *dev )
{
  ldv_func_ret_type___9 ldv_func_res ;
  int tmp ;
  int tmp___0 ;
  {
  tmp = request_irq(irq, handler, flags, name, dev);
  ldv_func_res = tmp;
  tmp___0 = reg_check_2(handler);
  if (tmp___0 != 0 && ldv_func_res == 0) {
    activate_suitable_irq_2((int )irq, dev);
  } else {
  }
  return (ldv_func_res);
}
}
int ldv_mod_timer_50(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_51(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___11 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_52(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_53(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___13 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_54(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___14 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_55(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
void ldv_destroy_workqueue_56(struct workqueue_struct *ldv_func_arg1 )
{
  {
  destroy_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
int ldv_register_netdev_57(struct net_device *dev )
{
  ldv_func_ret_type___15 ldv_func_res ;
  int tmp ;
  {
  tmp = register_netdev(dev);
  ldv_func_res = tmp;
  ldv_state_variable_21 = 1;
  ldv_net_device_ops_21();
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_58(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___16 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_59(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___17 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_60(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___18 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_free_netdev_61(struct net_device *dev )
{
  {
  free_netdev(dev);
  ldv_state_variable_21 = 0;
  return;
}
}
void ldv_unregister_netdev_62(struct net_device *dev )
{
  {
  unregister_netdev(dev);
  ldv_state_variable_21 = 0;
  return;
}
}
int ldv_del_timer_sync_63(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___19 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_64(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___20 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_sync_65(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___21 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
void ldv_free_netdev_66(struct net_device *dev )
{
  {
  free_netdev(dev);
  ldv_state_variable_21 = 0;
  return;
}
}
int ldv___pci_register_driver_67(struct pci_driver *ldv_func_arg1 , struct module *ldv_func_arg2 ,
                                 char const *ldv_func_arg3 )
{
  ldv_func_ret_type___22 ldv_func_res ;
  int tmp ;
  {
  tmp = __pci_register_driver(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  ldv_state_variable_20 = 1;
  ldv_pci_driver_20();
  return (ldv_func_res);
}
}
void ldv_pci_unregister_driver_68(struct pci_driver *ldv_func_arg1 )
{
  {
  pci_unregister_driver(ldv_func_arg1);
  ldv_state_variable_20 = 0;
  return;
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static bool is_power_of_2(unsigned long n )
{
  {
  return ((bool )(n != 0UL && ((n - 1UL) & n) == 0UL));
}
}
extern void *memcpy(void * , void const * , size_t ) ;
extern size_t strlen(char const * ) ;
extern size_t strlcpy(char * , char const * , size_t ) ;
extern void _raw_spin_lock_irq(raw_spinlock_t * ) ;
extern void _raw_spin_unlock_irq(raw_spinlock_t * ) ;
__inline static void ldv_spin_lock_irq_107(spinlock_t *lock )
{
  {
  _raw_spin_lock_irq(& lock->__annonCompField18.rlock);
  return;
}
}
__inline static void spin_lock_irq(spinlock_t *lock ) ;
__inline static void ldv_spin_unlock_irq_110(spinlock_t *lock )
{
  {
  _raw_spin_unlock_irq(& lock->__annonCompField18.rlock);
  return;
}
}
__inline static void spin_unlock_irq(spinlock_t *lock ) ;
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) ;
int ldv_del_timer_sync_142(struct timer_list *ldv_func_arg1 ) ;
bool ldv_queue_work_on_114(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_116(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_115(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_118(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_117(struct workqueue_struct *ldv_func_arg1 ) ;
__inline static char const *kobject_name(struct kobject const *kobj )
{
  {
  return ((char const *)kobj->name);
}
}
void *ldv_kmem_cache_alloc_124(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
void *ldv_kmem_cache_alloc_141(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) ;
__inline static char const *dev_name(struct device const *dev )
{
  char const *tmp ;
  {
  if ((unsigned long )dev->init_name != (unsigned long )((char const * )0)) {
    return ((char const *)dev->init_name);
  } else {
  }
  tmp = kobject_name(& dev->kobj);
  return (tmp);
}
}
__inline static char const *pci_name(struct pci_dev const *pdev )
{
  char const *tmp ;
  {
  tmp = dev_name(& pdev->dev);
  return (tmp);
}
}
struct sk_buff *ldv_skb_clone_132(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_140(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_134(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_130(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_138(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_139(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_135(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_136(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_137(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static void ethtool_cmd_speed_set(struct ethtool_cmd *ep , __u32 speed )
{
  {
  ep->speed = (unsigned short )speed;
  ep->speed_hi = (unsigned short )(speed >> 16);
  return;
}
}
__inline static __u32 ethtool_cmd_speed(struct ethtool_cmd const *ep )
{
  {
  return ((__u32 )(((int )ep->speed_hi << 16) | (int )ep->speed));
}
}
extern u32 ethtool_op_get_link(struct net_device * ) ;
extern int ethtool_op_get_ts_info(struct net_device * , struct ethtool_ts_info * ) ;
extern void netdev_warn(struct net_device const * , char const * , ...) ;
void bfa_nw_ioc_get_attr(struct bfa_ioc *ioc , struct bfa_ioc_attr *ioc_attr ) ;
enum bfa_status bfa_nw_flash_get_attr(struct bfa_flash *flash , struct bfa_flash_attr *attr ,
                                      void (*cbfn)(void * , enum bfa_status ) , void *cbarg ) ;
enum bfa_status bfa_nw_flash_update_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                         void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                         enum bfa_status ) ,
                                         void *cbarg ) ;
enum bfa_status bfa_nw_flash_read_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                       void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                       enum bfa_status ) ,
                                       void *cbarg ) ;
extern int request_firmware(struct firmware const ** , char const * , struct device * ) ;
static char const *bnad_net_stats_strings[196U] =
  { "rx_packets", "tx_packets", "rx_bytes", "tx_bytes",
        "rx_errors", "tx_errors", "rx_dropped", "tx_dropped",
        "multicast", "collisions", "rx_length_errors", "rx_over_errors",
        "rx_crc_errors", "rx_frame_errors", "rx_fifo_errors", "rx_missed_errors",
        "tx_aborted_errors", "tx_carrier_errors", "tx_fifo_errors", "tx_heartbeat_errors",
        "tx_window_errors", "rx_compressed", "tx_compressed", "netif_queue_stop",
        "netif_queue_wakeup", "netif_queue_stopped", "tso4", "tso6",
        "tso_err", "tcpcsum_offload", "udpcsum_offload", "csum_help",
        "tx_skb_too_short", "tx_skb_stopping", "tx_skb_max_vectors", "tx_skb_mss_too_long",
        "tx_skb_tso_too_short", "tx_skb_tso_prepare", "tx_skb_non_tso_too_long", "tx_skb_tcp_hdr",
        "tx_skb_udp_hdr", "tx_skb_csum_err", "tx_skb_headlen_too_long", "tx_skb_headlen_zero",
        "tx_skb_frag_zero", "tx_skb_len_mismatch", "hw_stats_updates", "netif_rx_dropped",
        "link_toggle", "cee_toggle", "rxp_info_alloc_failed", "mbox_intr_disabled",
        "mbox_intr_enabled", "tx_unmap_q_alloc_failed", "rx_unmap_q_alloc_failed", "rxbuf_alloc_failed",
        "mac_stats_clr_cnt", "mac_frame_64", "mac_frame_65_127", "mac_frame_128_255",
        "mac_frame_256_511", "mac_frame_512_1023", "mac_frame_1024_1518", "mac_frame_1518_1522",
        "mac_rx_bytes", "mac_rx_packets", "mac_rx_fcs_error", "mac_rx_multicast",
        "mac_rx_broadcast", "mac_rx_control_frames", "mac_rx_pause", "mac_rx_unknown_opcode",
        "mac_rx_alignment_error", "mac_rx_frame_length_error", "mac_rx_code_error", "mac_rx_carrier_sense_error",
        "mac_rx_undersize", "mac_rx_oversize", "mac_rx_fragments", "mac_rx_jabber",
        "mac_rx_drop", "mac_tx_bytes", "mac_tx_packets", "mac_tx_multicast",
        "mac_tx_broadcast", "mac_tx_pause", "mac_tx_deferral", "mac_tx_excessive_deferral",
        "mac_tx_single_collision", "mac_tx_muliple_collision", "mac_tx_late_collision", "mac_tx_excessive_collision",
        "mac_tx_total_collision", "mac_tx_pause_honored", "mac_tx_drop", "mac_tx_jabber",
        "mac_tx_fcs_error", "mac_tx_control_frame", "mac_tx_oversize", "mac_tx_undersize",
        "mac_tx_fragments", "bpc_tx_pause_0", "bpc_tx_pause_1", "bpc_tx_pause_2",
        "bpc_tx_pause_3", "bpc_tx_pause_4", "bpc_tx_pause_5", "bpc_tx_pause_6",
        "bpc_tx_pause_7", "bpc_tx_zero_pause_0", "bpc_tx_zero_pause_1", "bpc_tx_zero_pause_2",
        "bpc_tx_zero_pause_3", "bpc_tx_zero_pause_4", "bpc_tx_zero_pause_5", "bpc_tx_zero_pause_6",
        "bpc_tx_zero_pause_7", "bpc_tx_first_pause_0", "bpc_tx_first_pause_1", "bpc_tx_first_pause_2",
        "bpc_tx_first_pause_3", "bpc_tx_first_pause_4", "bpc_tx_first_pause_5", "bpc_tx_first_pause_6",
        "bpc_tx_first_pause_7", "bpc_rx_pause_0", "bpc_rx_pause_1", "bpc_rx_pause_2",
        "bpc_rx_pause_3", "bpc_rx_pause_4", "bpc_rx_pause_5", "bpc_rx_pause_6",
        "bpc_rx_pause_7", "bpc_rx_zero_pause_0", "bpc_rx_zero_pause_1", "bpc_rx_zero_pause_2",
        "bpc_rx_zero_pause_3", "bpc_rx_zero_pause_4", "bpc_rx_zero_pause_5", "bpc_rx_zero_pause_6",
        "bpc_rx_zero_pause_7", "bpc_rx_first_pause_0", "bpc_rx_first_pause_1", "bpc_rx_first_pause_2",
        "bpc_rx_first_pause_3", "bpc_rx_first_pause_4", "bpc_rx_first_pause_5", "bpc_rx_first_pause_6",
        "bpc_rx_first_pause_7", "rad_rx_frames", "rad_rx_octets", "rad_rx_vlan_frames",
        "rad_rx_ucast", "rad_rx_ucast_octets", "rad_rx_ucast_vlan", "rad_rx_mcast",
        "rad_rx_mcast_octets", "rad_rx_mcast_vlan", "rad_rx_bcast", "rad_rx_bcast_octets",
        "rad_rx_bcast_vlan", "rad_rx_drops", "rlb_rad_rx_frames", "rlb_rad_rx_octets",
        "rlb_rad_rx_vlan_frames", "rlb_rad_rx_ucast", "rlb_rad_rx_ucast_octets", "rlb_rad_rx_ucast_vlan",
        "rlb_rad_rx_mcast", "rlb_rad_rx_mcast_octets", "rlb_rad_rx_mcast_vlan", "rlb_rad_rx_bcast",
        "rlb_rad_rx_bcast_octets", "rlb_rad_rx_bcast_vlan", "rlb_rad_rx_drops", "fc_rx_ucast_octets",
        "fc_rx_ucast", "fc_rx_ucast_vlan", "fc_rx_mcast_octets", "fc_rx_mcast",
        "fc_rx_mcast_vlan", "fc_rx_bcast_octets", "fc_rx_bcast", "fc_rx_bcast_vlan",
        "fc_tx_ucast_octets", "fc_tx_ucast", "fc_tx_ucast_vlan", "fc_tx_mcast_octets",
        "fc_tx_mcast", "fc_tx_mcast_vlan", "fc_tx_bcast_octets", "fc_tx_bcast",
        "fc_tx_bcast_vlan", "fc_tx_parity_errors", "fc_tx_timeout", "fc_tx_fid_parity_errors"};
static int bnad_get_settings(struct net_device *netdev , struct ethtool_cmd *cmd )
{
  bool tmp ;
  {
  cmd->supported = 4096U;
  cmd->advertising = 4096U;
  cmd->autoneg = 0U;
  cmd->supported = cmd->supported | 1024U;
  cmd->advertising = cmd->advertising | 1024U;
  cmd->port = 3U;
  cmd->phy_address = 0U;
  tmp = netif_carrier_ok((struct net_device const *)netdev);
  if ((int )tmp) {
    ethtool_cmd_speed_set(cmd, 10000U);
    cmd->duplex = 1U;
  } else {
    ethtool_cmd_speed_set(cmd, 4294967295U);
    cmd->duplex = 255U;
  }
  cmd->transceiver = 1U;
  cmd->maxtxpkt = 0U;
  cmd->maxrxpkt = 0U;
  return (0);
}
}
static int bnad_set_settings(struct net_device *netdev , struct ethtool_cmd *cmd )
{
  __u32 tmp ;
  {
  if ((unsigned int )cmd->autoneg == 1U) {
    return (-95);
  } else {
    tmp = ethtool_cmd_speed((struct ethtool_cmd const *)cmd);
    if (tmp == 10000U && (unsigned int )cmd->duplex == 1U) {
      return (0);
    } else {
    }
  }
  return (-95);
}
}
static void bnad_get_drvinfo(struct net_device *netdev , struct ethtool_drvinfo *drvinfo )
{
  struct bnad *bnad ;
  void *tmp ;
  struct bfa_ioc_attr *ioc_attr ;
  unsigned long flags ;
  void *tmp___0 ;
  char const *tmp___1 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  strlcpy((char *)(& drvinfo->driver), "bna", 32UL);
  strlcpy((char *)(& drvinfo->version), "3.2.25.1", 32UL);
  tmp___0 = kzalloc(1600UL, 208U);
  ioc_attr = (struct bfa_ioc_attr *)tmp___0;
  if ((unsigned long )ioc_attr != (unsigned long )((struct bfa_ioc_attr *)0)) {
    ldv_spin_lock();
    bfa_nw_ioc_get_attr(& bnad->bna.ioceth.ioc, ioc_attr);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    strlcpy((char *)(& drvinfo->fw_version), (char const *)(& ioc_attr->adapter_attr.fw_ver),
            32UL);
    kfree((void const *)ioc_attr);
  } else {
  }
  tmp___1 = pci_name((struct pci_dev const *)bnad->pcidev);
  strlcpy((char *)(& drvinfo->bus_info), tmp___1, 32UL);
  return;
}
}
static void bnad_get_wol(struct net_device *netdev , struct ethtool_wolinfo *wolinfo )
{
  {
  wolinfo->supported = 0U;
  wolinfo->wolopts = 0U;
  return;
}
}
static int bnad_get_coalesce(struct net_device *netdev , struct ethtool_coalesce *coalesce )
{
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  ldv_spin_lock();
  coalesce->use_adaptive_rx_coalesce = bnad->cfg_flags & 1U;
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  coalesce->rx_coalesce_usecs = (__u32 )((int )bnad->rx_coalescing_timeo * 5);
  coalesce->tx_coalesce_usecs = (__u32 )((int )bnad->tx_coalescing_timeo * 5);
  coalesce->tx_max_coalesced_frames = 12U;
  return (0);
}
}
static int bnad_set_coalesce(struct net_device *netdev , struct ethtool_coalesce *coalesce )
{
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  int to_del ;
  int tmp___0 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  to_del = 0;
  if (coalesce->rx_coalesce_usecs == 0U || coalesce->rx_coalesce_usecs > 1275U) {
    return (-22);
  } else {
  }
  if (coalesce->tx_coalesce_usecs == 0U || coalesce->tx_coalesce_usecs > 1275U) {
    return (-22);
  } else {
  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  ldv_spin_lock();
  if (coalesce->use_adaptive_rx_coalesce != 0U) {
    if ((bnad->cfg_flags & 1U) == 0U) {
      bnad->cfg_flags = bnad->cfg_flags | 1U;
      bnad_dim_timer_start(bnad);
    } else {
    }
  } else
  if ((int )bnad->cfg_flags & 1) {
    bnad->cfg_flags = bnad->cfg_flags & 4294967294U;
    if ((int )bnad->cfg_flags & 1) {
      tmp___0 = constant_test_bit(4L, (unsigned long const volatile *)(& bnad->run_flags));
      if (tmp___0 != 0) {
        clear_bit(4L, (unsigned long volatile *)(& bnad->run_flags));
        to_del = 1;
      } else {
      }
    } else {
    }
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    if (to_del != 0) {
      ldv_del_timer_sync_142(& bnad->dim_timer);
    } else {
    }
    ldv_spin_lock();
    bnad_rx_coalescing_timeo_set(bnad);
  } else {
  }
  if ((__u32 )bnad->tx_coalescing_timeo != coalesce->tx_coalesce_usecs / 5U) {
    bnad->tx_coalescing_timeo = (u8 )(coalesce->tx_coalesce_usecs / 5U);
    bnad_tx_coalescing_timeo_set(bnad);
  } else {
  }
  if ((__u32 )bnad->rx_coalescing_timeo != coalesce->rx_coalesce_usecs / 5U) {
    bnad->rx_coalescing_timeo = (u8 )(coalesce->rx_coalesce_usecs / 5U);
    if ((bnad->cfg_flags & 1U) == 0U) {
      bnad_rx_coalescing_timeo_set(bnad);
    } else {
    }
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static void bnad_get_ringparam(struct net_device *netdev , struct ethtool_ringparam *ringparam )
{
  struct bnad *bnad ;
  void *tmp ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  ringparam->rx_max_pending = 16384U;
  ringparam->tx_max_pending = 2048U;
  ringparam->rx_pending = bnad->rxq_depth;
  ringparam->tx_pending = bnad->txq_depth;
  return;
}
}
static int bnad_set_ringparam(struct net_device *netdev , struct ethtool_ringparam *ringparam )
{
  int i ;
  int current_err ;
  int err ;
  struct bnad *bnad ;
  void *tmp ;
  unsigned long flags ;
  bool tmp___0 ;
  int tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  bool tmp___4 ;
  int tmp___5 ;
  bool tmp___6 ;
  int tmp___7 ;
  {
  err = 0;
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  if (ringparam->rx_pending == bnad->rxq_depth && ringparam->tx_pending == bnad->txq_depth) {
    mutex_unlock(& bnad->conf_mutex);
    return (0);
  } else {
  }
  if (ringparam->rx_pending <= 511U || ringparam->rx_pending > 16384U) {
    mutex_unlock(& bnad->conf_mutex);
    return (-22);
  } else {
    tmp___0 = is_power_of_2((unsigned long )ringparam->rx_pending);
    if (tmp___0) {
      tmp___1 = 0;
    } else {
      tmp___1 = 1;
    }
    if (tmp___1) {
      mutex_unlock(& bnad->conf_mutex);
      return (-22);
    } else {
    }
  }
  if (ringparam->tx_pending <= 511U || ringparam->tx_pending > 2048U) {
    mutex_unlock(& bnad->conf_mutex);
    return (-22);
  } else {
    tmp___2 = is_power_of_2((unsigned long )ringparam->tx_pending);
    if (tmp___2) {
      tmp___3 = 0;
    } else {
      tmp___3 = 1;
    }
    if (tmp___3) {
      mutex_unlock(& bnad->conf_mutex);
      return (-22);
    } else {
    }
  }
  if (ringparam->rx_pending != bnad->rxq_depth) {
    bnad->rxq_depth = ringparam->rx_pending;
    tmp___4 = netif_running((struct net_device const *)netdev);
    if (tmp___4) {
      tmp___5 = 0;
    } else {
      tmp___5 = 1;
    }
    if (tmp___5) {
      mutex_unlock(& bnad->conf_mutex);
      return (0);
    } else {
    }
    i = 0;
    goto ldv_58209;
    ldv_58208: ;
    if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
      goto ldv_58207;
    } else {
    }
    bnad_destroy_rx(bnad, (u32 )i);
    current_err = bnad_setup_rx(bnad, (u32 )i);
    if (current_err != 0 && err == 0) {
      err = current_err;
    } else {
    }
    ldv_58207:
    i = i + 1;
    ldv_58209: ;
    if ((u32 )i < bnad->num_rx) {
      goto ldv_58208;
    } else {
    }
    if (err == 0 && (unsigned long )bnad->rx_info[0].rx != (unsigned long )((struct bna_rx *)0)) {
      bnad_restore_vlans(bnad, 0U);
      bnad_enable_default_bcast(bnad);
      ldv_spin_lock();
      bnad_mac_addr_set_locked(bnad, (u8 const *)netdev->dev_addr);
      spin_unlock_irqrestore(& bnad->bna_lock, flags);
      bnad->cfg_flags = bnad->cfg_flags & 4294967289U;
      bnad_set_rx_mode(netdev);
    } else {
    }
  } else {
  }
  if (ringparam->tx_pending != bnad->txq_depth) {
    bnad->txq_depth = ringparam->tx_pending;
    tmp___6 = netif_running((struct net_device const *)netdev);
    if (tmp___6) {
      tmp___7 = 0;
    } else {
      tmp___7 = 1;
    }
    if (tmp___7) {
      mutex_unlock(& bnad->conf_mutex);
      return (0);
    } else {
    }
    i = 0;
    goto ldv_58213;
    ldv_58212: ;
    if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
      goto ldv_58211;
    } else {
    }
    bnad_destroy_tx(bnad, (u32 )i);
    current_err = bnad_setup_tx(bnad, (u32 )i);
    if (current_err != 0 && err == 0) {
      err = current_err;
    } else {
    }
    ldv_58211:
    i = i + 1;
    ldv_58213: ;
    if ((u32 )i < bnad->num_tx) {
      goto ldv_58212;
    } else {
    }
  } else {
  }
  mutex_unlock(& bnad->conf_mutex);
  return (err);
}
}
static void bnad_get_pauseparam(struct net_device *netdev , struct ethtool_pauseparam *pauseparam )
{
  struct bnad *bnad ;
  void *tmp ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  pauseparam->autoneg = 0U;
  pauseparam->rx_pause = (__u32 )bnad->bna.enet.pause_config.rx_pause;
  pauseparam->tx_pause = (__u32 )bnad->bna.enet.pause_config.tx_pause;
  return;
}
}
static int bnad_set_pauseparam(struct net_device *netdev , struct ethtool_pauseparam *pauseparam )
{
  struct bnad *bnad ;
  void *tmp ;
  struct bna_pause_config pause_config ;
  unsigned long flags ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  if (pauseparam->autoneg == 1U) {
    return (-22);
  } else {
  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  if (pauseparam->rx_pause != (__u32 )bnad->bna.enet.pause_config.rx_pause || pauseparam->tx_pause != (__u32 )bnad->bna.enet.pause_config.tx_pause) {
    pause_config.rx_pause = (enum bna_status )pauseparam->rx_pause;
    pause_config.tx_pause = (enum bna_status )pauseparam->tx_pause;
    ldv_spin_lock();
    bna_enet_pause_config(& bnad->bna.enet, & pause_config);
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
  } else {
  }
  mutex_unlock(& bnad->conf_mutex);
  return (0);
}
}
static void bnad_get_strings(struct net_device *netdev , u32 stringset , u8 *string )
{
  struct bnad *bnad ;
  void *tmp ;
  int i ;
  int j ;
  int q_num ;
  u32 bmap___0 ;
  size_t tmp___0 ;
  long tmp___1 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  switch (stringset) {
  case 1U:
  i = 0;
  goto ldv_58240;
  ldv_58239:
  tmp___0 = strlen(bnad_net_stats_strings[i]);
  tmp___1 = ldv__builtin_expect(tmp___0 > 31UL, 0L);
  if (tmp___1 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bnad_ethtool.c"),
                         "i" (556), "i" (12UL));
    ldv_58238: ;
    goto ldv_58238;
  } else {
  }
  memcpy((void *)string, (void const *)bnad_net_stats_strings[i], 32UL);
  string = string + 32UL;
  i = i + 1;
  ldv_58240: ;
  if ((unsigned int )i <= 195U) {
    goto ldv_58239;
  } else {
  }
  bmap___0 = bnad->bna.tx_mod.rid_mask;
  i = 0;
  goto ldv_58243;
  ldv_58242: ;
  if ((int )bmap___0 & 1) {
    sprintf((char *)string, "txf%d_ucast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_ucast", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_ucast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_mcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_mcast", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_mcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_bcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_bcast", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_bcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_errors", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_filter_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "txf%d_filter_mac_sa", i);
    string = string + 32UL;
  } else {
  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58243: ;
  if (bmap___0 != 0U) {
    goto ldv_58242;
  } else {
  }
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_58246;
  ldv_58245: ;
  if ((int )bmap___0 & 1) {
    sprintf((char *)string, "rxf%d_ucast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_ucast", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_ucast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_mcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_mcast", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_mcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_bcast_octets", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_bcast", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_bcast_vlan", i);
    string = string + 32UL;
    sprintf((char *)string, "rxf%d_frame_drops", i);
    string = string + 32UL;
  } else {
  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58246: ;
  if (bmap___0 != 0U) {
    goto ldv_58245;
  } else {
  }
  q_num = 0;
  i = 0;
  goto ldv_58253;
  ldv_58252: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58248;
  } else {
  }
  j = 0;
  goto ldv_58250;
  ldv_58249:
  sprintf((char *)string, "cq%d_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_consumer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_hw_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_intr", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_poll", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_schedule", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_keep_poll", q_num);
  string = string + 32UL;
  sprintf((char *)string, "cq%d_complete", q_num);
  string = string + 32UL;
  q_num = q_num + 1;
  j = j + 1;
  ldv_58250: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58249;
  } else {
  }
  ldv_58248:
  i = i + 1;
  ldv_58253: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58252;
  } else {
  }
  q_num = 0;
  i = 0;
  goto ldv_58260;
  ldv_58259: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58255;
  } else {
  }
  j = 0;
  goto ldv_58257;
  ldv_58256:
  sprintf((char *)string, "rxq%d_packets", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_bytes", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_packets_with_error", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_allocbuf_failed", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "rxq%d_consumer_index", q_num);
  string = string + 32UL;
  q_num = q_num + 1;
  if (((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0) && (unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0)) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
    sprintf((char *)string, "rxq%d_packets", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_bytes", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_packets_with_error", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_allocbuf_failed", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_producer_index", q_num);
    string = string + 32UL;
    sprintf((char *)string, "rxq%d_consumer_index", q_num);
    string = string + 32UL;
    q_num = q_num + 1;
  } else {
  }
  j = j + 1;
  ldv_58257: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58256;
  } else {
  }
  ldv_58255:
  i = i + 1;
  ldv_58260: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58259;
  } else {
  }
  q_num = 0;
  i = 0;
  goto ldv_58267;
  ldv_58266: ;
  if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
    goto ldv_58262;
  } else {
  }
  j = 0;
  goto ldv_58264;
  ldv_58263:
  sprintf((char *)string, "txq%d_packets", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_bytes", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_producer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_consumer_index", q_num);
  string = string + 32UL;
  sprintf((char *)string, "txq%d_hw_consumer_index", q_num);
  string = string + 32UL;
  q_num = q_num + 1;
  j = j + 1;
  ldv_58264: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_58263;
  } else {
  }
  ldv_58262:
  i = i + 1;
  ldv_58267: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58266;
  } else {
  }
  goto ldv_58269;
  default: ;
  goto ldv_58269;
  }
  ldv_58269:
  mutex_unlock(& bnad->conf_mutex);
  return;
}
}
static int bnad_get_stats_count_locked(struct net_device *netdev )
{
  struct bnad *bnad ;
  void *tmp ;
  int i ;
  int j ;
  int count ;
  int rxf_active_num ;
  int txf_active_num ;
  u32 bmap___0 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  count = 0;
  rxf_active_num = 0;
  txf_active_num = 0;
  bmap___0 = bnad->bna.tx_mod.rid_mask;
  i = 0;
  goto ldv_58282;
  ldv_58281: ;
  if ((int )bmap___0 & 1) {
    txf_active_num = txf_active_num + 1;
  } else {
  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58282: ;
  if (bmap___0 != 0U) {
    goto ldv_58281;
  } else {
  }
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_58285;
  ldv_58284: ;
  if ((int )bmap___0 & 1) {
    rxf_active_num = rxf_active_num + 1;
  } else {
  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58285: ;
  if (bmap___0 != 0U) {
    goto ldv_58284;
  } else {
  }
  count = (int )(((unsigned int )(txf_active_num * 12) + (unsigned int )(rxf_active_num * 10)) + 196U);
  i = 0;
  goto ldv_58292;
  ldv_58291: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58287;
  } else {
  }
  count = (int )(bnad->num_rxp_per_rx * 8U + (u32 )count);
  count = (int )(bnad->num_rxp_per_rx * 6U + (u32 )count);
  j = 0;
  goto ldv_58289;
  ldv_58288: ;
  if (((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0) && (unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0)) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
    count = count + 6;
  } else {
  }
  j = j + 1;
  ldv_58289: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58288;
  } else {
  }
  ldv_58287:
  i = i + 1;
  ldv_58292: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58291;
  } else {
  }
  i = 0;
  goto ldv_58296;
  ldv_58295: ;
  if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
    goto ldv_58294;
  } else {
  }
  count = (int )(bnad->num_txq_per_tx * 5U + (u32 )count);
  ldv_58294:
  i = i + 1;
  ldv_58296: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58295;
  } else {
  }
  return (count);
}
}
static int bnad_per_q_stats_fill(struct bnad *bnad , u64 *buf , int bi )
{
  int i ;
  int j ;
  struct bna_rcb *rcb ;
  struct bna_tcb *tcb ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  int tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;
  int tmp___15 ;
  int tmp___16 ;
  int tmp___17 ;
  int tmp___18 ;
  int tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  int tmp___22 ;
  int tmp___23 ;
  {
  rcb = (struct bna_rcb *)0;
  tcb = (struct bna_tcb *)0;
  i = 0;
  goto ldv_58312;
  ldv_58311: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58307;
  } else {
  }
  j = 0;
  goto ldv_58309;
  ldv_58308: ;
  if (((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0) && (unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0] != (unsigned long )((struct bna_rcb *)0)) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq != (unsigned long )((struct bna_rxq *)0)) {
    tmp = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp) = (u64 )(bnad->rx_info[i].rx_ctrl[j].ccb)->producer_index;
    tmp___0 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___0) = 0ULL;
    tmp___1 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___1) = (u64 )*((bnad->rx_info[i].rx_ctrl[j].ccb)->hw_producer_index);
    tmp___2 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___2) = bnad->rx_info[i].rx_ctrl[j].rx_intr_ctr;
    tmp___3 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___3) = bnad->rx_info[i].rx_ctrl[j].rx_poll_ctr;
    tmp___4 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___4) = bnad->rx_info[i].rx_ctrl[j].rx_schedule;
    tmp___5 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___5) = bnad->rx_info[i].rx_ctrl[j].rx_keep_poll;
    tmp___6 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___6) = bnad->rx_info[i].rx_ctrl[j].rx_complete;
  } else {
  }
  j = j + 1;
  ldv_58309: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58308;
  } else {
  }
  ldv_58307:
  i = i + 1;
  ldv_58312: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58311;
  } else {
  }
  i = 0;
  goto ldv_58319;
  ldv_58318: ;
  if ((unsigned long )bnad->rx_info[i].rx == (unsigned long )((struct bna_rx *)0)) {
    goto ldv_58314;
  } else {
  }
  j = 0;
  goto ldv_58316;
  ldv_58315: ;
  if ((unsigned long )bnad->rx_info[i].rx_ctrl[j].ccb != (unsigned long )((struct bna_ccb *)0)) {
    if ((unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0] != (unsigned long )((struct bna_rcb *)0) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0])->rxq != (unsigned long )((struct bna_rxq *)0)) {
      rcb = (bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[0];
      tmp___7 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___7) = (rcb->rxq)->rx_packets;
      tmp___8 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___8) = (rcb->rxq)->rx_bytes;
      tmp___9 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___9) = (rcb->rxq)->rx_packets_with_error;
      tmp___10 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___10) = (rcb->rxq)->rxbuf_alloc_failed;
      tmp___11 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___11) = (u64 )rcb->producer_index;
      tmp___12 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___12) = (u64 )rcb->consumer_index;
    } else {
    }
    if ((unsigned long )(bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1] != (unsigned long )((struct bna_rcb *)0) && (unsigned long )((bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1])->rxq != (unsigned long )((struct bna_rxq *)0)) {
      rcb = (bnad->rx_info[i].rx_ctrl[j].ccb)->rcb[1];
      tmp___13 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___13) = (rcb->rxq)->rx_packets;
      tmp___14 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___14) = (rcb->rxq)->rx_bytes;
      tmp___15 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___15) = (rcb->rxq)->rx_packets_with_error;
      tmp___16 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___16) = (rcb->rxq)->rxbuf_alloc_failed;
      tmp___17 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___17) = (u64 )rcb->producer_index;
      tmp___18 = bi;
      bi = bi + 1;
      *(buf + (unsigned long )tmp___18) = (u64 )rcb->consumer_index;
    } else {
    }
  } else {
  }
  j = j + 1;
  ldv_58316: ;
  if ((u32 )j < bnad->num_rxp_per_rx) {
    goto ldv_58315;
  } else {
  }
  ldv_58314:
  i = i + 1;
  ldv_58319: ;
  if ((u32 )i < bnad->num_rx) {
    goto ldv_58318;
  } else {
  }
  i = 0;
  goto ldv_58326;
  ldv_58325: ;
  if ((unsigned long )bnad->tx_info[i].tx == (unsigned long )((struct bna_tx *)0)) {
    goto ldv_58321;
  } else {
  }
  j = 0;
  goto ldv_58323;
  ldv_58322: ;
  if ((unsigned long )bnad->tx_info[i].tcb[j] != (unsigned long )((struct bna_tcb *)0) && (unsigned long )(bnad->tx_info[i].tcb[j])->txq != (unsigned long )((struct bna_txq *)0)) {
    tcb = bnad->tx_info[i].tcb[j];
    tmp___19 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___19) = (tcb->txq)->tx_packets;
    tmp___20 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___20) = (tcb->txq)->tx_bytes;
    tmp___21 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___21) = (u64 )tcb->producer_index;
    tmp___22 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___22) = (u64 )tcb->consumer_index;
    tmp___23 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___23) = (u64 )*(tcb->hw_consumer_index);
  } else {
  }
  j = j + 1;
  ldv_58323: ;
  if ((u32 )j < bnad->num_txq_per_tx) {
    goto ldv_58322;
  } else {
  }
  ldv_58321:
  i = i + 1;
  ldv_58326: ;
  if ((u32 )i < bnad->num_tx) {
    goto ldv_58325;
  } else {
  }
  return (bi);
}
}
static void bnad_get_ethtool_stats(struct net_device *netdev , struct ethtool_stats *stats ,
                                   u64 *buf )
{
  struct bnad *bnad ;
  void *tmp ;
  int i ;
  int j ;
  int bi ;
  unsigned long flags ;
  struct rtnl_link_stats64 *net_stats64 ;
  u64 *stats64 ;
  u32 bmap___0 ;
  int tmp___0 ;
  bool tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  tmp___0 = bnad_get_stats_count_locked(netdev);
  if ((__u32 )tmp___0 != stats->n_stats) {
    mutex_unlock(& bnad->conf_mutex);
    return;
  } else {
  }
  ldv_spin_lock();
  bi = 0;
  memset((void *)buf, 0, (unsigned long )stats->n_stats * 8UL);
  net_stats64 = (struct rtnl_link_stats64 *)buf;
  bnad_netdev_qstats_fill(bnad, net_stats64);
  bnad_netdev_hwstats_fill(bnad, net_stats64);
  bi = 23;
  tmp___1 = netif_queue_stopped((struct net_device const *)netdev);
  bnad->stats.drv_stats.netif_queue_stopped = (u64 )tmp___1;
  stats64 = (u64 *)(& bnad->stats.drv_stats);
  i = 0;
  goto ldv_58342;
  ldv_58341:
  tmp___2 = bi;
  bi = bi + 1;
  *(buf + (unsigned long )tmp___2) = *(stats64 + (unsigned long )i);
  i = i + 1;
  ldv_58342: ;
  if ((unsigned int )i <= 32U) {
    goto ldv_58341;
  } else {
  }
  stats64 = (u64 *)(& (bnad->stats.bna_stats)->hw_stats);
  i = 0;
  goto ldv_58345;
  ldv_58344:
  tmp___3 = bi;
  bi = bi + 1;
  *(buf + (unsigned long )tmp___3) = *(stats64 + (unsigned long )i);
  i = i + 1;
  ldv_58345: ;
  if ((unsigned int )i <= 139U) {
    goto ldv_58344;
  } else {
  }
  bmap___0 = bnad->bna.tx_mod.rid_mask;
  i = 0;
  goto ldv_58351;
  ldv_58350: ;
  if ((int )bmap___0 & 1) {
    stats64 = (u64 *)(& (bnad->stats.bna_stats)->hw_stats.txf_stats) + (unsigned long )i;
    j = 0;
    goto ldv_58348;
    ldv_58347:
    tmp___4 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___4) = *(stats64 + (unsigned long )j);
    j = j + 1;
    ldv_58348: ;
    if ((unsigned int )j <= 11U) {
      goto ldv_58347;
    } else {
    }
  } else {
  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58351: ;
  if (bmap___0 != 0U) {
    goto ldv_58350;
  } else {
  }
  bmap___0 = bnad->bna.rx_mod.rid_mask;
  i = 0;
  goto ldv_58357;
  ldv_58356: ;
  if ((int )bmap___0 & 1) {
    stats64 = (u64 *)(& (bnad->stats.bna_stats)->hw_stats.rxf_stats) + (unsigned long )i;
    j = 0;
    goto ldv_58354;
    ldv_58353:
    tmp___5 = bi;
    bi = bi + 1;
    *(buf + (unsigned long )tmp___5) = *(stats64 + (unsigned long )j);
    j = j + 1;
    ldv_58354: ;
    if ((unsigned int )j <= 9U) {
      goto ldv_58353;
    } else {
    }
  } else {
  }
  bmap___0 = bmap___0 >> 1;
  i = i + 1;
  ldv_58357: ;
  if (bmap___0 != 0U) {
    goto ldv_58356;
  } else {
  }
  bi = bnad_per_q_stats_fill(bnad, buf, bi);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  mutex_unlock(& bnad->conf_mutex);
  return;
}
}
static int bnad_get_sset_count(struct net_device *netdev , int sset )
{
  int tmp ;
  {
  switch (sset) {
  case 1:
  tmp = bnad_get_stats_count_locked(netdev);
  return (tmp);
  default: ;
  return (-95);
  }
}
}
static u32 bnad_get_flash_partition_by_offset(struct bnad *bnad , u32 offset , u32 *base_offset )
{
  struct bfa_flash_attr *flash_attr ;
  struct bnad_iocmd_comp fcomp ;
  u32 i ;
  u32 flash_part ;
  u32 ret ;
  unsigned long flags ;
  void *tmp ;
  enum bfa_status tmp___0 ;
  {
  flash_part = 0U;
  flags = 0UL;
  tmp = kzalloc(1032UL, 208U);
  flash_attr = (struct bfa_flash_attr *)tmp;
  if ((unsigned long )flash_attr == (unsigned long )((struct bfa_flash_attr *)0)) {
    return (0U);
  } else {
  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_get_attr(& bnad->bna.flash, flash_attr, & bnad_cb_completion,
                                  (void *)(& fcomp));
  ret = (u32 )tmp___0;
  if (ret != 0U) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    kfree((void const *)flash_attr);
    return (0U);
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  ret = (u32 )fcomp.comp_status;
  if (ret == 0U) {
    i = 0U;
    goto ldv_58378;
    ldv_58377: ;
    if (flash_attr->part[i].part_off <= offset && flash_attr->part[i].part_off + flash_attr->part[i].part_size > offset) {
      flash_part = flash_attr->part[i].part_type;
      *base_offset = flash_attr->part[i].part_off;
      goto ldv_58376;
    } else {
    }
    i = i + 1U;
    ldv_58378: ;
    if (flash_attr->npart > i) {
      goto ldv_58377;
    } else {
    }
    ldv_58376: ;
  } else {
  }
  kfree((void const *)flash_attr);
  return (flash_part);
}
}
static int bnad_get_eeprom_len(struct net_device *netdev )
{
  {
  return (4194304);
}
}
static int bnad_get_eeprom(struct net_device *netdev , struct ethtool_eeprom *eeprom ,
                           u8 *bytes )
{
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_iocmd_comp fcomp ;
  u32 flash_part ;
  u32 base_offset ;
  unsigned long flags ;
  int ret ;
  enum bfa_status tmp___0 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  flash_part = 0U;
  base_offset = 0U;
  flags = 0UL;
  ret = 0;
  eeprom->magic = (__u32 )((int )(bnad->pcidev)->vendor | ((int )(bnad->pcidev)->device << 16));
  flash_part = bnad_get_flash_partition_by_offset(bnad, eeprom->offset, & base_offset);
  if (flash_part == 0U) {
    return (-14);
  } else {
  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_read_part(& bnad->bna.flash, flash_part, (int )((u8 )bnad->id),
                                   (void *)bytes, eeprom->len, eeprom->offset - base_offset,
                                   & bnad_cb_completion, (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto done;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  ret = fcomp.comp_status;
  done: ;
  return (ret);
}
}
static int bnad_set_eeprom(struct net_device *netdev , struct ethtool_eeprom *eeprom ,
                           u8 *bytes )
{
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_iocmd_comp fcomp ;
  u32 flash_part ;
  u32 base_offset ;
  unsigned long flags ;
  int ret ;
  enum bfa_status tmp___0 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  flash_part = 0U;
  base_offset = 0U;
  flags = 0UL;
  ret = 0;
  if (eeprom->magic != (__u32 )((int )(bnad->pcidev)->vendor | ((int )(bnad->pcidev)->device << 16))) {
    return (-22);
  } else {
  }
  flash_part = bnad_get_flash_partition_by_offset(bnad, eeprom->offset, & base_offset);
  if (flash_part == 0U) {
    return (-14);
  } else {
  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_update_part(& bnad->bna.flash, flash_part, (int )((u8 )bnad->id),
                                     (void *)bytes, eeprom->len, eeprom->offset - base_offset,
                                     & bnad_cb_completion, (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto done;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  ret = fcomp.comp_status;
  done: ;
  return (ret);
}
}
static int bnad_flash_device(struct net_device *netdev , struct ethtool_flash *eflash )
{
  struct bnad *bnad ;
  void *tmp ;
  struct bnad_iocmd_comp fcomp ;
  struct firmware const *fw ;
  int ret ;
  enum bfa_status tmp___0 ;
  {
  tmp = netdev_priv((struct net_device const *)netdev);
  bnad = (struct bnad *)tmp;
  ret = 0;
  ret = request_firmware(& fw, (char const *)(& eflash->data), & (bnad->pcidev)->dev);
  if (ret != 0) {
    netdev_err((struct net_device const *)netdev, "can\'t load firmware %s\n", (char *)(& eflash->data));
    goto out;
  } else {
  }
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  spin_lock_irq(& bnad->bna_lock);
  tmp___0 = bfa_nw_flash_update_part(& bnad->bna.flash, 2U, (int )((u8 )bnad->id),
                                     (void *)fw->data, (u32 )fw->size, 0U, & bnad_cb_completion,
                                     (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    netdev_warn((struct net_device const *)netdev, "flash update failed with err=%d\n",
                ret);
    ret = -5;
    spin_unlock_irq(& bnad->bna_lock);
    goto out;
  } else {
  }
  spin_unlock_irq(& bnad->bna_lock);
  wait_for_completion(& fcomp.comp);
  if (fcomp.comp_status != 0) {
    ret = -5;
    netdev_warn((struct net_device const *)netdev, "firmware image update failed with err=%d\n",
                fcomp.comp_status);
  } else {
  }
  out:
  release_firmware(fw);
  return (ret);
}
}
static struct ethtool_ops const bnad_ethtool_ops =
     {& bnad_get_settings, & bnad_set_settings, & bnad_get_drvinfo, 0, 0, & bnad_get_wol,
    0, 0, 0, 0, & ethtool_op_get_link, & bnad_get_eeprom_len, & bnad_get_eeprom, & bnad_set_eeprom,
    & bnad_get_coalesce, & bnad_set_coalesce, & bnad_get_ringparam, & bnad_set_ringparam,
    & bnad_get_pauseparam, & bnad_set_pauseparam, 0, & bnad_get_strings, 0, & bnad_get_ethtool_stats,
    0, 0, 0, 0, & bnad_get_sset_count, 0, 0, & bnad_flash_device, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, & ethtool_op_get_ts_info, 0, 0, 0, 0, 0, 0};
void bnad_set_ethtool_ops(struct net_device *netdev )
{
  {
  netdev->ethtool_ops = & bnad_ethtool_ops;
  return;
}
}
void ldv_initialize_ethtool_ops_19(void)
{
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;
  {
  tmp = ldv_init_zalloc(92UL);
  bnad_ethtool_ops_group4 = (struct ethtool_coalesce *)tmp;
  tmp___0 = ldv_init_zalloc(36UL);
  bnad_ethtool_ops_group0 = (struct ethtool_ringparam *)tmp___0;
  tmp___1 = ldv_init_zalloc(3008UL);
  bnad_ethtool_ops_group5 = (struct net_device *)tmp___1;
  tmp___2 = ldv_init_zalloc(16UL);
  bnad_ethtool_ops_group2 = (struct ethtool_eeprom *)tmp___2;
  tmp___3 = ldv_init_zalloc(44UL);
  bnad_ethtool_ops_group1 = (struct ethtool_cmd *)tmp___3;
  tmp___4 = ldv_init_zalloc(16UL);
  bnad_ethtool_ops_group3 = (struct ethtool_pauseparam *)tmp___4;
  return;
}
}
void ldv_main_exported_19(void)
{
  u8 *ldvarg52 ;
  void *tmp ;
  u32 ldvarg55 ;
  struct ethtool_wolinfo *ldvarg53 ;
  void *tmp___0 ;
  struct ethtool_stats *ldvarg61 ;
  void *tmp___1 ;
  struct ethtool_ts_info *ldvarg58 ;
  void *tmp___2 ;
  u8 *ldvarg54 ;
  void *tmp___3 ;
  struct ethtool_flash *ldvarg57 ;
  void *tmp___4 ;
  struct ethtool_drvinfo *ldvarg62 ;
  void *tmp___5 ;
  u8 *ldvarg56 ;
  void *tmp___6 ;
  int ldvarg59 ;
  u64 *ldvarg60 ;
  void *tmp___7 ;
  int tmp___8 ;
  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg52 = (u8 *)tmp;
  tmp___0 = ldv_init_zalloc(20UL);
  ldvarg53 = (struct ethtool_wolinfo *)tmp___0;
  tmp___1 = ldv_init_zalloc(8UL);
  ldvarg61 = (struct ethtool_stats *)tmp___1;
  tmp___2 = ldv_init_zalloc(44UL);
  ldvarg58 = (struct ethtool_ts_info *)tmp___2;
  tmp___3 = ldv_init_zalloc(1UL);
  ldvarg54 = (u8 *)tmp___3;
  tmp___4 = ldv_init_zalloc(136UL);
  ldvarg57 = (struct ethtool_flash *)tmp___4;
  tmp___5 = ldv_init_zalloc(196UL);
  ldvarg62 = (struct ethtool_drvinfo *)tmp___5;
  tmp___6 = ldv_init_zalloc(1UL);
  ldvarg56 = (u8 *)tmp___6;
  tmp___7 = ldv_init_zalloc(8UL);
  ldvarg60 = (u64 *)tmp___7;
  ldv_memset((void *)(& ldvarg55), 0, 4UL);
  ldv_memset((void *)(& ldvarg59), 0, 4UL);
  tmp___8 = __VERIFIER_nondet_int();
  switch (tmp___8) {
  case 0: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_drvinfo(bnad_ethtool_ops_group5, ldvarg62);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 1: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_pauseparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group3);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 2: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_coalesce(bnad_ethtool_ops_group5, bnad_ethtool_ops_group4);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 3: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_ethtool_stats(bnad_ethtool_ops_group5, ldvarg61, ldvarg60);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 4: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_ringparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group0);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 5: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_pauseparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group3);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 6: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_sset_count(bnad_ethtool_ops_group5, ldvarg59);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 7: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_settings(bnad_ethtool_ops_group5, bnad_ethtool_ops_group1);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 8: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_coalesce(bnad_ethtool_ops_group5, bnad_ethtool_ops_group4);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 9: ;
  if (ldv_state_variable_19 == 1) {
    ethtool_op_get_ts_info(bnad_ethtool_ops_group5, ldvarg58);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 10: ;
  if (ldv_state_variable_19 == 1) {
    bnad_flash_device(bnad_ethtool_ops_group5, ldvarg57);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 11: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_eeprom_len(bnad_ethtool_ops_group5);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 12: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_settings(bnad_ethtool_ops_group5, bnad_ethtool_ops_group1);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 13: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_eeprom(bnad_ethtool_ops_group5, bnad_ethtool_ops_group2, ldvarg56);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 14: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_strings(bnad_ethtool_ops_group5, ldvarg55, ldvarg54);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 15: ;
  if (ldv_state_variable_19 == 1) {
    bnad_get_wol(bnad_ethtool_ops_group5, ldvarg53);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 16: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_eeprom(bnad_ethtool_ops_group5, bnad_ethtool_ops_group2, ldvarg52);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 17: ;
  if (ldv_state_variable_19 == 1) {
    bnad_set_ringparam(bnad_ethtool_ops_group5, bnad_ethtool_ops_group0);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  case 18: ;
  if (ldv_state_variable_19 == 1) {
    ethtool_op_get_link(bnad_ethtool_ops_group5);
    ldv_state_variable_19 = 1;
  } else {
  }
  goto ldv_58437;
  default:
  ldv_stop();
  }
  ldv_58437: ;
  return;
}
}
__inline static void spin_lock_irq(spinlock_t *lock )
{
  {
  ldv_spin_lock();
  ldv_spin_lock_irq_107(lock);
  return;
}
}
__inline static void spin_unlock_irq(spinlock_t *lock )
{
  {
  ldv_spin_unlock();
  ldv_spin_unlock_irq_110(lock);
  return;
}
}
bool ldv_queue_work_on_114(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_115(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_116(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_117(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_118(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_124(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_130(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_132(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_134(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_135(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_136(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_137(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_138(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_139(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_140(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
void *ldv_kmem_cache_alloc_141(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_del_timer_sync_142(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer_sync(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
extern int snprintf(char * , size_t , char const * , ...) ;
extern int sscanf(char const * , char const * , ...) ;
bool ldv_is_err(void const *ptr ) ;
long ldv_ptr_err(void const *ptr ) ;
extern void *memdup_user(void const * , size_t ) ;
__inline static long PTR_ERR(void const *ptr ) ;
__inline static bool IS_ERR(void const *ptr ) ;
__inline static void atomic_set(atomic_t *v , int i )
{
  {
  v->counter = i;
  return;
}
}
__inline static void atomic_dec(atomic_t *v )
{
  {
  __asm__ volatile (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0": "+m" (v->counter));
  return;
}
}
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) ;
__inline static void reinit_completion(struct completion *x )
{
  {
  x->done = 0U;
  return;
}
}
bool ldv_queue_work_on_163(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_165(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_164(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_167(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_166(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_173(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
void *ldv_kmem_cache_alloc_190(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
__inline static void *kzalloc(size_t size , gfp_t flags ) ;
extern loff_t fixed_size_llseek(struct file * , loff_t , int , loff_t ) ;
extern ssize_t simple_read_from_buffer(void * , size_t , loff_t * , void const * ,
                                       size_t ) ;
extern struct dentry *debugfs_create_file(char const * , umode_t , struct dentry * ,
                                          void * , struct file_operations const * ) ;
extern struct dentry *debugfs_create_dir(char const * , struct dentry * ) ;
extern void debugfs_remove(struct dentry * ) ;
struct sk_buff *ldv_skb_clone_181(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_189(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_183(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_179(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_187(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_188(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_184(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_185(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_186(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
int bfa_nw_ioc_debug_fwtrc(struct bfa_ioc *ioc , void *trcdata , int *trclen ) ;
int bfa_nw_ioc_debug_fwsave(struct bfa_ioc *ioc , void *trcdata , int *trclen ) ;
enum bfa_status bfa_nw_cee_get_attr(struct bfa_cee *cee , struct bfa_cee_attr *attr ,
                                    void (*cbfn)(void * , enum bfa_status ) , void *cbarg ) ;
static int bnad_debugfs_open_fwtrc(struct inode *inode , struct file *file )
{
  struct bnad *bnad ;
  struct bnad_debug_info *fw_debug ;
  unsigned long flags ;
  int rc ;
  void *tmp ;
  void *tmp___0 ;
  {
  bnad = (struct bnad *)inode->i_private;
  tmp = kzalloc(24UL, 208U);
  fw_debug = (struct bnad_debug_info *)tmp;
  if ((unsigned long )fw_debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {
  }
  fw_debug->buffer_len = 4128;
  tmp___0 = kzalloc((size_t )fw_debug->buffer_len, 208U);
  fw_debug->debug_buffer = (char *)tmp___0;
  if ((unsigned long )fw_debug->debug_buffer == (unsigned long )((char *)0)) {
    kfree((void const *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    return (-12);
  } else {
  }
  ldv_spin_lock();
  rc = bfa_nw_ioc_debug_fwtrc(& bnad->bna.ioceth.ioc, (void *)fw_debug->debug_buffer,
                              & fw_debug->buffer_len);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (rc != 0) {
    kfree((void const *)fw_debug->debug_buffer);
    fw_debug->debug_buffer = (char *)0;
    kfree((void const *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    netdev_warn((struct net_device const *)bnad->netdev, "failed to collect fwtrc\n");
    return (-12);
  } else {
  }
  file->private_data = (void *)fw_debug;
  return (0);
}
}
static int bnad_debugfs_open_fwsave(struct inode *inode , struct file *file )
{
  struct bnad *bnad ;
  struct bnad_debug_info *fw_debug ;
  unsigned long flags ;
  int rc ;
  void *tmp ;
  void *tmp___0 ;
  {
  bnad = (struct bnad *)inode->i_private;
  tmp = kzalloc(24UL, 208U);
  fw_debug = (struct bnad_debug_info *)tmp;
  if ((unsigned long )fw_debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {
  }
  fw_debug->buffer_len = 4128;
  tmp___0 = kzalloc((size_t )fw_debug->buffer_len, 208U);
  fw_debug->debug_buffer = (char *)tmp___0;
  if ((unsigned long )fw_debug->debug_buffer == (unsigned long )((char *)0)) {
    kfree((void const *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    return (-12);
  } else {
  }
  ldv_spin_lock();
  rc = bfa_nw_ioc_debug_fwsave(& bnad->bna.ioceth.ioc, (void *)fw_debug->debug_buffer,
                               & fw_debug->buffer_len);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  if (rc != 0 && rc != 78) {
    kfree((void const *)fw_debug->debug_buffer);
    fw_debug->debug_buffer = (char *)0;
    kfree((void const *)fw_debug);
    fw_debug = (struct bnad_debug_info *)0;
    netdev_warn((struct net_device const *)bnad->netdev, "failed to collect fwsave\n");
    return (-12);
  } else {
  }
  file->private_data = (void *)fw_debug;
  return (0);
}
}
static int bnad_debugfs_open_reg(struct inode *inode , struct file *file )
{
  struct bnad_debug_info *reg_debug ;
  void *tmp ;
  {
  tmp = kzalloc(24UL, 208U);
  reg_debug = (struct bnad_debug_info *)tmp;
  if ((unsigned long )reg_debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {
  }
  reg_debug->i_private = inode->i_private;
  file->private_data = (void *)reg_debug;
  return (0);
}
}
static int bnad_get_debug_drvinfo(struct bnad *bnad , void *buffer , u32 len )
{
  struct bnad_drvinfo *drvinfo ;
  struct bnad_iocmd_comp fcomp ;
  unsigned long flags ;
  int ret ;
  enum bfa_status tmp ;
  enum bfa_status tmp___0 ;
  {
  drvinfo = (struct bnad_drvinfo *)buffer;
  flags = 0UL;
  ret = 1;
  ldv_spin_lock();
  bfa_nw_ioc_get_attr(& bnad->bna.ioceth.ioc, & drvinfo->ioc_attr);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  fcomp.bnad = bnad;
  fcomp.comp_status = 0;
  init_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp = bfa_nw_cee_get_attr(& bnad->bna.cee, & drvinfo->cee_attr, & bnad_cb_completion,
                            (void *)(& fcomp));
  ret = (int )tmp;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto out;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  drvinfo->cee_status = (u32 )fcomp.comp_status;
  fcomp.comp_status = 0;
  reinit_completion(& fcomp.comp);
  ldv_spin_lock();
  tmp___0 = bfa_nw_flash_get_attr(& bnad->bna.flash, & drvinfo->flash_attr, & bnad_cb_completion,
                                  (void *)(& fcomp));
  ret = (int )tmp___0;
  if (ret != 0) {
    spin_unlock_irqrestore(& bnad->bna_lock, flags);
    goto out;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  wait_for_completion(& fcomp.comp);
  drvinfo->flash_status = (u32 )fcomp.comp_status;
  out: ;
  return (ret);
}
}
static int bnad_debugfs_open_drvinfo(struct inode *inode , struct file *file )
{
  struct bnad *bnad ;
  struct bnad_debug_info *drv_info ;
  int rc ;
  void *tmp ;
  void *tmp___0 ;
  {
  bnad = (struct bnad *)inode->i_private;
  tmp = kzalloc(24UL, 208U);
  drv_info = (struct bnad_debug_info *)tmp;
  if ((unsigned long )drv_info == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-12);
  } else {
  }
  drv_info->buffer_len = 3472;
  tmp___0 = kzalloc((size_t )drv_info->buffer_len, 208U);
  drv_info->debug_buffer = (char *)tmp___0;
  if ((unsigned long )drv_info->debug_buffer == (unsigned long )((char *)0)) {
    kfree((void const *)drv_info);
    drv_info = (struct bnad_debug_info *)0;
    return (-12);
  } else {
  }
  mutex_lock_nested(& bnad->conf_mutex, 0U);
  rc = bnad_get_debug_drvinfo(bnad, (void *)drv_info->debug_buffer, (u32 )drv_info->buffer_len);
  mutex_unlock(& bnad->conf_mutex);
  if (rc != 0) {
    kfree((void const *)drv_info->debug_buffer);
    drv_info->debug_buffer = (char *)0;
    kfree((void const *)drv_info);
    drv_info = (struct bnad_debug_info *)0;
    netdev_warn((struct net_device const *)bnad->netdev, "failed to collect drvinfo\n");
    return (-12);
  } else {
  }
  file->private_data = (void *)drv_info;
  return (0);
}
}
static loff_t bnad_debugfs_lseek(struct file *file , loff_t offset , int orig )
{
  struct bnad_debug_info *debug ;
  loff_t tmp ;
  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (-22LL);
  } else {
  }
  tmp = fixed_size_llseek(file, offset, orig, (loff_t )debug->buffer_len);
  return (tmp);
}
}
static ssize_t bnad_debugfs_read(struct file *file , char *buf , size_t nbytes , loff_t *pos )
{
  struct bnad_debug_info *debug ;
  ssize_t tmp ;
  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0) || (unsigned long )debug->debug_buffer == (unsigned long )((char *)0)) {
    return (0L);
  } else {
  }
  tmp = simple_read_from_buffer((void *)buf, nbytes, pos, (void const *)debug->debug_buffer,
                                (size_t )debug->buffer_len);
  return (tmp);
}
}
static int bna_reg_offset_check(struct bfa_ioc *ioc , u32 offset , u32 len )
{
  u8 area ;
  {
  area = (unsigned int )((u8 )(offset >> 15)) & 7U;
  if ((unsigned int )area == 0U) {
    if ((len << 2) + offset > 32768U) {
      return (2);
    } else {
    }
  } else
  if ((unsigned int )area == 1U) {
    if ((len << 2) + offset > 65536U) {
      return (2);
    } else {
    }
  } else
  if ((len << 2) + offset > (((unsigned int )ioc->pcidev.device_id == 20U || (unsigned int )ioc->pcidev.device_id == 33U) || (unsigned int )ioc->pcidev.device_id == 34U ? 262143U : 131071U)) {
    return (2);
  } else {
  }
  return (0);
}
}
static ssize_t bnad_debugfs_read_regrd(struct file *file , char *buf , size_t nbytes ,
                                       loff_t *pos )
{
  struct bnad_debug_info *regrd_debug ;
  struct bnad *bnad ;
  ssize_t rc ;
  {
  regrd_debug = (struct bnad_debug_info *)file->private_data;
  bnad = (struct bnad *)regrd_debug->i_private;
  if ((unsigned long )bnad->regdata == (unsigned long )((char *)0)) {
    return (0L);
  } else {
  }
  rc = simple_read_from_buffer((void *)buf, nbytes, pos, (void const *)bnad->regdata,
                               (size_t )bnad->reglen);
  if ((unsigned long long )*pos + (unsigned long long )nbytes >= (unsigned long long )bnad->reglen) {
    kfree((void const *)bnad->regdata);
    bnad->regdata = (char *)0;
    bnad->reglen = 0U;
  } else {
  }
  return (rc);
}
}
static ssize_t bnad_debugfs_write_regrd(struct file *file , char const *buf , size_t nbytes ,
                                        loff_t *ppos )
{
  struct bnad_debug_info *regrd_debug ;
  struct bnad *bnad ;
  struct bfa_ioc *ioc ;
  int addr ;
  int len ;
  int rc ;
  int i ;
  u32 *regbuf ;
  void *rb ;
  void *reg_addr ;
  unsigned long flags ;
  void *kern_buf ;
  long tmp ;
  bool tmp___0 ;
  void *tmp___1 ;
  {
  regrd_debug = (struct bnad_debug_info *)file->private_data;
  bnad = (struct bnad *)regrd_debug->i_private;
  ioc = & bnad->bna.ioceth.ioc;
  kern_buf = memdup_user((void const *)buf, nbytes);
  tmp___0 = IS_ERR((void const *)kern_buf);
  if ((int )tmp___0) {
    tmp = PTR_ERR((void const *)kern_buf);
    return (tmp);
  } else {
  }
  rc = sscanf((char const *)kern_buf, "%x:%x", & addr, & len);
  if (rc <= 1) {
    netdev_warn((struct net_device const *)bnad->netdev, "failed to read user buffer\n");
    kfree((void const *)kern_buf);
    return (-22L);
  } else {
  }
  kfree((void const *)kern_buf);
  kfree((void const *)bnad->regdata);
  bnad->reglen = 0U;
  tmp___1 = kzalloc((size_t )(len << 2), 208U);
  bnad->regdata = (char *)tmp___1;
  if ((unsigned long )bnad->regdata == (unsigned long )((char *)0)) {
    return (-12L);
  } else {
  }
  bnad->reglen = (u32 )(len << 2);
  rb = ioc->pcidev.pci_bar_kva;
  addr = (int )((((unsigned int )ioc->pcidev.device_id == 20U || (unsigned int )ioc->pcidev.device_id == 33U) || (unsigned int )ioc->pcidev.device_id == 34U ? 262143U : 131071U) & (unsigned int )addr);
  rc = bna_reg_offset_check(ioc, (u32 )addr, (u32 )len);
  if (rc != 0) {
    netdev_warn((struct net_device const *)bnad->netdev, "failed reg offset check\n");
    kfree((void const *)bnad->regdata);
    bnad->regdata = (char *)0;
    bnad->reglen = 0U;
    return (-22L);
  } else {
  }
  reg_addr = rb + (unsigned long )addr;
  regbuf = (u32 *)bnad->regdata;
  ldv_spin_lock();
  i = 0;
  goto ldv_58378;
  ldv_58377:
  *regbuf = readl((void const volatile *)reg_addr);
  regbuf = regbuf + 1;
  reg_addr = reg_addr + 4UL;
  i = i + 1;
  ldv_58378: ;
  if (i < len) {
    goto ldv_58377;
  } else {
  }
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return ((ssize_t )nbytes);
}
}
static ssize_t bnad_debugfs_write_regwr(struct file *file , char const *buf , size_t nbytes ,
                                        loff_t *ppos )
{
  struct bnad_debug_info *debug ;
  struct bnad *bnad ;
  struct bfa_ioc *ioc ;
  int addr ;
  int val ;
  int rc ;
  void *reg_addr ;
  unsigned long flags ;
  void *kern_buf ;
  long tmp ;
  bool tmp___0 ;
  {
  debug = (struct bnad_debug_info *)file->private_data;
  bnad = (struct bnad *)debug->i_private;
  ioc = & bnad->bna.ioceth.ioc;
  kern_buf = memdup_user((void const *)buf, nbytes);
  tmp___0 = IS_ERR((void const *)kern_buf);
  if ((int )tmp___0) {
    tmp = PTR_ERR((void const *)kern_buf);
    return (tmp);
  } else {
  }
  rc = sscanf((char const *)kern_buf, "%x:%x", & addr, & val);
  if (rc <= 1) {
    netdev_warn((struct net_device const *)bnad->netdev, "failed to read user buffer\n");
    kfree((void const *)kern_buf);
    return (-22L);
  } else {
  }
  kfree((void const *)kern_buf);
  addr = (int )((((unsigned int )ioc->pcidev.device_id == 20U || (unsigned int )ioc->pcidev.device_id == 33U) || (unsigned int )ioc->pcidev.device_id == 34U ? 262143U : 131071U) & (unsigned int )addr);
  rc = bna_reg_offset_check(ioc, (u32 )addr, 1U);
  if (rc != 0) {
    netdev_warn((struct net_device const *)bnad->netdev, "failed reg offset check\n");
    return (-22L);
  } else {
  }
  reg_addr = ioc->pcidev.pci_bar_kva + (unsigned long )addr;
  ldv_spin_lock();
  writel((unsigned int )val, (void volatile *)reg_addr);
  spin_unlock_irqrestore(& bnad->bna_lock, flags);
  return ((ssize_t )nbytes);
}
}
static int bnad_debugfs_release(struct inode *inode , struct file *file )
{
  struct bnad_debug_info *debug ;
  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (0);
  } else {
  }
  file->private_data = (void *)0;
  kfree((void const *)debug);
  return (0);
}
}
static int bnad_debugfs_buffer_release(struct inode *inode , struct file *file )
{
  struct bnad_debug_info *debug ;
  {
  debug = (struct bnad_debug_info *)file->private_data;
  if ((unsigned long )debug == (unsigned long )((struct bnad_debug_info *)0)) {
    return (0);
  } else {
  }
  kfree((void const *)debug->debug_buffer);
  file->private_data = (void *)0;
  kfree((void const *)debug);
  debug = (struct bnad_debug_info *)0;
  return (0);
}
}
static struct file_operations const bnad_debugfs_op_fwtrc =
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read, 0, 0, 0, 0, 0, 0,
    0, 0, 0, & bnad_debugfs_open_fwtrc, 0, & bnad_debugfs_buffer_release, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations const bnad_debugfs_op_fwsave =
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read, 0, 0, 0, 0, 0, 0,
    0, 0, 0, & bnad_debugfs_open_fwsave, 0, & bnad_debugfs_buffer_release, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations const bnad_debugfs_op_regrd =
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read_regrd, & bnad_debugfs_write_regrd,
    0, 0, 0, 0, 0, 0, 0, 0, & bnad_debugfs_open_reg, 0, & bnad_debugfs_release, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations const bnad_debugfs_op_regwr =
     {& __this_module, & bnad_debugfs_lseek, 0, & bnad_debugfs_write_regwr, 0, 0, 0,
    0, 0, 0, 0, 0, & bnad_debugfs_open_reg, 0, & bnad_debugfs_release, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct file_operations const bnad_debugfs_op_drvinfo =
     {& __this_module, & bnad_debugfs_lseek, & bnad_debugfs_read, 0, 0, 0, 0, 0, 0,
    0, 0, 0, & bnad_debugfs_open_drvinfo, 0, & bnad_debugfs_buffer_release, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static struct bnad_debugfs_entry const bnad_debugfs_files[5U] = { {"fwtrc", 33060U, & bnad_debugfs_op_fwtrc},
        {"fwsave", 33060U, & bnad_debugfs_op_fwsave},
        {"regrd", 33188U, & bnad_debugfs_op_regrd},
        {"regwr", 32896U, & bnad_debugfs_op_regwr},
        {"drvinfo", 33060U, & bnad_debugfs_op_drvinfo}};
static struct dentry *bna_debugfs_root ;
static atomic_t bna_debugfs_port_count ;
void bnad_debugfs_init(struct bnad *bnad )
{
  struct bnad_debugfs_entry const *file ;
  char name[64U] ;
  int i ;
  char const *tmp ;
  {
  if ((unsigned long )bna_debugfs_root == (unsigned long )((struct dentry *)0)) {
    bna_debugfs_root = debugfs_create_dir("bna", (struct dentry *)0);
    atomic_set(& bna_debugfs_port_count, 0);
    if ((unsigned long )bna_debugfs_root == (unsigned long )((struct dentry *)0)) {
      netdev_warn((struct net_device const *)bnad->netdev, "debugfs root dir creation failed\n");
      return;
    } else {
    }
  } else {
  }
  tmp = pci_name((struct pci_dev const *)bnad->pcidev);
  snprintf((char *)(& name), 64UL, "pci_dev:%s", tmp);
  if ((unsigned long )bnad->port_debugfs_root == (unsigned long )((struct dentry *)0)) {
    bnad->port_debugfs_root = debugfs_create_dir((char const *)(& name), bna_debugfs_root);
    if ((unsigned long )bnad->port_debugfs_root == (unsigned long )((struct dentry *)0)) {
      netdev_warn((struct net_device const *)bnad->netdev, "debugfs root dir creation failed\n");
      return;
    } else {
    }
    atomic_inc(& bna_debugfs_port_count);
    i = 0;
    goto ldv_58426;
    ldv_58425:
    file = (struct bnad_debugfs_entry const *)(& bnad_debugfs_files) + (unsigned long )i;
    bnad->bnad_dentry_files[i] = debugfs_create_file(file->name, (int )file->mode,
                                                     bnad->port_debugfs_root, (void *)bnad,
                                                     file->fops);
    if ((unsigned long )bnad->bnad_dentry_files[i] == (unsigned long )((struct dentry *)0)) {
      netdev_warn((struct net_device const *)bnad->netdev, "create %s entry failed\n",
                  file->name);
      return;
    } else {
    }
    i = i + 1;
    ldv_58426: ;
    if ((unsigned int )i <= 4U) {
      goto ldv_58425;
    } else {
    }
  } else {
  }
  return;
}
}
void bnad_debugfs_uninit(struct bnad *bnad )
{
  int i ;
  int tmp ;
  {
  i = 0;
  goto ldv_58435;
  ldv_58434: ;
  if ((unsigned long )bnad->bnad_dentry_files[i] != (unsigned long )((struct dentry *)0)) {
    debugfs_remove(bnad->bnad_dentry_files[i]);
    bnad->bnad_dentry_files[i] = (struct dentry *)0;
  } else {
  }
  i = i + 1;
  ldv_58435: ;
  if ((unsigned int )i <= 4U) {
    goto ldv_58434;
  } else {
  }
  if ((unsigned long )bnad->port_debugfs_root != (unsigned long )((struct dentry *)0)) {
    debugfs_remove(bnad->port_debugfs_root);
    bnad->port_debugfs_root = (struct dentry *)0;
    atomic_dec(& bna_debugfs_port_count);
  } else {
  }
  tmp = atomic_read((atomic_t const *)(& bna_debugfs_port_count));
  if (tmp == 0) {
    debugfs_remove(bna_debugfs_root);
    bna_debugfs_root = (struct dentry *)0;
  } else {
  }
  return;
}
}
int ldv_retval_5 ;
int ldv_retval_8 ;
int ldv_retval_3 ;
int ldv_retval_2 ;
int ldv_retval_7 ;
void ldv_file_operations_15(void)
{
  void *tmp ;
  void *tmp___0 ;
  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_regwr_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_regwr_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_14(void)
{
  void *tmp ;
  void *tmp___0 ;
  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_drvinfo_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_drvinfo_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_16(void)
{
  void *tmp ;
  void *tmp___0 ;
  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_regrd_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_regrd_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_17(void)
{
  void *tmp ;
  void *tmp___0 ;
  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_fwsave_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_fwsave_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_file_operations_18(void)
{
  void *tmp ;
  void *tmp___0 ;
  {
  tmp = ldv_init_zalloc(1000UL);
  bnad_debugfs_op_fwtrc_group1 = (struct inode *)tmp;
  tmp___0 = ldv_init_zalloc(504UL);
  bnad_debugfs_op_fwtrc_group2 = (struct file *)tmp___0;
  return;
}
}
void ldv_main_exported_18(void)
{
  loff_t ldvarg19 ;
  char *ldvarg22 ;
  void *tmp ;
  loff_t *ldvarg20 ;
  void *tmp___0 ;
  int ldvarg18 ;
  size_t ldvarg21 ;
  int tmp___1 ;
  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg22 = (char *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg20 = (loff_t *)tmp___0;
  ldv_memset((void *)(& ldvarg19), 0, 8UL);
  ldv_memset((void *)(& ldvarg18), 0, 4UL);
  ldv_memset((void *)(& ldvarg21), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_18 == 1) {
    ldv_retval_3 = bnad_debugfs_open_fwtrc(bnad_debugfs_op_fwtrc_group1, bnad_debugfs_op_fwtrc_group2);
    if (ldv_retval_3 == 0) {
      ldv_state_variable_18 = 2;
      ref_cnt = ref_cnt + 1;
    } else {
    }
  } else {
  }
  goto ldv_58466;
  case 1: ;
  if (ldv_state_variable_18 == 2) {
    bnad_debugfs_buffer_release(bnad_debugfs_op_fwtrc_group1, bnad_debugfs_op_fwtrc_group2);
    ldv_state_variable_18 = 1;
    ref_cnt = ref_cnt - 1;
  } else {
  }
  goto ldv_58466;
  case 2: ;
  if (ldv_state_variable_18 == 2) {
    bnad_debugfs_read(bnad_debugfs_op_fwtrc_group2, ldvarg22, ldvarg21, ldvarg20);
    ldv_state_variable_18 = 2;
  } else {
  }
  goto ldv_58466;
  case 3: ;
  if (ldv_state_variable_18 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_fwtrc_group2, ldvarg19, ldvarg18);
    ldv_state_variable_18 = 2;
  } else {
  }
  goto ldv_58466;
  default:
  ldv_stop();
  }
  ldv_58466: ;
  return;
}
}
void ldv_main_exported_16(void)
{
  loff_t *ldvarg28 ;
  void *tmp ;
  size_t ldvarg29 ;
  loff_t *ldvarg25 ;
  void *tmp___0 ;
  char *ldvarg30 ;
  void *tmp___1 ;
  int ldvarg23 ;
  size_t ldvarg26 ;
  char *ldvarg27 ;
  void *tmp___2 ;
  loff_t ldvarg24 ;
  int tmp___3 ;
  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg28 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg25 = (loff_t *)tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg30 = (char *)tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg27 = (char *)tmp___2;
  ldv_memset((void *)(& ldvarg29), 0, 8UL);
  ldv_memset((void *)(& ldvarg23), 0, 4UL);
  ldv_memset((void *)(& ldvarg26), 0, 8UL);
  ldv_memset((void *)(& ldvarg24), 0, 8UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_16 == 1) {
    ldv_retval_5 = bnad_debugfs_open_reg(bnad_debugfs_op_regrd_group1, bnad_debugfs_op_regrd_group2);
    if (ldv_retval_5 == 0) {
      ldv_state_variable_16 = 2;
      ref_cnt = ref_cnt + 1;
    } else {
    }
  } else {
  }
  goto ldv_58483;
  case 1: ;
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_release(bnad_debugfs_op_regrd_group1, bnad_debugfs_op_regrd_group2);
    ldv_state_variable_16 = 1;
    ref_cnt = ref_cnt - 1;
  } else {
  }
  goto ldv_58483;
  case 2: ;
  if (ldv_state_variable_16 == 1) {
    bnad_debugfs_write_regrd(bnad_debugfs_op_regrd_group2, (char const *)ldvarg30,
                             ldvarg29, ldvarg28);
    ldv_state_variable_16 = 1;
  } else {
  }
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_write_regrd(bnad_debugfs_op_regrd_group2, (char const *)ldvarg30,
                             ldvarg29, ldvarg28);
    ldv_state_variable_16 = 2;
  } else {
  }
  goto ldv_58483;
  case 3: ;
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_read_regrd(bnad_debugfs_op_regrd_group2, ldvarg27, ldvarg26, ldvarg25);
    ldv_state_variable_16 = 2;
  } else {
  }
  goto ldv_58483;
  case 4: ;
  if (ldv_state_variable_16 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_regrd_group2, ldvarg24, ldvarg23);
    ldv_state_variable_16 = 2;
  } else {
  }
  goto ldv_58483;
  default:
  ldv_stop();
  }
  ldv_58483: ;
  return;
}
}
void ldv_main_exported_17(void)
{
  loff_t *ldvarg15 ;
  void *tmp ;
  size_t ldvarg16 ;
  int ldvarg13 ;
  loff_t ldvarg14 ;
  char *ldvarg17 ;
  void *tmp___0 ;
  int tmp___1 ;
  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg15 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg17 = (char *)tmp___0;
  ldv_memset((void *)(& ldvarg16), 0, 8UL);
  ldv_memset((void *)(& ldvarg13), 0, 4UL);
  ldv_memset((void *)(& ldvarg14), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_17 == 1) {
    ldv_retval_2 = bnad_debugfs_open_fwsave(bnad_debugfs_op_fwsave_group1, bnad_debugfs_op_fwsave_group2);
    if (ldv_retval_2 == 0) {
      ldv_state_variable_17 = 2;
      ref_cnt = ref_cnt + 1;
    } else {
    }
  } else {
  }
  goto ldv_58498;
  case 1: ;
  if (ldv_state_variable_17 == 2) {
    bnad_debugfs_buffer_release(bnad_debugfs_op_fwsave_group1, bnad_debugfs_op_fwsave_group2);
    ldv_state_variable_17 = 1;
    ref_cnt = ref_cnt - 1;
  } else {
  }
  goto ldv_58498;
  case 2: ;
  if (ldv_state_variable_17 == 2) {
    bnad_debugfs_read(bnad_debugfs_op_fwsave_group2, ldvarg17, ldvarg16, ldvarg15);
    ldv_state_variable_17 = 2;
  } else {
  }
  goto ldv_58498;
  case 3: ;
  if (ldv_state_variable_17 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_fwsave_group2, ldvarg14, ldvarg13);
    ldv_state_variable_17 = 2;
  } else {
  }
  goto ldv_58498;
  default:
  ldv_stop();
  }
  ldv_58498: ;
  return;
}
}
void ldv_main_exported_15(void)
{
  int ldvarg47 ;
  size_t ldvarg50 ;
  loff_t *ldvarg49 ;
  void *tmp ;
  char *ldvarg51 ;
  void *tmp___0 ;
  loff_t ldvarg48 ;
  int tmp___1 ;
  {
  tmp = ldv_init_zalloc(8UL);
  ldvarg49 = (loff_t *)tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg51 = (char *)tmp___0;
  ldv_memset((void *)(& ldvarg47), 0, 4UL);
  ldv_memset((void *)(& ldvarg50), 0, 8UL);
  ldv_memset((void *)(& ldvarg48), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_15 == 1) {
    ldv_retval_8 = bnad_debugfs_open_reg(bnad_debugfs_op_regwr_group1, bnad_debugfs_op_regwr_group2);
    if (ldv_retval_8 == 0) {
      ldv_state_variable_15 = 2;
      ref_cnt = ref_cnt + 1;
    } else {
    }
  } else {
  }
  goto ldv_58512;
  case 1: ;
  if (ldv_state_variable_15 == 2) {
    bnad_debugfs_release(bnad_debugfs_op_regwr_group1, bnad_debugfs_op_regwr_group2);
    ldv_state_variable_15 = 1;
    ref_cnt = ref_cnt - 1;
  } else {
  }
  goto ldv_58512;
  case 2: ;
  if (ldv_state_variable_15 == 1) {
    bnad_debugfs_write_regwr(bnad_debugfs_op_regwr_group2, (char const *)ldvarg51,
                             ldvarg50, ldvarg49);
    ldv_state_variable_15 = 1;
  } else {
  }
  if (ldv_state_variable_15 == 2) {
    bnad_debugfs_write_regwr(bnad_debugfs_op_regwr_group2, (char const *)ldvarg51,
                             ldvarg50, ldvarg49);
    ldv_state_variable_15 = 2;
  } else {
  }
  goto ldv_58512;
  case 3: ;
  if (ldv_state_variable_15 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_regwr_group2, ldvarg48, ldvarg47);
    ldv_state_variable_15 = 2;
  } else {
  }
  goto ldv_58512;
  default:
  ldv_stop();
  }
  ldv_58512: ;
  return;
}
}
void ldv_main_exported_14(void)
{
  char *ldvarg46 ;
  void *tmp ;
  loff_t *ldvarg44 ;
  void *tmp___0 ;
  int ldvarg42 ;
  loff_t ldvarg43 ;
  size_t ldvarg45 ;
  int tmp___1 ;
  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg46 = (char *)tmp;
  tmp___0 = ldv_init_zalloc(8UL);
  ldvarg44 = (loff_t *)tmp___0;
  ldv_memset((void *)(& ldvarg42), 0, 4UL);
  ldv_memset((void *)(& ldvarg43), 0, 8UL);
  ldv_memset((void *)(& ldvarg45), 0, 8UL);
  tmp___1 = __VERIFIER_nondet_int();
  switch (tmp___1) {
  case 0: ;
  if (ldv_state_variable_14 == 1) {
    ldv_retval_7 = bnad_debugfs_open_drvinfo(bnad_debugfs_op_drvinfo_group1, bnad_debugfs_op_drvinfo_group2);
    if (ldv_retval_7 == 0) {
      ldv_state_variable_14 = 2;
      ref_cnt = ref_cnt + 1;
    } else {
    }
  } else {
  }
  goto ldv_58526;
  case 1: ;
  if (ldv_state_variable_14 == 2) {
    bnad_debugfs_buffer_release(bnad_debugfs_op_drvinfo_group1, bnad_debugfs_op_drvinfo_group2);
    ldv_state_variable_14 = 1;
    ref_cnt = ref_cnt - 1;
  } else {
  }
  goto ldv_58526;
  case 2: ;
  if (ldv_state_variable_14 == 2) {
    bnad_debugfs_read(bnad_debugfs_op_drvinfo_group2, ldvarg46, ldvarg45, ldvarg44);
    ldv_state_variable_14 = 2;
  } else {
  }
  goto ldv_58526;
  case 3: ;
  if (ldv_state_variable_14 == 2) {
    bnad_debugfs_lseek(bnad_debugfs_op_drvinfo_group2, ldvarg43, ldvarg42);
    ldv_state_variable_14 = 2;
  } else {
  }
  goto ldv_58526;
  default:
  ldv_stop();
  }
  ldv_58526: ;
  return;
}
}
__inline static long PTR_ERR(void const *ptr )
{
  long tmp ;
  {
  tmp = ldv_ptr_err(ptr);
  return (tmp);
}
}
__inline static bool IS_ERR(void const *ptr )
{
  bool tmp ;
  {
  tmp = ldv_is_err(ptr);
  return (tmp);
}
}
bool ldv_queue_work_on_163(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_164(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_165(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_166(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_167(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_173(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_179(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_181(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_183(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_184(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_185(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_186(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_187(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_188(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_189(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
void *ldv_kmem_cache_alloc_190(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
__inline static int list_empty(struct list_head const *head )
{
  {
  return ((unsigned long )((struct list_head const *)head->next) == (unsigned long )head);
}
}
bool ldv_queue_work_on_210(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_212(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_211(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_214(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_213(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_220(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_228(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_236(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_230(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_226(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_234(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_235(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_231(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_232(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_233(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static void bfa_wc_up(struct bfa_wc *wc )
{
  {
  wc->wc_count = wc->wc_count + 1;
  return;
}
}
__inline static void bfa_wc_down(struct bfa_wc *wc )
{
  {
  wc->wc_count = wc->wc_count - 1;
  if (wc->wc_count == 0) {
    (*(wc->wc_resume))(wc->wc_cbarg);
  } else {
  }
  return;
}
}
__inline static void bfa_wc_init(struct bfa_wc *wc , void (*wc_resume)(void * ) ,
                                 void *wc_cbarg )
{
  {
  wc->wc_resume = wc_resume;
  wc->wc_cbarg = wc_cbarg;
  wc->wc_count = 0;
  bfa_wc_up(wc);
  return;
}
}
__inline static void bfa_wc_wait(struct bfa_wc *wc )
{
  {
  bfa_wc_down(wc);
  return;
}
}
void bfa_nw_ioc_mbox_isr(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_attach(struct bfa_ioc *ioc , void *bfa , struct bfa_ioc_cbfn *cbfn ) ;
void bfa_nw_ioc_detach(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_pci_init(struct bfa_ioc *ioc , struct bfa_pcidev *pcidev , enum bfi_pcifn_class clscode ) ;
u32 bfa_nw_ioc_meminfo(void) ;
void bfa_nw_ioc_mem_claim(struct bfa_ioc *ioc , u8 *dm_kva , u64 dm_pa ) ;
void bfa_nw_ioc_enable(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_disable(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_error_isr(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_get_mac(struct bfa_ioc *ioc , u8 *mac ) ;
void bfa_nw_ioc_debug_memclaim(struct bfa_ioc *ioc , void *dbg_fwsave ) ;
u32 bfa_nw_flash_meminfo(void) ;
void bfa_nw_flash_attach(struct bfa_flash *flash , struct bfa_ioc *ioc , void *dev ) ;
void bfa_nw_flash_memclaim(struct bfa_flash *flash , u8 *dm_kva , u64 dm_pa ) ;
u32 bfa_nw_cee_meminfo(void) ;
void bfa_nw_cee_mem_claim(struct bfa_cee *cee , u8 *dma_kva , u64 dma_pa ) ;
void bfa_nw_cee_attach(struct bfa_cee *cee , struct bfa_ioc *ioc , void *dev ) ;
u32 bfa_msgq_meminfo(void) ;
void bfa_msgq_memclaim(struct bfa_msgq *msgq , u8 *kva , u64 pa ) ;
void bfa_msgq_attach(struct bfa_msgq *msgq , struct bfa_ioc *ioc ) ;
void bfa_msgq_regisr(struct bfa_msgq *msgq , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                               struct bfi_msgq_mhdr * ) ,
                     void *cbarg ) ;
void bfa_msgq_cmd_post(struct bfa_msgq *msgq , struct bfa_msgq_cmd_entry *cmd ) ;
struct bna_mac *bna_cam_mod_mac_get(struct list_head *head ) ;
struct bna_mcam_handle *bna_mcam_mod_handle_get(struct bna_mcam_mod *mcam_mod ) ;
void bna_mcam_mod_handle_put(struct bna_mcam_mod *mcam_mod , struct bna_mcam_handle *handle ) ;
void bna_ethport_cb_rx_started(struct bna_ethport *ethport ) ;
void bna_ethport_cb_rx_stopped(struct bna_ethport *ethport ) ;
void bna_bfi_tx_enet_start_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_tx_enet_stop_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_bw_update_aen(struct bna_tx_mod *tx_mod ) ;
void bna_tx_mod_init(struct bna_tx_mod *tx_mod , struct bna *bna , struct bna_res_info *res_info ) ;
void bna_tx_mod_uninit(struct bna_tx_mod *tx_mod ) ;
void bna_tx_mod_start(struct bna_tx_mod *tx_mod , enum bna_tx_type type ) ;
void bna_tx_mod_stop(struct bna_tx_mod *tx_mod , enum bna_tx_type type ) ;
void bna_tx_mod_fail(struct bna_tx_mod *tx_mod ) ;
void bna_bfi_rx_enet_start_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rx_enet_stop_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rxf_cfg_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rxf_mcast_add_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) ;
void bna_bfi_rxf_ucast_set_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr ) ;
void bna_rx_mod_init(struct bna_rx_mod *rx_mod , struct bna *bna , struct bna_res_info *res_info ) ;
void bna_rx_mod_uninit(struct bna_rx_mod *rx_mod ) ;
void bna_rx_mod_start(struct bna_rx_mod *rx_mod , enum bna_rx_type type ) ;
void bna_rx_mod_stop(struct bna_rx_mod *rx_mod , enum bna_rx_type type ) ;
void bna_rx_mod_fail(struct bna_rx_mod *rx_mod ) ;
int bna_enet_mtu_get(struct bna_enet *enet ) ;
void bna_enet_cb_tx_stopped(struct bna_enet *enet ) ;
void bna_enet_cb_rx_stopped(struct bna_enet *enet ) ;
__inline static int ethport_can_be_up(struct bna_ethport *ethport )
{
  int ready ;
  {
  ready = 0;
  if ((unsigned int )(ethport->bna)->enet.type == 0U) {
    ready = ((int )ethport->flags & 1 && ((unsigned int )ethport->flags & 4U) != 0U) && ((unsigned int )ethport->flags & 2U) != 0U;
  } else {
    ready = ((int )ethport->flags & 1 && ((unsigned int )ethport->flags & 4U) != 0U) && ((unsigned int )ethport->flags & 2U) == 0U;
  }
  return (ready);
}
}
static void bna_bfi_ethport_enable_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr )
{
  int tmp ;
  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 2U);
  tmp = ethport_can_be_up(ethport);
  if (tmp != 0) {
    (*(ethport->fsm))((void *)ethport, 4);
  } else {
  }
  return;
}
}
static void bna_bfi_ethport_disable_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr )
{
  int ethport_up ;
  int tmp ;
  {
  tmp = ethport_can_be_up(ethport);
  ethport_up = tmp;
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967293U);
  if (ethport_up != 0) {
    (*(ethport->fsm))((void *)ethport, 5);
  } else {
  }
  return;
}
}
static void bna_bfi_ethport_admin_rsp(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_enable_req *admin_req ;
  struct bfi_enet_rsp *rsp ;
  struct bfi_msgq_mhdr const *__mptr ;
  {
  admin_req = & ethport->bfi_enet_cmd.admin_req;
  __mptr = (struct bfi_msgq_mhdr const *)msghdr;
  rsp = (struct bfi_enet_rsp *)__mptr;
  switch ((int )admin_req->enable) {
  case 1: ;
  if ((unsigned int )rsp->error == 0U) {
    (*(ethport->fsm))((void *)ethport, 6);
  } else {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967293U);
    (*(ethport->fsm))((void *)ethport, 8);
  }
  goto ldv_49150;
  case 0:
  (*(ethport->fsm))((void *)ethport, 7);
  ethport->link_status = 0;
  (*(ethport->link_cbfn))((ethport->bna)->bnad, 0);
  goto ldv_49150;
  }
  ldv_49150: ;
  return;
}
}
static void bna_bfi_ethport_lpbk_rsp(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_diag_lb_req *diag_lb_req ;
  struct bfi_enet_rsp *rsp ;
  struct bfi_msgq_mhdr const *__mptr ;
  {
  diag_lb_req = & ethport->bfi_enet_cmd.lpbk_req;
  __mptr = (struct bfi_msgq_mhdr const *)msghdr;
  rsp = (struct bfi_enet_rsp *)__mptr;
  switch ((int )diag_lb_req->enable) {
  case 1: ;
  if ((unsigned int )rsp->error == 0U) {
    (*(ethport->fsm))((void *)ethport, 6);
  } else {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967294U);
    (*(ethport->fsm))((void *)ethport, 8);
  }
  goto ldv_49161;
  case 0:
  (*(ethport->fsm))((void *)ethport, 7);
  goto ldv_49161;
  }
  ldv_49161: ;
  return;
}
}
static void bna_bfi_pause_set_rsp(struct bna_enet *enet , struct bfi_msgq_mhdr *msghdr )
{
  {
  (*(enet->fsm))((void *)enet, 6);
  return;
}
}
static void bna_bfi_attr_get_rsp(struct bna_ioceth *ioceth , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_attr_rsp *rsp ;
  struct bfi_msgq_mhdr const *__mptr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  {
  __mptr = (struct bfi_msgq_mhdr const *)msghdr;
  rsp = (struct bfi_enet_attr_rsp *)__mptr;
  if (! ioceth->attr.fw_query_complete) {
    tmp = __fswab32(rsp->max_cfg);
    ioceth->attr.num_txq = (int )tmp;
    tmp___0 = __fswab32(rsp->max_cfg);
    ioceth->attr.num_rxp = (int )tmp___0;
    tmp___1 = __fswab32(rsp->max_ucmac);
    ioceth->attr.num_ucmac = (int )tmp___1;
    ioceth->attr.num_mcmac = 256;
    tmp___2 = __fswab32(rsp->rit_size);
    ioceth->attr.max_rit_size = (int )tmp___2;
    ioceth->attr.fw_query_complete = 1;
  } else {
  }
  (*(ioceth->fsm))((void *)ioceth, 6);
  return;
}
}
static void bna_bfi_stats_get_rsp(struct bna *bna , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_stats_req *stats_req ;
  u64 *stats_src ;
  u64 *stats_dst ;
  u32 tx_enet_mask ;
  __u32 tmp ;
  u32 rx_enet_mask ;
  __u32 tmp___0 ;
  int count ;
  int i ;
  __u64 tmp___1 ;
  __u64 tmp___2 ;
  __u64 tmp___3 ;
  __u64 tmp___4 ;
  __u64 tmp___5 ;
  __u64 tmp___6 ;
  int k ;
  __u64 tmp___7 ;
  int k___0 ;
  __u64 tmp___8 ;
  {
  stats_req = & bna->stats_mod.stats_get;
  tmp = __fswab32(stats_req->tx_enet_mask);
  tx_enet_mask = tmp;
  tmp___0 = __fswab32(stats_req->rx_enet_mask);
  rx_enet_mask = tmp___0;
  count = 45;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->mac_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.mac_stats);
  i = 0;
  goto ldv_49186;
  ldv_49185:
  tmp___1 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___1;
  i = i + 1;
  ldv_49186: ;
  if (i < count) {
    goto ldv_49185;
  } else {
  }
  count = 48;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->bpc_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.bpc_stats);
  i = 0;
  goto ldv_49189;
  ldv_49188:
  tmp___2 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___2;
  i = i + 1;
  ldv_49189: ;
  if (i < count) {
    goto ldv_49188;
  } else {
  }
  count = 13;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->rad_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.rad_stats);
  i = 0;
  goto ldv_49192;
  ldv_49191:
  tmp___3 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___3;
  i = i + 1;
  ldv_49192: ;
  if (i < count) {
    goto ldv_49191;
  } else {
  }
  count = 13;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->rlb_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.rlb_stats);
  i = 0;
  goto ldv_49195;
  ldv_49194:
  tmp___4 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___4;
  i = i + 1;
  ldv_49195: ;
  if (i < count) {
    goto ldv_49194;
  } else {
  }
  count = 9;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->fc_rx_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.fc_rx_stats);
  i = 0;
  goto ldv_49198;
  ldv_49197:
  tmp___5 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___5;
  i = i + 1;
  ldv_49198: ;
  if (i < count) {
    goto ldv_49197;
  } else {
  }
  count = 12;
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->fc_tx_stats);
  stats_dst = (u64 *)(& bna->stats.hw_stats.fc_tx_stats);
  i = 0;
  goto ldv_49201;
  ldv_49200:
  tmp___6 = __fswab64(*(stats_src + (unsigned long )i));
  *(stats_dst + (unsigned long )i) = tmp___6;
  i = i + 1;
  ldv_49201: ;
  if (i < count) {
    goto ldv_49200;
  } else {
  }
  stats_src = (u64 *)(& (bna->stats.hw_stats_kva)->rxf_stats);
  i = 0;
  goto ldv_49208;
  ldv_49207:
  stats_dst = (u64 *)(& bna->stats.hw_stats.rxf_stats) + (unsigned long )i;
  memset((void *)stats_dst, 0, 80UL);
  if ((int )((unsigned long )rx_enet_mask >> i) & 1) {
    count = 10;
    k = 0;
    goto ldv_49205;
    ldv_49204:
    tmp___7 = __fswab64(*stats_src);
    *(stats_dst + (unsigned long )k) = tmp___7;
    stats_src = stats_src + 1;
    k = k + 1;
    ldv_49205: ;
    if (k < count) {
      goto ldv_49204;
    } else {
    }
  } else {
  }
  i = i + 1;
  ldv_49208: ;
  if (i <= 31) {
    goto ldv_49207;
  } else {
  }
  i = 0;
  goto ldv_49215;
  ldv_49214:
  stats_dst = (u64 *)(& bna->stats.hw_stats.txf_stats) + (unsigned long )i;
  memset((void *)stats_dst, 0, 96UL);
  if ((int )((unsigned long )tx_enet_mask >> i) & 1) {
    count = 12;
    k___0 = 0;
    goto ldv_49212;
    ldv_49211:
    tmp___8 = __fswab64(*stats_src);
    *(stats_dst + (unsigned long )k___0) = tmp___8;
    stats_src = stats_src + 1;
    k___0 = k___0 + 1;
    ldv_49212: ;
    if (k___0 < count) {
      goto ldv_49211;
    } else {
    }
  } else {
  }
  i = i + 1;
  ldv_49215: ;
  if (i <= 31) {
    goto ldv_49214;
  } else {
  }
  bna->stats_mod.stats_get_busy = 0;
  bnad_cb_stats_get(bna->bnad, 0, & bna->stats);
  return;
}
}
static void bna_bfi_ethport_linkup_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr )
{
  {
  ethport->link_status = 1;
  (*(ethport->link_cbfn))((ethport->bna)->bnad, ethport->link_status);
  return;
}
}
static void bna_bfi_ethport_linkdown_aen(struct bna_ethport *ethport , struct bfi_msgq_mhdr *msghdr )
{
  {
  ethport->link_status = 0;
  (*(ethport->link_cbfn))((ethport->bna)->bnad, 0);
  return;
}
}
static void bna_err_handler(struct bna *bna , u32 intr_status )
{
  u32 init_halt ;
  {
  if ((bna->bits.halt_status_bits & intr_status) != 0U) {
    init_halt = readl((void const volatile *)bna->ioceth.ioc.ioc_regs.ll_halt);
    init_halt = init_halt & 4294967294U;
    writel(init_halt, (void volatile *)bna->ioceth.ioc.ioc_regs.ll_halt);
    init_halt = readl((void const volatile *)bna->ioceth.ioc.ioc_regs.ll_halt);
  } else {
  }
  bfa_nw_ioc_error_isr(& bna->ioceth.ioc);
  return;
}
}
void bna_mbox_handler(struct bna *bna , u32 intr_status )
{
  {
  if ((bna->bits.error_status_bits & intr_status) != 0U) {
    bna_err_handler(bna, intr_status);
    return;
  } else {
  }
  if ((bna->bits.mbox_status_bits & intr_status) != 0U) {
    bfa_nw_ioc_mbox_isr(& bna->ioceth.ioc);
  } else {
  }
  return;
}
}
static void bna_msgq_rsp_handler(void *arg , struct bfi_msgq_mhdr *msghdr )
{
  struct bna *bna ;
  struct bna_tx *tx ;
  struct bna_rx *rx ;
  struct bna_rx_mod *__rx_mod ;
  struct bna_rx *__rx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  struct bna_rx_mod *__rx_mod___0 ;
  struct bna_rx *__rx___0 ;
  struct list_head const *__mptr___1 ;
  struct list_head const *__mptr___2 ;
  struct bna_rx_mod *__rx_mod___1 ;
  struct bna_rx *__rx___1 ;
  struct list_head const *__mptr___3 ;
  struct list_head const *__mptr___4 ;
  struct bna_rx_mod *__rx_mod___2 ;
  struct bna_rx *__rx___2 ;
  struct list_head const *__mptr___5 ;
  struct list_head const *__mptr___6 ;
  struct bna_rx_mod *__rx_mod___3 ;
  struct bna_rx *__rx___3 ;
  struct list_head const *__mptr___7 ;
  struct list_head const *__mptr___8 ;
  struct bna_tx_mod *__tx_mod ;
  struct bna_tx *__tx ;
  struct list_head const *__mptr___9 ;
  struct list_head const *__mptr___10 ;
  struct bna_tx_mod *__tx_mod___0 ;
  struct bna_tx *__tx___0 ;
  struct list_head const *__mptr___11 ;
  struct list_head const *__mptr___12 ;
  {
  bna = (struct bna *)arg;
  switch ((int )msghdr->msg_id) {
  case 129:
  __rx_mod = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr = (struct list_head const *)__rx_mod->rx_active_q.next;
  __rx = (struct bna_rx *)__mptr;
  goto ldv_49250;
  ldv_49249: ;
  if (__rx->rid == (int )msghdr->enet_id) {
    rx = __rx;
    goto ldv_49248;
  } else {
  }
  __mptr___0 = (struct list_head const *)__rx->qe.next;
  __rx = (struct bna_rx *)__mptr___0;
  ldv_49250: ;
  if ((unsigned long )(& __rx->qe) != (unsigned long )(& __rx_mod->rx_active_q)) {
    goto ldv_49249;
  } else {
  }
  ldv_49248: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rx_enet_start_rsp(rx, msghdr);
  } else {
  }
  goto ldv_49251;
  case 130:
  __rx_mod___0 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___1 = (struct list_head const *)__rx_mod___0->rx_active_q.next;
  __rx___0 = (struct bna_rx *)__mptr___1;
  goto ldv_49261;
  ldv_49260: ;
  if (__rx___0->rid == (int )msghdr->enet_id) {
    rx = __rx___0;
    goto ldv_49259;
  } else {
  }
  __mptr___2 = (struct list_head const *)__rx___0->qe.next;
  __rx___0 = (struct bna_rx *)__mptr___2;
  ldv_49261: ;
  if ((unsigned long )(& __rx___0->qe) != (unsigned long )(& __rx_mod___0->rx_active_q)) {
    goto ldv_49260;
  } else {
  }
  ldv_49259: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rx_enet_stop_rsp(rx, msghdr);
  } else {
  }
  goto ldv_49251;
  case 131: ;
  case 132: ;
  case 133: ;
  case 134: ;
  case 135: ;
  case 137: ;
  case 138: ;
  case 139: ;
  case 141: ;
  case 142: ;
  case 143: ;
  case 144:
  __rx_mod___1 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___3 = (struct list_head const *)__rx_mod___1->rx_active_q.next;
  __rx___1 = (struct bna_rx *)__mptr___3;
  goto ldv_49282;
  ldv_49281: ;
  if (__rx___1->rid == (int )msghdr->enet_id) {
    rx = __rx___1;
    goto ldv_49280;
  } else {
  }
  __mptr___4 = (struct list_head const *)__rx___1->qe.next;
  __rx___1 = (struct bna_rx *)__mptr___4;
  ldv_49282: ;
  if ((unsigned long )(& __rx___1->qe) != (unsigned long )(& __rx_mod___1->rx_active_q)) {
    goto ldv_49281;
  } else {
  }
  ldv_49280: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rxf_cfg_rsp(& rx->rxf, msghdr);
  } else {
  }
  goto ldv_49251;
  case 136:
  __rx_mod___2 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___5 = (struct list_head const *)__rx_mod___2->rx_active_q.next;
  __rx___2 = (struct bna_rx *)__mptr___5;
  goto ldv_49292;
  ldv_49291: ;
  if (__rx___2->rid == (int )msghdr->enet_id) {
    rx = __rx___2;
    goto ldv_49290;
  } else {
  }
  __mptr___6 = (struct list_head const *)__rx___2->qe.next;
  __rx___2 = (struct bna_rx *)__mptr___6;
  ldv_49292: ;
  if ((unsigned long )(& __rx___2->qe) != (unsigned long )(& __rx_mod___2->rx_active_q)) {
    goto ldv_49291;
  } else {
  }
  ldv_49290: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rxf_ucast_set_rsp(& rx->rxf, msghdr);
  } else {
  }
  goto ldv_49251;
  case 140:
  __rx_mod___3 = & bna->rx_mod;
  rx = (struct bna_rx *)0;
  __mptr___7 = (struct list_head const *)__rx_mod___3->rx_active_q.next;
  __rx___3 = (struct bna_rx *)__mptr___7;
  goto ldv_49302;
  ldv_49301: ;
  if (__rx___3->rid == (int )msghdr->enet_id) {
    rx = __rx___3;
    goto ldv_49300;
  } else {
  }
  __mptr___8 = (struct list_head const *)__rx___3->qe.next;
  __rx___3 = (struct bna_rx *)__mptr___8;
  ldv_49302: ;
  if ((unsigned long )(& __rx___3->qe) != (unsigned long )(& __rx_mod___3->rx_active_q)) {
    goto ldv_49301;
  } else {
  }
  ldv_49300: ;
  if ((unsigned long )rx != (unsigned long )((struct bna_rx *)0)) {
    bna_bfi_rxf_mcast_add_rsp(& rx->rxf, msghdr);
  } else {
  }
  goto ldv_49251;
  case 145:
  __tx_mod = & bna->tx_mod;
  tx = (struct bna_tx *)0;
  __mptr___9 = (struct list_head const *)__tx_mod->tx_active_q.next;
  __tx = (struct bna_tx *)__mptr___9;
  goto ldv_49312;
  ldv_49311: ;
  if (__tx->rid == (int )msghdr->enet_id) {
    tx = __tx;
    goto ldv_49310;
  } else {
  }
  __mptr___10 = (struct list_head const *)__tx->qe.next;
  __tx = (struct bna_tx *)__mptr___10;
  ldv_49312: ;
  if ((unsigned long )(& __tx->qe) != (unsigned long )(& __tx_mod->tx_active_q)) {
    goto ldv_49311;
  } else {
  }
  ldv_49310: ;
  if ((unsigned long )tx != (unsigned long )((struct bna_tx *)0)) {
    bna_bfi_tx_enet_start_rsp(tx, msghdr);
  } else {
  }
  goto ldv_49251;
  case 146:
  __tx_mod___0 = & bna->tx_mod;
  tx = (struct bna_tx *)0;
  __mptr___11 = (struct list_head const *)__tx_mod___0->tx_active_q.next;
  __tx___0 = (struct bna_tx *)__mptr___11;
  goto ldv_49322;
  ldv_49321: ;
  if (__tx___0->rid == (int )msghdr->enet_id) {
    tx = __tx___0;
    goto ldv_49320;
  } else {
  }
  __mptr___12 = (struct list_head const *)__tx___0->qe.next;
  __tx___0 = (struct bna_tx *)__mptr___12;
  ldv_49322: ;
  if ((unsigned long )(& __tx___0->qe) != (unsigned long )(& __tx_mod___0->tx_active_q)) {
    goto ldv_49321;
  } else {
  }
  ldv_49320: ;
  if ((unsigned long )tx != (unsigned long )((struct bna_tx *)0)) {
    bna_bfi_tx_enet_stop_rsp(tx, msghdr);
  } else {
  }
  goto ldv_49251;
  case 147:
  bna_bfi_ethport_admin_rsp(& bna->ethport, msghdr);
  goto ldv_49251;
  case 149:
  bna_bfi_ethport_lpbk_rsp(& bna->ethport, msghdr);
  goto ldv_49251;
  case 148:
  bna_bfi_pause_set_rsp(& bna->enet, msghdr);
  goto ldv_49251;
  case 150:
  bna_bfi_attr_get_rsp(& bna->ioceth, msghdr);
  goto ldv_49251;
  case 151:
  bna_bfi_stats_get_rsp(bna, msghdr);
  goto ldv_49251;
  case 152: ;
  goto ldv_49251;
  case 156:
  bna_bfi_ethport_linkup_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 155:
  bna_bfi_ethport_linkdown_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 157:
  bna_bfi_ethport_enable_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 158:
  bna_bfi_ethport_disable_aen(& bna->ethport, msghdr);
  goto ldv_49251;
  case 159:
  bna_bfi_bw_update_aen(& bna->tx_mod);
  goto ldv_49251;
  default: ;
  goto ldv_49251;
  }
  ldv_49251: ;
  return;
}
}
static void bna_bfi_ethport_admin_up(struct bna_ethport *ethport )
{
  struct bfi_enet_enable_req *admin_up_req ;
  {
  admin_up_req = & ethport->bfi_enet_cmd.admin_req;
  admin_up_req->mh.msg_class = 24U;
  admin_up_req->mh.msg_id = 19U;
  admin_up_req->mh.msg_token = 0U;
  admin_up_req->mh.enet_id = 0U;
  admin_up_req->mh.num_entries = 256U;
  admin_up_req->enable = 1U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & admin_up_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_admin_down(struct bna_ethport *ethport )
{
  struct bfi_enet_enable_req *admin_down_req ;
  {
  admin_down_req = & ethport->bfi_enet_cmd.admin_req;
  admin_down_req->mh.msg_class = 24U;
  admin_down_req->mh.msg_id = 19U;
  admin_down_req->mh.msg_token = 0U;
  admin_down_req->mh.enet_id = 0U;
  admin_down_req->mh.num_entries = 256U;
  admin_down_req->enable = 0U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & admin_down_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_lpbk_up(struct bna_ethport *ethport )
{
  struct bfi_enet_diag_lb_req *lpbk_up_req ;
  {
  lpbk_up_req = & ethport->bfi_enet_cmd.lpbk_req;
  lpbk_up_req->mh.msg_class = 24U;
  lpbk_up_req->mh.msg_id = 21U;
  lpbk_up_req->mh.msg_token = 0U;
  lpbk_up_req->mh.enet_id = 0U;
  lpbk_up_req->mh.num_entries = 256U;
  lpbk_up_req->mode = (unsigned int )(ethport->bna)->enet.type != 1U;
  lpbk_up_req->enable = 1U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & lpbk_up_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_lpbk_down(struct bna_ethport *ethport )
{
  struct bfi_enet_diag_lb_req *lpbk_down_req ;
  {
  lpbk_down_req = & ethport->bfi_enet_cmd.lpbk_req;
  lpbk_down_req->mh.msg_class = 24U;
  lpbk_down_req->mh.msg_id = 21U;
  lpbk_down_req->mh.msg_token = 0U;
  lpbk_down_req->mh.enet_id = 0U;
  lpbk_down_req->mh.num_entries = 256U;
  lpbk_down_req->enable = 0U;
  ethport->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  ethport->msgq_cmd.cbarg = (void *)0;
  ethport->msgq_cmd.msg_size = 12UL;
  ethport->msgq_cmd.msg_hdr = & lpbk_down_req->mh;
  bfa_msgq_cmd_post(& (ethport->bna)->msgq, & ethport->msgq_cmd);
  return;
}
}
static void bna_bfi_ethport_up(struct bna_ethport *ethport )
{
  {
  if ((unsigned int )(ethport->bna)->enet.type == 0U) {
    bna_bfi_ethport_admin_up(ethport);
  } else {
    bna_bfi_ethport_lpbk_up(ethport);
  }
  return;
}
}
static void bna_bfi_ethport_down(struct bna_ethport *ethport )
{
  {
  if ((unsigned int )(ethport->bna)->enet.type == 0U) {
    bna_bfi_ethport_admin_down(ethport);
  } else {
    bna_bfi_ethport_lpbk_down(ethport);
  }
  return;
}
}
static void bna_ethport_sm_stopped(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_stopped_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_down(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_down_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_up_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_up_resp_wait_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_down_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_down_resp_wait_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_up(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_up_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_last_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event ) ;
static void bna_ethport_sm_last_resp_wait_entry(struct bna_ethport *ethport ) ;
static void bna_ethport_sm_stopped_entry(struct bna_ethport *ethport )
{
  void (*cbfn)(struct bna_enet * ) ;
  {
  if ((unsigned long )ethport->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    cbfn = ethport->stop_cbfn;
    ethport->stop_cbfn = (void (*)(struct bna_enet * ))0;
    (*cbfn)(& (ethport->bna)->enet);
  } else {
  }
  return;
}
}
static void bna_ethport_sm_stopped(struct bna_ethport *ethport , enum bna_ethport_event event )
{
  void (*cbfn)(struct bna_enet * ) ;
  {
  switch ((unsigned int )event) {
  case 1U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_down);
  bna_ethport_sm_down_entry(ethport);
  goto ldv_49397;
  case 2U: ;
  if ((unsigned long )ethport->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    cbfn = ethport->stop_cbfn;
    ethport->stop_cbfn = (void (*)(struct bna_enet * ))0;
    (*cbfn)(& (ethport->bna)->enet);
  } else {
  }
  goto ldv_49397;
  case 3U: ;
  goto ldv_49397;
  case 5U: ;
  goto ldv_49397;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         544, (unsigned int )event);
  }
  ldv_49397: ;
  return;
}
}
static void bna_ethport_sm_down_entry(struct bna_ethport *ethport )
{
  {
  return;
}
}
static void bna_ethport_sm_down(struct bna_ethport *ethport , enum bna_ethport_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49412;
  case 3U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49412;
  case 4U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_up_resp_wait);
  bna_ethport_sm_up_resp_wait_entry(ethport);
  bna_bfi_ethport_up(ethport);
  goto ldv_49412;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         572, (unsigned int )event);
  }
  ldv_49412: ;
  return;
}
}
static void bna_ethport_sm_up_resp_wait_entry(struct bna_ethport *ethport )
{
  {
  return;
}
}
static void bna_ethport_sm_up_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event )
{
  void (*cbfn)(struct bnad * , enum bna_cb_status ) ;
  void (*cbfn___0)(struct bnad * , enum bna_cb_status ) ;
  void (*cbfn___1)(struct bnad * , enum bna_cb_status ) ;
  void (*cbfn___2)(struct bnad * , enum bna_cb_status ) ;
  {
  switch ((unsigned int )event) {
  case 2U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_last_resp_wait);
  bna_ethport_sm_last_resp_wait_entry(ethport);
  goto ldv_49424;
  case 3U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status ))0)) {
    cbfn = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status ))0;
    (*cbfn)((ethport->bna)->bnad, 1);
  } else {
  }
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49424;
  case 5U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status ))0)) {
    cbfn___0 = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status ))0;
    (*cbfn___0)((ethport->bna)->bnad, 2);
  } else {
  }
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_down_resp_wait);
  bna_ethport_sm_down_resp_wait_entry(ethport);
  goto ldv_49424;
  case 6U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status ))0)) {
    cbfn___1 = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status ))0;
    (*cbfn___1)((ethport->bna)->bnad, 0);
  } else {
  }
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_up);
  bna_ethport_sm_up_entry(ethport);
  goto ldv_49424;
  case 8U: ;
  if ((unsigned long )ethport->adminup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                          enum bna_cb_status ))0)) {
    cbfn___2 = ethport->adminup_cbfn;
    ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status ))0;
    (*cbfn___2)((ethport->bna)->bnad, 1);
  } else {
  }
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_down);
  bna_ethport_sm_down_entry(ethport);
  goto ldv_49424;
  case 7U:
  bna_bfi_ethport_up(ethport);
  goto ldv_49424;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         616, (unsigned int )event);
  }
  ldv_49424: ;
  return;
}
}
static void bna_ethport_sm_down_resp_wait_entry(struct bna_ethport *ethport )
{
  {
  return;
}
}
static void bna_ethport_sm_down_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_last_resp_wait);
  bna_ethport_sm_last_resp_wait_entry(ethport);
  goto ldv_49451;
  case 3U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49451;
  case 4U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_up_resp_wait);
  bna_ethport_sm_up_resp_wait_entry(ethport);
  goto ldv_49451;
  case 6U:
  bna_bfi_ethport_down(ethport);
  goto ldv_49451;
  case 8U: ;
  case 7U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_down);
  bna_ethport_sm_down_entry(ethport);
  goto ldv_49451;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         658, (unsigned int )event);
  }
  ldv_49451: ;
  return;
}
}
static void bna_ethport_sm_up_entry(struct bna_ethport *ethport )
{
  {
  return;
}
}
static void bna_ethport_sm_up(struct bna_ethport *ethport , enum bna_ethport_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_last_resp_wait);
  bna_ethport_sm_last_resp_wait_entry(ethport);
  bna_bfi_ethport_down(ethport);
  goto ldv_49466;
  case 3U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49466;
  case 5U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_down_resp_wait);
  bna_ethport_sm_down_resp_wait_entry(ethport);
  bna_bfi_ethport_down(ethport);
  goto ldv_49466;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         687, (unsigned int )event);
  }
  ldv_49466: ;
  return;
}
}
static void bna_ethport_sm_last_resp_wait_entry(struct bna_ethport *ethport )
{
  {
  return;
}
}
static void bna_ethport_sm_last_resp_wait(struct bna_ethport *ethport , enum bna_ethport_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49478;
  case 5U: ;
  goto ldv_49478;
  case 6U:
  bna_bfi_ethport_down(ethport);
  goto ldv_49478;
  case 8U: ;
  case 7U:
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  goto ldv_49478;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         724, (unsigned int )event);
  }
  ldv_49478: ;
  return;
}
}
static void bna_ethport_init(struct bna_ethport *ethport , struct bna *bna )
{
  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 3U);
  ethport->bna = bna;
  ethport->link_status = 0;
  ethport->link_cbfn = & bnad_cb_ethport_link_status;
  ethport->rx_started_count = 0;
  ethport->stop_cbfn = (void (*)(struct bna_enet * ))0;
  ethport->adminup_cbfn = (void (*)(struct bnad * , enum bna_cb_status ))0;
  ethport->fsm = (void (*)(void * , int ))(& bna_ethport_sm_stopped);
  bna_ethport_sm_stopped_entry(ethport);
  return;
}
}
static void bna_ethport_uninit(struct bna_ethport *ethport )
{
  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967294U);
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967293U);
  ethport->bna = (struct bna *)0;
  return;
}
}
static void bna_ethport_start(struct bna_ethport *ethport )
{
  {
  (*(ethport->fsm))((void *)ethport, 1);
  return;
}
}
static void bna_enet_cb_ethport_stopped(struct bna_enet *enet )
{
  {
  bfa_wc_down(& enet->chld_stop_wc);
  return;
}
}
static void bna_ethport_stop(struct bna_ethport *ethport )
{
  {
  ethport->stop_cbfn = & bna_enet_cb_ethport_stopped;
  (*(ethport->fsm))((void *)ethport, 2);
  return;
}
}
static void bna_ethport_fail(struct bna_ethport *ethport )
{
  {
  ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 2U);
  if ((unsigned int )ethport->link_status != 0U) {
    ethport->link_status = 0;
    (*(ethport->link_cbfn))((ethport->bna)->bnad, 0);
  } else {
  }
  (*(ethport->fsm))((void *)ethport, 3);
  return;
}
}
void bna_ethport_cb_rx_started(struct bna_ethport *ethport )
{
  int tmp ;
  {
  ethport->rx_started_count = ethport->rx_started_count + 1;
  if (ethport->rx_started_count == 1) {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags | 4U);
    tmp = ethport_can_be_up(ethport);
    if (tmp != 0) {
      (*(ethport->fsm))((void *)ethport, 4);
    } else {
    }
  } else {
  }
  return;
}
}
void bna_ethport_cb_rx_stopped(struct bna_ethport *ethport )
{
  int ethport_up ;
  int tmp ;
  {
  tmp = ethport_can_be_up(ethport);
  ethport_up = tmp;
  ethport->rx_started_count = ethport->rx_started_count - 1;
  if (ethport->rx_started_count == 0) {
    ethport->flags = (enum bna_ethport_flags )((unsigned int )ethport->flags & 4294967291U);
    if (ethport_up != 0) {
      (*(ethport->fsm))((void *)ethport, 5);
    } else {
    }
  } else {
  }
  return;
}
}
static void bna_enet_cb_chld_stopped(void *arg ) ;
static void bna_bfi_pause_set(struct bna_enet *enet ) ;
static void bna_enet_sm_stopped(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_stopped_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_pause_init_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_pause_init_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_last_resp_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_last_resp_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_started(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_started_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_cfg_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_cfg_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_cfg_stop_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_cfg_stop_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_chld_stop_wait(struct bna_enet *enet , enum bna_enet_event event ) ;
static void bna_enet_sm_chld_stop_wait_entry(struct bna_enet *enet ) ;
static void bna_enet_sm_stopped_entry(struct bna_enet *enet )
{
  void (*cbfn)(struct bnad * ) ;
  void (*cbfn___0)(void * ) ;
  void *cbarg ;
  {
  if ((unsigned long )enet->mtu_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn = enet->mtu_cbfn;
    enet->mtu_cbfn = (void (*)(struct bnad * ))0;
    (*cbfn)((enet->bna)->bnad);
  } else {
  }
  if ((unsigned long )enet->stop_cbfn != (unsigned long )((void (*)(void * ))0)) {
    cbfn___0 = enet->stop_cbfn;
    cbarg = enet->stop_cbarg;
    enet->stop_cbfn = (void (*)(void * ))0;
    enet->stop_cbarg = (void *)0;
    (*cbfn___0)(cbarg);
  } else {
  }
  return;
}
}
static void bna_enet_sm_stopped(struct bna_enet *enet , enum bna_enet_event event )
{
  void (*cbfn)(void * ) ;
  void *cbarg ;
  void (*cbfn___0)(struct bnad * ) ;
  {
  switch ((unsigned int )event) {
  case 1U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_pause_init_wait);
  bna_enet_sm_pause_init_wait_entry(enet);
  goto ldv_49562;
  case 2U: ;
  if ((unsigned long )enet->stop_cbfn != (unsigned long )((void (*)(void * ))0)) {
    cbfn = enet->stop_cbfn;
    cbarg = enet->stop_cbarg;
    enet->stop_cbfn = (void (*)(void * ))0;
    enet->stop_cbarg = (void *)0;
    (*cbfn)(cbarg);
  } else {
  }
  goto ldv_49562;
  case 3U: ;
  goto ldv_49562;
  case 4U: ;
  goto ldv_49562;
  case 5U: ;
  if ((unsigned long )enet->mtu_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn___0 = enet->mtu_cbfn;
    enet->mtu_cbfn = (void (*)(struct bnad * ))0;
    (*cbfn___0)((enet->bna)->bnad);
  } else {
  }
  goto ldv_49562;
  case 7U: ;
  goto ldv_49562;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         954, (unsigned int )event);
  }
  ldv_49562: ;
  return;
}
}
static void bna_enet_sm_pause_init_wait_entry(struct bna_enet *enet )
{
  {
  bna_bfi_pause_set(enet);
  return;
}
}
static void bna_enet_sm_pause_init_wait(struct bna_enet *enet , enum bna_enet_event event )
{
  enum bna_tx_type tx_type ;
  enum bna_rx_type rx_type ;
  {
  switch ((unsigned int )event) {
  case 2U:
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_last_resp_wait);
  bna_enet_sm_last_resp_wait_entry(enet);
  goto ldv_49582;
  case 3U:
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  goto ldv_49582;
  case 4U:
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 4U);
  goto ldv_49582;
  case 5U: ;
  goto ldv_49582;
  case 6U: ;
  if (((unsigned int )enet->flags & 4U) != 0U) {
    enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
    bna_bfi_pause_set(enet);
  } else {
    enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_started);
    bna_enet_sm_started_entry(enet);
    tx_type = (unsigned int )enet->type != 0U;
    rx_type = (unsigned int )enet->type != 0U;
    bna_ethport_start(& (enet->bna)->ethport);
    bna_tx_mod_start(& (enet->bna)->tx_mod, tx_type);
    bna_rx_mod_start(& (enet->bna)->rx_mod, rx_type);
  }
  goto ldv_49582;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         998, (unsigned int )event);
  }
  ldv_49582: ;
  return;
}
}
static void bna_enet_sm_last_resp_wait_entry(struct bna_enet *enet )
{
  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  return;
}
}
static void bna_enet_sm_last_resp_wait(struct bna_enet *enet , enum bna_enet_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 6U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  goto ldv_49599;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1019, (unsigned int )event);
  }
  ldv_49599: ;
  return;
}
}
static void bna_enet_sm_started_entry(struct bna_enet *enet )
{
  void (*cbfn)(struct bnad * ) ;
  {
  if ((unsigned long )enet->mtu_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn = enet->mtu_cbfn;
    enet->mtu_cbfn = (void (*)(struct bnad * ))0;
    (*cbfn)((enet->bna)->bnad);
  } else {
  }
  return;
}
}
static void bna_enet_sm_started(struct bna_enet *enet , enum bna_enet_event event )
{
  enum bna_rx_type rx_type ;
  {
  switch ((unsigned int )event) {
  case 2U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_chld_stop_wait);
  bna_enet_sm_chld_stop_wait_entry(enet);
  goto ldv_49611;
  case 3U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49611;
  case 4U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_cfg_wait);
  bna_enet_sm_cfg_wait_entry(enet);
  bna_bfi_pause_set(enet);
  goto ldv_49611;
  case 5U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_cfg_wait);
  bna_enet_sm_cfg_wait_entry(enet);
  rx_type = (unsigned int )enet->type != 0U;
  bfa_wc_init(& enet->chld_stop_wc, & bna_enet_cb_chld_stopped, (void *)enet);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_rx_mod_stop(& (enet->bna)->rx_mod, rx_type);
  bfa_wc_wait(& enet->chld_stop_wc);
  goto ldv_49611;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1058, (unsigned int )event);
  }
  ldv_49611: ;
  return;
}
}
static void bna_enet_sm_cfg_wait_entry(struct bna_enet *enet )
{
  {
  return;
}
}
static void bna_enet_sm_cfg_wait(struct bna_enet *enet , enum bna_enet_event event )
{
  enum bna_rx_type rx_type ;
  enum bna_rx_type rx_type___0 ;
  {
  switch ((unsigned int )event) {
  case 2U:
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_cfg_stop_wait);
  bna_enet_sm_cfg_stop_wait_entry(enet);
  goto ldv_49625;
  case 3U:
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49625;
  case 4U:
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 4U);
  goto ldv_49625;
  case 5U:
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 8U);
  goto ldv_49625;
  case 7U:
  rx_type = (unsigned int )enet->type != 0U;
  bna_rx_mod_start(& (enet->bna)->rx_mod, rx_type);
  case 6U: ;
  if (((unsigned int )enet->flags & 4U) != 0U) {
    enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
    bna_bfi_pause_set(enet);
  } else
  if (((unsigned int )enet->flags & 8U) != 0U) {
    enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
    rx_type___0 = (unsigned int )enet->type != 0U;
    bfa_wc_init(& enet->chld_stop_wc, & bna_enet_cb_chld_stopped, (void *)enet);
    bfa_wc_up(& enet->chld_stop_wc);
    bna_rx_mod_stop(& (enet->bna)->rx_mod, rx_type___0);
    bfa_wc_wait(& enet->chld_stop_wc);
  } else {
    enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_started);
    bna_enet_sm_started_entry(enet);
  }
  goto ldv_49625;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1109, (unsigned int )event);
  }
  ldv_49625: ;
  return;
}
}
static void bna_enet_sm_cfg_stop_wait_entry(struct bna_enet *enet )
{
  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967291U);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967287U);
  return;
}
}
static void bna_enet_sm_cfg_stop_wait(struct bna_enet *enet , enum bna_enet_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49642;
  case 6U: ;
  case 7U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_chld_stop_wait);
  bna_enet_sm_chld_stop_wait_entry(enet);
  goto ldv_49642;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1136, (unsigned int )event);
  }
  ldv_49642: ;
  return;
}
}
static void bna_enet_sm_chld_stop_wait_entry(struct bna_enet *enet )
{
  enum bna_tx_type tx_type ;
  enum bna_rx_type rx_type ;
  {
  tx_type = (unsigned int )enet->type != 0U;
  rx_type = (unsigned int )enet->type != 0U;
  bfa_wc_init(& enet->chld_stop_wc, & bna_enet_cb_chld_stopped, (void *)enet);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_ethport_stop(& (enet->bna)->ethport);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_tx_mod_stop(& (enet->bna)->tx_mod, tx_type);
  bfa_wc_up(& enet->chld_stop_wc);
  bna_rx_mod_stop(& (enet->bna)->rx_mod, rx_type);
  bfa_wc_wait(& enet->chld_stop_wc);
  return;
}
}
static void bna_enet_sm_chld_stop_wait(struct bna_enet *enet , enum bna_enet_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  bna_ethport_fail(& (enet->bna)->ethport);
  bna_tx_mod_fail(& (enet->bna)->tx_mod);
  bna_rx_mod_fail(& (enet->bna)->rx_mod);
  goto ldv_49656;
  case 7U:
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  goto ldv_49656;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1161, (unsigned int )event);
  }
  ldv_49656: ;
  return;
}
}
static void bna_bfi_pause_set(struct bna_enet *enet )
{
  struct bfi_enet_set_pause_req *pause_req ;
  {
  pause_req = & enet->pause_req;
  pause_req->mh.msg_class = 24U;
  pause_req->mh.msg_id = 20U;
  pause_req->mh.msg_token = 0U;
  pause_req->mh.enet_id = 0U;
  pause_req->mh.num_entries = 256U;
  pause_req->tx_pause = (u8 )enet->pause_config.tx_pause;
  pause_req->rx_pause = (u8 )enet->pause_config.rx_pause;
  enet->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  enet->msgq_cmd.cbarg = (void *)0;
  enet->msgq_cmd.msg_size = 12UL;
  enet->msgq_cmd.msg_hdr = & pause_req->mh;
  bfa_msgq_cmd_post(& (enet->bna)->msgq, & enet->msgq_cmd);
  return;
}
}
static void bna_enet_cb_chld_stopped(void *arg )
{
  struct bna_enet *enet ;
  {
  enet = (struct bna_enet *)arg;
  (*(enet->fsm))((void *)enet, 7);
  return;
}
}
static void bna_enet_init(struct bna_enet *enet , struct bna *bna )
{
  {
  enet->bna = bna;
  enet->flags = 0;
  enet->mtu = 0;
  enet->type = 0;
  enet->stop_cbfn = (void (*)(void * ))0;
  enet->stop_cbarg = (void *)0;
  enet->mtu_cbfn = (void (*)(struct bnad * ))0;
  enet->fsm = (void (*)(void * , int ))(& bna_enet_sm_stopped);
  bna_enet_sm_stopped_entry(enet);
  return;
}
}
static void bna_enet_uninit(struct bna_enet *enet )
{
  {
  enet->flags = 0;
  enet->bna = (struct bna *)0;
  return;
}
}
static void bna_enet_start(struct bna_enet *enet )
{
  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 1U);
  if (((unsigned int )enet->flags & 2U) != 0U) {
    (*(enet->fsm))((void *)enet, 1);
  } else {
  }
  return;
}
}
static void bna_ioceth_cb_enet_stopped(void *arg )
{
  struct bna_ioceth *ioceth ;
  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 7);
  return;
}
}
static void bna_enet_stop(struct bna_enet *enet )
{
  {
  enet->stop_cbfn = & bna_ioceth_cb_enet_stopped;
  enet->stop_cbarg = (void *)(& (enet->bna)->ioceth);
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967294U);
  (*(enet->fsm))((void *)enet, 2);
  return;
}
}
static void bna_enet_fail(struct bna_enet *enet )
{
  {
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967294U);
  (*(enet->fsm))((void *)enet, 3);
  return;
}
}
void bna_enet_cb_tx_stopped(struct bna_enet *enet )
{
  {
  bfa_wc_down(& enet->chld_stop_wc);
  return;
}
}
void bna_enet_cb_rx_stopped(struct bna_enet *enet )
{
  {
  bfa_wc_down(& enet->chld_stop_wc);
  return;
}
}
int bna_enet_mtu_get(struct bna_enet *enet )
{
  {
  return (enet->mtu);
}
}
void bna_enet_enable(struct bna_enet *enet )
{
  {
  if ((unsigned long )enet->fsm != (unsigned long )((void (*)(void * , int ))(& bna_enet_sm_stopped))) {
    return;
  } else {
  }
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags | 2U);
  if ((int )enet->flags & 1) {
    (*(enet->fsm))((void *)enet, 1);
  } else {
  }
  return;
}
}
void bna_enet_disable(struct bna_enet *enet , enum bna_cleanup_type type , void (*cbfn)(void * ) )
{
  {
  if ((unsigned int )type == 1U) {
    (*cbfn)((void *)(enet->bna)->bnad);
    return;
  } else {
  }
  enet->stop_cbfn = cbfn;
  enet->stop_cbarg = (void *)(enet->bna)->bnad;
  enet->flags = (enum bna_enet_flags )((unsigned int )enet->flags & 4294967293U);
  (*(enet->fsm))((void *)enet, 2);
  return;
}
}
void bna_enet_pause_config(struct bna_enet *enet , struct bna_pause_config *pause_config )
{
  {
  enet->pause_config = *pause_config;
  (*(enet->fsm))((void *)enet, 4);
  return;
}
}
void bna_enet_mtu_set(struct bna_enet *enet , int mtu , void (*cbfn)(struct bnad * ) )
{
  {
  enet->mtu = mtu;
  enet->mtu_cbfn = cbfn;
  (*(enet->fsm))((void *)enet, 5);
  return;
}
}
void bna_enet_perm_mac_get(struct bna_enet *enet , u8 *mac )
{
  {
  bfa_nw_ioc_get_mac(& (enet->bna)->ioceth.ioc, mac);
  return;
}
}
static void bna_bfi_attr_get(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_stopped(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_stopped_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_ioc_ready_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_ioc_ready_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_enet_attr_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_enet_attr_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_ready(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_ready_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_last_resp_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_last_resp_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_enet_stop_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_enet_stop_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_ioc_disable_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_ioc_disable_wait_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_failed(struct bna_ioceth *ioceth , enum bna_ioceth_event event ) ;
static void bna_ioceth_sm_failed_entry(struct bna_ioceth *ioceth ) ;
static void bna_ioceth_sm_stopped_entry(struct bna_ioceth *ioceth )
{
  void (*cbfn)(struct bnad * ) ;
  struct bnad *cbarg ;
  {
  if ((unsigned long )ioceth->stop_cbfn != (unsigned long )((void (*)(struct bnad * ))0)) {
    cbfn = ioceth->stop_cbfn;
    cbarg = ioceth->stop_cbarg;
    ioceth->stop_cbfn = (void (*)(struct bnad * ))0;
    ioceth->stop_cbarg = (struct bnad *)0;
    (*cbfn)(cbarg);
  } else {
  }
  return;
}
}
static void bna_ioceth_sm_stopped(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 intr_status ;
  u32 mask ;
  u32 mask___0 ;
  {
  switch ((unsigned int )event) {
  case 1U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_ready_wait);
  bna_ioceth_sm_ioc_ready_wait_entry(ioceth);
  bfa_nw_ioc_enable(& ioceth->ioc);
  goto ldv_49772;
  case 2U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_stopped);
  bna_ioceth_sm_stopped_entry(ioceth);
  goto ldv_49772;
  case 3U:
  intr_status = readl((void const volatile *)(ioceth->bna)->regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ (ioceth->bna)->bits.mbox_status_bits & intr_status, (void volatile *)(ioceth->bna)->regs.fn_int_status);
  } else {
  }
  bnad_cb_mbox_intr_enable((ioceth->bna)->bnad);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(~ ((ioceth->bna)->bits.mbox_mask_bits | (ioceth->bna)->bits.error_mask_bits) & mask,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  goto ldv_49772;
  case 4U:
  mask___0 = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask___0) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask___0 = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49772;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1419, (unsigned int )event);
  }
  ldv_49772: ;
  return;
}
}
static void bna_ioceth_sm_ioc_ready_wait_entry(struct bna_ioceth *ioceth )
{
  {
  return;
}
}
static void bna_ioceth_sm_ioc_ready_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 intr_status ;
  u32 mask ;
  u32 mask___0 ;
  {
  switch ((unsigned int )event) {
  case 2U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49788;
  case 3U:
  intr_status = readl((void const volatile *)(ioceth->bna)->regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ (ioceth->bna)->bits.mbox_status_bits & intr_status, (void volatile *)(ioceth->bna)->regs.fn_int_status);
  } else {
  }
  bnad_cb_mbox_intr_enable((ioceth->bna)->bnad);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(~ ((ioceth->bna)->bits.mbox_mask_bits | (ioceth->bna)->bits.error_mask_bits) & mask,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  goto ldv_49788;
  case 4U:
  mask___0 = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask___0) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask___0 = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49788;
  case 5U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_enet_attr_wait);
  bna_ioceth_sm_enet_attr_wait_entry(ioceth);
  goto ldv_49788;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1456, (unsigned int )event);
  }
  ldv_49788: ;
  return;
}
}
static void bna_ioceth_sm_enet_attr_wait_entry(struct bna_ioceth *ioceth )
{
  {
  bna_bfi_attr_get(ioceth);
  return;
}
}
static void bna_ioceth_sm_enet_attr_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 mask ;
  {
  switch ((unsigned int )event) {
  case 2U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_last_resp_wait);
  bna_ioceth_sm_last_resp_wait_entry(ioceth);
  goto ldv_49804;
  case 4U:
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49804;
  case 6U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ready);
  bna_ioceth_sm_ready_entry(ioceth);
  goto ldv_49804;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1485, (unsigned int )event);
  }
  ldv_49804: ;
  return;
}
}
static void bna_ioceth_sm_ready_entry(struct bna_ioceth *ioceth )
{
  {
  bna_enet_start(& (ioceth->bna)->enet);
  (ioceth->bna)->stats_mod.ioc_ready = 1;
  bnad_cb_ioceth_ready((ioceth->bna)->bnad);
  return;
}
}
static void bna_ioceth_sm_ready(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 mask ;
  {
  switch ((unsigned int )event) {
  case 2U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_enet_stop_wait);
  bna_ioceth_sm_enet_stop_wait_entry(ioceth);
  goto ldv_49817;
  case 4U:
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  bna_enet_fail(& (ioceth->bna)->enet);
  (ioceth->bna)->stats_mod.ioc_ready = 0;
  (ioceth->bna)->stats_mod.stats_get_busy = 0;
  (ioceth->bna)->stats_mod.stats_clr_busy = 0;
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_failed);
  bna_ioceth_sm_failed_entry(ioceth);
  goto ldv_49817;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1513, (unsigned int )event);
  }
  ldv_49817: ;
  return;
}
}
static void bna_ioceth_sm_last_resp_wait_entry(struct bna_ioceth *ioceth )
{
  {
  return;
}
}
static void bna_ioceth_sm_last_resp_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 mask ;
  {
  switch ((unsigned int )event) {
  case 4U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49830;
  case 6U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49830;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1539, (unsigned int )event);
  }
  ldv_49830: ;
  return;
}
}
static void bna_ioceth_sm_enet_stop_wait_entry(struct bna_ioceth *ioceth )
{
  {
  (ioceth->bna)->stats_mod.ioc_ready = 0;
  bna_enet_stop(& (ioceth->bna)->enet);
  return;
}
}
static void bna_ioceth_sm_enet_stop_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 mask ;
  {
  switch ((unsigned int )event) {
  case 4U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  bna_enet_fail(& (ioceth->bna)->enet);
  (ioceth->bna)->stats_mod.ioc_ready = 0;
  (ioceth->bna)->stats_mod.stats_get_busy = 0;
  (ioceth->bna)->stats_mod.stats_clr_busy = 0;
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49842;
  case 7U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49842;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1569, (unsigned int )event);
  }
  ldv_49842: ;
  return;
}
}
static void bna_ioceth_sm_ioc_disable_wait_entry(struct bna_ioceth *ioceth )
{
  {
  return;
}
}
static void bna_ioceth_sm_ioc_disable_wait(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 mask ;
  {
  switch ((unsigned int )event) {
  case 8U:
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(((ioceth->bna)->bits.mbox_mask_bits | mask) | (ioceth->bna)->bits.error_mask_bits,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  bnad_cb_mbox_intr_disable((ioceth->bna)->bnad);
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_stopped);
  bna_ioceth_sm_stopped_entry(ioceth);
  goto ldv_49854;
  case 7U: ;
  goto ldv_49854;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1594, (unsigned int )event);
  }
  ldv_49854: ;
  return;
}
}
static void bna_ioceth_sm_failed_entry(struct bna_ioceth *ioceth )
{
  {
  bnad_cb_ioceth_failed((ioceth->bna)->bnad);
  return;
}
}
static void bna_ioceth_sm_failed(struct bna_ioceth *ioceth , enum bna_ioceth_event event )
{
  u32 intr_status ;
  u32 mask ;
  {
  switch ((unsigned int )event) {
  case 2U:
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_disable_wait);
  bna_ioceth_sm_ioc_disable_wait_entry(ioceth);
  bfa_nw_ioc_disable(& ioceth->ioc);
  goto ldv_49865;
  case 3U:
  intr_status = readl((void const volatile *)(ioceth->bna)->regs.fn_int_status);
  if (intr_status != 0U) {
    writel(~ (ioceth->bna)->bits.mbox_status_bits & intr_status, (void volatile *)(ioceth->bna)->regs.fn_int_status);
  } else {
  }
  bnad_cb_mbox_intr_enable((ioceth->bna)->bnad);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  writel(~ ((ioceth->bna)->bits.mbox_mask_bits | (ioceth->bna)->bits.error_mask_bits) & mask,
         (void volatile *)(ioceth->bna)->regs.fn_int_mask);
  mask = readl((void const volatile *)(ioceth->bna)->regs.fn_int_mask);
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_ioc_ready_wait);
  bna_ioceth_sm_ioc_ready_wait_entry(ioceth);
  goto ldv_49865;
  case 4U: ;
  goto ldv_49865;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_enet.c",
         1623, (unsigned int )event);
  }
  ldv_49865: ;
  return;
}
}
static void bna_bfi_attr_get(struct bna_ioceth *ioceth )
{
  struct bfi_enet_attr_req *attr_req ;
  {
  attr_req = & ioceth->attr_req;
  attr_req->mh.msg_class = 24U;
  attr_req->mh.msg_id = 22U;
  attr_req->mh.msg_token = 0U;
  attr_req->mh.enet_id = 0U;
  attr_req->mh.num_entries = 256U;
  ioceth->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  ioceth->msgq_cmd.cbarg = (void *)0;
  ioceth->msgq_cmd.msg_size = 8UL;
  ioceth->msgq_cmd.msg_hdr = & attr_req->mh;
  bfa_msgq_cmd_post(& (ioceth->bna)->msgq, & ioceth->msgq_cmd);
  return;
}
}
static void bna_cb_ioceth_enable(void *arg , enum bfa_status error )
{
  struct bna_ioceth *ioceth ;
  {
  ioceth = (struct bna_ioceth *)arg;
  if ((unsigned int )error != 0U) {
    (*(ioceth->fsm))((void *)ioceth, 4);
  } else {
    (*(ioceth->fsm))((void *)ioceth, 5);
  }
  return;
}
}
static void bna_cb_ioceth_disable(void *arg )
{
  struct bna_ioceth *ioceth ;
  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 8);
  return;
}
}
static void bna_cb_ioceth_hbfail(void *arg )
{
  struct bna_ioceth *ioceth ;
  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 4);
  return;
}
}
static void bna_cb_ioceth_reset(void *arg )
{
  struct bna_ioceth *ioceth ;
  {
  ioceth = (struct bna_ioceth *)arg;
  (*(ioceth->fsm))((void *)ioceth, 3);
  return;
}
}
static struct bfa_ioc_cbfn bna_ioceth_cbfn = {& bna_cb_ioceth_enable, & bna_cb_ioceth_disable, & bna_cb_ioceth_hbfail, & bna_cb_ioceth_reset};
static void bna_attr_init(struct bna_ioceth *ioceth )
{
  {
  ioceth->attr.num_txq = 1;
  ioceth->attr.num_rxp = 1;
  ioceth->attr.num_ucmac = 1;
  ioceth->attr.num_mcmac = 256;
  ioceth->attr.max_rit_size = 1;
  ioceth->attr.fw_query_complete = 0;
  return;
}
}
static void bna_ioceth_init(struct bna_ioceth *ioceth , struct bna *bna , struct bna_res_info *res_info )
{
  u64 dma ;
  u8 *kva ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  u32 tmp___3 ;
  u32 tmp___4 ;
  u32 tmp___5 ;
  u32 tmp___6 ;
  u32 tmp___7 ;
  u32 tmp___8 ;
  {
  ioceth->bna = bna;
  bfa_nw_ioc_attach(& ioceth->ioc, (void *)ioceth, & bna_ioceth_cbfn);
  bfa_nw_ioc_pci_init(& ioceth->ioc, & bna->pcidev, 512);
  tmp = __fswab32(((res_info + 1UL)->res_u.mem_info.mdl)->dma.msb);
  tmp___0 = __fswab32(((res_info + 1UL)->res_u.mem_info.mdl)->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  kva = (u8 *)((res_info + 1UL)->res_u.mem_info.mdl)->kva;
  bfa_nw_ioc_mem_claim(& ioceth->ioc, kva, dma);
  kva = (u8 *)((res_info + 2UL)->res_u.mem_info.mdl)->kva;
  bfa_nw_ioc_debug_memclaim(& ioceth->ioc, (void *)kva);
  tmp___1 = __fswab32((res_info->res_u.mem_info.mdl)->dma.msb);
  tmp___2 = __fswab32((res_info->res_u.mem_info.mdl)->dma.lsb);
  dma = ((unsigned long long )tmp___1 << 32) | (unsigned long long )tmp___2;
  kva = (u8 *)(res_info->res_u.mem_info.mdl)->kva;
  bfa_nw_cee_attach(& bna->cee, & ioceth->ioc, (void *)bna);
  bfa_nw_cee_mem_claim(& bna->cee, kva, dma);
  tmp___3 = bfa_nw_cee_meminfo();
  kva = kva + (unsigned long )tmp___3;
  tmp___4 = bfa_nw_cee_meminfo();
  dma = (u64 )tmp___4 + dma;
  bfa_nw_flash_attach(& bna->flash, & ioceth->ioc, (void *)bna);
  bfa_nw_flash_memclaim(& bna->flash, kva, dma);
  tmp___5 = bfa_nw_flash_meminfo();
  kva = kva + (unsigned long )tmp___5;
  tmp___6 = bfa_nw_flash_meminfo();
  dma = (u64 )tmp___6 + dma;
  bfa_msgq_attach(& bna->msgq, & ioceth->ioc);
  bfa_msgq_memclaim(& bna->msgq, kva, dma);
  bfa_msgq_regisr(& bna->msgq, 24, & bna_msgq_rsp_handler, (void *)bna);
  tmp___7 = bfa_msgq_meminfo();
  kva = kva + (unsigned long )tmp___7;
  tmp___8 = bfa_msgq_meminfo();
  dma = (u64 )tmp___8 + dma;
  ioceth->stop_cbfn = (void (*)(struct bnad * ))0;
  ioceth->stop_cbarg = (struct bnad *)0;
  bna_attr_init(ioceth);
  ioceth->fsm = (void (*)(void * , int ))(& bna_ioceth_sm_stopped);
  bna_ioceth_sm_stopped_entry(ioceth);
  return;
}
}
static void bna_ioceth_uninit(struct bna_ioceth *ioceth )
{
  {
  bfa_nw_ioc_detach(& ioceth->ioc);
  ioceth->bna = (struct bna *)0;
  return;
}
}
void bna_ioceth_enable(struct bna_ioceth *ioceth )
{
  {
  if ((unsigned long )ioceth->fsm == (unsigned long )((void (*)(void * , int ))(& bna_ioceth_sm_ready))) {
    bnad_cb_ioceth_ready((ioceth->bna)->bnad);
    return;
  } else {
  }
  if ((unsigned long )ioceth->fsm == (unsigned long )((void (*)(void * , int ))(& bna_ioceth_sm_stopped))) {
    (*(ioceth->fsm))((void *)ioceth, 1);
  } else {
  }
  return;
}
}
void bna_ioceth_disable(struct bna_ioceth *ioceth , enum bna_cleanup_type type )
{
  {
  if ((unsigned int )type == 1U) {
    bnad_cb_ioceth_disabled((ioceth->bna)->bnad);
    return;
  } else {
  }
  ioceth->stop_cbfn = & bnad_cb_ioceth_disabled;
  ioceth->stop_cbarg = (ioceth->bna)->bnad;
  (*(ioceth->fsm))((void *)ioceth, 2);
  return;
}
}
static void bna_ucam_mod_init(struct bna_ucam_mod *ucam_mod , struct bna *bna , struct bna_res_info *res_info )
{
  int i ;
  {
  ucam_mod->ucmac = (struct bna_mac *)((res_info + 5UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& ucam_mod->free_q);
  i = 0;
  goto ldv_49920;
  ldv_49919:
  list_add_tail(& (ucam_mod->ucmac + (unsigned long )i)->qe, & ucam_mod->free_q);
  i = i + 1;
  ldv_49920: ;
  if (bna->ioceth.attr.num_ucmac > i) {
    goto ldv_49919;
  } else {
  }
  INIT_LIST_HEAD(& ucam_mod->del_q);
  i = i;
  goto ldv_49923;
  ldv_49922:
  list_add_tail(& (ucam_mod->ucmac + (unsigned long )i)->qe, & ucam_mod->del_q);
  i = i + 1;
  ldv_49923: ;
  if (bna->ioceth.attr.num_ucmac * 2 > i) {
    goto ldv_49922;
  } else {
  }
  ucam_mod->bna = bna;
  return;
}
}
static void bna_ucam_mod_uninit(struct bna_ucam_mod *ucam_mod )
{
  {
  ucam_mod->bna = (struct bna *)0;
  return;
}
}
static void bna_mcam_mod_init(struct bna_mcam_mod *mcam_mod , struct bna *bna , struct bna_res_info *res_info )
{
  int i ;
  {
  mcam_mod->mcmac = (struct bna_mac *)((res_info + 6UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& mcam_mod->free_q);
  i = 0;
  goto ldv_49935;
  ldv_49934:
  list_add_tail(& (mcam_mod->mcmac + (unsigned long )i)->qe, & mcam_mod->free_q);
  i = i + 1;
  ldv_49935: ;
  if (bna->ioceth.attr.num_mcmac > i) {
    goto ldv_49934;
  } else {
  }
  mcam_mod->mchandle = (struct bna_mcam_handle *)((res_info + 7UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& mcam_mod->free_handle_q);
  i = 0;
  goto ldv_49938;
  ldv_49937:
  list_add_tail(& (mcam_mod->mchandle + (unsigned long )i)->qe, & mcam_mod->free_handle_q);
  i = i + 1;
  ldv_49938: ;
  if (bna->ioceth.attr.num_mcmac > i) {
    goto ldv_49937;
  } else {
  }
  INIT_LIST_HEAD(& mcam_mod->del_q);
  i = i;
  goto ldv_49941;
  ldv_49940:
  list_add_tail(& (mcam_mod->mcmac + (unsigned long )i)->qe, & mcam_mod->del_q);
  i = i + 1;
  ldv_49941: ;
  if (bna->ioceth.attr.num_mcmac * 2 > i) {
    goto ldv_49940;
  } else {
  }
  mcam_mod->bna = bna;
  return;
}
}
static void bna_mcam_mod_uninit(struct bna_mcam_mod *mcam_mod )
{
  {
  mcam_mod->bna = (struct bna *)0;
  return;
}
}
static void bna_bfi_stats_get(struct bna *bna )
{
  struct bfi_enet_stats_req *stats_req ;
  __u32 tmp ;
  __u32 tmp___0 ;
  {
  stats_req = & bna->stats_mod.stats_get;
  bna->stats_mod.stats_get_busy = 1;
  stats_req->mh.msg_class = 24U;
  stats_req->mh.msg_id = 23U;
  stats_req->mh.msg_token = 0U;
  stats_req->mh.enet_id = 0U;
  stats_req->mh.num_entries = 256U;
  stats_req->stats_mask = 7936U;
  tmp = __fswab32(bna->tx_mod.rid_mask);
  stats_req->tx_enet_mask = tmp;
  tmp___0 = __fswab32(bna->rx_mod.rid_mask);
  stats_req->rx_enet_mask = tmp___0;
  stats_req->host_buffer.a32.addr_hi = bna->stats.hw_stats_dma.msb;
  stats_req->host_buffer.a32.addr_lo = bna->stats.hw_stats_dma.lsb;
  bna->stats_mod.stats_get_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  bna->stats_mod.stats_get_cmd.cbarg = (void *)0;
  bna->stats_mod.stats_get_cmd.msg_size = 28UL;
  bna->stats_mod.stats_get_cmd.msg_hdr = & stats_req->mh;
  bfa_msgq_cmd_post(& bna->msgq, & bna->stats_mod.stats_get_cmd);
  return;
}
}
void bna_res_req(struct bna_res_info *res_info )
{
  u32 tmp ;
  u32 tmp___0 ;
  u32 tmp___1 ;
  u32 tmp___2 ;
  {
  res_info->res_type = 1;
  res_info->res_u.mem_info.mem_type = 2;
  res_info->res_u.mem_info.num = 1U;
  tmp = bfa_nw_cee_meminfo();
  tmp___0 = bfa_nw_flash_meminfo();
  tmp___1 = bfa_msgq_meminfo();
  res_info->res_u.mem_info.len = (((tmp + tmp___0) + tmp___1) + 4095U) & 4294963200U;
  (res_info + 1UL)->res_type = 1;
  (res_info + 1UL)->res_u.mem_info.mem_type = 2;
  (res_info + 1UL)->res_u.mem_info.num = 1U;
  tmp___2 = bfa_nw_ioc_meminfo();
  (res_info + 1UL)->res_u.mem_info.len = (tmp___2 + 4095U) & 4294963200U;
  (res_info + 2UL)->res_type = 1;
  (res_info + 2UL)->res_u.mem_info.mem_type = 1;
  (res_info + 2UL)->res_u.mem_info.num = 1U;
  (res_info + 2UL)->res_u.mem_info.len = 4128U;
  (res_info + 3UL)->res_type = 1;
  (res_info + 3UL)->res_u.mem_info.mem_type = 2;
  (res_info + 3UL)->res_u.mem_info.num = 1U;
  (res_info + 3UL)->res_u.mem_info.len = 8192U;
  return;
}
}
void bna_mod_res_req(struct bna *bna , struct bna_res_info *res_info )
{
  struct bna_attr *attr ;
  {
  attr = & bna->ioceth.attr;
  res_info->res_type = 1;
  res_info->res_u.mem_info.mem_type = 1;
  res_info->res_u.mem_info.num = 1U;
  res_info->res_u.mem_info.len = (u32 )((unsigned long )attr->num_txq) * 520U;
  (res_info + 1UL)->res_type = 1;
  (res_info + 1UL)->res_u.mem_info.mem_type = 1;
  (res_info + 1UL)->res_u.mem_info.num = 1U;
  (res_info + 1UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_txq) * 144U;
  (res_info + 2UL)->res_type = 1;
  (res_info + 2UL)->res_u.mem_info.mem_type = 1;
  (res_info + 2UL)->res_u.mem_info.num = 1U;
  (res_info + 2UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_rxp) * 2512U;
  (res_info + 3UL)->res_type = 1;
  (res_info + 3UL)->res_u.mem_info.mem_type = 1;
  (res_info + 3UL)->res_u.mem_info.num = 1U;
  (res_info + 3UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_rxp) * 152U;
  (res_info + 4UL)->res_type = 1;
  (res_info + 4UL)->res_u.mem_info.mem_type = 1;
  (res_info + 4UL)->res_u.mem_info.num = 1U;
  (res_info + 4UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_rxp) * 240U;
  (res_info + 5UL)->res_type = 1;
  (res_info + 5UL)->res_u.mem_info.mem_type = 1;
  (res_info + 5UL)->res_u.mem_info.num = 1U;
  (res_info + 5UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_ucmac) * 64U;
  (res_info + 6UL)->res_type = 1;
  (res_info + 6UL)->res_u.mem_info.mem_type = 1;
  (res_info + 6UL)->res_u.mem_info.num = 1U;
  (res_info + 6UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_mcmac) * 64U;
  (res_info + 7UL)->res_type = 1;
  (res_info + 7UL)->res_u.mem_info.mem_type = 1;
  (res_info + 7UL)->res_u.mem_info.num = 1U;
  (res_info + 7UL)->res_u.mem_info.len = (u32 )((unsigned long )attr->num_mcmac) * 24U;
  return;
}
}
void bna_init(struct bna *bna , struct bnad *bnad , struct bfa_pcidev *pcidev , struct bna_res_info *res_info )
{
  struct bna_reg_offset reg_offset[4U] ;
  {
  bna->bnad = bnad;
  bna->pcidev = *pcidev;
  bna->stats.hw_stats_kva = (struct bfi_enet_stats *)((res_info + 3UL)->res_u.mem_info.mdl)->kva;
  bna->stats.hw_stats_dma.msb = ((res_info + 3UL)->res_u.mem_info.mdl)->dma.msb;
  bna->stats.hw_stats_dma.lsb = ((res_info + 3UL)->res_u.mem_info.mdl)->dma.lsb;
  switch ((int )bna->pcidev.device_id) {
  case 20:
  reg_offset[0].fn_int_status = 81920U;
  reg_offset[0].fn_int_mask = 81924U;
  reg_offset[1].fn_int_status = 82176U;
  reg_offset[1].fn_int_mask = 82180U;
  reg_offset[2].fn_int_status = 82688U;
  reg_offset[2].fn_int_mask = 82692U;
  reg_offset[3].fn_int_status = 82944U;
  reg_offset[3].fn_int_mask = 82948U;
  bna->regs.fn_int_status = bna->pcidev.pci_bar_kva + (unsigned long )reg_offset[(int )bna->pcidev.pci_func].fn_int_status;
  bna->regs.fn_int_mask = bna->pcidev.pci_bar_kva + (unsigned long )reg_offset[(int )bna->pcidev.pci_func].fn_int_mask;
  bna->bits.mbox_status_bits = 3145728U;
  bna->bits.mbox_mask_bits = 3145728U;
  bna->bits.error_status_bits = 17760256U;
  bna->bits.error_mask_bits = 17760256U;
  bna->bits.halt_status_bits = 16777216U;
  bna->bits.halt_mask_bits = 16777216U;
  goto ldv_49966;
  case 34:
  bna->regs.fn_int_status = bna->pcidev.pci_bar_kva + 196864UL;
  bna->regs.fn_int_mask = bna->pcidev.pci_bar_kva + 196868UL;
  bna->bits.mbox_status_bits = 196608U;
  bna->bits.mbox_mask_bits = 196608U;
  bna->bits.error_status_bits = 33292288U;
  bna->bits.error_mask_bits = 33292288U;
  bna->bits.halt_status_bits = 2097152U;
  bna->bits.halt_mask_bits = 2097152U;
  goto ldv_49966;
  }
  ldv_49966:
  bna_ioceth_init(& bna->ioceth, bna, res_info);
  bna_enet_init(& bna->enet, bna);
  bna_ethport_init(& bna->ethport, bna);
  return;
}
}
void bna_mod_init(struct bna *bna , struct bna_res_info *res_info )
{
  {
  bna_tx_mod_init(& bna->tx_mod, bna, res_info);
  bna_rx_mod_init(& bna->rx_mod, bna, res_info);
  bna_ucam_mod_init(& bna->ucam_mod, bna, res_info);
  bna_mcam_mod_init(& bna->mcam_mod, bna, res_info);
  bna->default_mode_rid = -1;
  bna->promisc_rid = -1;
  bna->mod_flags = (enum bna_mod_flags )((unsigned int )bna->mod_flags | 1U);
  return;
}
}
void bna_uninit(struct bna *bna )
{
  {
  if ((int )bna->mod_flags & 1) {
    bna_mcam_mod_uninit(& bna->mcam_mod);
    bna_ucam_mod_uninit(& bna->ucam_mod);
    bna_rx_mod_uninit(& bna->rx_mod);
    bna_tx_mod_uninit(& bna->tx_mod);
    bna->mod_flags = (enum bna_mod_flags )((unsigned int )bna->mod_flags & 4294967294U);
  } else {
  }
  bna_ethport_uninit(& bna->ethport);
  bna_enet_uninit(& bna->enet);
  bna_ioceth_uninit(& bna->ioceth);
  bna->bnad = (struct bnad *)0;
  return;
}
}
int bna_num_txq_set(struct bna *bna , int num_txq )
{
  {
  if ((int )bna->ioceth.attr.fw_query_complete && bna->ioceth.attr.num_txq >= num_txq) {
    bna->ioceth.attr.num_txq = num_txq;
    return (0);
  } else {
  }
  return (1);
}
}
int bna_num_rxp_set(struct bna *bna , int num_rxp )
{
  {
  if ((int )bna->ioceth.attr.fw_query_complete && bna->ioceth.attr.num_rxp >= num_rxp) {
    bna->ioceth.attr.num_rxp = num_rxp;
    return (0);
  } else {
  }
  return (1);
}
}
struct bna_mac *bna_cam_mod_mac_get(struct list_head *head )
{
  struct bna_mac *mac ;
  struct list_head const *__mptr ;
  int tmp___0 ;
  {
  tmp___0 = list_empty((struct list_head const *)head);
  if (tmp___0 == 0) {
    __mptr = (struct list_head const *)head->next;
    mac = (struct bna_mac *)__mptr;
  } else {
    mac = (struct bna_mac *)0;
  }
  if ((unsigned long )mac != (unsigned long )((struct bna_mac *)0)) {
    list_del(& mac->qe);
  } else {
  }
  return (mac);
}
}
struct bna_mcam_handle *bna_mcam_mod_handle_get(struct bna_mcam_mod *mcam_mod )
{
  struct bna_mcam_handle *handle ;
  struct list_head const *__mptr ;
  int tmp___0 ;
  {
  tmp___0 = list_empty((struct list_head const *)(& mcam_mod->free_handle_q));
  if (tmp___0 == 0) {
    __mptr = (struct list_head const *)mcam_mod->free_handle_q.next;
    handle = (struct bna_mcam_handle *)__mptr;
  } else {
    handle = (struct bna_mcam_handle *)0;
  }
  if ((unsigned long )handle != (unsigned long )((struct bna_mcam_handle *)0)) {
    list_del(& handle->qe);
  } else {
  }
  return (handle);
}
}
void bna_mcam_mod_handle_put(struct bna_mcam_mod *mcam_mod , struct bna_mcam_handle *handle )
{
  {
  list_add_tail(& handle->qe, & mcam_mod->free_handle_q);
  return;
}
}
void bna_hw_stats_get(struct bna *bna )
{
  {
  if (! bna->stats_mod.ioc_ready) {
    bnad_cb_stats_get(bna->bnad, 1, & bna->stats);
    return;
  } else {
  }
  if ((int )bna->stats_mod.stats_get_busy) {
    bnad_cb_stats_get(bna->bnad, 3, & bna->stats);
    return;
  } else {
  }
  bna_bfi_stats_get(bna);
  return;
}
}
void ldv_main_exported_13(void)
{
  void *ldvarg33 ;
  void *tmp ;
  enum bfa_status ldvarg34 ;
  void *ldvarg31 ;
  void *tmp___0 ;
  void *ldvarg32 ;
  void *tmp___1 ;
  void *ldvarg35 ;
  void *tmp___2 ;
  int tmp___3 ;
  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg33 = tmp;
  tmp___0 = ldv_init_zalloc(1UL);
  ldvarg31 = tmp___0;
  tmp___1 = ldv_init_zalloc(1UL);
  ldvarg32 = tmp___1;
  tmp___2 = ldv_init_zalloc(1UL);
  ldvarg35 = tmp___2;
  ldv_memset((void *)(& ldvarg34), 0, 4UL);
  tmp___3 = __VERIFIER_nondet_int();
  switch (tmp___3) {
  case 0: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_disable(ldvarg35);
    ldv_state_variable_13 = 1;
  } else {
  }
  goto ldv_50011;
  case 1: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_enable(ldvarg33, ldvarg34);
    ldv_state_variable_13 = 1;
  } else {
  }
  goto ldv_50011;
  case 2: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_hbfail(ldvarg32);
    ldv_state_variable_13 = 1;
  } else {
  }
  goto ldv_50011;
  case 3: ;
  if (ldv_state_variable_13 == 1) {
    bna_cb_ioceth_reset(ldvarg31);
    ldv_state_variable_13 = 1;
  } else {
  }
  goto ldv_50011;
  default:
  ldv_stop();
  }
  ldv_50011: ;
  return;
}
}
bool ldv_queue_work_on_210(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_211(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_212(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_213(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_214(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_220(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_226(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_228(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_230(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_231(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_232(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_233(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_234(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_235(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_236(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
__inline static unsigned int fls_long(unsigned long l )
{
  int tmp___0 ;
  {
  tmp___0 = fls64((__u64 )l);
  return ((unsigned int )tmp___0);
}
}
__inline static unsigned long __roundup_pow_of_two(unsigned long n )
{
  unsigned int tmp ;
  {
  tmp = fls_long(n - 1UL);
  return (1UL << (int )tmp);
}
}
__inline static void list_add(struct list_head *new , struct list_head *head )
{
  {
  __list_add(new, head, head->next);
  return;
}
}
extern void __list_del_entry(struct list_head * ) ;
__inline static void list_move_tail(struct list_head *list , struct list_head *head )
{
  {
  __list_del_entry(list);
  list_add_tail(list, head);
  return;
}
}
bool ldv_queue_work_on_256(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_258(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_257(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_260(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_259(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_266(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_274(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_282(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_276(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_272(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_280(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_281(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_277(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_278(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_279(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static bool ether_addr_equal(u8 const *addr1 , u8 const *addr2 )
{
  u32 fold ;
  {
  fold = ((unsigned int )*((u32 const *)addr1) ^ (unsigned int )*((u32 const *)addr2)) | (unsigned int )((int )((unsigned short )*((u16 const *)addr1 + 4U)) ^ (int )((unsigned short )*((u16 const *)addr2 + 4U)));
  return (fold == 0U);
}
}
void bfa_msgq_rsp_copy(struct bfa_msgq *msgq , u8 *buf , size_t buf_len ) ;
__inline static struct bna_mac *bna_mac_find(struct list_head *q , u8 const *addr )
{
  struct bna_mac *mac ;
  struct list_head const *__mptr ;
  bool tmp ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)q->next;
  mac = (struct bna_mac *)__mptr;
  goto ldv_48872;
  ldv_48871:
  tmp = ether_addr_equal((u8 const *)(& mac->addr), addr);
  if ((int )tmp) {
    return (mac);
  } else {
  }
  __mptr___0 = (struct list_head const *)mac->qe.next;
  mac = (struct bna_mac *)__mptr___0;
  ldv_48872: ;
  if ((unsigned long )(& mac->qe) != (unsigned long )q) {
    goto ldv_48871;
  } else {
  }
  return ((struct bna_mac *)0);
}
}
static void bna_ib_coalescing_timeo_set(struct bna_ib *ib , u8 coalescing_timeo )
{
  {
  ib->coalescing_timeo = coalescing_timeo;
  ib->door_bell.doorbell_ack = ((unsigned int )ib->coalescing_timeo << 16) | 2147483648U;
  return;
}
}
static int bna_rxf_cfg_apply(struct bna_rxf *rxf ) ;
static void bna_rxf_cfg_reset(struct bna_rxf *rxf ) ;
static int bna_rxf_ucast_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_promisc_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_allmulti_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_vlan_strip_cfg_apply(struct bna_rxf *rxf ) ;
static int bna_rxf_ucast_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) ;
static int bna_rxf_promisc_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) ;
static int bna_rxf_allmulti_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup ) ;
static void bna_rxf_sm_stopped(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_stopped_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_cfg_wait(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_cfg_wait_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_started(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_started_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_last_resp_wait(struct bna_rxf *rxf , enum bna_rxf_event event ) ;
static void bna_rxf_sm_last_resp_wait_entry(struct bna_rxf *rxf ) ;
static void bna_rxf_sm_stopped_entry(struct bna_rxf *rxf )
{
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;
  {
  if ((unsigned long )rxf->stop_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->stop_cbfn;
    cbarg = rxf->stop_cbarg;
    rxf->stop_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->stop_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {
  }
  return;
}
}
static void bna_rxf_sm_stopped(struct bna_rxf *rxf , enum bna_rxf_event event )
{
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;
  void (*cbfn___0)(struct bnad * , struct bna_rx * ) ;
  struct bnad *cbarg___0 ;
  {
  switch ((unsigned int )event) {
  case 1U:
  rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_cfg_wait);
  bna_rxf_sm_cfg_wait_entry(rxf);
  goto ldv_49158;
  case 2U: ;
  if ((unsigned long )rxf->stop_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->stop_cbfn;
    cbarg = rxf->stop_cbarg;
    rxf->stop_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->stop_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {
  }
  goto ldv_49158;
  case 3U: ;
  goto ldv_49158;
  case 4U: ;
  if ((unsigned long )rxf->cam_fltr_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rx * ))0)) {
    cbfn___0 = rxf->cam_fltr_cbfn;
    cbarg___0 = rxf->cam_fltr_cbarg;
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (struct bnad *)0;
    (*cbfn___0)(cbarg___0, rxf->rx);
  } else {
  }
  goto ldv_49158;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         96, (unsigned int )event);
  }
  ldv_49158: ;
  return;
}
}
static void bna_rxf_sm_cfg_wait_entry(struct bna_rxf *rxf )
{
  int tmp ;
  {
  tmp = bna_rxf_cfg_apply(rxf);
  if (tmp == 0) {
    rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_started);
    bna_rxf_sm_started_entry(rxf);
  } else {
  }
  return;
}
}
static void bna_rxf_sm_cfg_wait(struct bna_rxf *rxf , enum bna_rxf_event event )
{
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;
  void (*cbfn___0)(struct bnad * , struct bna_rx * ) ;
  struct bnad *cbarg___0 ;
  int tmp ;
  {
  switch ((unsigned int )event) {
  case 2U:
  rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_last_resp_wait);
  bna_rxf_sm_last_resp_wait_entry(rxf);
  goto ldv_49178;
  case 3U:
  bna_rxf_cfg_reset(rxf);
  if ((unsigned long )rxf->start_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->start_cbfn;
    cbarg = rxf->start_cbarg;
    rxf->start_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->start_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {
  }
  if ((unsigned long )rxf->cam_fltr_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rx * ))0)) {
    cbfn___0 = rxf->cam_fltr_cbfn;
    cbarg___0 = rxf->cam_fltr_cbarg;
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (struct bnad *)0;
    (*cbfn___0)(cbarg___0, rxf->rx);
  } else {
  }
  rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  goto ldv_49178;
  case 4U: ;
  goto ldv_49178;
  case 7U:
  tmp = bna_rxf_cfg_apply(rxf);
  if (tmp == 0) {
    rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_started);
    bna_rxf_sm_started_entry(rxf);
  } else {
  }
  goto ldv_49178;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         136, (unsigned int )event);
  }
  ldv_49178: ;
  return;
}
}
static void bna_rxf_sm_started_entry(struct bna_rxf *rxf )
{
  void (*cbfn)(struct bna_rx * ) ;
  struct bna_rx *cbarg ;
  void (*cbfn___0)(struct bnad * , struct bna_rx * ) ;
  struct bnad *cbarg___0 ;
  {
  if ((unsigned long )rxf->start_cbfn != (unsigned long )((void (*)(struct bna_rx * ))0)) {
    cbfn = rxf->start_cbfn;
    cbarg = rxf->start_cbarg;
    rxf->start_cbfn = (void (*)(struct bna_rx * ))0;
    rxf->start_cbarg = (struct bna_rx *)0;
    (*cbfn)(cbarg);
  } else {
  }
  if ((unsigned long )rxf->cam_fltr_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rx * ))0)) {
    cbfn___0 = rxf->cam_fltr_cbfn;
    cbarg___0 = rxf->cam_fltr_cbarg;
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (struct bnad *)0;
    (*cbfn___0)(cbarg___0, rxf->rx);
  } else {
  }
  return;
}
}
static void bna_rxf_sm_started(struct bna_rxf *rxf , enum bna_rxf_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U:
  bna_rxf_cfg_reset(rxf);
  rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  goto ldv_49206;
  case 4U:
  rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_cfg_wait);
  bna_rxf_sm_cfg_wait_entry(rxf);
  goto ldv_49206;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         162, (unsigned int )event);
  }
  ldv_49206: ;
  return;
}
}
static void bna_rxf_sm_last_resp_wait_entry(struct bna_rxf *rxf )
{
  {
  return;
}
}
static void bna_rxf_sm_last_resp_wait(struct bna_rxf *rxf , enum bna_rxf_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 7U:
  bna_rxf_cfg_reset(rxf);
  rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  goto ldv_49218;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         182, (unsigned int )event);
  }
  ldv_49218: ;
  return;
}
}
static void bna_bfi_ucast_req(struct bna_rxf *rxf , struct bna_mac *mac , enum bfi_enet_h2i_msgs req_type )
{
  struct bfi_enet_ucast_req *req ;
  {
  req = & rxf->bfi_enet_cmd.ucast_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = (u8 )req_type;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  ether_addr_copy((u8 *)(& req->mac_addr), (u8 const *)(& mac->addr));
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 16UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_mcast_add_req(struct bna_rxf *rxf , struct bna_mac *mac )
{
  struct bfi_enet_mcast_add_req *req ;
  {
  req = & rxf->bfi_enet_cmd.mcast_add_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 12U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  ether_addr_copy((u8 *)(& req->mac_addr), (u8 const *)(& mac->addr));
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 16UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_mcast_del_req(struct bna_rxf *rxf , u16 handle )
{
  struct bfi_enet_mcast_del_req *req ;
  __u16 tmp ;
  {
  req = & rxf->bfi_enet_cmd.mcast_del_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 13U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  tmp = __fswab16((int )handle);
  req->handle = tmp;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_mcast_filter_req(struct bna_rxf *rxf , enum bna_status status )
{
  struct bfi_enet_enable_req *req ;
  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 14U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rx_promisc_req(struct bna_rxf *rxf , enum bna_status status )
{
  struct bfi_enet_enable_req *req ;
  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 6U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rx_vlan_filter_set(struct bna_rxf *rxf , u8 block_idx )
{
  struct bfi_enet_rx_vlan_req *req ;
  int i ;
  int j ;
  __u32 tmp ;
  {
  req = & rxf->bfi_enet_cmd.vlan_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 15U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 512U;
  req->block_idx = block_idx;
  i = 0;
  goto ldv_49254;
  ldv_49253:
  j = (int )block_idx * 16 + i;
  if ((unsigned int )rxf->vlan_filter_status == 1U) {
    tmp = __fswab32(rxf->vlan_filter_table[j]);
    req->bit_mask[i] = tmp;
  } else {
    req->bit_mask[i] = 4294967295U;
  }
  i = i + 1;
  ldv_49254: ;
  if (i <= 15) {
    goto ldv_49253;
  } else {
  }
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 76UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_vlan_strip_enable(struct bna_rxf *rxf )
{
  struct bfi_enet_enable_req *req ;
  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 16U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )rxf->vlan_strip_status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rit_cfg(struct bna_rxf *rxf )
{
  struct bfi_enet_rit_req *req ;
  __u16 tmp ;
  {
  req = & rxf->bfi_enet_cmd.rit_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 3U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 512U;
  tmp = __fswab16((int )((__u16 )rxf->rit_size));
  req->size = tmp;
  memcpy((void *)(& req->table), (void const *)rxf->rit, (size_t )rxf->rit_size);
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 76UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rss_cfg(struct bna_rxf *rxf )
{
  struct bfi_enet_rss_cfg_req *req ;
  int i ;
  __u32 tmp ;
  {
  req = & rxf->bfi_enet_cmd.rss_req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 4U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->cfg.type = (u8 )rxf->rss_cfg.hash_type;
  req->cfg.mask = rxf->rss_cfg.hash_mask;
  i = 0;
  goto ldv_49270;
  ldv_49269:
  tmp = __fswab32(rxf->rss_cfg.toeplitz_hash_key[i]);
  req->cfg.key[i] = tmp;
  i = i + 1;
  ldv_49270: ;
  if (i <= 9) {
    goto ldv_49269;
  } else {
  }
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 52UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static void bna_bfi_rss_enable(struct bna_rxf *rxf )
{
  struct bfi_enet_enable_req *req ;
  {
  req = & rxf->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 5U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )(rxf->rx)->rid;
  req->mh.num_entries = 256U;
  req->enable = (u8 )rxf->rss_status;
  rxf->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rxf->msgq_cmd.cbarg = (void *)0;
  rxf->msgq_cmd.msg_size = 12UL;
  rxf->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& ((rxf->rx)->bna)->msgq, & rxf->msgq_cmd);
  return;
}
}
static struct bna_mac *bna_rxf_mcmac_get(struct bna_rxf *rxf , u8 const *mac_addr )
{
  struct bna_mac *mac ;
  struct list_head const *__mptr ;
  bool tmp ;
  struct list_head const *__mptr___0 ;
  struct list_head const *__mptr___1 ;
  bool tmp___0 ;
  struct list_head const *__mptr___2 ;
  {
  __mptr = (struct list_head const *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr;
  goto ldv_49286;
  ldv_49285:
  tmp = ether_addr_equal((u8 const *)(& mac->addr), mac_addr);
  if ((int )tmp) {
    return (mac);
  } else {
  }
  __mptr___0 = (struct list_head const *)mac->qe.next;
  mac = (struct bna_mac *)__mptr___0;
  ldv_49286: ;
  if ((unsigned long )(& mac->qe) != (unsigned long )(& rxf->mcast_active_q)) {
    goto ldv_49285;
  } else {
  }
  __mptr___1 = (struct list_head const *)rxf->mcast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr___1;
  goto ldv_49293;
  ldv_49292:
  tmp___0 = ether_addr_equal((u8 const *)(& mac->addr), mac_addr);
  if ((int )tmp___0) {
    return (mac);
  } else {
  }
  __mptr___2 = (struct list_head const *)mac->qe.next;
  mac = (struct bna_mac *)__mptr___2;
  ldv_49293: ;
  if ((unsigned long )(& mac->qe) != (unsigned long )(& rxf->mcast_pending_del_q)) {
    goto ldv_49292;
  } else {
  }
  return ((struct bna_mac *)0);
}
}
static struct bna_mcam_handle *bna_rxf_mchandle_get(struct bna_rxf *rxf , int handle )
{
  struct bna_mcam_handle *mchandle ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)rxf->mcast_handle_q.next;
  mchandle = (struct bna_mcam_handle *)__mptr;
  goto ldv_49305;
  ldv_49304: ;
  if (mchandle->handle == handle) {
    return (mchandle);
  } else {
  }
  __mptr___0 = (struct list_head const *)mchandle->qe.next;
  mchandle = (struct bna_mcam_handle *)__mptr___0;
  ldv_49305: ;
  if ((unsigned long )(& mchandle->qe) != (unsigned long )(& rxf->mcast_handle_q)) {
    goto ldv_49304;
  } else {
  }
  return ((struct bna_mcam_handle *)0);
}
}
static void bna_rxf_mchandle_attach(struct bna_rxf *rxf , u8 *mac_addr , int handle )
{
  struct bna_mac *mcmac ;
  struct bna_mcam_handle *mchandle ;
  {
  mcmac = bna_rxf_mcmac_get(rxf, (u8 const *)mac_addr);
  mchandle = bna_rxf_mchandle_get(rxf, handle);
  if ((unsigned long )mchandle == (unsigned long )((struct bna_mcam_handle *)0)) {
    mchandle = bna_mcam_mod_handle_get(& ((rxf->rx)->bna)->mcam_mod);
    mchandle->handle = handle;
    mchandle->refcnt = 0;
    list_add_tail(& mchandle->qe, & rxf->mcast_handle_q);
  } else {
  }
  mchandle->refcnt = mchandle->refcnt + 1;
  mcmac->handle = mchandle;
  return;
}
}
static int bna_rxf_mcast_del(struct bna_rxf *rxf , struct bna_mac *mac , enum bna_cleanup_type cleanup )
{
  struct bna_mcam_handle *mchandle ;
  int ret ;
  {
  ret = 0;
  mchandle = mac->handle;
  if ((unsigned long )mchandle == (unsigned long )((struct bna_mcam_handle *)0)) {
    return (ret);
  } else {
  }
  mchandle->refcnt = mchandle->refcnt - 1;
  if (mchandle->refcnt == 0) {
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_mcast_del_req(rxf, (int )((u16 )mchandle->handle));
      ret = 1;
    } else {
    }
    list_del(& mchandle->qe);
    bna_mcam_mod_handle_put(& ((rxf->rx)->bna)->mcam_mod, mchandle);
  } else {
  }
  mac->handle = (struct bna_mcam_handle *)0;
  return (ret);
}
}
static int bna_rxf_mcast_cfg_apply(struct bna_rxf *rxf )
{
  struct bna_mac *mac ;
  int ret ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  {
  mac = (struct bna_mac *)0;
  goto ldv_49329;
  ldv_49328:
  __mptr = (struct list_head const *)rxf->mcast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr;
  ret = bna_rxf_mcast_del(rxf, mac, 0);
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.del_q);
  if (ret != 0) {
    return (ret);
  } else {
  }
  ldv_49329:
  tmp = list_empty((struct list_head const *)(& rxf->mcast_pending_del_q));
  if (tmp == 0) {
    goto ldv_49328;
  } else {
  }
  tmp___0 = list_empty((struct list_head const *)(& rxf->mcast_pending_add_q));
  if (tmp___0 == 0) {
    __mptr___0 = (struct list_head const *)rxf->mcast_pending_add_q.next;
    mac = (struct bna_mac *)__mptr___0;
    list_move_tail(& mac->qe, & rxf->mcast_active_q);
    bna_bfi_mcast_add_req(rxf, mac);
    return (1);
  } else {
  }
  return (0);
}
}
static int bna_rxf_vlan_cfg_apply(struct bna_rxf *rxf )
{
  u8 vlan_pending_bitmask ;
  int block_idx ;
  {
  block_idx = 0;
  if ((unsigned int )rxf->vlan_pending_bitmask != 0U) {
    vlan_pending_bitmask = rxf->vlan_pending_bitmask;
    goto ldv_49339;
    ldv_49338:
    block_idx = block_idx + 1;
    vlan_pending_bitmask = (u8 )((int )vlan_pending_bitmask >> 1);
    ldv_49339: ;
    if (((int )vlan_pending_bitmask & 1) == 0) {
      goto ldv_49338;
    } else {
    }
    rxf->vlan_pending_bitmask = (int )rxf->vlan_pending_bitmask & ~ ((int )((u8 )(1UL << block_idx)));
    bna_bfi_rx_vlan_filter_set(rxf, (int )((u8 )block_idx));
    return (1);
  } else {
  }
  return (0);
}
}
static int bna_rxf_mcast_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup )
{
  struct bna_mac *mac ;
  int ret ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  int tmp___1 ;
  {
  goto ldv_49350;
  ldv_49349:
  __mptr = (struct list_head const *)rxf->mcast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr;
  ret = bna_rxf_mcast_del(rxf, mac, cleanup);
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.del_q);
  if (ret != 0) {
    return (ret);
  } else {
  }
  ldv_49350:
  tmp = list_empty((struct list_head const *)(& rxf->mcast_pending_del_q));
  if (tmp == 0) {
    goto ldv_49349;
  } else {
  }
  goto ldv_49355;
  ldv_49354:
  __mptr___0 = (struct list_head const *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_move_tail(& mac->qe, & rxf->mcast_pending_add_q);
  tmp___0 = bna_rxf_mcast_del(rxf, mac, cleanup);
  if (tmp___0 != 0) {
    return (1);
  } else {
  }
  ldv_49355:
  tmp___1 = list_empty((struct list_head const *)(& rxf->mcast_active_q));
  if (tmp___1 == 0) {
    goto ldv_49354;
  } else {
  }
  return (0);
}
}
static int bna_rxf_rss_cfg_apply(struct bna_rxf *rxf )
{
  {
  if ((unsigned int )rxf->rss_pending != 0U) {
    if ((int )rxf->rss_pending & 1) {
      rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending & 4294967294U);
      bna_bfi_rit_cfg(rxf);
      return (1);
    } else {
    }
    if (((unsigned int )rxf->rss_pending & 2U) != 0U) {
      rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending & 4294967293U);
      bna_bfi_rss_cfg(rxf);
      return (1);
    } else {
    }
    if (((unsigned int )rxf->rss_pending & 4U) != 0U) {
      rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending & 4294967291U);
      bna_bfi_rss_enable(rxf);
      return (1);
    } else {
    }
  } else {
  }
  return (0);
}
}
static int bna_rxf_cfg_apply(struct bna_rxf *rxf )
{
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;
  {
  tmp = bna_rxf_ucast_cfg_apply(rxf);
  if (tmp != 0) {
    return (1);
  } else {
  }
  tmp___0 = bna_rxf_mcast_cfg_apply(rxf);
  if (tmp___0 != 0) {
    return (1);
  } else {
  }
  tmp___1 = bna_rxf_promisc_cfg_apply(rxf);
  if (tmp___1 != 0) {
    return (1);
  } else {
  }
  tmp___2 = bna_rxf_allmulti_cfg_apply(rxf);
  if (tmp___2 != 0) {
    return (1);
  } else {
  }
  tmp___3 = bna_rxf_vlan_cfg_apply(rxf);
  if (tmp___3 != 0) {
    return (1);
  } else {
  }
  tmp___4 = bna_rxf_vlan_strip_cfg_apply(rxf);
  if (tmp___4 != 0) {
    return (1);
  } else {
  }
  tmp___5 = bna_rxf_rss_cfg_apply(rxf);
  if (tmp___5 != 0) {
    return (1);
  } else {
  }
  return (0);
}
}
static void bna_rxf_cfg_reset(struct bna_rxf *rxf )
{
  {
  bna_rxf_ucast_cfg_reset(rxf, 1);
  bna_rxf_mcast_cfg_reset(rxf, 1);
  bna_rxf_promisc_cfg_reset(rxf, 1);
  bna_rxf_allmulti_cfg_reset(rxf, 1);
  rxf->vlan_pending_bitmask = 255U;
  rxf->vlan_strip_pending = 1;
  if ((unsigned int )rxf->rss_status == 1U) {
    rxf->rss_pending = 7;
  } else {
  }
  return;
}
}
static void bna_rit_init(struct bna_rxf *rxf , int rit_size )
{
  struct bna_rx *rx ;
  struct bna_rxp *rxp ;
  int offset ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  rx = rxf->rx;
  offset = 0;
  rxf->rit_size = rit_size;
  __mptr = (struct list_head const *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_49378;
  ldv_49377:
  *(rxf->rit + (unsigned long )offset) = (u8 )(rxp->cq.ccb)->id;
  offset = offset + 1;
  __mptr___0 = (struct list_head const *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_49378: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_49377;
  } else {
  }
  return;
}
}
void bna_bfi_rxf_cfg_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr )
{
  {
  (*(rxf->fsm))((void *)rxf, 7);
  return;
}
}
void bna_bfi_rxf_ucast_set_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_rsp *rsp ;
  struct bfi_msgq_mhdr const *__mptr ;
  {
  __mptr = (struct bfi_msgq_mhdr const *)msghdr;
  rsp = (struct bfi_enet_rsp *)__mptr;
  if ((unsigned int )rsp->error != 0U) {
    rxf->ucast_active_set = 0;
  } else {
  }
  (*(rxf->fsm))((void *)rxf, 7);
  return;
}
}
void bna_bfi_rxf_mcast_add_rsp(struct bna_rxf *rxf , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_mcast_add_req *req ;
  struct bfi_enet_mcast_add_rsp *rsp ;
  struct bfi_msgq_mhdr const *__mptr ;
  __u16 tmp ;
  {
  req = & rxf->bfi_enet_cmd.mcast_add_req;
  __mptr = (struct bfi_msgq_mhdr const *)msghdr;
  rsp = (struct bfi_enet_mcast_add_rsp *)__mptr;
  tmp = __fswab16((int )rsp->handle);
  bna_rxf_mchandle_attach(rxf, (u8 *)(& req->mac_addr), (int )tmp);
  (*(rxf->fsm))((void *)rxf, 7);
  return;
}
}
static void bna_rxf_init(struct bna_rxf *rxf , struct bna_rx *rx , struct bna_rx_config *q_config ,
                         struct bna_res_info *res_info )
{
  {
  rxf->rx = rx;
  INIT_LIST_HEAD(& rxf->ucast_pending_add_q);
  INIT_LIST_HEAD(& rxf->ucast_pending_del_q);
  rxf->ucast_pending_set = 0;
  rxf->ucast_active_set = 0;
  INIT_LIST_HEAD(& rxf->ucast_active_q);
  rxf->ucast_pending_mac = (struct bna_mac *)0;
  INIT_LIST_HEAD(& rxf->mcast_pending_add_q);
  INIT_LIST_HEAD(& rxf->mcast_pending_del_q);
  INIT_LIST_HEAD(& rxf->mcast_active_q);
  INIT_LIST_HEAD(& rxf->mcast_handle_q);
  rxf->rit = (u8 *)((res_info + 14UL)->res_u.mem_info.mdl)->kva;
  bna_rit_init(rxf, q_config->num_paths);
  rxf->rss_status = q_config->rss_status;
  if ((unsigned int )rxf->rss_status == 1U) {
    rxf->rss_cfg = q_config->rss_config;
    rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending | 2U);
    rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending | 1U);
    rxf->rss_pending = (enum bna_rss_flags )((unsigned int )rxf->rss_pending | 4U);
  } else {
  }
  rxf->vlan_filter_status = 0;
  memset((void *)(& rxf->vlan_filter_table), 0, 512UL);
  rxf->vlan_filter_table[0] = rxf->vlan_filter_table[0] | 1U;
  rxf->vlan_pending_bitmask = 255U;
  rxf->vlan_strip_status = q_config->vlan_strip_status;
  rxf->fsm = (void (*)(void * , int ))(& bna_rxf_sm_stopped);
  bna_rxf_sm_stopped_entry(rxf);
  return;
}
}
static void bna_rxf_uninit(struct bna_rxf *rxf )
{
  struct bna_mac *mac ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  {
  rxf->ucast_pending_set = 0;
  rxf->ucast_active_set = 0;
  goto ldv_49412;
  ldv_49411:
  __mptr = (struct list_head const *)rxf->ucast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.free_q);
  ldv_49412:
  tmp = list_empty((struct list_head const *)(& rxf->ucast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49411;
  } else {
  }
  if ((unsigned long )rxf->ucast_pending_mac != (unsigned long )((struct bna_mac *)0)) {
    list_add_tail(& (rxf->ucast_pending_mac)->qe, & ((rxf->rx)->bna)->ucam_mod.free_q);
    rxf->ucast_pending_mac = (struct bna_mac *)0;
  } else {
  }
  goto ldv_49417;
  ldv_49416:
  __mptr___0 = (struct list_head const *)rxf->mcast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.free_q);
  ldv_49417:
  tmp___0 = list_empty((struct list_head const *)(& rxf->mcast_pending_add_q));
  if (tmp___0 == 0) {
    goto ldv_49416;
  } else {
  }
  rxf->rxmode_pending = 0;
  rxf->rxmode_pending_bitmask = 0;
  if (((rxf->rx)->bna)->promisc_rid == (rxf->rx)->rid) {
    ((rxf->rx)->bna)->promisc_rid = -1;
  } else {
  }
  if (((rxf->rx)->bna)->default_mode_rid == (rxf->rx)->rid) {
    ((rxf->rx)->bna)->default_mode_rid = -1;
  } else {
  }
  rxf->rss_pending = 0;
  rxf->vlan_strip_pending = 0;
  rxf->rx = (struct bna_rx *)0;
  return;
}
}
static void bna_rx_cb_rxf_started(struct bna_rx *rx )
{
  {
  (*(rx->fsm))((void *)rx, 6);
  return;
}
}
static void bna_rxf_start(struct bna_rxf *rxf )
{
  {
  rxf->start_cbfn = & bna_rx_cb_rxf_started;
  rxf->start_cbarg = rxf->rx;
  (*(rxf->fsm))((void *)rxf, 1);
  return;
}
}
static void bna_rx_cb_rxf_stopped(struct bna_rx *rx )
{
  {
  (*(rx->fsm))((void *)rx, 7);
  return;
}
}
static void bna_rxf_stop(struct bna_rxf *rxf )
{
  {
  rxf->stop_cbfn = & bna_rx_cb_rxf_stopped;
  rxf->stop_cbarg = rxf->rx;
  (*(rxf->fsm))((void *)rxf, 2);
  return;
}
}
static void bna_rxf_fail(struct bna_rxf *rxf )
{
  {
  (*(rxf->fsm))((void *)rxf, 3);
  return;
}
}
enum bna_cb_status bna_rx_ucast_set(struct bna_rx *rx , u8 const *ucmac )
{
  struct bna_rxf *rxf ;
  {
  rxf = & rx->rxf;
  if ((unsigned long )rxf->ucast_pending_mac == (unsigned long )((struct bna_mac *)0)) {
    rxf->ucast_pending_mac = bna_cam_mod_mac_get(& ((rxf->rx)->bna)->ucam_mod.free_q);
    if ((unsigned long )rxf->ucast_pending_mac == (unsigned long )((struct bna_mac *)0)) {
      return (6);
    } else {
    }
  } else {
  }
  ether_addr_copy((u8 *)(& (rxf->ucast_pending_mac)->addr), ucmac);
  rxf->ucast_pending_set = 1;
  rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
  rxf->cam_fltr_cbarg = (rx->bna)->bnad;
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
}
}
enum bna_cb_status bna_rx_mcast_add(struct bna_rx *rx , u8 const *addr , void (*cbfn)(struct bnad * ,
                                                                                        struct bna_rx * ) )
{
  struct bna_rxf *rxf ;
  struct bna_mac *mac ;
  struct bna_mac *tmp ;
  struct bna_mac *tmp___0 ;
  {
  rxf = & rx->rxf;
  tmp = bna_mac_find(& rxf->mcast_active_q, addr);
  if ((unsigned long )tmp != (unsigned long )((struct bna_mac *)0)) {
    goto _L;
  } else {
    tmp___0 = bna_mac_find(& rxf->mcast_pending_add_q, addr);
    if ((unsigned long )tmp___0 != (unsigned long )((struct bna_mac *)0)) {
      _L:
      if ((unsigned long )cbfn != (unsigned long )((void (*)(struct bnad * , struct bna_rx * ))0)) {
        (*cbfn)((rx->bna)->bnad, rx);
      } else {
      }
      return (0);
    } else {
    }
  }
  mac = bna_cam_mod_mac_get(& ((rxf->rx)->bna)->mcam_mod.free_q);
  if ((unsigned long )mac == (unsigned long )((struct bna_mac *)0)) {
    return (5);
  } else {
  }
  ether_addr_copy((u8 *)(& mac->addr), addr);
  list_add_tail(& mac->qe, & rxf->mcast_pending_add_q);
  rxf->cam_fltr_cbfn = cbfn;
  rxf->cam_fltr_cbarg = (rx->bna)->bnad;
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
}
}
enum bna_cb_status bna_rx_ucast_listset(struct bna_rx *rx , int count , u8 const *uclist )
{
  struct bna_ucam_mod *ucam_mod ;
  struct bna_rxf *rxf ;
  struct list_head list_head ;
  u8 const *mcaddr ;
  struct bna_mac *mac ;
  struct bna_mac *del_mac ;
  int i ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  struct list_head const *__mptr___1 ;
  int tmp___1 ;
  struct list_head const *__mptr___2 ;
  int tmp___2 ;
  {
  ucam_mod = & (rx->bna)->ucam_mod;
  rxf = & rx->rxf;
  goto ldv_49463;
  ldv_49462:
  __mptr = (struct list_head const *)rxf->ucast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & ucam_mod->free_q);
  ldv_49463:
  tmp = list_empty((struct list_head const *)(& rxf->ucast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49462;
  } else {
  }
  goto ldv_49468;
  ldv_49467:
  __mptr___0 = (struct list_head const *)rxf->ucast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  del_mac = bna_cam_mod_mac_get(& ucam_mod->del_q);
  ether_addr_copy((u8 *)(& del_mac->addr), (u8 const *)(& mac->addr));
  del_mac->handle = mac->handle;
  list_add_tail(& del_mac->qe, & rxf->ucast_pending_del_q);
  list_move_tail(& mac->qe, & ucam_mod->free_q);
  ldv_49468:
  tmp___0 = list_empty((struct list_head const *)(& rxf->ucast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49467;
  } else {
  }
  INIT_LIST_HEAD(& list_head);
  i = 0;
  mcaddr = uclist;
  goto ldv_49472;
  ldv_49471:
  mac = bna_cam_mod_mac_get(& ucam_mod->free_q);
  if ((unsigned long )mac == (unsigned long )((struct bna_mac *)0)) {
    goto err_return;
  } else {
  }
  ether_addr_copy((u8 *)(& mac->addr), mcaddr);
  list_add_tail(& mac->qe, & list_head);
  mcaddr = mcaddr + 6UL;
  i = i + 1;
  ldv_49472: ;
  if (i < count) {
    goto ldv_49471;
  } else {
  }
  goto ldv_49477;
  ldv_49476:
  __mptr___1 = (struct list_head const *)list_head.next;
  mac = (struct bna_mac *)__mptr___1;
  list_move_tail(& mac->qe, & rxf->ucast_pending_add_q);
  ldv_49477:
  tmp___1 = list_empty((struct list_head const *)(& list_head));
  if (tmp___1 == 0) {
    goto ldv_49476;
  } else {
  }
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
  err_return: ;
  goto ldv_49482;
  ldv_49481:
  __mptr___2 = (struct list_head const *)list_head.next;
  mac = (struct bna_mac *)__mptr___2;
  list_move_tail(& mac->qe, & ucam_mod->free_q);
  ldv_49482:
  tmp___2 = list_empty((struct list_head const *)(& list_head));
  if (tmp___2 == 0) {
    goto ldv_49481;
  } else {
  }
  return (6);
}
}
enum bna_cb_status bna_rx_mcast_listset(struct bna_rx *rx , int count , u8 const *mclist )
{
  struct bna_mcam_mod *mcam_mod ;
  struct bna_rxf *rxf ;
  struct list_head list_head ;
  u8 const *mcaddr ;
  struct bna_mac *mac ;
  struct bna_mac *del_mac ;
  int i ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  struct list_head const *__mptr___1 ;
  int tmp___1 ;
  struct list_head const *__mptr___2 ;
  int tmp___2 ;
  {
  mcam_mod = & (rx->bna)->mcam_mod;
  rxf = & rx->rxf;
  goto ldv_49499;
  ldv_49498:
  __mptr = (struct list_head const *)rxf->mcast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & mcam_mod->free_q);
  ldv_49499:
  tmp = list_empty((struct list_head const *)(& rxf->mcast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49498;
  } else {
  }
  goto ldv_49504;
  ldv_49503:
  __mptr___0 = (struct list_head const *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  del_mac = bna_cam_mod_mac_get(& mcam_mod->del_q);
  ether_addr_copy((u8 *)(& del_mac->addr), (u8 const *)(& mac->addr));
  del_mac->handle = mac->handle;
  list_add_tail(& del_mac->qe, & rxf->mcast_pending_del_q);
  mac->handle = (struct bna_mcam_handle *)0;
  list_move_tail(& mac->qe, & mcam_mod->free_q);
  ldv_49504:
  tmp___0 = list_empty((struct list_head const *)(& rxf->mcast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49503;
  } else {
  }
  INIT_LIST_HEAD(& list_head);
  i = 0;
  mcaddr = mclist;
  goto ldv_49508;
  ldv_49507:
  mac = bna_cam_mod_mac_get(& mcam_mod->free_q);
  if ((unsigned long )mac == (unsigned long )((struct bna_mac *)0)) {
    goto err_return;
  } else {
  }
  ether_addr_copy((u8 *)(& mac->addr), mcaddr);
  list_add_tail(& mac->qe, & list_head);
  mcaddr = mcaddr + 6UL;
  i = i + 1;
  ldv_49508: ;
  if (i < count) {
    goto ldv_49507;
  } else {
  }
  goto ldv_49513;
  ldv_49512:
  __mptr___1 = (struct list_head const *)list_head.next;
  mac = (struct bna_mac *)__mptr___1;
  list_move_tail(& mac->qe, & rxf->mcast_pending_add_q);
  ldv_49513:
  tmp___1 = list_empty((struct list_head const *)(& list_head));
  if (tmp___1 == 0) {
    goto ldv_49512;
  } else {
  }
  (*(rxf->fsm))((void *)rxf, 4);
  return (0);
  err_return: ;
  goto ldv_49518;
  ldv_49517:
  __mptr___2 = (struct list_head const *)list_head.next;
  mac = (struct bna_mac *)__mptr___2;
  list_move_tail(& mac->qe, & mcam_mod->free_q);
  ldv_49518:
  tmp___2 = list_empty((struct list_head const *)(& list_head));
  if (tmp___2 == 0) {
    goto ldv_49517;
  } else {
  }
  return (5);
}
}
void bna_rx_mcast_delall(struct bna_rx *rx )
{
  struct bna_rxf *rxf ;
  struct bna_mac *mac ;
  struct bna_mac *del_mac ;
  int need_hw_config ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  {
  rxf = & rx->rxf;
  need_hw_config = 0;
  goto ldv_49530;
  ldv_49529:
  __mptr = (struct list_head const *)rxf->mcast_pending_add_q.next;
  mac = (struct bna_mac *)__mptr;
  list_move_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.free_q);
  ldv_49530:
  tmp = list_empty((struct list_head const *)(& rxf->mcast_pending_add_q));
  if (tmp == 0) {
    goto ldv_49529;
  } else {
  }
  goto ldv_49535;
  ldv_49534:
  __mptr___0 = (struct list_head const *)rxf->mcast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_del(& mac->qe);
  del_mac = bna_cam_mod_mac_get(& ((rxf->rx)->bna)->mcam_mod.del_q);
  memcpy((void *)del_mac, (void const *)mac, 32UL);
  list_add_tail(& del_mac->qe, & rxf->mcast_pending_del_q);
  mac->handle = (struct bna_mcam_handle *)0;
  list_add_tail(& mac->qe, & ((rxf->rx)->bna)->mcam_mod.free_q);
  need_hw_config = 1;
  ldv_49535:
  tmp___0 = list_empty((struct list_head const *)(& rxf->mcast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49534;
  } else {
  }
  if (need_hw_config != 0) {
    (*(rxf->fsm))((void *)rxf, 4);
  } else {
  }
  return;
}
}
void bna_rx_vlan_add(struct bna_rx *rx , int vlan_id )
{
  struct bna_rxf *rxf ;
  int index ;
  int bit ;
  int group_id ;
  {
  rxf = & rx->rxf;
  index = vlan_id >> 5;
  bit = (int )(1UL << (vlan_id & 31));
  group_id = vlan_id >> 9;
  rxf->vlan_filter_table[index] = rxf->vlan_filter_table[index] | (u32 )bit;
  if ((unsigned int )rxf->vlan_filter_status == 1U) {
    rxf->vlan_pending_bitmask = (int )rxf->vlan_pending_bitmask | (int )((u8 )(1UL << group_id));
    (*(rxf->fsm))((void *)rxf, 4);
  } else {
  }
  return;
}
}
void bna_rx_vlan_del(struct bna_rx *rx , int vlan_id )
{
  struct bna_rxf *rxf ;
  int index ;
  int bit ;
  int group_id ;
  {
  rxf = & rx->rxf;
  index = vlan_id >> 5;
  bit = (int )(1UL << (vlan_id & 31));
  group_id = vlan_id >> 9;
  rxf->vlan_filter_table[index] = rxf->vlan_filter_table[index] & (u32 )(~ bit);
  if ((unsigned int )rxf->vlan_filter_status == 1U) {
    rxf->vlan_pending_bitmask = (int )rxf->vlan_pending_bitmask | (int )((u8 )(1UL << group_id));
    (*(rxf->fsm))((void *)rxf, 4);
  } else {
  }
  return;
}
}
static int bna_rxf_ucast_cfg_apply(struct bna_rxf *rxf )
{
  struct bna_mac *mac ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  {
  mac = (struct bna_mac *)0;
  tmp = list_empty((struct list_head const *)(& rxf->ucast_pending_del_q));
  if (tmp == 0) {
    __mptr = (struct list_head const *)rxf->ucast_pending_del_q.next;
    mac = (struct bna_mac *)__mptr;
    bna_bfi_ucast_req(rxf, mac, 11);
    list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.del_q);
    return (1);
  } else {
  }
  if (rxf->ucast_pending_set != 0) {
    rxf->ucast_pending_set = 0;
    ether_addr_copy((u8 *)(& rxf->ucast_active_mac.addr), (u8 const *)(& (rxf->ucast_pending_mac)->addr));
    rxf->ucast_active_set = 1;
    bna_bfi_ucast_req(rxf, & rxf->ucast_active_mac, 8);
    return (1);
  } else {
  }
  tmp___0 = list_empty((struct list_head const *)(& rxf->ucast_pending_add_q));
  if (tmp___0 == 0) {
    __mptr___0 = (struct list_head const *)rxf->ucast_pending_add_q.next;
    mac = (struct bna_mac *)__mptr___0;
    list_add_tail(& mac->qe, & rxf->ucast_active_q);
    bna_bfi_ucast_req(rxf, mac, 10);
    return (1);
  } else {
  }
  return (0);
}
}
static int bna_rxf_ucast_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup )
{
  struct bna_mac *mac ;
  struct list_head const *__mptr ;
  int tmp ;
  struct list_head const *__mptr___0 ;
  int tmp___0 ;
  {
  goto ldv_49569;
  ldv_49568:
  __mptr = (struct list_head const *)rxf->ucast_pending_del_q.next;
  mac = (struct bna_mac *)__mptr;
  if ((unsigned int )cleanup == 1U) {
    list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.del_q);
  } else {
    bna_bfi_ucast_req(rxf, mac, 11);
    list_move_tail(& mac->qe, & ((rxf->rx)->bna)->ucam_mod.del_q);
    return (1);
  }
  ldv_49569:
  tmp = list_empty((struct list_head const *)(& rxf->ucast_pending_del_q));
  if (tmp == 0) {
    goto ldv_49568;
  } else {
  }
  goto ldv_49574;
  ldv_49573:
  __mptr___0 = (struct list_head const *)rxf->ucast_active_q.next;
  mac = (struct bna_mac *)__mptr___0;
  list_move_tail(& mac->qe, & rxf->ucast_pending_add_q);
  if ((unsigned int )cleanup == 0U) {
    bna_bfi_ucast_req(rxf, mac, 11);
    return (1);
  } else {
  }
  ldv_49574:
  tmp___0 = list_empty((struct list_head const *)(& rxf->ucast_active_q));
  if (tmp___0 == 0) {
    goto ldv_49573;
  } else {
  }
  if (rxf->ucast_active_set != 0) {
    rxf->ucast_pending_set = 1;
    rxf->ucast_active_set = 0;
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_ucast_req(rxf, & rxf->ucast_active_mac, 9);
      return (1);
    } else {
    }
  } else {
  }
  return (0);
}
}
static int bna_rxf_promisc_cfg_apply(struct bna_rxf *rxf )
{
  struct bna *bna ;
  {
  bna = (rxf->rx)->bna;
  if ((int )rxf->rxmode_pending_bitmask & 1 && (int )rxf->rxmode_pending & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active | 1U);
    bna_bfi_rx_promisc_req(rxf, 1);
    return (1);
  } else
  if ((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967294U);
    bna->promisc_rid = -1;
    bna_bfi_rx_promisc_req(rxf, 0);
    return (1);
  } else {
  }
  return (0);
}
}
static int bna_rxf_promisc_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup )
{
  struct bna *bna ;
  {
  bna = (rxf->rx)->bna;
  if ((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967294U);
    bna->promisc_rid = -1;
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_rx_promisc_req(rxf, 0);
      return (1);
    } else {
    }
  } else {
  }
  if ((int )rxf->rxmode_active & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 1U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 1U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967294U);
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_rx_promisc_req(rxf, 0);
      return (1);
    } else {
    }
  } else {
  }
  return (0);
}
}
static int bna_rxf_allmulti_cfg_apply(struct bna_rxf *rxf )
{
  {
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active | 4U);
    bna_bfi_mcast_filter_req(rxf, 0);
    return (1);
  } else
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967291U);
    bna_bfi_mcast_filter_req(rxf, 1);
    return (1);
  } else {
  }
  return (0);
}
}
static int bna_rxf_allmulti_cfg_reset(struct bna_rxf *rxf , enum bna_cleanup_type cleanup )
{
  {
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967291U);
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_mcast_filter_req(rxf, 1);
      return (1);
    } else {
    }
  } else {
  }
  if (((unsigned int )rxf->rxmode_active & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 4U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 4U);
    rxf->rxmode_active = (enum bna_rxmode )((unsigned int )rxf->rxmode_active & 4294967291U);
    if ((unsigned int )cleanup == 0U) {
      bna_bfi_mcast_filter_req(rxf, 1);
      return (1);
    } else {
    }
  } else {
  }
  return (0);
}
}
static int bna_rxf_promisc_enable(struct bna_rxf *rxf )
{
  struct bna *bna ;
  int ret ;
  {
  bna = (rxf->rx)->bna;
  ret = 0;
  if (((int )rxf->rxmode_pending_bitmask & 1 && (int )rxf->rxmode_pending & 1) || (int )rxf->rxmode_active & 1) {
  } else
  if ((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
  } else {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 1U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 1U);
    bna->promisc_rid = (rxf->rx)->rid;
    ret = 1;
  }
  return (ret);
}
}
static int bna_rxf_promisc_disable(struct bna_rxf *rxf )
{
  struct bna *bna ;
  int ret ;
  {
  bna = (rxf->rx)->bna;
  ret = 0;
  if (((int )rxf->rxmode_pending_bitmask & 1 && ((unsigned int )rxf->rxmode_pending & 1U) == 0U) || ((unsigned int )rxf->rxmode_active & 1U) == 0U) {
  } else
  if ((int )rxf->rxmode_pending_bitmask & 1 && (int )rxf->rxmode_pending & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967294U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    bna->promisc_rid = -1;
  } else
  if ((int )rxf->rxmode_active & 1) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 1U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967294U);
    ret = 1;
  } else {
  }
  return (ret);
}
}
static int bna_rxf_allmulti_enable(struct bna_rxf *rxf )
{
  int ret ;
  {
  ret = 0;
  if ((((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) != 0U) || ((unsigned int )rxf->rxmode_active & 4U) != 0U) {
  } else
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
  } else {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 4U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending | 4U);
    ret = 1;
  }
  return (ret);
}
}
static int bna_rxf_allmulti_disable(struct bna_rxf *rxf )
{
  int ret ;
  {
  ret = 0;
  if ((((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) == 0U) || ((unsigned int )rxf->rxmode_active & 4U) == 0U) {
  } else
  if (((unsigned int )rxf->rxmode_pending_bitmask & 4U) != 0U && ((unsigned int )rxf->rxmode_pending & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask & 4294967291U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
  } else
  if (((unsigned int )rxf->rxmode_active & 4U) != 0U) {
    rxf->rxmode_pending_bitmask = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending_bitmask | 4U);
    rxf->rxmode_pending = (enum bna_rxmode )((unsigned int )rxf->rxmode_pending & 4294967291U);
    ret = 1;
  } else {
  }
  return (ret);
}
}
static int bna_rxf_vlan_strip_cfg_apply(struct bna_rxf *rxf )
{
  {
  if ((int )rxf->vlan_strip_pending) {
    rxf->vlan_strip_pending = 0;
    bna_bfi_vlan_strip_enable(rxf);
    return (1);
  } else {
  }
  return (0);
}
}
static void bna_bfi_rx_enet_start(struct bna_rx *rx ) ;
static void bna_rx_enet_stop(struct bna_rx *rx ) ;
static void bna_rx_mod_cb_rx_stopped(void *arg , struct bna_rx *rx ) ;
static void bna_rx_sm_stopped(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_stopped_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_start_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_start_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_start_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_start_stop_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_rxf_start_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_rxf_start_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_started(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_started_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_rxf_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_rxf_stop_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_stop_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_stop_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_cleanup_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_cleanup_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_failed(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_failed_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_quiesce_wait(struct bna_rx *rx , enum bna_rx_event event ) ;
static void bna_rx_sm_quiesce_wait_entry(struct bna_rx *rx ) ;
static void bna_rx_sm_stopped_entry(struct bna_rx *rx )
{
  void (*cbfn)(void * , struct bna_rx * ) ;
  void *cbarg ;
  {
  if ((unsigned long )rx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_rx * ))0)) {
    cbfn = rx->stop_cbfn;
    cbarg = rx->stop_cbarg;
    rx->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
    rx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, rx);
  } else {
  }
  return;
}
}
static void bna_rx_sm_stopped(struct bna_rx *rx , enum bna_rx_event event )
{
  void (*cbfn)(void * , struct bna_rx * ) ;
  void *cbarg ;
  {
  switch ((unsigned int )event) {
  case 1U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_start_wait);
  bna_rx_sm_start_wait_entry(rx);
  goto ldv_49682;
  case 2U: ;
  if ((unsigned long )rx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_rx * ))0)) {
    cbfn = rx->stop_cbfn;
    cbarg = rx->stop_cbarg;
    rx->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
    rx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, rx);
  } else {
  }
  goto ldv_49682;
  case 3U: ;
  goto ldv_49682;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1356, (unsigned int )event);
  goto ldv_49682;
  }
  ldv_49682: ;
  return;
}
}
static void bna_rx_sm_start_wait_entry(struct bna_rx *rx )
{
  {
  bna_bfi_rx_enet_start(rx);
  return;
}
}
static void bna_rx_sm_stop_wait_entry(struct bna_rx *rx )
{
  {
  return;
}
}
static void bna_rx_sm_stop_wait(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 5U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49702;
  case 4U:
  bna_rx_enet_stop(rx);
  goto ldv_49702;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1386, (unsigned int )event);
  goto ldv_49702;
  }
  ldv_49702: ;
  return;
}
}
static void bna_rx_sm_start_wait(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_start_stop_wait);
  bna_rx_sm_start_stop_wait_entry(rx);
  goto ldv_49710;
  case 3U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49710;
  case 4U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_rxf_start_wait);
  bna_rx_sm_rxf_start_wait_entry(rx);
  goto ldv_49710;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1408, (unsigned int )event);
  goto ldv_49710;
  }
  ldv_49710: ;
  return;
}
}
static void bna_rx_sm_rxf_start_wait_entry(struct bna_rx *rx )
{
  {
  (*(rx->rx_post_cbfn))((rx->bna)->bnad, rx);
  bna_rxf_start(& rx->rxf);
  return;
}
}
static void bna_rx_sm_rxf_stop_wait_entry(struct bna_rx *rx )
{
  {
  return;
}
}
static void bna_rx_sm_rxf_stop_wait(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  bna_rxf_fail(& rx->rxf);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {
  }
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49725;
  case 6U:
  bna_rxf_stop(& rx->rxf);
  goto ldv_49725;
  case 7U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_stop_wait);
  bna_rx_sm_stop_wait_entry(rx);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {
  }
  bna_rx_enet_stop(rx);
  goto ldv_49725;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1446, (unsigned int )event);
  goto ldv_49725;
  }
  ldv_49725: ;
  return;
}
}
static void bna_rx_sm_start_stop_wait_entry(struct bna_rx *rx )
{
  {
  return;
}
}
static void bna_rx_sm_start_stop_wait(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 5U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49738;
  case 4U:
  bna_rx_enet_stop(rx);
  goto ldv_49738;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1471, (unsigned int )event);
  }
  ldv_49738: ;
  return;
}
}
static void bna_rx_sm_started_entry(struct bna_rx *rx )
{
  struct bna_rxp *rxp ;
  int is_regular ;
  struct list_head const *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head const *__mptr___0 ;
  {
  is_regular = (unsigned int )rx->type == 0U;
  __mptr = (struct list_head const *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_49753;
  ldv_49752:
  ib = & rxp->cq.ib;
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile *)(rx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile *)(rx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )(~ ib->intr_vector) & intx_mask;
    writel(intx_mask, (void volatile *)(rx->bna)->regs.fn_int_mask);
  } else {
  }
  ib->door_bell.doorbell_ack = (unsigned int )((int )ib->coalescing_timeo << 16) | 2147483648U;
  if (is_regular != 0) {
    writel(ib->door_bell.doorbell_ack, (void volatile *)ib->door_bell.doorbell_addr);
  } else {
  }
  __mptr___0 = (struct list_head const *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_49753: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_49752;
  } else {
  }
  bna_ethport_cb_rx_started(& (rx->bna)->ethport);
  return;
}
}
static void bna_rx_sm_started(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_rxf_stop_wait);
  bna_rx_sm_rxf_stop_wait_entry(rx);
  bna_ethport_cb_rx_stopped(& (rx->bna)->ethport);
  bna_rxf_stop(& rx->rxf);
  goto ldv_49760;
  case 3U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_failed);
  bna_rx_sm_failed_entry(rx);
  bna_ethport_cb_rx_stopped(& (rx->bna)->ethport);
  bna_rxf_fail(& rx->rxf);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {
  }
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49760;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1507, (unsigned int )event);
  goto ldv_49760;
  }
  ldv_49760: ;
  return;
}
}
static void bna_rx_sm_rxf_start_wait(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_rxf_stop_wait);
  bna_rx_sm_rxf_stop_wait_entry(rx);
  goto ldv_49768;
  case 3U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_failed);
  bna_rx_sm_failed_entry(rx);
  bna_rxf_fail(& rx->rxf);
  if ((unsigned long )rx->rx_stall_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                      struct bna_rx * ))0)) {
    (*(rx->rx_stall_cbfn))((rx->bna)->bnad, rx);
  } else {
  }
  (*(rx->rx_cleanup_cbfn))((rx->bna)->bnad, rx);
  goto ldv_49768;
  case 6U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_started);
  bna_rx_sm_started_entry(rx);
  goto ldv_49768;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1532, (unsigned int )event);
  goto ldv_49768;
  }
  ldv_49768: ;
  return;
}
}
static void bna_rx_sm_cleanup_wait_entry(struct bna_rx *rx )
{
  {
  return;
}
}
static void bna_rx_sm_cleanup_wait(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 7U: ;
  goto ldv_49781;
  case 8U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49781;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1556, (unsigned int )event);
  goto ldv_49781;
  }
  ldv_49781: ;
  return;
}
}
static void bna_rx_sm_failed_entry(struct bna_rx *rx )
{
  {
  return;
}
}
static void bna_rx_sm_failed(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 1U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_quiesce_wait);
  bna_rx_sm_quiesce_wait_entry(rx);
  goto ldv_49792;
  case 2U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  goto ldv_49792;
  case 3U: ;
  case 6U: ;
  case 7U: ;
  goto ldv_49792;
  case 8U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  goto ldv_49792;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1589, (unsigned int )event);
  goto ldv_49792;
  }
  ldv_49792: ;
  return;
}
}
static void bna_rx_sm_quiesce_wait_entry(struct bna_rx *rx )
{
  {
  return;
}
}
static void bna_rx_sm_quiesce_wait(struct bna_rx *rx , enum bna_rx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_cleanup_wait);
  bna_rx_sm_cleanup_wait_entry(rx);
  goto ldv_49807;
  case 3U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_failed);
  bna_rx_sm_failed_entry(rx);
  goto ldv_49807;
  case 8U:
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_start_wait);
  bna_rx_sm_start_wait_entry(rx);
  goto ldv_49807;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         1615, (unsigned int )event);
  goto ldv_49807;
  }
  ldv_49807: ;
  return;
}
}
static void bna_bfi_rx_enet_start(struct bna_rx *rx )
{
  struct bfi_enet_rx_cfg_req *cfg_req ;
  struct bna_rxp *rxp ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  int i ;
  int tmp ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  struct bna_dma_addr cur_q_addr ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  __u16 tmp___2 ;
  struct bna_dma_addr cur_q_addr___0 ;
  __u16 tmp___3 ;
  __u16 tmp___4 ;
  __u16 tmp___5 ;
  long tmp___6 ;
  struct bna_dma_addr cur_q_addr___1 ;
  __u16 tmp___7 ;
  __u16 tmp___8 ;
  __u16 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  long tmp___12 ;
  {
  cfg_req = & rx->bfi_enet_cmd.cfg_req;
  rxp = (struct bna_rxp *)0;
  q0 = (struct bna_rxq *)0;
  q1 = (struct bna_rxq *)0;
  cfg_req->mh.msg_class = 24U;
  cfg_req->mh.msg_id = 1U;
  cfg_req->mh.msg_token = 0U;
  cfg_req->mh.enet_id = (u8 )rx->rid;
  cfg_req->mh.num_entries = 5376U;
  tmp = bna_enet_mtu_get(& (rx->bna)->enet);
  cfg_req->rx_cfg.frame_size = (u16 )tmp;
  cfg_req->num_queue_sets = (u8 )rx->num_paths;
  i = 0;
  goto ldv_49837;
  ldv_49836: ;
  if ((unsigned long )rxp != (unsigned long )((struct bna_rxp *)0)) {
    __mptr = (struct list_head const *)rxp->qe.next;
    rxp = (struct bna_rxp *)__mptr;
  } else {
    __mptr___0 = (struct list_head const *)rx->rxp_q.next;
    rxp = (struct bna_rxp *)__mptr___0;
  }
  switch ((unsigned int )rxp->type) {
  case 1U:
  q0 = rxp->rxq.single.only;
  q1 = (struct bna_rxq *)0;
  goto ldv_49824;
  case 2U:
  q0 = rxp->rxq.slr.large;
  q1 = rxp->rxq.slr.small;
  goto ldv_49824;
  case 3U:
  q0 = rxp->rxq.hds.data;
  q1 = rxp->rxq.hds.hdr;
  goto ldv_49824;
  }
  ldv_49824: ;
  switch ((unsigned int )rxp->type) {
  case 2U: ;
  case 3U:
  cur_q_addr = *((struct bna_dma_addr *)q1->qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].qs.q.pg_tbl.a32.addr_lo = q1->qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].qs.q.pg_tbl.a32.addr_hi = q1->qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].qs.q.first_entry.a32.addr_lo = cur_q_addr.lsb;
  cfg_req->q_cfg[i].qs.q.first_entry.a32.addr_hi = cur_q_addr.msb;
  tmp___0 = __fswab16((int )((unsigned short )q1->qpt.page_count));
  cfg_req->q_cfg[i].qs.q.pages = tmp___0;
  tmp___1 = __fswab16((int )((unsigned short )q1->qpt.page_size));
  cfg_req->q_cfg[i].qs.q.page_sz = tmp___1;
  tmp___2 = __fswab16((int )((unsigned short )q1->buffer_size));
  cfg_req->q_cfg[i].qs.rx_buffer_size = tmp___2;
  case 1U:
  cur_q_addr___0 = *((struct bna_dma_addr *)q0->qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].ql.q.pg_tbl.a32.addr_lo = q0->qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].ql.q.pg_tbl.a32.addr_hi = q0->qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].ql.q.first_entry.a32.addr_lo = cur_q_addr___0.lsb;
  cfg_req->q_cfg[i].ql.q.first_entry.a32.addr_hi = cur_q_addr___0.msb;
  tmp___3 = __fswab16((int )((unsigned short )q0->qpt.page_count));
  cfg_req->q_cfg[i].ql.q.pages = tmp___3;
  tmp___4 = __fswab16((int )((unsigned short )q0->qpt.page_size));
  cfg_req->q_cfg[i].ql.q.page_sz = tmp___4;
  if ((unsigned int )q0->multi_buffer != 0U) {
    cfg_req->rx_cfg.multi_buffer = 1U;
  } else {
    q0->buffer_size = bna_enet_mtu_get(& (rx->bna)->enet);
  }
  tmp___5 = __fswab16((int )((unsigned short )q0->buffer_size));
  cfg_req->q_cfg[i].ql.rx_buffer_size = tmp___5;
  goto ldv_49832;
  default:
  tmp___6 = ldv__builtin_expect(1L, 0L);
  if (tmp___6 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c"),
                         "i" (1669), "i" (12UL));
    ldv_49834: ;
    goto ldv_49834;
  } else {
  }
  }
  ldv_49832:
  cur_q_addr___1 = *((struct bna_dma_addr *)rxp->cq.qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].cq.q.pg_tbl.a32.addr_lo = rxp->cq.qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].cq.q.pg_tbl.a32.addr_hi = rxp->cq.qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].cq.q.first_entry.a32.addr_lo = cur_q_addr___1.lsb;
  cfg_req->q_cfg[i].cq.q.first_entry.a32.addr_hi = cur_q_addr___1.msb;
  tmp___7 = __fswab16((int )((unsigned short )rxp->cq.qpt.page_count));
  cfg_req->q_cfg[i].cq.q.pages = tmp___7;
  tmp___8 = __fswab16((int )((unsigned short )rxp->cq.qpt.page_size));
  cfg_req->q_cfg[i].cq.q.page_sz = tmp___8;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_lo = rxp->cq.ib.ib_seg_host_addr.lsb;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_hi = rxp->cq.ib.ib_seg_host_addr.msb;
  tmp___9 = __fswab16((int )((unsigned short )rxp->cq.ib.intr_vector));
  cfg_req->q_cfg[i].ib.intr.msix_index = tmp___9;
  i = i + 1;
  ldv_49837: ;
  if (rx->num_paths > i) {
    goto ldv_49836;
  } else {
  }
  cfg_req->ib_cfg.int_pkt_dma = 0U;
  cfg_req->ib_cfg.int_enabled = 1U;
  cfg_req->ib_cfg.int_pkt_enabled = 0U;
  cfg_req->ib_cfg.continuous_coalescing = 0U;
  cfg_req->ib_cfg.msix = (unsigned int )rxp->cq.ib.intr_type == 2U;
  tmp___10 = __fswab32((unsigned int )rxp->cq.ib.coalescing_timeo);
  cfg_req->ib_cfg.coalescing_timeout = tmp___10;
  tmp___11 = __fswab32((unsigned int )rxp->cq.ib.interpkt_timeo);
  cfg_req->ib_cfg.inter_pkt_timeout = tmp___11;
  cfg_req->ib_cfg.inter_pkt_count = (unsigned char )rxp->cq.ib.interpkt_count;
  switch ((unsigned int )rxp->type) {
  case 2U:
  cfg_req->rx_cfg.rxq_type = 2U;
  goto ldv_49840;
  case 3U:
  cfg_req->rx_cfg.rxq_type = 3U;
  cfg_req->rx_cfg.hds.type = (u8 )rx->hds_cfg.hdr_type;
  cfg_req->rx_cfg.hds.force_offset = (u8 )rx->hds_cfg.forced_offset;
  cfg_req->rx_cfg.hds.max_header_size = (u8 )rx->hds_cfg.forced_offset;
  goto ldv_49840;
  case 1U:
  cfg_req->rx_cfg.rxq_type = 1U;
  goto ldv_49840;
  default:
  tmp___12 = ldv__builtin_expect(1L, 0L);
  if (tmp___12 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c"),
                         "i" (1713), "i" (12UL));
    ldv_49844: ;
    goto ldv_49844;
  } else {
  }
  }
  ldv_49840:
  cfg_req->rx_cfg.strip_vlan = (u8 )rx->rxf.vlan_strip_status;
  rx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rx->msgq_cmd.cbarg = (void *)0;
  rx->msgq_cmd.msg_size = 1324UL;
  rx->msgq_cmd.msg_hdr = & cfg_req->mh;
  bfa_msgq_cmd_post(& (rx->bna)->msgq, & rx->msgq_cmd);
  return;
}
}
static void bna_bfi_rx_enet_stop(struct bna_rx *rx )
{
  struct bfi_enet_req *req ;
  {
  req = & rx->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 2U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )rx->rid;
  req->mh.num_entries = 256U;
  rx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  rx->msgq_cmd.cbarg = (void *)0;
  rx->msgq_cmd.msg_size = 8UL;
  rx->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& (rx->bna)->msgq, & rx->msgq_cmd);
  return;
}
}
static void bna_rx_enet_stop(struct bna_rx *rx )
{
  struct bna_rxp *rxp ;
  struct list_head const *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_49860;
  ldv_49859:
  ib = & rxp->cq.ib;
  writel(1073741824U, (void volatile *)ib->door_bell.doorbell_addr);
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile *)(rx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile *)(rx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )ib->intr_vector | intx_mask;
    writel(intx_mask, (void volatile *)(rx->bna)->regs.fn_int_mask);
  } else {
  }
  __mptr___0 = (struct list_head const *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_49860: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_49859;
  } else {
  }
  bna_bfi_rx_enet_stop(rx);
  return;
}
}
static int bna_rx_res_check(struct bna_rx_mod *rx_mod , struct bna_rx_config *rx_cfg )
{
  {
  if ((rx_mod->rx_free_count == 0 || rx_mod->rxp_free_count == 0) || rx_mod->rxq_free_count == 0) {
    return (0);
  } else {
  }
  if ((unsigned int )rx_cfg->rxp_type == 1U) {
    if (rx_mod->rxp_free_count < rx_cfg->num_paths || rx_mod->rxq_free_count < rx_cfg->num_paths) {
      return (0);
    } else {
    }
  } else
  if (rx_mod->rxp_free_count < rx_cfg->num_paths || rx_mod->rxq_free_count < rx_cfg->num_paths * 2) {
    return (0);
  } else {
  }
  return (1);
}
}
static struct bna_rxq *bna_rxq_get(struct bna_rx_mod *rx_mod )
{
  struct bna_rxq *rxq ;
  struct list_head const *__mptr ;
  {
  rxq = (struct bna_rxq *)0;
  __mptr = (struct list_head const *)rx_mod->rxq_free_q.next;
  rxq = (struct bna_rxq *)__mptr;
  list_del(& rxq->qe);
  rx_mod->rxq_free_count = rx_mod->rxq_free_count - 1;
  return (rxq);
}
}
static void bna_rxq_put(struct bna_rx_mod *rx_mod , struct bna_rxq *rxq )
{
  {
  list_add_tail(& rxq->qe, & rx_mod->rxq_free_q);
  rx_mod->rxq_free_count = rx_mod->rxq_free_count + 1;
  return;
}
}
static struct bna_rxp *bna_rxp_get(struct bna_rx_mod *rx_mod )
{
  struct bna_rxp *rxp ;
  struct list_head const *__mptr ;
  {
  rxp = (struct bna_rxp *)0;
  __mptr = (struct list_head const *)rx_mod->rxp_free_q.next;
  rxp = (struct bna_rxp *)__mptr;
  list_del(& rxp->qe);
  rx_mod->rxp_free_count = rx_mod->rxp_free_count - 1;
  return (rxp);
}
}
static void bna_rxp_put(struct bna_rx_mod *rx_mod , struct bna_rxp *rxp )
{
  {
  list_add_tail(& rxp->qe, & rx_mod->rxp_free_q);
  rx_mod->rxp_free_count = rx_mod->rxp_free_count + 1;
  return;
}
}
static struct bna_rx *bna_rx_get(struct bna_rx_mod *rx_mod , enum bna_rx_type type )
{
  struct bna_rx *rx ;
  int tmp ;
  long tmp___0 ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  rx = (struct bna_rx *)0;
  tmp = list_empty((struct list_head const *)(& rx_mod->rx_free_q));
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
  if (tmp___0 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c"),
                         "i" (1812), "i" (12UL));
    ldv_49891: ;
    goto ldv_49891;
  } else {
  }
  if ((unsigned int )type == 0U) {
    __mptr = (struct list_head const *)rx_mod->rx_free_q.next;
    rx = (struct bna_rx *)__mptr;
  } else {
    __mptr___0 = (struct list_head const *)rx_mod->rx_free_q.prev;
    rx = (struct bna_rx *)__mptr___0;
  }
  rx_mod->rx_free_count = rx_mod->rx_free_count - 1;
  list_move_tail(& rx->qe, & rx_mod->rx_active_q);
  rx->type = type;
  return (rx);
}
}
static void bna_rx_put(struct bna_rx_mod *rx_mod , struct bna_rx *rx )
{
  struct list_head *qe ;
  {
  qe = rx_mod->rx_free_q.prev;
  goto ldv_49903;
  ldv_49902: ;
  if (((struct bna_rx *)qe)->rid < rx->rid) {
    goto ldv_49901;
  } else {
  }
  qe = qe->prev;
  ldv_49903: ;
  if ((unsigned long )(& rx_mod->rx_free_q) != (unsigned long )qe) {
    goto ldv_49902;
  } else {
  }
  ldv_49901:
  list_add(& rx->qe, qe);
  rx_mod->rx_free_count = rx_mod->rx_free_count + 1;
  return;
}
}
static void bna_rxp_add_rxqs(struct bna_rxp *rxp , struct bna_rxq *q0 , struct bna_rxq *q1 )
{
  {
  switch ((unsigned int )rxp->type) {
  case 1U:
  rxp->rxq.single.only = q0;
  rxp->rxq.single.reserved = (struct bna_rxq *)0;
  goto ldv_49910;
  case 2U:
  rxp->rxq.slr.large = q0;
  rxp->rxq.slr.small = q1;
  goto ldv_49910;
  case 3U:
  rxp->rxq.hds.data = q0;
  rxp->rxq.hds.hdr = q1;
  goto ldv_49910;
  default: ;
  goto ldv_49910;
  }
  ldv_49910: ;
  return;
}
}
static void bna_rxq_qpt_setup(struct bna_rxq *rxq , struct bna_rxp *rxp , u32 page_count___0 ,
                              u32 page_size , struct bna_mem_descr *qpt_mem , struct bna_mem_descr *swqpt_mem ,
                              struct bna_mem_descr *page_mem )
{
  u8 *kva ;
  u64 dma ;
  struct bna_dma_addr bna_dma ;
  int i ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u64 tmp_addr ;
  __u64 tmp___1 ;
  {
  rxq->qpt.hw_qpt_ptr.lsb = qpt_mem->dma.lsb;
  rxq->qpt.hw_qpt_ptr.msb = qpt_mem->dma.msb;
  rxq->qpt.kv_qpt_ptr = qpt_mem->kva;
  rxq->qpt.page_count = page_count___0;
  rxq->qpt.page_size = page_size;
  (rxq->rcb)->sw_qpt = (void **)swqpt_mem->kva;
  (rxq->rcb)->sw_q = page_mem->kva;
  kva = (u8 *)page_mem->kva;
  tmp = __fswab32(page_mem->dma.msb);
  tmp___0 = __fswab32(page_mem->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  i = 0;
  goto ldv_49929;
  ldv_49928:
  *((rxq->rcb)->sw_qpt + (unsigned long )i) = (void *)kva;
  kva = kva + 4096UL;
  tmp___1 = __fswab64(dma);
  tmp_addr = tmp___1;
  bna_dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  bna_dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  ((struct bna_dma_addr *)rxq->qpt.kv_qpt_ptr + (unsigned long )i)->lsb = bna_dma.lsb;
  ((struct bna_dma_addr *)rxq->qpt.kv_qpt_ptr + (unsigned long )i)->msb = bna_dma.msb;
  dma = dma + 4096ULL;
  i = i + 1;
  ldv_49929: ;
  if ((u32 )i < rxq->qpt.page_count) {
    goto ldv_49928;
  } else {
  }
  return;
}
}
static void bna_rxp_cqpt_setup(struct bna_rxp *rxp , u32 page_count___0 , u32 page_size ,
                               struct bna_mem_descr *qpt_mem , struct bna_mem_descr *swqpt_mem ,
                               struct bna_mem_descr *page_mem )
{
  u8 *kva ;
  u64 dma ;
  struct bna_dma_addr bna_dma ;
  int i ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u64 tmp_addr ;
  __u64 tmp___1 ;
  {
  rxp->cq.qpt.hw_qpt_ptr.lsb = qpt_mem->dma.lsb;
  rxp->cq.qpt.hw_qpt_ptr.msb = qpt_mem->dma.msb;
  rxp->cq.qpt.kv_qpt_ptr = qpt_mem->kva;
  rxp->cq.qpt.page_count = page_count___0;
  rxp->cq.qpt.page_size = page_size;
  (rxp->cq.ccb)->sw_qpt = (void **)swqpt_mem->kva;
  (rxp->cq.ccb)->sw_q = page_mem->kva;
  kva = (u8 *)page_mem->kva;
  tmp = __fswab32(page_mem->dma.msb);
  tmp___0 = __fswab32(page_mem->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  i = 0;
  goto ldv_49945;
  ldv_49944:
  *((rxp->cq.ccb)->sw_qpt + (unsigned long )i) = (void *)kva;
  kva = kva + 4096UL;
  tmp___1 = __fswab64(dma);
  tmp_addr = tmp___1;
  bna_dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  bna_dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  ((struct bna_dma_addr *)rxp->cq.qpt.kv_qpt_ptr + (unsigned long )i)->lsb = bna_dma.lsb;
  ((struct bna_dma_addr *)rxp->cq.qpt.kv_qpt_ptr + (unsigned long )i)->msb = bna_dma.msb;
  dma = dma + 4096ULL;
  i = i + 1;
  ldv_49945: ;
  if ((u32 )i < rxp->cq.qpt.page_count) {
    goto ldv_49944;
  } else {
  }
  return;
}
}
static void bna_rx_mod_cb_rx_stopped(void *arg , struct bna_rx *rx )
{
  struct bna_rx_mod *rx_mod ;
  {
  rx_mod = (struct bna_rx_mod *)arg;
  bfa_wc_down(& rx_mod->rx_stop_wc);
  return;
}
}
static void bna_rx_mod_cb_rx_stopped_all(void *arg )
{
  struct bna_rx_mod *rx_mod ;
  {
  rx_mod = (struct bna_rx_mod *)arg;
  if ((unsigned long )rx_mod->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    (*(rx_mod->stop_cbfn))(& (rx_mod->bna)->enet);
  } else {
  }
  rx_mod->stop_cbfn = (void (*)(struct bna_enet * ))0;
  return;
}
}
static void bna_rx_start(struct bna_rx *rx )
{
  {
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 1U);
  if (((unsigned int )rx->rx_flags & 2U) != 0U) {
    (*(rx->fsm))((void *)rx, 1);
  } else {
  }
  return;
}
}
static void bna_rx_stop(struct bna_rx *rx )
{
  {
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags & 4294967294U);
  if ((unsigned long )rx->fsm == (unsigned long )((void (*)(void * , int ))(& bna_rx_sm_stopped))) {
    bna_rx_mod_cb_rx_stopped((void *)(& (rx->bna)->rx_mod), rx);
  } else {
    rx->stop_cbfn = & bna_rx_mod_cb_rx_stopped;
    rx->stop_cbarg = (void *)(& (rx->bna)->rx_mod);
    (*(rx->fsm))((void *)rx, 2);
  }
  return;
}
}
static void bna_rx_fail(struct bna_rx *rx )
{
  {
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags & 4294967294U);
  (*(rx->fsm))((void *)rx, 3);
  return;
}
}
void bna_rx_mod_start(struct bna_rx_mod *rx_mod , enum bna_rx_type type )
{
  struct bna_rx *rx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags | 1U);
  if ((unsigned int )type == 1U) {
    rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags | 2U);
  } else {
  }
  __mptr = (struct list_head const *)rx_mod->rx_active_q.next;
  rx = (struct bna_rx *)__mptr;
  goto ldv_49975;
  ldv_49974: ;
  if ((unsigned int )rx->type == (unsigned int )type) {
    bna_rx_start(rx);
  } else {
  }
  __mptr___0 = (struct list_head const *)rx->qe.next;
  rx = (struct bna_rx *)__mptr___0;
  ldv_49975: ;
  if ((unsigned long )(& rx->qe) != (unsigned long )(& rx_mod->rx_active_q)) {
    goto ldv_49974;
  } else {
  }
  return;
}
}
void bna_rx_mod_stop(struct bna_rx_mod *rx_mod , enum bna_rx_type type )
{
  struct bna_rx *rx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967294U);
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967293U);
  rx_mod->stop_cbfn = & bna_enet_cb_rx_stopped;
  bfa_wc_init(& rx_mod->rx_stop_wc, & bna_rx_mod_cb_rx_stopped_all, (void *)rx_mod);
  __mptr = (struct list_head const *)rx_mod->rx_active_q.next;
  rx = (struct bna_rx *)__mptr;
  goto ldv_49987;
  ldv_49986: ;
  if ((unsigned int )rx->type == (unsigned int )type) {
    bfa_wc_up(& rx_mod->rx_stop_wc);
    bna_rx_stop(rx);
  } else {
  }
  __mptr___0 = (struct list_head const *)rx->qe.next;
  rx = (struct bna_rx *)__mptr___0;
  ldv_49987: ;
  if ((unsigned long )(& rx->qe) != (unsigned long )(& rx_mod->rx_active_q)) {
    goto ldv_49986;
  } else {
  }
  bfa_wc_wait(& rx_mod->rx_stop_wc);
  return;
}
}
void bna_rx_mod_fail(struct bna_rx_mod *rx_mod )
{
  struct bna_rx *rx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967294U);
  rx_mod->flags = (enum bna_rx_mod_flags )((unsigned int )rx_mod->flags & 4294967293U);
  __mptr = (struct list_head const *)rx_mod->rx_active_q.next;
  rx = (struct bna_rx *)__mptr;
  goto ldv_49998;
  ldv_49997:
  bna_rx_fail(rx);
  __mptr___0 = (struct list_head const *)rx->qe.next;
  rx = (struct bna_rx *)__mptr___0;
  ldv_49998: ;
  if ((unsigned long )(& rx->qe) != (unsigned long )(& rx_mod->rx_active_q)) {
    goto ldv_49997;
  } else {
  }
  return;
}
}
void bna_rx_mod_init(struct bna_rx_mod *rx_mod , struct bna *bna , struct bna_res_info *res_info )
{
  int index ;
  struct bna_rx *rx_ptr ;
  struct bna_rxp *rxp_ptr ;
  struct bna_rxq *rxq_ptr ;
  {
  rx_mod->bna = bna;
  rx_mod->flags = 0;
  rx_mod->rx = (struct bna_rx *)((res_info + 2UL)->res_u.mem_info.mdl)->kva;
  rx_mod->rxp = (struct bna_rxp *)((res_info + 3UL)->res_u.mem_info.mdl)->kva;
  rx_mod->rxq = (struct bna_rxq *)((res_info + 4UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& rx_mod->rx_free_q);
  rx_mod->rx_free_count = 0;
  INIT_LIST_HEAD(& rx_mod->rxq_free_q);
  rx_mod->rxq_free_count = 0;
  INIT_LIST_HEAD(& rx_mod->rxp_free_q);
  rx_mod->rxp_free_count = 0;
  INIT_LIST_HEAD(& rx_mod->rx_active_q);
  index = 0;
  goto ldv_50010;
  ldv_50009:
  rx_ptr = rx_mod->rx + (unsigned long )index;
  INIT_LIST_HEAD(& rx_ptr->rxp_q);
  rx_ptr->bna = (struct bna *)0;
  rx_ptr->rid = index;
  rx_ptr->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
  rx_ptr->stop_cbarg = (void *)0;
  list_add_tail(& rx_ptr->qe, & rx_mod->rx_free_q);
  rx_mod->rx_free_count = rx_mod->rx_free_count + 1;
  index = index + 1;
  ldv_50010: ;
  if (bna->ioceth.attr.num_rxp > index) {
    goto ldv_50009;
  } else {
  }
  index = 0;
  goto ldv_50013;
  ldv_50012:
  rxp_ptr = rx_mod->rxp + (unsigned long )index;
  list_add_tail(& rxp_ptr->qe, & rx_mod->rxp_free_q);
  rx_mod->rxp_free_count = rx_mod->rxp_free_count + 1;
  index = index + 1;
  ldv_50013: ;
  if (bna->ioceth.attr.num_rxp > index) {
    goto ldv_50012;
  } else {
  }
  index = 0;
  goto ldv_50016;
  ldv_50015:
  rxq_ptr = rx_mod->rxq + (unsigned long )index;
  list_add_tail(& rxq_ptr->qe, & rx_mod->rxq_free_q);
  rx_mod->rxq_free_count = rx_mod->rxq_free_count + 1;
  index = index + 1;
  ldv_50016: ;
  if (bna->ioceth.attr.num_rxp * 2 > index) {
    goto ldv_50015;
  } else {
  }
  return;
}
}
void bna_rx_mod_uninit(struct bna_rx_mod *rx_mod )
{
  {
  rx_mod->bna = (struct bna *)0;
  return;
}
}
void bna_bfi_rx_enet_start_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_rx_cfg_rsp *cfg_rsp ;
  struct bna_rxp *rxp ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  int i ;
  struct list_head const *__mptr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  u32 tmp___2 ;
  u32 tmp___3 ;
  struct list_head const *__mptr___0 ;
  {
  cfg_rsp = & rx->bfi_enet_cmd.cfg_rsp;
  rxp = (struct bna_rxp *)0;
  q0 = (struct bna_rxq *)0;
  q1 = (struct bna_rxq *)0;
  bfa_msgq_rsp_copy(& (rx->bna)->msgq, (u8 *)cfg_rsp, 268UL);
  rx->hw_id = (int )cfg_rsp->hw_id;
  i = 0;
  __mptr = (struct list_head const *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_50039;
  ldv_50038: ;
  switch ((unsigned int )rxp->type) {
  case 1U:
  q0 = rxp->rxq.single.only;
  q1 = (struct bna_rxq *)0;
  goto ldv_50035;
  case 2U:
  q0 = rxp->rxq.slr.large;
  q1 = rxp->rxq.slr.small;
  goto ldv_50035;
  case 3U:
  q0 = rxp->rxq.hds.data;
  q1 = rxp->rxq.hds.hdr;
  goto ldv_50035;
  }
  ldv_50035:
  tmp = __fswab32(cfg_rsp->q_handles[i].i_dbell);
  ((rxp->cq.ccb)->i_dbell)->doorbell_addr = (rx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp;
  rxp->hw_id = (int )cfg_rsp->q_handles[i].hw_cqid;
  tmp___0 = __fswab32(cfg_rsp->q_handles[i].ql_dbell);
  (q0->rcb)->q_dbell = (rx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp___0;
  q0->hw_id = (int )cfg_rsp->q_handles[i].hw_lqid;
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    tmp___1 = __fswab32(cfg_rsp->q_handles[i].qs_dbell);
    (q1->rcb)->q_dbell = (rx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp___1;
    q1->hw_id = (int )cfg_rsp->q_handles[i].hw_sqid;
  } else {
  }
  *((rxp->cq.ccb)->hw_producer_index) = 0U;
  (rxp->cq.ccb)->producer_index = 0U;
  tmp___2 = 0U;
  (q0->rcb)->consumer_index = tmp___2;
  (q0->rcb)->producer_index = tmp___2;
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    tmp___3 = 0U;
    (q1->rcb)->consumer_index = tmp___3;
    (q1->rcb)->producer_index = tmp___3;
  } else {
  }
  i = i + 1;
  __mptr___0 = (struct list_head const *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_50039: ;
  if (rx->num_paths > i) {
    goto ldv_50038;
  } else {
  }
  (*(rx->fsm))((void *)rx, 4);
  return;
}
}
void bna_bfi_rx_enet_stop_rsp(struct bna_rx *rx , struct bfi_msgq_mhdr *msghdr )
{
  {
  (*(rx->fsm))((void *)rx, 5);
  return;
}
}
void bna_rx_res_req(struct bna_rx_config *q_cfg , struct bna_res_info *res_info )
{
  u32 cq_size ;
  u32 hq_size ;
  u32 dq_size ;
  u32 cpage_count ;
  u32 hpage_count ;
  u32 dpage_count ;
  struct bna_mem_info *mem_info ;
  u32 cq_depth ;
  u32 hq_depth ;
  u32 dq_depth ;
  unsigned long tmp ;
  unsigned long tmp___0 ;
  unsigned long tmp___1 ;
  {
  dq_depth = q_cfg->q0_depth;
  hq_depth = (unsigned int )q_cfg->rxp_type != 1U ? q_cfg->q1_depth : 0U;
  tmp = __roundup_pow_of_two((unsigned long )(dq_depth + hq_depth));
  cq_depth = (u32 )tmp;
  cq_size = cq_depth * 16U;
  cq_size = (cq_size + 4095U) & 4294963200U;
  cpage_count = (cq_size >> 12) + (u32 )((((unsigned long )cq_size & 4095UL) + 4095UL) >> 12);
  tmp___0 = __roundup_pow_of_two((unsigned long )dq_depth);
  dq_depth = (u32 )tmp___0;
  dq_size = dq_depth * 8U;
  dq_size = (dq_size + 4095U) & 4294963200U;
  dpage_count = (dq_size >> 12) + (u32 )((((unsigned long )dq_size & 4095UL) + 4095UL) >> 12);
  if ((unsigned int )q_cfg->rxp_type != 1U) {
    tmp___1 = __roundup_pow_of_two((unsigned long )hq_depth);
    hq_depth = (u32 )tmp___1;
    hq_size = hq_depth * 8U;
    hq_size = (hq_size + 4095U) & 4294963200U;
    hpage_count = (hq_size >> 12) + (u32 )((((unsigned long )hq_size & 4095UL) + 4095UL) >> 12);
  } else {
    hpage_count = 0U;
  }
  res_info->res_type = 1;
  mem_info = & res_info->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 144U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 1UL)->res_type = 1;
  mem_info = & (res_info + 1UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 96U;
  mem_info->num = (u32 )((unsigned int )q_cfg->rxp_type == 1U ? q_cfg->num_paths : q_cfg->num_paths * 2);
  (res_info + 4UL)->res_type = 1;
  mem_info = & (res_info + 4UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = cpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 5UL)->res_type = 1;
  mem_info = & (res_info + 5UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = cpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 6UL)->res_type = 1;
  mem_info = & (res_info + 6UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = cpage_count * 4096U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 8UL)->res_type = 1;
  mem_info = & (res_info + 8UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = dpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 10UL)->res_type = 1;
  mem_info = & (res_info + 10UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = dpage_count * 8U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 11UL)->res_type = 1;
  mem_info = & (res_info + 11UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = dpage_count * 4096U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 7UL)->res_type = 1;
  mem_info = & (res_info + 7UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = hpage_count * 8U;
  mem_info->num = hpage_count != 0U ? (u32 )q_cfg->num_paths : 0U;
  (res_info + 9UL)->res_type = 1;
  mem_info = & (res_info + 9UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = hpage_count * 8U;
  mem_info->num = hpage_count != 0U ? (u32 )q_cfg->num_paths : 0U;
  (res_info + 12UL)->res_type = 1;
  mem_info = & (res_info + 12UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = hpage_count * 4096U;
  mem_info->num = hpage_count != 0U ? (u32 )q_cfg->num_paths : 0U;
  (res_info + 13UL)->res_type = 1;
  mem_info = & (res_info + 13UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = 4U;
  mem_info->num = (u32 )q_cfg->num_paths;
  (res_info + 14UL)->res_type = 1;
  mem_info = & (res_info + 14UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 64U;
  mem_info->num = 1U;
  (res_info + 15UL)->res_type = 2;
  (res_info + 15UL)->res_u.intr_info.intr_type = 2;
  (res_info + 15UL)->res_u.intr_info.num = q_cfg->num_paths;
  return;
}
}
struct bna_rx *bna_rx_create(struct bna *bna , struct bnad *bnad , struct bna_rx_config *rx_cfg ,
                             struct bna_rx_event_cbfn const *rx_cbfn , struct bna_res_info *res_info ,
                             void *priv )
{
  struct bna_rx_mod *rx_mod ;
  struct bna_rx *rx ;
  struct bna_rxp *rxp ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  struct bna_intr_info *intr_info ;
  struct bna_mem_descr *hqunmap_mem ;
  struct bna_mem_descr *dqunmap_mem ;
  struct bna_mem_descr *ccb_mem ;
  struct bna_mem_descr *rcb_mem ;
  struct bna_mem_descr *cqpt_mem ;
  struct bna_mem_descr *cswqpt_mem ;
  struct bna_mem_descr *cpage_mem ;
  struct bna_mem_descr *hqpt_mem ;
  struct bna_mem_descr *dqpt_mem ;
  struct bna_mem_descr *hsqpt_mem ;
  struct bna_mem_descr *dsqpt_mem ;
  struct bna_mem_descr *hpage_mem ;
  struct bna_mem_descr *dpage_mem ;
  u32 dpage_count ;
  u32 hpage_count ;
  u32 hq_idx ;
  u32 dq_idx ;
  u32 rcb_idx ;
  u32 cq_depth ;
  u32 i ;
  u32 page_count___0 ;
  int tmp ;
  u64 tmp___0 ;
  u64 tmp___1 ;
  u64 tmp___2 ;
  u64 tmp___3 ;
  unsigned long tmp___4 ;
  {
  rx_mod = & bna->rx_mod;
  tmp = bna_rx_res_check(rx_mod, rx_cfg);
  if (tmp == 0) {
    return ((struct bna_rx *)0);
  } else {
  }
  intr_info = & (res_info + 15UL)->res_u.intr_info;
  ccb_mem = res_info->res_u.mem_info.mdl;
  rcb_mem = (res_info + 1UL)->res_u.mem_info.mdl;
  dqunmap_mem = (res_info + 3UL)->res_u.mem_info.mdl;
  hqunmap_mem = (res_info + 2UL)->res_u.mem_info.mdl;
  cqpt_mem = (res_info + 4UL)->res_u.mem_info.mdl;
  cswqpt_mem = (res_info + 5UL)->res_u.mem_info.mdl;
  cpage_mem = (res_info + 6UL)->res_u.mem_info.mdl;
  hqpt_mem = (res_info + 7UL)->res_u.mem_info.mdl;
  dqpt_mem = (res_info + 8UL)->res_u.mem_info.mdl;
  hsqpt_mem = (res_info + 9UL)->res_u.mem_info.mdl;
  dsqpt_mem = (res_info + 10UL)->res_u.mem_info.mdl;
  hpage_mem = (res_info + 12UL)->res_u.mem_info.mdl;
  dpage_mem = (res_info + 11UL)->res_u.mem_info.mdl;
  page_count___0 = (res_info + 6UL)->res_u.mem_info.len / 4096U;
  dpage_count = (res_info + 11UL)->res_u.mem_info.len / 4096U;
  hpage_count = (res_info + 12UL)->res_u.mem_info.len / 4096U;
  rx = bna_rx_get(rx_mod, rx_cfg->rx_type);
  rx->bna = bna;
  rx->rx_flags = 0;
  INIT_LIST_HEAD(& rx->rxp_q);
  rx->stop_cbfn = (void (*)(void * , struct bna_rx * ))0;
  rx->stop_cbarg = (void *)0;
  rx->priv = priv;
  rx->rcb_setup_cbfn = rx_cbfn->rcb_setup_cbfn;
  rx->rcb_destroy_cbfn = rx_cbfn->rcb_destroy_cbfn;
  rx->ccb_setup_cbfn = rx_cbfn->ccb_setup_cbfn;
  rx->ccb_destroy_cbfn = rx_cbfn->ccb_destroy_cbfn;
  rx->rx_stall_cbfn = rx_cbfn->rx_stall_cbfn;
  rx->rx_cleanup_cbfn = rx_cbfn->rx_cleanup_cbfn;
  rx->rx_post_cbfn = rx_cbfn->rx_post_cbfn;
  if ((int )(rx->bna)->rx_mod.flags & 1) {
    switch ((unsigned int )rx->type) {
    case 0U: ;
    if (((unsigned int )(rx->bna)->rx_mod.flags & 2U) == 0U) {
      rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 1U);
    } else {
    }
    goto ldv_50095;
    case 1U: ;
    if (((unsigned int )(rx->bna)->rx_mod.flags & 2U) != 0U) {
      rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 1U);
    } else {
    }
    goto ldv_50095;
    }
    ldv_50095: ;
  } else {
  }
  rx->num_paths = rx_cfg->num_paths;
  i = 0U;
  hq_idx = 0U;
  dq_idx = 0U;
  rcb_idx = 0U;
  goto ldv_50098;
  ldv_50097:
  rxp = bna_rxp_get(rx_mod);
  list_add_tail(& rxp->qe, & rx->rxp_q);
  rxp->type = rx_cfg->rxp_type;
  rxp->rx = rx;
  rxp->cq.rx = rx;
  q0 = bna_rxq_get(rx_mod);
  if ((unsigned int )rx_cfg->rxp_type == 1U) {
    q1 = (struct bna_rxq *)0;
  } else {
    q1 = bna_rxq_get(rx_mod);
  }
  if (intr_info->num == 1) {
    rxp->vector = (intr_info->idl)->vector;
  } else {
    rxp->vector = (intr_info->idl + (unsigned long )i)->vector;
  }
  rxp->cq.ib.ib_seg_host_addr.lsb = ((res_info + 13UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.lsb;
  rxp->cq.ib.ib_seg_host_addr.msb = ((res_info + 13UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.msb;
  rxp->cq.ib.ib_seg_host_addr_kva = ((res_info + 13UL)->res_u.mem_info.mdl + (unsigned long )i)->kva;
  rxp->cq.ib.intr_type = intr_info->intr_type;
  if ((unsigned int )intr_info->intr_type == 2U) {
    rxp->cq.ib.intr_vector = rxp->vector;
  } else {
    rxp->cq.ib.intr_vector = (int )(1UL << rxp->vector);
  }
  rxp->cq.ib.coalescing_timeo = (u8 )rx_cfg->coalescing_timeo;
  rxp->cq.ib.interpkt_count = 6;
  rxp->cq.ib.interpkt_timeo = 3;
  bna_rxp_add_rxqs(rxp, q0, q1);
  q0->rx = rx;
  q0->rxp = rxp;
  q0->rcb = (struct bna_rcb *)(rcb_mem + (unsigned long )rcb_idx)->kva;
  (q0->rcb)->unmap_q = (dqunmap_mem + (unsigned long )dq_idx)->kva;
  rcb_idx = rcb_idx + 1U;
  dq_idx = dq_idx + 1U;
  (q0->rcb)->q_depth = rx_cfg->q0_depth;
  q0->q_depth = (int )rx_cfg->q0_depth;
  q0->multi_buffer = rx_cfg->q0_multi_buf;
  q0->buffer_size = (int )rx_cfg->q0_buf_size;
  q0->num_vecs = rx_cfg->q0_num_vecs;
  (q0->rcb)->rxq = q0;
  (q0->rcb)->bnad = bna->bnad;
  (q0->rcb)->id = 0;
  tmp___0 = 0ULL;
  q0->rx_bytes = tmp___0;
  q0->rx_packets = tmp___0;
  tmp___1 = 0ULL;
  q0->rxbuf_alloc_failed = tmp___1;
  q0->rx_packets_with_error = tmp___1;
  bna_rxq_qpt_setup(q0, rxp, dpage_count, 4096U, dqpt_mem + (unsigned long )i, dsqpt_mem + (unsigned long )i,
                    dpage_mem + (unsigned long )i);
  if ((unsigned long )rx->rcb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_rcb * ))0)) {
    (*(rx->rcb_setup_cbfn))(bnad, q0->rcb);
  } else {
  }
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    q1->rx = rx;
    q1->rxp = rxp;
    q1->rcb = (struct bna_rcb *)(rcb_mem + (unsigned long )rcb_idx)->kva;
    (q1->rcb)->unmap_q = (hqunmap_mem + (unsigned long )hq_idx)->kva;
    rcb_idx = rcb_idx + 1U;
    hq_idx = hq_idx + 1U;
    (q1->rcb)->q_depth = rx_cfg->q1_depth;
    q1->q_depth = (int )rx_cfg->q1_depth;
    q1->multi_buffer = 0;
    q1->num_vecs = 1U;
    (q1->rcb)->rxq = q1;
    (q1->rcb)->bnad = bna->bnad;
    (q1->rcb)->id = 1;
    q1->buffer_size = (unsigned int )rx_cfg->rxp_type == 3U ? rx_cfg->hds_config.forced_offset : (int )rx_cfg->q1_buf_size;
    tmp___2 = 0ULL;
    q1->rx_bytes = tmp___2;
    q1->rx_packets = tmp___2;
    tmp___3 = 0ULL;
    q1->rxbuf_alloc_failed = tmp___3;
    q1->rx_packets_with_error = tmp___3;
    bna_rxq_qpt_setup(q1, rxp, hpage_count, 4096U, hqpt_mem + (unsigned long )i, hsqpt_mem + (unsigned long )i,
                      hpage_mem + (unsigned long )i);
    if ((unsigned long )rx->rcb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_rcb * ))0)) {
      (*(rx->rcb_setup_cbfn))(bnad, q1->rcb);
    } else {
    }
  } else {
  }
  rxp->cq.ccb = (struct bna_ccb *)(ccb_mem + (unsigned long )i)->kva;
  cq_depth = rx_cfg->q0_depth + ((unsigned int )rx_cfg->rxp_type != 1U ? rx_cfg->q1_depth : 0U);
  tmp___4 = __roundup_pow_of_two((unsigned long )cq_depth);
  cq_depth = (u32 )tmp___4;
  (rxp->cq.ccb)->q_depth = cq_depth;
  (rxp->cq.ccb)->cq = & rxp->cq;
  (rxp->cq.ccb)->rcb[0] = q0->rcb;
  (q0->rcb)->ccb = rxp->cq.ccb;
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    (rxp->cq.ccb)->rcb[1] = q1->rcb;
    (q1->rcb)->ccb = rxp->cq.ccb;
  } else {
  }
  (rxp->cq.ccb)->hw_producer_index = (u32 volatile *)rxp->cq.ib.ib_seg_host_addr_kva;
  (rxp->cq.ccb)->i_dbell = & rxp->cq.ib.door_bell;
  (rxp->cq.ccb)->intr_type = rxp->cq.ib.intr_type;
  (rxp->cq.ccb)->intr_vector = rxp->cq.ib.intr_vector;
  (rxp->cq.ccb)->rx_coalescing_timeo = rxp->cq.ib.coalescing_timeo;
  (rxp->cq.ccb)->pkt_rate.small_pkt_cnt = 0U;
  (rxp->cq.ccb)->pkt_rate.large_pkt_cnt = 0U;
  (rxp->cq.ccb)->bnad = bna->bnad;
  (rxp->cq.ccb)->id = (int )i;
  bna_rxp_cqpt_setup(rxp, page_count___0, 4096U, cqpt_mem + (unsigned long )i, cswqpt_mem + (unsigned long )i,
                     cpage_mem + (unsigned long )i);
  if ((unsigned long )rx->ccb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_ccb * ))0)) {
    (*(rx->ccb_setup_cbfn))(bnad, rxp->cq.ccb);
  } else {
  }
  i = i + 1U;
  ldv_50098: ;
  if ((u32 )rx->num_paths > i) {
    goto ldv_50097;
  } else {
  }
  rx->hds_cfg = rx_cfg->hds_config;
  bna_rxf_init(& rx->rxf, rx, rx_cfg, res_info);
  rx->fsm = (void (*)(void * , int ))(& bna_rx_sm_stopped);
  bna_rx_sm_stopped_entry(rx);
  rx_mod->rid_mask = rx_mod->rid_mask | (u32 )(1UL << rx->rid);
  return (rx);
}
}
void bna_rx_destroy(struct bna_rx *rx )
{
  struct bna_rx_mod *rx_mod ;
  struct bna_rxq *q0 ;
  struct bna_rxq *q1 ;
  struct bna_rxp *rxp ;
  struct list_head *qe ;
  struct list_head const *__mptr ;
  int tmp ;
  {
  rx_mod = & (rx->bna)->rx_mod;
  q0 = (struct bna_rxq *)0;
  q1 = (struct bna_rxq *)0;
  bna_rxf_uninit(& rx->rxf);
  goto ldv_50115;
  ldv_50114:
  __mptr = (struct list_head const *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  list_del(& rxp->qe);
  switch ((unsigned int )rxp->type) {
  case 1U:
  q0 = rxp->rxq.single.only;
  q1 = (struct bna_rxq *)0;
  goto ldv_50111;
  case 2U:
  q0 = rxp->rxq.slr.large;
  q1 = rxp->rxq.slr.small;
  goto ldv_50111;
  case 3U:
  q0 = rxp->rxq.hds.data;
  q1 = rxp->rxq.hds.hdr;
  goto ldv_50111;
  }
  ldv_50111: ;
  if ((unsigned long )rx->rcb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_rcb * ))0)) {
    (*(rx->rcb_destroy_cbfn))((rx->bna)->bnad, q0->rcb);
  } else {
  }
  q0->rcb = (struct bna_rcb *)0;
  q0->rxp = (struct bna_rxp *)0;
  q0->rx = (struct bna_rx *)0;
  bna_rxq_put(rx_mod, q0);
  if ((unsigned long )q1 != (unsigned long )((struct bna_rxq *)0)) {
    if ((unsigned long )rx->rcb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                           struct bna_rcb * ))0)) {
      (*(rx->rcb_destroy_cbfn))((rx->bna)->bnad, q1->rcb);
    } else {
    }
    q1->rcb = (struct bna_rcb *)0;
    q1->rxp = (struct bna_rxp *)0;
    q1->rx = (struct bna_rx *)0;
    bna_rxq_put(rx_mod, q1);
  } else {
  }
  rxp->rxq.slr.large = (struct bna_rxq *)0;
  rxp->rxq.slr.small = (struct bna_rxq *)0;
  if ((unsigned long )rx->ccb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_ccb * ))0)) {
    (*(rx->ccb_destroy_cbfn))((rx->bna)->bnad, rxp->cq.ccb);
  } else {
  }
  rxp->cq.ccb = (struct bna_ccb *)0;
  rxp->rx = (struct bna_rx *)0;
  bna_rxp_put(rx_mod, rxp);
  ldv_50115:
  tmp = list_empty((struct list_head const *)(& rx->rxp_q));
  if (tmp == 0) {
    goto ldv_50114;
  } else {
  }
  qe = rx_mod->rx_active_q.next;
  goto ldv_50119;
  ldv_50118: ;
  if ((unsigned long )(& rx->qe) == (unsigned long )qe) {
    list_del(& rx->qe);
    goto ldv_50117;
  } else {
  }
  qe = qe->next;
  ldv_50119: ;
  if ((unsigned long )(& rx_mod->rx_active_q) != (unsigned long )qe) {
    goto ldv_50118;
  } else {
  }
  ldv_50117:
  rx_mod->rid_mask = rx_mod->rid_mask & ~ ((u32 )(1UL << rx->rid));
  rx->bna = (struct bna *)0;
  rx->priv = (void *)0;
  bna_rx_put(rx_mod, rx);
  return;
}
}
void bna_rx_enable(struct bna_rx *rx )
{
  {
  if ((unsigned long )rx->fsm != (unsigned long )((void (*)(void * , int ))(& bna_rx_sm_stopped))) {
    return;
  } else {
  }
  rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags | 2U);
  if ((int )rx->rx_flags & 1) {
    (*(rx->fsm))((void *)rx, 1);
  } else {
  }
  return;
}
}
void bna_rx_disable(struct bna_rx *rx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_rx * ) )
{
  {
  if ((unsigned int )type == 1U) {
    (*cbfn)((void *)(rx->bna)->bnad, rx);
  } else {
    rx->stop_cbfn = cbfn;
    rx->stop_cbarg = (void *)(rx->bna)->bnad;
    rx->rx_flags = (enum bna_rx_flags )((unsigned int )rx->rx_flags & 4294967293U);
    (*(rx->fsm))((void *)rx, 2);
  }
  return;
}
}
void bna_rx_cleanup_complete(struct bna_rx *rx )
{
  {
  (*(rx->fsm))((void *)rx, 8);
  return;
}
}
void bna_rx_vlan_strip_enable(struct bna_rx *rx )
{
  struct bna_rxf *rxf ;
  {
  rxf = & rx->rxf;
  if ((unsigned int )rxf->vlan_strip_status == 0U) {
    rxf->vlan_strip_status = 1;
    rxf->vlan_strip_pending = 1;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {
  }
  return;
}
}
void bna_rx_vlan_strip_disable(struct bna_rx *rx )
{
  struct bna_rxf *rxf ;
  {
  rxf = & rx->rxf;
  if ((unsigned int )rxf->vlan_strip_status != 0U) {
    rxf->vlan_strip_status = 0;
    rxf->vlan_strip_pending = 1;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {
  }
  return;
}
}
enum bna_cb_status bna_rx_mode_set(struct bna_rx *rx , enum bna_rxmode new_mode ,
                                   enum bna_rxmode bitmask )
{
  struct bna_rxf *rxf ;
  int need_hw_config ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  {
  rxf = & rx->rxf;
  need_hw_config = 0;
  if ((int )bitmask & 1 && (int )new_mode & 1) {
    if ((rx->bna)->promisc_rid != -1 && (rx->bna)->promisc_rid != (rxf->rx)->rid) {
      goto err_return;
    } else {
    }
    if ((rx->bna)->default_mode_rid != -1) {
      goto err_return;
    } else {
    }
    if (((unsigned int )bitmask & 2U) != 0U && ((unsigned int )new_mode & 2U) != 0U) {
      goto err_return;
    } else {
    }
  } else {
  }
  if (((unsigned int )bitmask & 2U) != 0U && ((unsigned int )new_mode & 2U) != 0U) {
    if ((rx->bna)->default_mode_rid != -1 && (rx->bna)->default_mode_rid != (rxf->rx)->rid) {
      goto err_return;
    } else {
    }
    if ((rx->bna)->promisc_rid != -1) {
      goto err_return;
    } else {
    }
  } else {
  }
  if ((int )bitmask & 1 && (int )new_mode & 1) {
    tmp = bna_rxf_promisc_enable(rxf);
    if (tmp != 0) {
      need_hw_config = 1;
    } else {
    }
  } else
  if ((int )bitmask & 1 && ((unsigned int )new_mode & 1U) == 0U) {
    tmp___0 = bna_rxf_promisc_disable(rxf);
    if (tmp___0 != 0) {
      need_hw_config = 1;
    } else {
    }
  } else {
  }
  if (((unsigned int )bitmask & 4U) != 0U && ((unsigned int )new_mode & 4U) != 0U) {
    tmp___1 = bna_rxf_allmulti_enable(rxf);
    if (tmp___1 != 0) {
      need_hw_config = 1;
    } else {
    }
  } else
  if (((unsigned int )bitmask & 4U) != 0U && ((unsigned int )new_mode & 4U) == 0U) {
    tmp___2 = bna_rxf_allmulti_disable(rxf);
    if (tmp___2 != 0) {
      need_hw_config = 1;
    } else {
    }
  } else {
  }
  if (need_hw_config != 0) {
    rxf->cam_fltr_cbfn = (void (*)(struct bnad * , struct bna_rx * ))0;
    rxf->cam_fltr_cbarg = (rx->bna)->bnad;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {
  }
  return (0);
  err_return: ;
  return (1);
}
}
void bna_rx_vlanfilter_enable(struct bna_rx *rx )
{
  struct bna_rxf *rxf ;
  {
  rxf = & rx->rxf;
  if ((unsigned int )rxf->vlan_filter_status == 0U) {
    rxf->vlan_filter_status = 1;
    rxf->vlan_pending_bitmask = 255U;
    (*(rxf->fsm))((void *)rxf, 4);
  } else {
  }
  return;
}
}
void bna_rx_coalescing_timeo_set(struct bna_rx *rx , int coalescing_timeo )
{
  struct bna_rxp *rxp ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)rx->rxp_q.next;
  rxp = (struct bna_rxp *)__mptr;
  goto ldv_50163;
  ldv_50162:
  (rxp->cq.ccb)->rx_coalescing_timeo = (u8 )coalescing_timeo;
  bna_ib_coalescing_timeo_set(& rxp->cq.ib, (int )((u8 )coalescing_timeo));
  __mptr___0 = (struct list_head const *)rxp->qe.next;
  rxp = (struct bna_rxp *)__mptr___0;
  ldv_50163: ;
  if ((unsigned long )(& rxp->qe) != (unsigned long )(& rx->rxp_q)) {
    goto ldv_50162;
  } else {
  }
  return;
}
}
void bna_rx_dim_reconfig(struct bna *bna , u32 const (*vector)[2] )
{
  int i ;
  int j ;
  {
  i = 0;
  goto ldv_50175;
  ldv_50174:
  j = 0;
  goto ldv_50172;
  ldv_50171:
  bna->rx_mod.dim_vector[i][j] = (*(vector + (unsigned long )i))[j];
  j = j + 1;
  ldv_50172: ;
  if (j <= 1) {
    goto ldv_50171;
  } else {
  }
  i = i + 1;
  ldv_50175: ;
  if (i <= 7) {
    goto ldv_50174;
  } else {
  }
  return;
}
}
void bna_rx_dim_update(struct bna_ccb *ccb )
{
  struct bna *bna ;
  u32 load ;
  u32 bias ;
  u32 pkt_rt ;
  u32 small_rt ;
  u32 large_rt ;
  u8 coalescing_timeo ;
  {
  bna = ((ccb->cq)->rx)->bna;
  if (ccb->pkt_rate.small_pkt_cnt == 0U && ccb->pkt_rate.large_pkt_cnt == 0U) {
    return;
  } else {
  }
  small_rt = ccb->pkt_rate.small_pkt_cnt;
  large_rt = ccb->pkt_rate.large_pkt_cnt;
  pkt_rt = small_rt + large_rt;
  if (pkt_rt <= 9999U) {
    load = 7U;
  } else
  if (pkt_rt <= 19999U) {
    load = 6U;
  } else
  if (pkt_rt <= 29999U) {
    load = 5U;
  } else
  if (pkt_rt <= 39999U) {
    load = 4U;
  } else
  if (pkt_rt <= 49999U) {
    load = 3U;
  } else
  if (pkt_rt <= 59999U) {
    load = 2U;
  } else
  if (pkt_rt <= 79999U) {
    load = 1U;
  } else {
    load = 0U;
  }
  if (large_rt << 1 < small_rt) {
    bias = 0U;
  } else {
    bias = 1U;
  }
  ccb->pkt_rate.small_pkt_cnt = 0U;
  ccb->pkt_rate.large_pkt_cnt = 0U;
  coalescing_timeo = (u8 )bna->rx_mod.dim_vector[load][bias];
  ccb->rx_coalescing_timeo = coalescing_timeo;
  bna_ib_coalescing_timeo_set(& (ccb->cq)->ib, (int )coalescing_timeo);
  return;
}
}
u32 const bna_napi_dim_vector[8U][2U] =
  { { 12U, 12U},
   { 6U, 10U},
   { 5U, 10U},
   { 4U, 8U},
   { 3U, 6U},
   { 3U, 6U},
   { 2U, 4U},
   { 1U, 2U}};
static void bna_tx_mod_cb_tx_stopped(void *arg , struct bna_tx *tx ) ;
static void bna_bfi_tx_enet_start(struct bna_tx *tx ) ;
static void bna_tx_enet_stop(struct bna_tx *tx ) ;
static void bna_tx_sm_stopped(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_stopped_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_start_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_start_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_started(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_started_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_stop_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_stop_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_cleanup_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_prio_stop_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_prio_stop_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_prio_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_prio_cleanup_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_failed(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_failed_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_quiesce_wait(struct bna_tx *tx , enum bna_tx_event event ) ;
static void bna_tx_sm_quiesce_wait_entry(struct bna_tx *tx ) ;
static void bna_tx_sm_stopped_entry(struct bna_tx *tx )
{
  void (*cbfn)(void * , struct bna_tx * ) ;
  void *cbarg ;
  {
  if ((unsigned long )tx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_tx * ))0)) {
    cbfn = tx->stop_cbfn;
    cbarg = tx->stop_cbarg;
    tx->stop_cbfn = (void (*)(void * , struct bna_tx * ))0;
    tx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, tx);
  } else {
  }
  return;
}
}
static void bna_tx_sm_stopped(struct bna_tx *tx , enum bna_tx_event event )
{
  void (*cbfn)(void * , struct bna_tx * ) ;
  void *cbarg ;
  {
  switch ((unsigned int )event) {
  case 1U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_start_wait);
  bna_tx_sm_start_wait_entry(tx);
  goto ldv_50260;
  case 2U: ;
  if ((unsigned long )tx->stop_cbfn != (unsigned long )((void (*)(void * , struct bna_tx * ))0)) {
    cbfn = tx->stop_cbfn;
    cbarg = tx->stop_cbarg;
    tx->stop_cbfn = (void (*)(void * , struct bna_tx * ))0;
    tx->stop_cbarg = (void *)0;
    (*cbfn)(cbarg, tx);
  } else {
  }
  goto ldv_50260;
  case 3U: ;
  goto ldv_50260;
  case 8U: ;
  goto ldv_50260;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2832, (unsigned int )event);
  }
  ldv_50260: ;
  return;
}
}
static void bna_tx_sm_start_wait_entry(struct bna_tx *tx )
{
  {
  bna_bfi_tx_enet_start(tx);
  return;
}
}
static void bna_tx_sm_start_wait(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967287U);
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_stop_wait);
  bna_tx_sm_stop_wait_entry(tx);
  goto ldv_50277;
  case 3U:
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967287U);
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  goto ldv_50277;
  case 4U: ;
  if (((unsigned int )tx->flags & 8U) != 0U) {
    tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967287U);
    tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_prio_stop_wait);
    bna_tx_sm_prio_stop_wait_entry(tx);
  } else {
    tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_started);
    bna_tx_sm_started_entry(tx);
  }
  goto ldv_50277;
  case 8U:
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 8U);
  goto ldv_50277;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2869, (unsigned int )event);
  }
  ldv_50277: ;
  return;
}
}
static void bna_tx_sm_started_entry(struct bna_tx *tx )
{
  struct bna_txq *txq ;
  int is_regular ;
  struct list_head const *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head const *__mptr___0 ;
  {
  is_regular = (unsigned int )tx->type == 0U;
  __mptr = (struct list_head const *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50294;
  ldv_50293:
  (txq->tcb)->priority = txq->priority;
  ib = & txq->ib;
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile *)(tx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile *)(tx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )(~ ib->intr_vector) & intx_mask;
    writel(intx_mask, (void volatile *)(tx->bna)->regs.fn_int_mask);
  } else {
  }
  ib->door_bell.doorbell_ack = (unsigned int )((int )ib->coalescing_timeo << 16) | 2147483648U;
  if (is_regular != 0) {
    writel(ib->door_bell.doorbell_ack, (void volatile *)ib->door_bell.doorbell_addr);
  } else {
  }
  __mptr___0 = (struct list_head const *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50294: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50293;
  } else {
  }
  (*(tx->tx_resume_cbfn))((tx->bna)->bnad, tx);
  return;
}
}
static void bna_tx_sm_started(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_stop_wait);
  bna_tx_sm_stop_wait_entry(tx);
  (*(tx->tx_stall_cbfn))((tx->bna)->bnad, tx);
  bna_tx_enet_stop(tx);
  goto ldv_50301;
  case 3U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  (*(tx->tx_stall_cbfn))((tx->bna)->bnad, tx);
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  goto ldv_50301;
  case 8U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_prio_stop_wait);
  bna_tx_sm_prio_stop_wait_entry(tx);
  goto ldv_50301;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2908, (unsigned int )event);
  }
  ldv_50301: ;
  return;
}
}
static void bna_tx_sm_stop_wait_entry(struct bna_tx *tx )
{
  {
  return;
}
}
static void bna_tx_sm_stop_wait(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 5U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  goto ldv_50314;
  case 4U:
  bna_tx_enet_stop(tx);
  goto ldv_50314;
  case 8U: ;
  goto ldv_50314;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2940, (unsigned int )event);
  }
  ldv_50314: ;
  return;
}
}
static void bna_tx_sm_cleanup_wait_entry(struct bna_tx *tx )
{
  {
  return;
}
}
static void bna_tx_sm_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 8U: ;
  goto ldv_50327;
  case 7U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  goto ldv_50327;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2963, (unsigned int )event);
  }
  ldv_50327: ;
  return;
}
}
static void bna_tx_sm_prio_stop_wait_entry(struct bna_tx *tx )
{
  {
  (*(tx->tx_stall_cbfn))((tx->bna)->bnad, tx);
  bna_tx_enet_stop(tx);
  return;
}
}
static void bna_tx_sm_prio_stop_wait(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_stop_wait);
  bna_tx_sm_stop_wait_entry(tx);
  goto ldv_50338;
  case 3U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  goto ldv_50338;
  case 5U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_prio_cleanup_wait);
  bna_tx_sm_prio_cleanup_wait_entry(tx);
  goto ldv_50338;
  case 8U: ;
  goto ldv_50338;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         2996, (unsigned int )event);
  }
  ldv_50338: ;
  return;
}
}
static void bna_tx_sm_prio_cleanup_wait_entry(struct bna_tx *tx )
{
  {
  (*(tx->tx_cleanup_cbfn))((tx->bna)->bnad, tx);
  return;
}
}
static void bna_tx_sm_prio_cleanup_wait(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  goto ldv_50351;
  case 3U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  goto ldv_50351;
  case 8U: ;
  goto ldv_50351;
  case 7U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_start_wait);
  bna_tx_sm_start_wait_entry(tx);
  goto ldv_50351;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         3027, (unsigned int )event);
  }
  ldv_50351: ;
  return;
}
}
static void bna_tx_sm_failed_entry(struct bna_tx *tx )
{
  {
  return;
}
}
static void bna_tx_sm_failed(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 1U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_quiesce_wait);
  bna_tx_sm_quiesce_wait_entry(tx);
  goto ldv_50364;
  case 2U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  goto ldv_50364;
  case 3U: ;
  goto ldv_50364;
  case 7U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  goto ldv_50364;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         3057, (unsigned int )event);
  }
  ldv_50364: ;
  return;
}
}
static void bna_tx_sm_quiesce_wait_entry(struct bna_tx *tx )
{
  {
  return;
}
}
static void bna_tx_sm_quiesce_wait(struct bna_tx *tx , enum bna_tx_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_cleanup_wait);
  bna_tx_sm_cleanup_wait_entry(tx);
  goto ldv_50377;
  case 3U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_failed);
  bna_tx_sm_failed_entry(tx);
  goto ldv_50377;
  case 7U:
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_start_wait);
  bna_tx_sm_start_wait_entry(tx);
  goto ldv_50377;
  case 8U: ;
  goto ldv_50377;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bna_tx_rx.c",
         3087, (unsigned int )event);
  }
  ldv_50377: ;
  return;
}
}
static void bna_bfi_tx_enet_start(struct bna_tx *tx )
{
  struct bfi_enet_tx_cfg_req *cfg_req ;
  struct bna_txq *txq ;
  int i ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  struct bna_dma_addr cur_q_addr ;
  __u16 tmp ;
  __u16 tmp___0 ;
  __u16 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u16 tmp___4 ;
  {
  cfg_req = & tx->bfi_enet_cmd.cfg_req;
  txq = (struct bna_txq *)0;
  cfg_req->mh.msg_class = 24U;
  cfg_req->mh.msg_id = 17U;
  cfg_req->mh.msg_token = 0U;
  cfg_req->mh.enet_id = (u8 )tx->rid;
  cfg_req->mh.num_entries = 1536U;
  cfg_req->num_queues = (u8 )tx->num_txq;
  i = 0;
  goto ldv_50394;
  ldv_50393: ;
  if ((unsigned long )txq != (unsigned long )((struct bna_txq *)0)) {
    __mptr = (struct list_head const *)txq->qe.next;
    txq = (struct bna_txq *)__mptr;
  } else {
    __mptr___0 = (struct list_head const *)tx->txq_q.next;
    txq = (struct bna_txq *)__mptr___0;
  }
  cur_q_addr = *((struct bna_dma_addr *)txq->qpt.kv_qpt_ptr);
  cfg_req->q_cfg[i].q.q.pg_tbl.a32.addr_lo = txq->qpt.hw_qpt_ptr.lsb;
  cfg_req->q_cfg[i].q.q.pg_tbl.a32.addr_hi = txq->qpt.hw_qpt_ptr.msb;
  cfg_req->q_cfg[i].q.q.first_entry.a32.addr_lo = cur_q_addr.lsb;
  cfg_req->q_cfg[i].q.q.first_entry.a32.addr_hi = cur_q_addr.msb;
  tmp = __fswab16((int )((unsigned short )txq->qpt.page_count));
  cfg_req->q_cfg[i].q.q.pages = tmp;
  tmp___0 = __fswab16((int )((unsigned short )txq->qpt.page_size));
  cfg_req->q_cfg[i].q.q.page_sz = tmp___0;
  cfg_req->q_cfg[i].q.priority = txq->priority;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_lo = txq->ib.ib_seg_host_addr.lsb;
  cfg_req->q_cfg[i].ib.index_addr.a32.addr_hi = txq->ib.ib_seg_host_addr.msb;
  tmp___1 = __fswab16((int )((unsigned short )txq->ib.intr_vector));
  cfg_req->q_cfg[i].ib.intr.msix_index = tmp___1;
  i = i + 1;
  ldv_50394: ;
  if (tx->num_txq > i) {
    goto ldv_50393;
  } else {
  }
  cfg_req->ib_cfg.int_pkt_dma = 1U;
  cfg_req->ib_cfg.int_enabled = 1U;
  cfg_req->ib_cfg.int_pkt_enabled = 0U;
  cfg_req->ib_cfg.continuous_coalescing = 1U;
  cfg_req->ib_cfg.msix = (unsigned int )txq->ib.intr_type == 2U;
  tmp___2 = __fswab32((unsigned int )txq->ib.coalescing_timeo);
  cfg_req->ib_cfg.coalescing_timeout = tmp___2;
  tmp___3 = __fswab32((unsigned int )txq->ib.interpkt_timeo);
  cfg_req->ib_cfg.inter_pkt_timeout = tmp___3;
  cfg_req->ib_cfg.inter_pkt_count = (unsigned char )txq->ib.interpkt_count;
  cfg_req->tx_cfg.vlan_mode = 2U;
  tmp___4 = __fswab16((int )tx->txf_vlan_id);
  cfg_req->tx_cfg.vlan_id = tmp___4;
  cfg_req->tx_cfg.admit_tagged_frame = 1U;
  cfg_req->tx_cfg.apply_vlan_filter = 0U;
  tx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  tx->msgq_cmd.cbarg = (void *)0;
  tx->msgq_cmd.msg_size = 328UL;
  tx->msgq_cmd.msg_hdr = & cfg_req->mh;
  bfa_msgq_cmd_post(& (tx->bna)->msgq, & tx->msgq_cmd);
  return;
}
}
static void bna_bfi_tx_enet_stop(struct bna_tx *tx )
{
  struct bfi_enet_req *req ;
  {
  req = & tx->bfi_enet_cmd.req;
  req->mh.msg_class = 24U;
  req->mh.msg_id = 18U;
  req->mh.msg_token = 0U;
  req->mh.enet_id = (u8 )tx->rid;
  req->mh.num_entries = 256U;
  tx->msgq_cmd.cbfn = (void (*)(void * , enum bfa_status ))0;
  tx->msgq_cmd.cbarg = (void *)0;
  tx->msgq_cmd.msg_size = 8UL;
  tx->msgq_cmd.msg_hdr = & req->mh;
  bfa_msgq_cmd_post(& (tx->bna)->msgq, & tx->msgq_cmd);
  return;
}
}
static void bna_tx_enet_stop(struct bna_tx *tx )
{
  struct bna_txq *txq ;
  struct list_head const *__mptr ;
  u32 intx_mask ;
  struct bna_ib *ib ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50411;
  ldv_50410:
  ib = & txq->ib;
  writel(1073741824U, (void volatile *)ib->door_bell.doorbell_addr);
  if ((unsigned int )ib->intr_type == 1U) {
    intx_mask = readl((void const volatile *)(tx->bna)->regs.fn_int_mask);
    writel(4294967295U, (void volatile *)(tx->bna)->regs.fn_int_mask);
    intx_mask = (u32 )ib->intr_vector | intx_mask;
    writel(intx_mask, (void volatile *)(tx->bna)->regs.fn_int_mask);
  } else {
  }
  __mptr___0 = (struct list_head const *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50411: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50410;
  } else {
  }
  bna_bfi_tx_enet_stop(tx);
  return;
}
}
static void bna_txq_qpt_setup(struct bna_txq *txq , int page_count___0 , int page_size ,
                              struct bna_mem_descr *qpt_mem , struct bna_mem_descr *swqpt_mem ,
                              struct bna_mem_descr *page_mem )
{
  u8 *kva ;
  u64 dma ;
  struct bna_dma_addr bna_dma ;
  int i ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u64 tmp_addr ;
  __u64 tmp___1 ;
  {
  txq->qpt.hw_qpt_ptr.lsb = qpt_mem->dma.lsb;
  txq->qpt.hw_qpt_ptr.msb = qpt_mem->dma.msb;
  txq->qpt.kv_qpt_ptr = qpt_mem->kva;
  txq->qpt.page_count = (u32 )page_count___0;
  txq->qpt.page_size = (u32 )page_size;
  (txq->tcb)->sw_qpt = (void **)swqpt_mem->kva;
  (txq->tcb)->sw_q = page_mem->kva;
  kva = (u8 *)page_mem->kva;
  tmp = __fswab32(page_mem->dma.msb);
  tmp___0 = __fswab32(page_mem->dma.lsb);
  dma = ((unsigned long long )tmp << 32) | (unsigned long long )tmp___0;
  i = 0;
  goto ldv_50427;
  ldv_50426:
  *((txq->tcb)->sw_qpt + (unsigned long )i) = (void *)kva;
  kva = kva + 4096UL;
  tmp___1 = __fswab64(dma);
  tmp_addr = tmp___1;
  bna_dma.msb = ((struct bna_dma_addr *)(& tmp_addr))->msb;
  bna_dma.lsb = ((struct bna_dma_addr *)(& tmp_addr))->lsb;
  ((struct bna_dma_addr *)txq->qpt.kv_qpt_ptr + (unsigned long )i)->lsb = bna_dma.lsb;
  ((struct bna_dma_addr *)txq->qpt.kv_qpt_ptr + (unsigned long )i)->msb = bna_dma.msb;
  dma = dma + 4096ULL;
  i = i + 1;
  ldv_50427: ;
  if (i < page_count___0) {
    goto ldv_50426;
  } else {
  }
  return;
}
}
static struct bna_tx *bna_tx_get(struct bna_tx_mod *tx_mod , enum bna_tx_type type )
{
  struct bna_tx *tx ;
  int tmp ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  tx = (struct bna_tx *)0;
  tmp = list_empty((struct list_head const *)(& tx_mod->tx_free_q));
  if (tmp != 0) {
    return ((struct bna_tx *)0);
  } else {
  }
  if ((unsigned int )type == 0U) {
    __mptr = (struct list_head const *)tx_mod->tx_free_q.next;
    tx = (struct bna_tx *)__mptr;
  } else {
    __mptr___0 = (struct list_head const *)tx_mod->tx_free_q.prev;
    tx = (struct bna_tx *)__mptr___0;
  }
  list_del(& tx->qe);
  tx->type = type;
  return (tx);
}
}
static void bna_tx_free(struct bna_tx *tx )
{
  struct bna_tx_mod *tx_mod ;
  struct bna_txq *txq ;
  struct list_head *qe ;
  struct list_head const *__mptr ;
  int tmp ;
  {
  tx_mod = & (tx->bna)->tx_mod;
  goto ldv_50447;
  ldv_50446:
  __mptr = (struct list_head const *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  txq->tcb = (struct bna_tcb *)0;
  txq->tx = (struct bna_tx *)0;
  list_move_tail(& txq->qe, & tx_mod->txq_free_q);
  ldv_50447:
  tmp = list_empty((struct list_head const *)(& tx->txq_q));
  if (tmp == 0) {
    goto ldv_50446;
  } else {
  }
  qe = tx_mod->tx_active_q.next;
  goto ldv_50451;
  ldv_50450: ;
  if ((unsigned long )(& tx->qe) == (unsigned long )qe) {
    list_del(& tx->qe);
    goto ldv_50449;
  } else {
  }
  qe = qe->next;
  ldv_50451: ;
  if ((unsigned long )(& tx_mod->tx_active_q) != (unsigned long )qe) {
    goto ldv_50450;
  } else {
  }
  ldv_50449:
  tx->bna = (struct bna *)0;
  tx->priv = (void *)0;
  qe = tx_mod->tx_free_q.prev;
  goto ldv_50454;
  ldv_50453: ;
  if (((struct bna_tx *)qe)->rid < tx->rid) {
    goto ldv_50452;
  } else {
  }
  qe = qe->prev;
  ldv_50454: ;
  if ((unsigned long )(& tx_mod->tx_free_q) != (unsigned long )qe) {
    goto ldv_50453;
  } else {
  }
  ldv_50452:
  list_add(& tx->qe, qe);
  return;
}
}
static void bna_tx_start(struct bna_tx *tx )
{
  {
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 1U);
  if (((unsigned int )tx->flags & 2U) != 0U) {
    (*(tx->fsm))((void *)tx, 1);
  } else {
  }
  return;
}
}
static void bna_tx_stop(struct bna_tx *tx )
{
  {
  tx->stop_cbfn = & bna_tx_mod_cb_tx_stopped;
  tx->stop_cbarg = (void *)(& (tx->bna)->tx_mod);
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967294U);
  (*(tx->fsm))((void *)tx, 2);
  return;
}
}
static void bna_tx_fail(struct bna_tx *tx )
{
  {
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967294U);
  (*(tx->fsm))((void *)tx, 3);
  return;
}
}
void bna_bfi_tx_enet_start_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr )
{
  struct bfi_enet_tx_cfg_rsp *cfg_rsp ;
  struct bna_txq *txq ;
  int i ;
  struct list_head const *__mptr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  u32 tmp___1 ;
  struct list_head const *__mptr___0 ;
  {
  cfg_rsp = & tx->bfi_enet_cmd.cfg_rsp;
  txq = (struct bna_txq *)0;
  bfa_msgq_rsp_copy(& (tx->bna)->msgq, (u8 *)cfg_rsp, 108UL);
  tx->hw_id = (int )cfg_rsp->hw_id;
  i = 0;
  __mptr = (struct list_head const *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50476;
  ldv_50475:
  tmp = __fswab32(cfg_rsp->q_handles[i].i_dbell);
  ((txq->tcb)->i_dbell)->doorbell_addr = (tx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp;
  tmp___0 = __fswab32(cfg_rsp->q_handles[i].q_dbell);
  (txq->tcb)->q_dbell = (tx->bna)->pcidev.pci_bar_kva + (unsigned long )tmp___0;
  txq->hw_id = (int )cfg_rsp->q_handles[i].hw_qid;
  *((txq->tcb)->hw_consumer_index) = 0U;
  tmp___1 = 0U;
  (txq->tcb)->consumer_index = tmp___1;
  (txq->tcb)->producer_index = tmp___1;
  i = i + 1;
  __mptr___0 = (struct list_head const *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50476: ;
  if (tx->num_txq > i) {
    goto ldv_50475;
  } else {
  }
  (*(tx->fsm))((void *)tx, 4);
  return;
}
}
void bna_bfi_tx_enet_stop_rsp(struct bna_tx *tx , struct bfi_msgq_mhdr *msghdr )
{
  {
  (*(tx->fsm))((void *)tx, 5);
  return;
}
}
void bna_bfi_bw_update_aen(struct bna_tx_mod *tx_mod )
{
  struct bna_tx *tx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50491;
  ldv_50490:
  (*(tx->fsm))((void *)tx, 8);
  __mptr___0 = (struct list_head const *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50491: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50490;
  } else {
  }
  return;
}
}
void bna_tx_res_req(int num_txq , int txq_depth , struct bna_res_info *res_info )
{
  u32 q_size ;
  u32 page_count___0 ;
  struct bna_mem_info *mem_info ;
  {
  res_info->res_type = 1;
  mem_info = & res_info->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = 136U;
  mem_info->num = (u32 )num_txq;
  q_size = (u32 )(txq_depth * 64);
  q_size = (q_size + 4095U) & 4294963200U;
  page_count___0 = q_size >> 12;
  (res_info + 2UL)->res_type = 1;
  mem_info = & (res_info + 2UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = page_count___0 * 8U;
  mem_info->num = (u32 )num_txq;
  (res_info + 3UL)->res_type = 1;
  mem_info = & (res_info + 3UL)->res_u.mem_info;
  mem_info->mem_type = 1;
  mem_info->len = page_count___0 * 8U;
  mem_info->num = (u32 )num_txq;
  (res_info + 4UL)->res_type = 1;
  mem_info = & (res_info + 4UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = page_count___0 * 4096U;
  mem_info->num = (u32 )num_txq;
  (res_info + 5UL)->res_type = 1;
  mem_info = & (res_info + 5UL)->res_u.mem_info;
  mem_info->mem_type = 2;
  mem_info->len = 4U;
  mem_info->num = (u32 )num_txq;
  (res_info + 6UL)->res_type = 2;
  (res_info + 6UL)->res_u.intr_info.intr_type = 2;
  (res_info + 6UL)->res_u.intr_info.num = num_txq;
  return;
}
}
struct bna_tx *bna_tx_create(struct bna *bna , struct bnad *bnad , struct bna_tx_config *tx_cfg ,
                             struct bna_tx_event_cbfn const *tx_cbfn , struct bna_res_info *res_info ,
                             void *priv )
{
  struct bna_intr_info *intr_info ;
  struct bna_tx_mod *tx_mod ;
  struct bna_tx *tx ;
  struct bna_txq *txq ;
  int page_count___0 ;
  int i ;
  int tmp ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  struct list_head const *__mptr___1 ;
  {
  tx_mod = & bna->tx_mod;
  intr_info = & (res_info + 6UL)->res_u.intr_info;
  page_count___0 = (int )((res_info + 4UL)->res_u.mem_info.len / 4096U);
  if (intr_info->num != 1 && intr_info->num != tx_cfg->num_txq) {
    return ((struct bna_tx *)0);
  } else {
  }
  tx = bna_tx_get(tx_mod, tx_cfg->tx_type);
  if ((unsigned long )tx == (unsigned long )((struct bna_tx *)0)) {
    return ((struct bna_tx *)0);
  } else {
  }
  tx->bna = bna;
  tx->priv = priv;
  INIT_LIST_HEAD(& tx->txq_q);
  i = 0;
  goto ldv_50519;
  ldv_50518:
  tmp = list_empty((struct list_head const *)(& tx_mod->txq_free_q));
  if (tmp != 0) {
    goto err_return;
  } else {
  }
  __mptr = (struct list_head const *)tx_mod->txq_free_q.next;
  txq = (struct bna_txq *)__mptr;
  list_move_tail(& txq->qe, & tx->txq_q);
  txq->tx = tx;
  i = i + 1;
  ldv_50519: ;
  if (tx_cfg->num_txq > i) {
    goto ldv_50518;
  } else {
  }
  tx->tcb_setup_cbfn = tx_cbfn->tcb_setup_cbfn;
  tx->tcb_destroy_cbfn = tx_cbfn->tcb_destroy_cbfn;
  tx->tx_stall_cbfn = tx_cbfn->tx_stall_cbfn;
  tx->tx_resume_cbfn = tx_cbfn->tx_resume_cbfn;
  tx->tx_cleanup_cbfn = tx_cbfn->tx_cleanup_cbfn;
  list_add_tail(& tx->qe, & tx_mod->tx_active_q);
  tx->num_txq = tx_cfg->num_txq;
  tx->flags = 0;
  if ((int )(tx->bna)->tx_mod.flags & 1) {
    switch ((unsigned int )tx->type) {
    case 0U: ;
    if (((unsigned int )(tx->bna)->tx_mod.flags & 2U) == 0U) {
      tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 1U);
    } else {
    }
    goto ldv_50522;
    case 1U: ;
    if (((unsigned int )(tx->bna)->tx_mod.flags & 2U) != 0U) {
      tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 1U);
    } else {
    }
    goto ldv_50522;
    }
    ldv_50522: ;
  } else {
  }
  i = 0;
  __mptr___0 = (struct list_head const *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr___0;
  goto ldv_50529;
  ldv_50528:
  txq->tcb = (struct bna_tcb *)(res_info->res_u.mem_info.mdl + (unsigned long )i)->kva;
  txq->tx_packets = 0ULL;
  txq->tx_bytes = 0ULL;
  txq->ib.ib_seg_host_addr.lsb = ((res_info + 5UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.lsb;
  txq->ib.ib_seg_host_addr.msb = ((res_info + 5UL)->res_u.mem_info.mdl + (unsigned long )i)->dma.msb;
  txq->ib.ib_seg_host_addr_kva = ((res_info + 5UL)->res_u.mem_info.mdl + (unsigned long )i)->kva;
  txq->ib.intr_type = intr_info->intr_type;
  txq->ib.intr_vector = intr_info->num == 1 ? (intr_info->idl)->vector : (intr_info->idl + (unsigned long )i)->vector;
  if ((unsigned int )intr_info->intr_type == 1U) {
    txq->ib.intr_vector = (int )(1UL << txq->ib.intr_vector);
  } else {
  }
  txq->ib.coalescing_timeo = (u8 )tx_cfg->coalescing_timeo;
  txq->ib.interpkt_timeo = 15;
  txq->ib.interpkt_count = 12;
  (txq->tcb)->q_depth = (u32 )tx_cfg->txq_depth;
  (txq->tcb)->unmap_q = ((res_info + 1UL)->res_u.mem_info.mdl + (unsigned long )i)->kva;
  (txq->tcb)->hw_consumer_index = (u32 volatile *)txq->ib.ib_seg_host_addr_kva;
  (txq->tcb)->i_dbell = & txq->ib.door_bell;
  (txq->tcb)->intr_type = txq->ib.intr_type;
  (txq->tcb)->intr_vector = txq->ib.intr_vector;
  (txq->tcb)->txq = txq;
  (txq->tcb)->bnad = bnad;
  (txq->tcb)->id = i;
  bna_txq_qpt_setup(txq, page_count___0, 4096, (res_info + 2UL)->res_u.mem_info.mdl + (unsigned long )i,
                    (res_info + 3UL)->res_u.mem_info.mdl + (unsigned long )i, (res_info + 4UL)->res_u.mem_info.mdl + (unsigned long )i);
  if ((unsigned long )tx->tcb_setup_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                       struct bna_tcb * ))0)) {
    (*(tx->tcb_setup_cbfn))(bna->bnad, txq->tcb);
  } else {
  }
  if (tx_cfg->num_txq == 8) {
    txq->priority = (u8 )(txq->tcb)->id;
  } else {
    txq->priority = (u8 )tx_mod->default_prio;
  }
  i = i + 1;
  __mptr___1 = (struct list_head const *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___1;
  ldv_50529: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50528;
  } else {
  }
  tx->txf_vlan_id = 0U;
  tx->fsm = (void (*)(void * , int ))(& bna_tx_sm_stopped);
  bna_tx_sm_stopped_entry(tx);
  tx_mod->rid_mask = tx_mod->rid_mask | (u32 )(1UL << tx->rid);
  return (tx);
  err_return:
  bna_tx_free(tx);
  return ((struct bna_tx *)0);
}
}
void bna_tx_destroy(struct bna_tx *tx )
{
  struct bna_txq *txq ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50540;
  ldv_50539: ;
  if ((unsigned long )tx->tcb_destroy_cbfn != (unsigned long )((void (*)(struct bnad * ,
                                                                         struct bna_tcb * ))0)) {
    (*(tx->tcb_destroy_cbfn))((tx->bna)->bnad, txq->tcb);
  } else {
  }
  __mptr___0 = (struct list_head const *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50540: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50539;
  } else {
  }
  (tx->bna)->tx_mod.rid_mask = (tx->bna)->tx_mod.rid_mask & ~ ((u32 )(1UL << tx->rid));
  bna_tx_free(tx);
  return;
}
}
void bna_tx_enable(struct bna_tx *tx )
{
  {
  if ((unsigned long )tx->fsm != (unsigned long )((void (*)(void * , int ))(& bna_tx_sm_stopped))) {
    return;
  } else {
  }
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags | 2U);
  if ((int )tx->flags & 1) {
    (*(tx->fsm))((void *)tx, 1);
  } else {
  }
  return;
}
}
void bna_tx_disable(struct bna_tx *tx , enum bna_cleanup_type type , void (*cbfn)(void * ,
                                                                                  struct bna_tx * ) )
{
  {
  if ((unsigned int )type == 1U) {
    (*cbfn)((void *)(tx->bna)->bnad, tx);
    return;
  } else {
  }
  tx->stop_cbfn = cbfn;
  tx->stop_cbarg = (void *)(tx->bna)->bnad;
  tx->flags = (enum bna_tx_flags )((unsigned int )tx->flags & 4294967293U);
  (*(tx->fsm))((void *)tx, 2);
  return;
}
}
void bna_tx_cleanup_complete(struct bna_tx *tx )
{
  {
  (*(tx->fsm))((void *)tx, 7);
  return;
}
}
static void bna_tx_mod_cb_tx_stopped(void *arg , struct bna_tx *tx )
{
  struct bna_tx_mod *tx_mod ;
  {
  tx_mod = (struct bna_tx_mod *)arg;
  bfa_wc_down(& tx_mod->tx_stop_wc);
  return;
}
}
static void bna_tx_mod_cb_tx_stopped_all(void *arg )
{
  struct bna_tx_mod *tx_mod ;
  {
  tx_mod = (struct bna_tx_mod *)arg;
  if ((unsigned long )tx_mod->stop_cbfn != (unsigned long )((void (*)(struct bna_enet * ))0)) {
    (*(tx_mod->stop_cbfn))(& (tx_mod->bna)->enet);
  } else {
  }
  tx_mod->stop_cbfn = (void (*)(struct bna_enet * ))0;
  return;
}
}
void bna_tx_mod_init(struct bna_tx_mod *tx_mod , struct bna *bna , struct bna_res_info *res_info )
{
  int i ;
  {
  tx_mod->bna = bna;
  tx_mod->flags = 0;
  tx_mod->tx = (struct bna_tx *)(res_info->res_u.mem_info.mdl)->kva;
  tx_mod->txq = (struct bna_txq *)((res_info + 1UL)->res_u.mem_info.mdl)->kva;
  INIT_LIST_HEAD(& tx_mod->tx_free_q);
  INIT_LIST_HEAD(& tx_mod->tx_active_q);
  INIT_LIST_HEAD(& tx_mod->txq_free_q);
  i = 0;
  goto ldv_50571;
  ldv_50570:
  (tx_mod->tx + (unsigned long )i)->rid = i;
  list_add_tail(& (tx_mod->tx + (unsigned long )i)->qe, & tx_mod->tx_free_q);
  list_add_tail(& (tx_mod->txq + (unsigned long )i)->qe, & tx_mod->txq_free_q);
  i = i + 1;
  ldv_50571: ;
  if (bna->ioceth.attr.num_txq > i) {
    goto ldv_50570;
  } else {
  }
  tx_mod->prio_map = 255U;
  tx_mod->default_prio = 0;
  tx_mod->iscsi_over_cee = 0;
  tx_mod->iscsi_prio = -1;
  return;
}
}
void bna_tx_mod_uninit(struct bna_tx_mod *tx_mod )
{
  {
  tx_mod->bna = (struct bna *)0;
  return;
}
}
void bna_tx_mod_start(struct bna_tx_mod *tx_mod , enum bna_tx_type type )
{
  struct bna_tx *tx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags | 1U);
  if ((unsigned int )type == 1U) {
    tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags | 2U);
  } else {
  }
  __mptr = (struct list_head const *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50586;
  ldv_50585: ;
  if ((unsigned int )tx->type == (unsigned int )type) {
    bna_tx_start(tx);
  } else {
  }
  __mptr___0 = (struct list_head const *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50586: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50585;
  } else {
  }
  return;
}
}
void bna_tx_mod_stop(struct bna_tx_mod *tx_mod , enum bna_tx_type type )
{
  struct bna_tx *tx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967294U);
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967293U);
  tx_mod->stop_cbfn = & bna_enet_cb_tx_stopped;
  bfa_wc_init(& tx_mod->tx_stop_wc, & bna_tx_mod_cb_tx_stopped_all, (void *)tx_mod);
  __mptr = (struct list_head const *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50598;
  ldv_50597: ;
  if ((unsigned int )tx->type == (unsigned int )type) {
    bfa_wc_up(& tx_mod->tx_stop_wc);
    bna_tx_stop(tx);
  } else {
  }
  __mptr___0 = (struct list_head const *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50598: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50597;
  } else {
  }
  bfa_wc_wait(& tx_mod->tx_stop_wc);
  return;
}
}
void bna_tx_mod_fail(struct bna_tx_mod *tx_mod )
{
  struct bna_tx *tx ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967294U);
  tx_mod->flags = (enum bna_tx_mod_flags )((unsigned int )tx_mod->flags & 4294967293U);
  __mptr = (struct list_head const *)tx_mod->tx_active_q.next;
  tx = (struct bna_tx *)__mptr;
  goto ldv_50609;
  ldv_50608:
  bna_tx_fail(tx);
  __mptr___0 = (struct list_head const *)tx->qe.next;
  tx = (struct bna_tx *)__mptr___0;
  ldv_50609: ;
  if ((unsigned long )(& tx->qe) != (unsigned long )(& tx_mod->tx_active_q)) {
    goto ldv_50608;
  } else {
  }
  return;
}
}
void bna_tx_coalescing_timeo_set(struct bna_tx *tx , int coalescing_timeo )
{
  struct bna_txq *txq ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)tx->txq_q.next;
  txq = (struct bna_txq *)__mptr;
  goto ldv_50621;
  ldv_50620:
  bna_ib_coalescing_timeo_set(& txq->ib, (int )((u8 )coalescing_timeo));
  __mptr___0 = (struct list_head const *)txq->qe.next;
  txq = (struct bna_txq *)__mptr___0;
  ldv_50621: ;
  if ((unsigned long )(& txq->qe) != (unsigned long )(& tx->txq_q)) {
    goto ldv_50620;
  } else {
  }
  return;
}
}
bool ldv_queue_work_on_256(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_257(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_258(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_259(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_260(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_266(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_272(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_274(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_276(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_277(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_278(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_279(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_280(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_281(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_282(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
bool ldv_queue_work_on_302(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_304(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_303(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_306(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_305(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_312(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_320(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_328(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_322(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_318(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_326(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_327(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_323(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_324(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_325(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static void __bfa_dma_be_addr_set(union bfi_addr_u *dma_addr , u64 pa )
{
  __u32 tmp ;
  __u32 tmp___0 ;
  {
  tmp = __fswab32((__u32 )pa);
  dma_addr->a32.addr_lo = tmp;
  tmp___0 = __fswab32((unsigned int )(pa >> 32ULL));
  dma_addr->a32.addr_hi = tmp___0;
  return;
}
}
bool bfa_nw_ioc_mbox_queue(struct bfa_ioc *ioc , struct bfa_mbox_cmd *cmd , void (*cbfn)(void * ) ,
                           void *cbarg ) ;
void bfa_nw_ioc_mbox_regisr(struct bfa_ioc *ioc , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                                    struct bfi_mbmsg * ) ,
                            void *cbarg ) ;
bool bfa_nw_ioc_is_disabled(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_notify_register(struct bfa_ioc *ioc , struct bfa_ioc_notify *notify ) ;
static void bfa_msgq_cmdq_dbell(struct bfa_msgq_cmdq *cmdq ) ;
static void bfa_msgq_cmdq_copy_rsp(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_stopped(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_stopped_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_init_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_init_wait_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_ready(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_ready_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_dbell_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event ) ;
static void cmdq_sm_dbell_wait_entry(struct bfa_msgq_cmdq *cmdq ) ;
static void cmdq_sm_stopped_entry(struct bfa_msgq_cmdq *cmdq )
{
  struct bfa_msgq_cmd_entry *cmdq_ent ;
  struct list_head const *__mptr ;
  void (*cbfn)(void * , enum bfa_status ) ;
  void *cbarg ;
  int tmp ;
  {
  cmdq->producer_index = 0U;
  cmdq->consumer_index = 0U;
  cmdq->flags = 0;
  cmdq->token = 0U;
  cmdq->offset = 0;
  cmdq->bytes_to_copy = 0;
  goto ldv_47569;
  ldv_47568:
  __mptr = (struct list_head const *)cmdq->pending_q.next;
  cmdq_ent = (struct bfa_msgq_cmd_entry *)__mptr;
  list_del(& cmdq_ent->qe);
  cbfn = cmdq_ent->cbfn;
  cbarg = cmdq_ent->cbarg;
  cmdq_ent->cbfn = (void (*)(void * , enum bfa_status ))0;
  cmdq_ent->cbarg = (void *)0;
  if ((unsigned long )cbfn != (unsigned long )((void (*)(void * , enum bfa_status ))0)) {
    (*cbfn)(cbarg, 1);
  } else {
  }
  ldv_47569:
  tmp = list_empty((struct list_head const *)(& cmdq->pending_q));
  if (tmp == 0) {
    goto ldv_47568;
  } else {
  }
  return;
}
}
static void cmdq_sm_stopped(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event )
{
  {
  switch ((unsigned int )event) {
  case 1U:
  cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_init_wait);
  cmdq_sm_init_wait_entry(cmdq);
  goto ldv_47576;
  case 2U: ;
  case 3U: ;
  goto ldv_47576;
  case 4U:
  cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags | 1U);
  goto ldv_47576;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         94, (unsigned int )event);
  }
  ldv_47576: ;
  return;
}
}
static void cmdq_sm_init_wait_entry(struct bfa_msgq_cmdq *cmdq )
{
  {
  bfa_wc_down(& (cmdq->msgq)->init_wc);
  return;
}
}
static void cmdq_sm_init_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U:
  cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  goto ldv_47590;
  case 4U:
  cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags | 1U);
  goto ldv_47590;
  case 5U: ;
  if ((int )cmdq->flags & 1) {
    cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags & 4294967294U);
    cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_dbell_wait);
    cmdq_sm_dbell_wait_entry(cmdq);
  } else {
    cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_ready);
    cmdq_sm_ready_entry(cmdq);
  }
  goto ldv_47590;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         126, (unsigned int )event);
  }
  ldv_47590: ;
  return;
}
}
static void cmdq_sm_ready_entry(struct bfa_msgq_cmdq *cmdq )
{
  {
  return;
}
}
static void cmdq_sm_ready(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U:
  cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  goto ldv_47603;
  case 4U:
  cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_dbell_wait);
  cmdq_sm_dbell_wait_entry(cmdq);
  goto ldv_47603;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         149, (unsigned int )event);
  }
  ldv_47603: ;
  return;
}
}
static void cmdq_sm_dbell_wait_entry(struct bfa_msgq_cmdq *cmdq )
{
  {
  bfa_msgq_cmdq_dbell(cmdq);
  return;
}
}
static void cmdq_sm_dbell_wait(struct bfa_msgq_cmdq *cmdq , enum cmdq_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U:
  cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  goto ldv_47615;
  case 4U:
  cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags | 1U);
  goto ldv_47615;
  case 6U: ;
  if ((int )cmdq->flags & 1) {
    cmdq->flags = (enum bfa_msgq_cmdq_flags )((unsigned int )cmdq->flags & 4294967294U);
    cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_dbell_wait);
    cmdq_sm_dbell_wait_entry(cmdq);
  } else {
    cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_ready);
    cmdq_sm_ready_entry(cmdq);
  }
  goto ldv_47615;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         181, (unsigned int )event);
  }
  ldv_47615: ;
  return;
}
}
static void bfa_msgq_cmdq_dbell_ready(void *arg )
{
  struct bfa_msgq_cmdq *cmdq ;
  {
  cmdq = (struct bfa_msgq_cmdq *)arg;
  (*(cmdq->fsm))((void *)cmdq, 6);
  return;
}
}
static void bfa_msgq_cmdq_dbell(struct bfa_msgq_cmdq *cmdq )
{
  struct bfi_msgq_h2i_db *dbell ;
  __u16 tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  {
  dbell = (struct bfi_msgq_h2i_db *)(& cmdq->dbell_mb.msg);
  memset((void *)dbell, 0, 6UL);
  dbell->mh.msg_class = 23U;
  dbell->mh.msg_id = 2U;
  dbell->mh.mtag.h2i.fn_lpu = 0U;
  dbell->mh.mtag.i2htok = 0U;
  tmp = __fswab16((int )cmdq->producer_index);
  dbell->idx.cmdq_pi = tmp;
  tmp___0 = bfa_nw_ioc_mbox_queue((cmdq->msgq)->ioc, & cmdq->dbell_mb, & bfa_msgq_cmdq_dbell_ready,
                                  (void *)cmdq);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    bfa_msgq_cmdq_dbell_ready((void *)cmdq);
  } else {
  }
  return;
}
}
static void __cmd_copy(struct bfa_msgq_cmdq *cmdq , struct bfa_msgq_cmd_entry *cmd )
{
  size_t len ;
  int num_entries ;
  size_t to_copy ;
  u8 *src ;
  u8 *dst ;
  {
  len = cmd->msg_size;
  num_entries = 0;
  src = (u8 *)cmd->msg_hdr;
  dst = (u8 *)cmdq->addr.kva;
  dst = dst + (unsigned long )((int )cmdq->producer_index * 64);
  goto ldv_47637;
  ldv_47636:
  to_copy = 64UL < len ? 64UL : len;
  memcpy((void *)dst, (void const *)src, to_copy);
  len = len - to_copy;
  src = src + 64UL;
  cmdq->producer_index = (u16 )((int )((short )((unsigned int )cmdq->producer_index + 1U)) & (int )((short )((unsigned int )cmdq->depth + 65535U)));
  dst = (u8 *)cmdq->addr.kva;
  dst = dst + (unsigned long )((int )cmdq->producer_index * 64);
  num_entries = num_entries + 1;
  ldv_47637: ;
  if (len != 0UL) {
    goto ldv_47636;
  } else {
  }
  return;
}
}
static void bfa_msgq_cmdq_ci_update(struct bfa_msgq_cmdq *cmdq , struct bfi_mbmsg *mb )
{
  struct bfi_msgq_i2h_db *dbell ;
  struct bfa_msgq_cmd_entry *cmd ;
  int posted ;
  __u16 tmp ;
  struct list_head const *__mptr ;
  void (*cbfn)(void * , enum bfa_status ) ;
  void *cbarg ;
  __u16 tmp___0 ;
  int tmp___1 ;
  {
  dbell = (struct bfi_msgq_i2h_db *)mb;
  posted = 0;
  tmp = __fswab16((int )dbell->idx.cmdq_ci);
  cmdq->consumer_index = tmp;
  goto ldv_47652;
  ldv_47651:
  __mptr = (struct list_head const *)cmdq->pending_q.next;
  cmd = (struct bfa_msgq_cmd_entry *)__mptr;
  tmp___0 = __fswab16((int )(cmd->msg_hdr)->num_entries);
  if ((int )tmp___0 <= ((((int )cmdq->consumer_index - (int )cmdq->producer_index) + -1) & ((int )cmdq->depth + -1))) {
    list_del(& cmd->qe);
    __cmd_copy(cmdq, cmd);
    posted = 1;
    cbfn = cmd->cbfn;
    cbarg = cmd->cbarg;
    cmd->cbfn = (void (*)(void * , enum bfa_status ))0;
    cmd->cbarg = (void *)0;
    if ((unsigned long )cbfn != (unsigned long )((void (*)(void * , enum bfa_status ))0)) {
      (*cbfn)(cbarg, 0);
    } else {
    }
  } else {
    goto ldv_47650;
  }
  ldv_47652:
  tmp___1 = list_empty((struct list_head const *)(& cmdq->pending_q));
  if (tmp___1 == 0) {
    goto ldv_47651;
  } else {
  }
  ldv_47650: ;
  if (posted != 0) {
    (*(cmdq->fsm))((void *)cmdq, 4);
  } else {
  }
  return;
}
}
static void bfa_msgq_cmdq_copy_next(void *arg )
{
  struct bfa_msgq_cmdq *cmdq ;
  {
  cmdq = (struct bfa_msgq_cmdq *)arg;
  if (cmdq->bytes_to_copy != 0) {
    bfa_msgq_cmdq_copy_rsp(cmdq);
  } else {
  }
  return;
}
}
static void bfa_msgq_cmdq_copy_req(struct bfa_msgq_cmdq *cmdq , struct bfi_mbmsg *mb )
{
  struct bfi_msgq_i2h_cmdq_copy_req *req ;
  __u16 tmp ;
  __u16 tmp___0 ;
  {
  req = (struct bfi_msgq_i2h_cmdq_copy_req *)mb;
  cmdq->token = 0U;
  tmp = __fswab16((int )req->offset);
  cmdq->offset = (int )tmp;
  tmp___0 = __fswab16((int )req->len);
  cmdq->bytes_to_copy = (int )tmp___0;
  bfa_msgq_cmdq_copy_rsp(cmdq);
  return;
}
}
static void bfa_msgq_cmdq_copy_rsp(struct bfa_msgq_cmdq *cmdq )
{
  struct bfi_msgq_h2i_cmdq_copy_rsp *rsp ;
  int copied ;
  u8 *addr ;
  __u16 tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  {
  rsp = (struct bfi_msgq_h2i_cmdq_copy_rsp *)(& cmdq->copy_mb.msg);
  addr = (u8 *)cmdq->addr.kva;
  memset((void *)rsp, 0, 32UL);
  rsp->mh.msg_class = 23U;
  rsp->mh.msg_id = 4U;
  rsp->mh.mtag.h2i.fn_lpu = 0U;
  tmp = __fswab16((int )cmdq->token);
  rsp->mh.mtag.i2htok = tmp;
  copied = 28 < cmdq->bytes_to_copy ? 28 : cmdq->bytes_to_copy;
  addr = addr + (unsigned long )cmdq->offset;
  memcpy((void *)(& rsp->data), (void const *)addr, (size_t )copied);
  cmdq->token = (u16 )((int )cmdq->token + 1);
  cmdq->offset = cmdq->offset + copied;
  cmdq->bytes_to_copy = cmdq->bytes_to_copy - copied;
  tmp___0 = bfa_nw_ioc_mbox_queue((cmdq->msgq)->ioc, & cmdq->copy_mb, & bfa_msgq_cmdq_copy_next,
                                  (void *)cmdq);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    bfa_msgq_cmdq_copy_next((void *)cmdq);
  } else {
  }
  return;
}
}
static void bfa_msgq_cmdq_attach(struct bfa_msgq_cmdq *cmdq , struct bfa_msgq *msgq )
{
  {
  cmdq->depth = 128U;
  INIT_LIST_HEAD(& cmdq->pending_q);
  cmdq->msgq = msgq;
  cmdq->fsm = (void (*)(void * , int ))(& cmdq_sm_stopped);
  cmdq_sm_stopped_entry(cmdq);
  return;
}
}
static void bfa_msgq_rspq_dbell(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_stopped(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_stopped_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_init_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_init_wait_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_ready(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_ready_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_dbell_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event ) ;
static void rspq_sm_dbell_wait_entry(struct bfa_msgq_rspq *rspq ) ;
static void rspq_sm_stopped_entry(struct bfa_msgq_rspq *rspq )
{
  {
  rspq->producer_index = 0U;
  rspq->consumer_index = 0U;
  rspq->flags = 0;
  return;
}
}
static void rspq_sm_stopped(struct bfa_msgq_rspq *rspq , enum rspq_event event )
{
  {
  switch ((unsigned int )event) {
  case 1U:
  rspq->fsm = (void (*)(void * , int ))(& rspq_sm_init_wait);
  rspq_sm_init_wait_entry(rspq);
  goto ldv_47709;
  case 2U: ;
  case 3U: ;
  goto ldv_47709;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         359, (unsigned int )event);
  }
  ldv_47709: ;
  return;
}
}
static void rspq_sm_init_wait_entry(struct bfa_msgq_rspq *rspq )
{
  {
  bfa_wc_down(& (rspq->msgq)->init_wc);
  return;
}
}
static void rspq_sm_init_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event )
{
  {
  switch ((unsigned int )event) {
  case 3U: ;
  case 2U:
  rspq->fsm = (void (*)(void * , int ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  goto ldv_47722;
  case 5U:
  rspq->fsm = (void (*)(void * , int ))(& rspq_sm_ready);
  rspq_sm_ready_entry(rspq);
  goto ldv_47722;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         383, (unsigned int )event);
  }
  ldv_47722: ;
  return;
}
}
static void rspq_sm_ready_entry(struct bfa_msgq_rspq *rspq )
{
  {
  return;
}
}
static void rspq_sm_ready(struct bfa_msgq_rspq *rspq , enum rspq_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U:
  rspq->fsm = (void (*)(void * , int ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  goto ldv_47734;
  case 4U:
  rspq->fsm = (void (*)(void * , int ))(& rspq_sm_dbell_wait);
  rspq_sm_dbell_wait_entry(rspq);
  goto ldv_47734;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         406, (unsigned int )event);
  }
  ldv_47734: ;
  return;
}
}
static void rspq_sm_dbell_wait_entry(struct bfa_msgq_rspq *rspq )
{
  bool tmp ;
  int tmp___0 ;
  {
  tmp = bfa_nw_ioc_is_disabled((rspq->msgq)->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    bfa_msgq_rspq_dbell(rspq);
  } else {
  }
  return;
}
}
static void rspq_sm_dbell_wait(struct bfa_msgq_rspq *rspq , enum rspq_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U:
  rspq->fsm = (void (*)(void * , int ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  goto ldv_47746;
  case 4U:
  rspq->flags = (enum bfa_msgq_rspq_flags )((unsigned int )rspq->flags | 1U);
  goto ldv_47746;
  case 6U: ;
  if ((int )rspq->flags & 1) {
    rspq->flags = (enum bfa_msgq_rspq_flags )((unsigned int )rspq->flags & 4294967294U);
    rspq->fsm = (void (*)(void * , int ))(& rspq_sm_dbell_wait);
    rspq_sm_dbell_wait_entry(rspq);
  } else {
    rspq->fsm = (void (*)(void * , int ))(& rspq_sm_ready);
    rspq_sm_ready_entry(rspq);
  }
  goto ldv_47746;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c",
         439, (unsigned int )event);
  }
  ldv_47746: ;
  return;
}
}
static void bfa_msgq_rspq_dbell_ready(void *arg )
{
  struct bfa_msgq_rspq *rspq ;
  {
  rspq = (struct bfa_msgq_rspq *)arg;
  (*(rspq->fsm))((void *)rspq, 6);
  return;
}
}
static void bfa_msgq_rspq_dbell(struct bfa_msgq_rspq *rspq )
{
  struct bfi_msgq_h2i_db *dbell ;
  __u16 tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  {
  dbell = (struct bfi_msgq_h2i_db *)(& rspq->dbell_mb.msg);
  memset((void *)dbell, 0, 6UL);
  dbell->mh.msg_class = 23U;
  dbell->mh.msg_id = 3U;
  dbell->mh.mtag.h2i.fn_lpu = 0U;
  dbell->mh.mtag.i2htok = 0U;
  tmp = __fswab16((int )rspq->consumer_index);
  dbell->idx.rspq_ci = tmp;
  tmp___0 = bfa_nw_ioc_mbox_queue((rspq->msgq)->ioc, & rspq->dbell_mb, & bfa_msgq_rspq_dbell_ready,
                                  (void *)rspq);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    bfa_msgq_rspq_dbell_ready((void *)rspq);
  } else {
  }
  return;
}
}
static void bfa_msgq_rspq_pi_update(struct bfa_msgq_rspq *rspq , struct bfi_mbmsg *mb )
{
  struct bfi_msgq_i2h_db *dbell ;
  struct bfi_msgq_mhdr *msghdr ;
  int num_entries ;
  int mc ;
  u8 *rspq_qe ;
  __u16 tmp ;
  __u16 tmp___0 ;
  {
  dbell = (struct bfi_msgq_i2h_db *)mb;
  tmp = __fswab16((int )dbell->idx.rspq_pi);
  rspq->producer_index = tmp;
  goto ldv_47769;
  ldv_47768:
  rspq_qe = (u8 *)rspq->addr.kva;
  rspq_qe = rspq_qe + (unsigned long )((int )rspq->consumer_index * 64);
  msghdr = (struct bfi_msgq_mhdr *)rspq_qe;
  mc = (int )msghdr->msg_class;
  tmp___0 = __fswab16((int )msghdr->num_entries);
  num_entries = (int )tmp___0;
  if (mc > 33 || (unsigned long )rspq->rsphdlr[mc].cbfn == (unsigned long )((void (*)(void * ,
                                                                                      struct bfi_msgq_mhdr * ))0)) {
    goto ldv_47767;
  } else {
  }
  (*(rspq->rsphdlr[mc].cbfn))(rspq->rsphdlr[mc].cbarg, msghdr);
  rspq->consumer_index = (u16 )((int )((short )((int )rspq->consumer_index + (int )((unsigned short )num_entries))) & (int )((short )((unsigned int )rspq->depth + 65535U)));
  ldv_47769: ;
  if ((int )rspq->consumer_index != (int )rspq->producer_index) {
    goto ldv_47768;
  } else {
  }
  ldv_47767:
  (*(rspq->fsm))((void *)rspq, 4);
  return;
}
}
static void bfa_msgq_rspq_attach(struct bfa_msgq_rspq *rspq , struct bfa_msgq *msgq )
{
  {
  rspq->depth = 128U;
  rspq->msgq = msgq;
  rspq->fsm = (void (*)(void * , int ))(& rspq_sm_stopped);
  rspq_sm_stopped_entry(rspq);
  return;
}
}
static void bfa_msgq_init_rsp(struct bfa_msgq *msgq , struct bfi_mbmsg *mb )
{
  {
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 5);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 5);
  return;
}
}
static void bfa_msgq_init(void *arg )
{
  struct bfa_msgq *msgq ;
  struct bfi_msgq_cfg_req *msgq_cfg ;
  __u16 tmp ;
  __u16 tmp___0 ;
  {
  msgq = (struct bfa_msgq *)arg;
  msgq_cfg = (struct bfi_msgq_cfg_req *)(& msgq->init_mb.msg);
  memset((void *)msgq_cfg, 0, 28UL);
  msgq_cfg->mh.msg_class = 23U;
  msgq_cfg->mh.msg_id = 1U;
  msgq_cfg->mh.mtag.h2i.fn_lpu = 0U;
  msgq_cfg->mh.mtag.i2htok = 0U;
  __bfa_dma_be_addr_set(& msgq_cfg->cmdq.addr, msgq->cmdq.addr.pa);
  tmp = __fswab16((int )msgq->cmdq.depth);
  msgq_cfg->cmdq.q_depth = tmp;
  __bfa_dma_be_addr_set(& msgq_cfg->rspq.addr, msgq->rspq.addr.pa);
  tmp___0 = __fswab16((int )msgq->rspq.depth);
  msgq_cfg->rspq.q_depth = tmp___0;
  bfa_nw_ioc_mbox_queue(msgq->ioc, & msgq->init_mb, (void (*)(void * ))0, (void *)0);
  return;
}
}
static void bfa_msgq_isr(void *cbarg , struct bfi_mbmsg *msg )
{
  struct bfa_msgq *msgq ;
  long tmp ;
  {
  msgq = (struct bfa_msgq *)cbarg;
  switch ((int )msg->mh.msg_id) {
  case 129:
  bfa_msgq_init_rsp(msgq, msg);
  goto ldv_47789;
  case 130:
  bfa_msgq_rspq_pi_update(& msgq->rspq, msg);
  goto ldv_47789;
  case 131:
  bfa_msgq_cmdq_ci_update(& msgq->cmdq, msg);
  goto ldv_47789;
  case 132:
  bfa_msgq_cmdq_copy_req(& msgq->cmdq, msg);
  goto ldv_47789;
  default:
  tmp = ldv__builtin_expect(1L, 0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_msgq.c"),
                         "i" (556), "i" (12UL));
    ldv_47794: ;
    goto ldv_47794;
  } else {
  }
  }
  ldv_47789: ;
  return;
}
}
static void bfa_msgq_notify(void *cbarg , enum bfa_ioc_event event )
{
  struct bfa_msgq *msgq ;
  {
  msgq = (struct bfa_msgq *)cbarg;
  switch ((unsigned int )event) {
  case 1U:
  bfa_wc_init(& msgq->init_wc, & bfa_msgq_init, (void *)msgq);
  bfa_wc_up(& msgq->init_wc);
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 1);
  bfa_wc_up(& msgq->init_wc);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 1);
  bfa_wc_wait(& msgq->init_wc);
  goto ldv_47801;
  case 2U:
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 2);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 2);
  goto ldv_47801;
  case 3U:
  (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 3);
  (*(msgq->rspq.fsm))((void *)(& msgq->rspq), 3);
  goto ldv_47801;
  default: ;
  goto ldv_47801;
  }
  ldv_47801: ;
  return;
}
}
u32 bfa_msgq_meminfo(void)
{
  int __y ;
  int __y___0 ;
  {
  __y = 256;
  __y___0 = 256;
  return ((u32 )(((__y + 8191) / __y) * __y + ((__y___0 + 8191) / __y___0) * __y___0));
}
}
void bfa_msgq_memclaim(struct bfa_msgq *msgq , u8 *kva , u64 pa )
{
  int __y ;
  int __y___0 ;
  {
  msgq->cmdq.addr.kva = (void *)kva;
  msgq->cmdq.addr.pa = pa;
  __y = 256;
  kva = kva + (unsigned long )(((__y + 8191) / __y) * __y);
  __y___0 = 256;
  pa = (u64 )(((__y___0 + 8191) / __y___0) * __y___0) + pa;
  msgq->rspq.addr.kva = (void *)kva;
  msgq->rspq.addr.pa = pa;
  return;
}
}
void bfa_msgq_attach(struct bfa_msgq *msgq , struct bfa_ioc *ioc )
{
  {
  msgq->ioc = ioc;
  bfa_msgq_cmdq_attach(& msgq->cmdq, msgq);
  bfa_msgq_rspq_attach(& msgq->rspq, msgq);
  bfa_nw_ioc_mbox_regisr(msgq->ioc, 23, & bfa_msgq_isr, (void *)msgq);
  msgq->ioc_notify.cbfn = & bfa_msgq_notify;
  msgq->ioc_notify.cbarg = (void *)msgq;
  bfa_nw_ioc_notify_register(msgq->ioc, & msgq->ioc_notify);
  return;
}
}
void bfa_msgq_regisr(struct bfa_msgq *msgq , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                               struct bfi_msgq_mhdr * ) ,
                     void *cbarg )
{
  {
  msgq->rspq.rsphdlr[(unsigned int )mc].cbfn = cbfn;
  msgq->rspq.rsphdlr[(unsigned int )mc].cbarg = cbarg;
  return;
}
}
void bfa_msgq_cmd_post(struct bfa_msgq *msgq , struct bfa_msgq_cmd_entry *cmd )
{
  void (*cbfn)(void * , enum bfa_status ) ;
  void *cbarg ;
  __u16 tmp ;
  {
  tmp = __fswab16((int )(cmd->msg_hdr)->num_entries);
  if ((int )tmp <= ((((int )msgq->cmdq.consumer_index - (int )msgq->cmdq.producer_index) + -1) & ((int )msgq->cmdq.depth + -1))) {
    __cmd_copy(& msgq->cmdq, cmd);
    cbfn = cmd->cbfn;
    cbarg = cmd->cbarg;
    cmd->cbfn = (void (*)(void * , enum bfa_status ))0;
    cmd->cbarg = (void *)0;
    if ((unsigned long )cbfn != (unsigned long )((void (*)(void * , enum bfa_status ))0)) {
      (*cbfn)(cbarg, 0);
    } else {
    }
    (*(msgq->cmdq.fsm))((void *)(& msgq->cmdq), 4);
  } else {
    list_add_tail(& cmd->qe, & msgq->cmdq.pending_q);
  }
  return;
}
}
void bfa_msgq_rsp_copy(struct bfa_msgq *msgq , u8 *buf , size_t buf_len )
{
  struct bfa_msgq_rspq *rspq ;
  size_t len ;
  size_t to_copy ;
  int ci ;
  u8 *src ;
  u8 *dst ;
  {
  rspq = & msgq->rspq;
  len = buf_len;
  ci = (int )rspq->consumer_index;
  src = (u8 *)rspq->addr.kva;
  src = src + (unsigned long )(ci * 64);
  dst = buf;
  goto ldv_47849;
  ldv_47848:
  to_copy = 64UL < len ? 64UL : len;
  memcpy((void *)dst, (void const *)src, to_copy);
  len = len - to_copy;
  dst = dst + 64UL;
  ci = (ci + 1) & ((int )rspq->depth + -1);
  src = (u8 *)rspq->addr.kva;
  src = src + (unsigned long )(ci * 64);
  ldv_47849: ;
  if (len != 0UL) {
    goto ldv_47848;
  } else {
  }
  return;
}
}
bool ldv_queue_work_on_302(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_303(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_304(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_305(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_306(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_312(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_318(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_320(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_322(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_323(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_324(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_325(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_326(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_327(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_328(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
extern void do_gettimeofday(struct timeval * ) ;
extern int del_timer(struct timer_list * ) ;
int ldv_del_timer_376(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_377(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_378(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_381(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_382(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_384(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_386(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_387(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_388(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_390(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_391(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_393(struct timer_list *ldv_func_arg1 ) ;
int ldv_del_timer_396(struct timer_list *ldv_func_arg1 ) ;
int ldv_mod_timer_375(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_379(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_380(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_383(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_385(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_389(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_392(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_394(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_395(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
int ldv_mod_timer_397(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
bool ldv_queue_work_on_348(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_350(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_352(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_351(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_358(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
extern void __const_udelay(unsigned long ) ;
struct sk_buff *ldv_skb_clone_366(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_374(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_368(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_364(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_372(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_373(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_369(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_370(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_371(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
__inline static int bfa_sm_to_state(struct bfa_sm_table const *smt , void (*sm)(void * ,
                                                                                  int ) )
{
  int i ;
  {
  i = 0;
  goto ldv_46557;
  ldv_46556:
  i = i + 1;
  ldv_46557: ;
  if ((unsigned long )(smt + (unsigned long )i)->sm != (unsigned long )((void (*)(void * ,
                                                                                  int ))0) && (unsigned long )((void (*)(void * ,
                                                                                                                          int ))(smt + (unsigned long )i)->sm) != (unsigned long )sm) {
    goto ldv_46556;
  } else {
  }
  return ((int )(smt + (unsigned long )i)->state);
}
}
__inline static void __bfa_alen_set(struct bfi_alen *alen , u32 len , u64 pa )
{
  __u32 tmp ;
  {
  tmp = __fswab32(len);
  alen->al_len = tmp;
  __bfa_dma_be_addr_set(& alen->al_addr, pa);
  return;
}
}
void bfa_nw_ioc_set_ct_hwif(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_set_ct2_hwif(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_ct2_poweron(struct bfa_ioc *ioc ) ;
bool bfa_nw_ioc_is_operational(struct bfa_ioc *ioc ) ;
bool bfa_nw_ioc_sem_get(void *sem_reg ) ;
void bfa_nw_ioc_sem_release(void *sem_reg ) ;
void bfa_nw_ioc_hw_sem_release(struct bfa_ioc *ioc ) ;
void bfa_nw_ioc_fwver_get(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr ) ;
bool bfa_nw_ioc_fwver_cmp(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr ) ;
u32 *bfa_cb_image_get_chunk(enum bfi_asic_gen asic_gen , u32 off ) ;
u32 bfa_cb_image_get_size(enum bfi_asic_gen asic_gen ) ;
static bool bfa_nw_auto_recover = 1;
static void bfa_ioc_hw_sem_init(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hw_sem_get(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hw_sem_get_cancel(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hwinit(struct bfa_ioc *ioc , bool force ) ;
static void bfa_ioc_poll_fwinit(struct bfa_ioc *ioc ) ;
static void bfa_ioc_send_enable(struct bfa_ioc *ioc ) ;
static void bfa_ioc_send_disable(struct bfa_ioc *ioc ) ;
static void bfa_ioc_send_getattr(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hb_monitor(struct bfa_ioc *ioc ) ;
static void bfa_ioc_hb_stop(struct bfa_ioc *ioc ) ;
static void bfa_ioc_reset(struct bfa_ioc *ioc , bool force ) ;
static void bfa_ioc_mbox_poll(struct bfa_ioc *ioc ) ;
static void bfa_ioc_mbox_flush(struct bfa_ioc *ioc ) ;
static void bfa_ioc_recover(struct bfa_ioc *ioc ) ;
static void bfa_ioc_event_notify(struct bfa_ioc *ioc , enum bfa_ioc_event event ) ;
static void bfa_ioc_disable_comp(struct bfa_ioc *ioc ) ;
static void bfa_ioc_lpu_stop(struct bfa_ioc *ioc ) ;
static void bfa_nw_ioc_debug_save_ftrc(struct bfa_ioc *ioc ) ;
static void bfa_ioc_fail_notify(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_enabled(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_disabled(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_failed(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_hwfailed(struct bfa_ioc *ioc ) ;
static void bfa_ioc_pf_fwmismatch(struct bfa_ioc *ioc ) ;
static enum bfa_status bfa_ioc_boot(struct bfa_ioc *ioc , enum bfi_fwboot_type boot_type ,
                                    u32 boot_env ) ;
static u32 bfa_ioc_smem_pgnum(struct bfa_ioc *ioc , u32 fmaddr ) ;
static void bfa_ioc_get_adapter_serial_num(struct bfa_ioc *ioc , char *serial_num ) ;
static void bfa_ioc_get_adapter_fw_ver(struct bfa_ioc *ioc , char *fw_ver ) ;
static void bfa_ioc_get_pci_chip_rev(struct bfa_ioc *ioc , char *chip_rev ) ;
static void bfa_ioc_get_adapter_optrom_ver(struct bfa_ioc *ioc , char *optrom_ver ) ;
static void bfa_ioc_get_adapter_manufacturer(struct bfa_ioc *ioc , char *manufacturer ) ;
static void bfa_ioc_get_adapter_model(struct bfa_ioc *ioc , char *model ) ;
static u64 bfa_ioc_get_pwwn(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_uninit(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_uninit_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_reset(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_reset_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_enabling(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_enabling_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_getattr(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_getattr_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_op(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_op_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_fail_retry(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_fail_retry_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_fail(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_fail_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_disabling(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_disabling_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_disabled(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_disabled_entry(struct bfa_ioc *ioc ) ;
static void bfa_ioc_sm_hwfail(struct bfa_ioc *ioc , enum ioc_event event ) ;
static void bfa_ioc_sm_hwfail_entry(struct bfa_ioc *ioc ) ;
static struct bfa_sm_table ioc_sm_table[10U] =
  { {(void (*)(void * , int ))(& bfa_ioc_sm_uninit), 1, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_reset), 2, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_enabling), 12, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_getattr), 5, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_op), 6, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_fail_retry), 7, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_fail), 8, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_disabling), 9, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_disabled), 10, 0},
        {(void (*)(void * , int ))(& bfa_ioc_sm_hwfail), 13, 0}};
static void bfa_iocpf_enable(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_disable(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_fail(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_initfail(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_getattrfail(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_stop(struct bfa_ioc *ioc ) ;
static void bfa_iocpf_sm_reset(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_reset_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_fwcheck(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_fwcheck_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_mismatch(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_mismatch_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_semwait(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_semwait_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_hwinit(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_hwinit_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_enabling(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_enabling_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_ready(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_ready_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_initfail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_initfail_sync_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_initfail(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_initfail_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_fail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_fail_sync_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_fail(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_fail_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_disabling(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_disabling_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_disabling_sync(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_disabling_sync_entry(struct bfa_iocpf *iocpf ) ;
static void bfa_iocpf_sm_disabled(struct bfa_iocpf *iocpf , enum iocpf_event event ) ;
static void bfa_iocpf_sm_disabled_entry(struct bfa_iocpf *iocpf ) ;
static struct bfa_sm_table iocpf_sm_table[14U] =
  { {(void (*)(void * , int ))(& bfa_iocpf_sm_reset), 1, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_fwcheck), 9, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_mismatch), 9, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_semwait), 2, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_hwinit), 3, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_enabling), 3, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_ready), 4, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_initfail_sync), 5, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_initfail), 5, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_fail_sync), 6, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_fail), 6, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_disabling), 7, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_disabling_sync), 7, 0},
        {(void (*)(void * , int ))(& bfa_iocpf_sm_disabled), 8, 0}};
static void bfa_ioc_sm_uninit_entry(struct bfa_ioc *ioc )
{
  {
  return;
}
}
static void bfa_ioc_sm_uninit(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 1U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_reset);
  bfa_ioc_sm_reset_entry(ioc);
  goto ldv_47838;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         229, (unsigned int )event);
  }
  ldv_47838: ;
  return;
}
}
static void bfa_ioc_sm_reset_entry(struct bfa_ioc *ioc )
{
  {
  ioc->iocpf.fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(& ioc->iocpf);
  return;
}
}
static void bfa_ioc_sm_reset(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_enabling);
  bfa_ioc_sm_enabling_entry(ioc);
  goto ldv_47848;
  case 3U:
  bfa_ioc_disable_comp(ioc);
  goto ldv_47848;
  case 4U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  goto ldv_47848;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         258, (unsigned int )event);
  }
  ldv_47848: ;
  return;
}
}
static void bfa_ioc_sm_enabling_entry(struct bfa_ioc *ioc )
{
  {
  bfa_iocpf_enable(ioc);
  return;
}
}
static void bfa_ioc_sm_enabling(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 5U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_getattr);
  bfa_ioc_sm_getattr_entry(ioc);
  goto ldv_47860;
  case 8U: ;
  case 10U:
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_fail);
  bfa_ioc_sm_fail_entry(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_initfail(ioc);
  } else {
  }
  goto ldv_47860;
  case 12U:
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_hwfail);
  bfa_ioc_sm_hwfail_entry(ioc);
  goto ldv_47860;
  case 3U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47860;
  case 4U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47860;
  case 2U: ;
  goto ldv_47860;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         306, (unsigned int )event);
  }
  ldv_47860: ;
  return;
}
}
static void bfa_ioc_sm_getattr_entry(struct bfa_ioc *ioc )
{
  unsigned long tmp ;
  {
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_375(& ioc->ioc_timer, tmp + (unsigned long )jiffies);
  bfa_ioc_send_getattr(ioc);
  return;
}
}
static void bfa_ioc_sm_getattr(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 6U:
  ldv_del_timer_376(& ioc->ioc_timer);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_op);
  bfa_ioc_sm_op_entry(ioc);
  goto ldv_47876;
  case 8U: ;
  case 10U:
  ldv_del_timer_377(& ioc->ioc_timer);
  case 11U:
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_fail);
  bfa_ioc_sm_fail_entry(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_getattrfail(ioc);
  } else {
  }
  goto ldv_47876;
  case 3U:
  ldv_del_timer_378(& ioc->ioc_timer);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47876;
  case 2U: ;
  goto ldv_47876;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         349, (unsigned int )event);
  }
  ldv_47876: ;
  return;
}
}
static void bfa_ioc_sm_op_entry(struct bfa_ioc *ioc )
{
  {
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 0);
  bfa_ioc_event_notify(ioc, 1);
  bfa_ioc_hb_monitor(ioc);
  return;
}
}
static void bfa_ioc_sm_op(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U: ;
  goto ldv_47891;
  case 3U:
  bfa_ioc_hb_stop(ioc);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47891;
  case 8U: ;
  case 10U:
  bfa_ioc_hb_stop(ioc);
  case 9U: ;
  if ((int )ioc->iocpf.auto_recover) {
    ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_fail_retry);
    bfa_ioc_sm_fail_retry_entry(ioc);
  } else {
    ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_fail);
    bfa_ioc_sm_fail_entry(ioc);
  }
  bfa_ioc_fail_notify(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_fail(ioc);
  } else {
  }
  goto ldv_47891;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         390, (unsigned int )event);
  }
  ldv_47891: ;
  return;
}
}
static void bfa_ioc_sm_disabling_entry(struct bfa_ioc *ioc )
{
  {
  bfa_iocpf_disable(ioc);
  return;
}
}
static void bfa_ioc_sm_disabling(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 7U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_disabled);
  bfa_ioc_sm_disabled_entry(ioc);
  goto ldv_47905;
  case 10U:
  bfa_iocpf_fail(ioc);
  goto ldv_47905;
  case 12U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_hwfail);
  bfa_ioc_sm_hwfail_entry(ioc);
  bfa_ioc_disable_comp(ioc);
  goto ldv_47905;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         424, (unsigned int )event);
  }
  ldv_47905: ;
  return;
}
}
static void bfa_ioc_sm_disabled_entry(struct bfa_ioc *ioc )
{
  {
  bfa_ioc_disable_comp(ioc);
  return;
}
}
static void bfa_ioc_sm_disabled(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_enabling);
  bfa_ioc_sm_enabling_entry(ioc);
  goto ldv_47917;
  case 3U:
  (*((ioc->cbfn)->disable_cbfn))((void *)ioc->bfa);
  goto ldv_47917;
  case 4U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47917;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         453, (unsigned int )event);
  }
  ldv_47917: ;
  return;
}
}
static void bfa_ioc_sm_fail_retry_entry(struct bfa_ioc *ioc )
{
  {
  return;
}
}
static void bfa_ioc_sm_fail_retry(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 5U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_getattr);
  bfa_ioc_sm_getattr_entry(ioc);
  goto ldv_47929;
  case 8U: ;
  case 10U:
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_fail);
  bfa_ioc_sm_fail_entry(ioc);
  if ((unsigned int )event != 8U) {
    bfa_iocpf_initfail(ioc);
  } else {
  }
  goto ldv_47929;
  case 12U:
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_hwfail);
  bfa_ioc_sm_hwfail_entry(ioc);
  goto ldv_47929;
  case 2U: ;
  goto ldv_47929;
  case 3U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47929;
  case 4U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47929;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         500, (unsigned int )event);
  }
  ldv_47929: ;
  return;
}
}
static void bfa_ioc_sm_fail_entry(struct bfa_ioc *ioc )
{
  {
  return;
}
}
static void bfa_ioc_sm_fail(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  goto ldv_47945;
  case 3U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_disabling);
  bfa_ioc_sm_disabling_entry(ioc);
  goto ldv_47945;
  case 4U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  bfa_iocpf_stop(ioc);
  goto ldv_47945;
  case 10U: ;
  goto ldv_47945;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         532, (unsigned int )event);
  }
  ldv_47945: ;
  return;
}
}
static void bfa_ioc_sm_hwfail_entry(struct bfa_ioc *ioc )
{
  {
  return;
}
}
static void bfa_ioc_sm_hwfail(struct bfa_ioc *ioc , enum ioc_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  goto ldv_47958;
  case 3U:
  (*((ioc->cbfn)->disable_cbfn))((void *)ioc->bfa);
  goto ldv_47958;
  case 4U:
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  goto ldv_47958;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         560, (unsigned int )event);
  }
  ldv_47958: ;
  return;
}
}
static void bfa_iocpf_sm_reset_entry(struct bfa_iocpf *iocpf )
{
  {
  iocpf->fw_mismatch_notified = 0;
  iocpf->auto_recover = bfa_nw_auto_recover;
  return;
}
}
static void bfa_iocpf_sm_reset(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  {
  switch ((unsigned int )event) {
  case 1U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fwcheck);
  bfa_iocpf_sm_fwcheck_entry(iocpf);
  goto ldv_47970;
  case 3U: ;
  goto ldv_47970;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         587, (unsigned int )event);
  }
  ldv_47970: ;
  return;
}
}
static void bfa_iocpf_sm_fwcheck_entry(struct bfa_iocpf *iocpf )
{
  {
  bfa_ioc_hw_sem_init(iocpf->ioc);
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_fwcheck(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  unsigned long tmp ;
  bool tmp___0 ;
  bool tmp___1 ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U:
  tmp___1 = (*((ioc->ioc_hwif)->ioc_firmware_lock))(ioc);
  if ((int )tmp___1) {
    tmp___0 = (*((ioc->ioc_hwif)->ioc_sync_start))(ioc);
    if ((int )tmp___0) {
      (*((ioc->ioc_hwif)->ioc_sync_join))(ioc);
      iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_hwinit);
      bfa_iocpf_sm_hwinit_entry(iocpf);
    } else {
      (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
      bfa_nw_ioc_hw_sem_release(ioc);
      tmp = msecs_to_jiffies(500U);
      ldv_mod_timer_379(& ioc->sem_timer, tmp + (unsigned long )jiffies);
    }
  } else {
    bfa_nw_ioc_hw_sem_release(ioc);
    iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_mismatch);
    bfa_iocpf_sm_mismatch_entry(iocpf);
  }
  goto ldv_47982;
  case 12U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_47982;
  case 2U:
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  bfa_ioc_pf_disabled(ioc);
  goto ldv_47982;
  case 3U:
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_47982;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         640, (unsigned int )event);
  }
  ldv_47982: ;
  return;
}
}
static void bfa_iocpf_sm_mismatch_entry(struct bfa_iocpf *iocpf )
{
  unsigned long tmp ;
  {
  if (! iocpf->fw_mismatch_notified) {
    bfa_ioc_pf_fwmismatch(iocpf->ioc);
  } else {
  }
  iocpf->fw_mismatch_notified = 1;
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_380(& (iocpf->ioc)->iocpf_timer, tmp + (unsigned long )jiffies);
  return;
}
}
static void bfa_iocpf_sm_mismatch(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 11U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fwcheck);
  bfa_iocpf_sm_fwcheck_entry(iocpf);
  goto ldv_47996;
  case 2U:
  ldv_del_timer_381(& ioc->iocpf_timer);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  bfa_ioc_pf_disabled(ioc);
  goto ldv_47996;
  case 3U:
  ldv_del_timer_382(& ioc->iocpf_timer);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_47996;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         680, (unsigned int )event);
  }
  ldv_47996: ;
  return;
}
}
static void bfa_iocpf_sm_semwait_entry(struct bfa_iocpf *iocpf )
{
  {
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_semwait(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  unsigned long tmp ;
  bool tmp___0 ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U:
  tmp___0 = (*((ioc->ioc_hwif)->ioc_sync_complete))(ioc);
  if ((int )tmp___0) {
    (*((ioc->ioc_hwif)->ioc_sync_join))(ioc);
    iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_hwinit);
    bfa_iocpf_sm_hwinit_entry(iocpf);
  } else {
    bfa_nw_ioc_hw_sem_release(ioc);
    tmp = msecs_to_jiffies(500U);
    ldv_mod_timer_383(& ioc->sem_timer, tmp + (unsigned long )jiffies);
  }
  goto ldv_48009;
  case 12U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48009;
  case 2U:
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48009;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         720, (unsigned int )event);
  }
  ldv_48009: ;
  return;
}
}
static void bfa_iocpf_sm_hwinit_entry(struct bfa_iocpf *iocpf )
{
  {
  iocpf->poll_time = 0U;
  bfa_ioc_reset(iocpf->ioc, 0);
  return;
}
}
static void bfa_iocpf_sm_hwinit(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 4U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_enabling);
  bfa_iocpf_sm_enabling_entry(iocpf);
  goto ldv_48022;
  case 11U:
  bfa_nw_ioc_hw_sem_release(ioc);
  bfa_ioc_pf_failed(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_initfail_sync);
  bfa_iocpf_sm_initfail_sync_entry(iocpf);
  goto ldv_48022;
  case 2U:
  ldv_del_timer_384(& ioc->iocpf_timer);
  (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48022;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         758, (unsigned int )event);
  }
  ldv_48022: ;
  return;
}
}
static void bfa_iocpf_sm_enabling_entry(struct bfa_iocpf *iocpf )
{
  unsigned long tmp ;
  {
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_385(& (iocpf->ioc)->iocpf_timer, tmp + (unsigned long )jiffies);
  (*(((iocpf->ioc)->cbfn)->reset_cbfn))((void *)(iocpf->ioc)->bfa);
  bfa_ioc_send_enable(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_enabling(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 5U:
  ldv_del_timer_386(& ioc->iocpf_timer);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_ready);
  bfa_iocpf_sm_ready_entry(iocpf);
  goto ldv_48035;
  case 8U:
  ldv_del_timer_387(& ioc->iocpf_timer);
  case 11U:
  bfa_nw_ioc_hw_sem_release(ioc);
  if ((unsigned int )event == 11U) {
    bfa_ioc_pf_failed(ioc);
  } else {
  }
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_initfail_sync);
  bfa_iocpf_sm_initfail_sync_entry(iocpf);
  goto ldv_48035;
  case 2U:
  ldv_del_timer_388(& ioc->iocpf_timer);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabling);
  bfa_iocpf_sm_disabling_entry(iocpf);
  goto ldv_48035;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         808, (unsigned int )event);
  }
  ldv_48035: ;
  return;
}
}
static void bfa_iocpf_sm_ready_entry(struct bfa_iocpf *iocpf )
{
  {
  bfa_ioc_pf_enabled(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_ready(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabling);
  bfa_iocpf_sm_disabling_entry(iocpf);
  goto ldv_48048;
  case 9U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_initfail_sync);
  bfa_iocpf_sm_initfail_sync_entry(iocpf);
  goto ldv_48048;
  case 7U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fail_sync);
  bfa_iocpf_sm_fail_sync_entry(iocpf);
  goto ldv_48048;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         835, (unsigned int )event);
  }
  ldv_48048: ;
  return;
}
}
static void bfa_iocpf_sm_disabling_entry(struct bfa_iocpf *iocpf )
{
  unsigned long tmp ;
  {
  tmp = msecs_to_jiffies(3000U);
  ldv_mod_timer_389(& (iocpf->ioc)->iocpf_timer, tmp + (unsigned long )jiffies);
  bfa_ioc_send_disable(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_disabling(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 6U:
  ldv_del_timer_390(& ioc->iocpf_timer);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48061;
  case 7U:
  ldv_del_timer_391(& ioc->iocpf_timer);
  case 11U:
  (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 8);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48061;
  case 5U: ;
  goto ldv_48061;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         874, (unsigned int )event);
  }
  ldv_48061: ;
  return;
}
}
static void bfa_iocpf_sm_disabling_sync_entry(struct bfa_iocpf *iocpf )
{
  {
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_disabling_sync(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U:
  (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48075;
  case 12U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48075;
  case 7U: ;
  goto ldv_48075;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         906, (unsigned int )event);
  }
  ldv_48075: ;
  return;
}
}
static void bfa_iocpf_sm_disabled_entry(struct bfa_iocpf *iocpf )
{
  {
  bfa_ioc_mbox_flush(iocpf->ioc);
  bfa_ioc_pf_disabled(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_disabled(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 1U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_semwait);
  bfa_iocpf_sm_semwait_entry(iocpf);
  goto ldv_48088;
  case 3U:
  (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_48088;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         934, (unsigned int )event);
  }
  ldv_48088: ;
  return;
}
}
static void bfa_iocpf_sm_initfail_sync_entry(struct bfa_iocpf *iocpf )
{
  {
  bfa_nw_ioc_debug_save_ftrc(iocpf->ioc);
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_initfail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U:
  (*((ioc->ioc_hwif)->ioc_notify_fail))(ioc);
  (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
  (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 8);
  bfa_nw_ioc_hw_sem_release(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_initfail);
  bfa_iocpf_sm_initfail_entry(iocpf);
  goto ldv_48100;
  case 12U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48100;
  case 2U:
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48100;
  case 3U:
  bfa_ioc_hw_sem_get_cancel(ioc);
  (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_48100;
  case 7U: ;
  goto ldv_48100;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         980, (unsigned int )event);
  }
  ldv_48100: ;
  return;
}
}
static void bfa_iocpf_sm_initfail_entry(struct bfa_iocpf *iocpf )
{
  {
  return;
}
}
static void bfa_iocpf_sm_initfail(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 2U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48115;
  case 3U:
  (*((ioc->ioc_hwif)->ioc_firmware_unlock))(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_reset);
  bfa_iocpf_sm_reset_entry(iocpf);
  goto ldv_48115;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         1006, (unsigned int )event);
  }
  ldv_48115: ;
  return;
}
}
static void bfa_iocpf_sm_fail_sync_entry(struct bfa_iocpf *iocpf )
{
  {
  bfa_ioc_lpu_stop(iocpf->ioc);
  bfa_ioc_mbox_flush(iocpf->ioc);
  bfa_ioc_hw_sem_get(iocpf->ioc);
  return;
}
}
static void bfa_iocpf_sm_fail_sync(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  struct bfa_ioc *ioc ;
  bool tmp ;
  {
  ioc = iocpf->ioc;
  switch ((unsigned int )event) {
  case 10U:
  (*((ioc->ioc_hwif)->ioc_sync_ack))(ioc);
  (*((ioc->ioc_hwif)->ioc_notify_fail))(ioc);
  if (! iocpf->auto_recover) {
    (*((ioc->ioc_hwif)->ioc_sync_leave))(ioc);
    (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 8);
    bfa_nw_ioc_hw_sem_release(ioc);
    iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fail);
    bfa_iocpf_sm_fail_entry(iocpf);
  } else {
    tmp = (*((ioc->ioc_hwif)->ioc_sync_complete))(ioc);
    if ((int )tmp) {
      iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_hwinit);
      bfa_iocpf_sm_hwinit_entry(iocpf);
    } else {
      bfa_nw_ioc_hw_sem_release(ioc);
      iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_semwait);
      bfa_iocpf_sm_semwait_entry(iocpf);
    }
  }
  goto ldv_48127;
  case 12U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_fail);
  bfa_iocpf_sm_fail_entry(iocpf);
  bfa_ioc_pf_hwfailed(ioc);
  goto ldv_48127;
  case 2U:
  bfa_ioc_hw_sem_get_cancel(ioc);
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabling_sync);
  bfa_iocpf_sm_disabling_sync_entry(iocpf);
  goto ldv_48127;
  case 7U: ;
  goto ldv_48127;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         1064, (unsigned int )event);
  }
  ldv_48127: ;
  return;
}
}
static void bfa_iocpf_sm_fail_entry(struct bfa_iocpf *iocpf )
{
  {
  return;
}
}
static void bfa_iocpf_sm_fail(struct bfa_iocpf *iocpf , enum iocpf_event event )
{
  {
  switch ((unsigned int )event) {
  case 2U:
  iocpf->fsm = (void (*)(void * , int ))(& bfa_iocpf_sm_disabled);
  bfa_iocpf_sm_disabled_entry(iocpf);
  goto ldv_48140;
  default:
  printk("\vSM Assertion failure: %s: %d: event = %d\n", (char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
         1083, (unsigned int )event);
  }
  ldv_48140: ;
  return;
}
}
static void bfa_ioc_event_notify(struct bfa_ioc *ioc , enum bfa_ioc_event event )
{
  struct bfa_ioc_notify *notify ;
  struct list_head const *__mptr ;
  struct list_head const *__mptr___0 ;
  {
  __mptr = (struct list_head const *)ioc->notify_q.next;
  notify = (struct bfa_ioc_notify *)__mptr;
  goto ldv_48152;
  ldv_48151:
  (*(notify->cbfn))(notify->cbarg, event);
  __mptr___0 = (struct list_head const *)notify->qe.next;
  notify = (struct bfa_ioc_notify *)__mptr___0;
  ldv_48152: ;
  if ((unsigned long )(& notify->qe) != (unsigned long )(& ioc->notify_q)) {
    goto ldv_48151;
  } else {
  }
  return;
}
}
static void bfa_ioc_disable_comp(struct bfa_ioc *ioc )
{
  {
  (*((ioc->cbfn)->disable_cbfn))((void *)ioc->bfa);
  bfa_ioc_event_notify(ioc, 2);
  return;
}
}
bool bfa_nw_ioc_sem_get(void *sem_reg )
{
  u32 r32 ;
  int cnt ;
  {
  cnt = 0;
  r32 = readl((void const volatile *)sem_reg);
  goto ldv_48163;
  ldv_48162:
  cnt = cnt + 1;
  __const_udelay(8590UL);
  r32 = readl((void const volatile *)sem_reg);
  ldv_48163: ;
  if ((int )r32 & 1 && cnt <= 2999) {
    goto ldv_48162;
  } else {
  }
  if ((r32 & 1U) == 0U) {
    return (1);
  } else {
  }
  return (0);
}
}
void bfa_nw_ioc_sem_release(void *sem_reg )
{
  {
  readl((void const volatile *)sem_reg);
  writel(1U, (void volatile *)sem_reg);
  return;
}
}
static void bfa_ioc_fwver_clear(struct bfa_ioc *ioc )
{
  u32 pgnum ;
  u32 pgoff ;
  u32 loff ;
  int i ;
  {
  loff = 0U;
  pgnum = ioc->ioc_regs.smem_pg0 + (loff >> 15);
  pgoff = loff & 32767U;
  writel(pgnum, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  i = 0;
  goto ldv_48176;
  ldv_48175:
  writel(0U, (void volatile *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  loff = loff + 4U;
  i = i + 1;
  ldv_48176: ;
  if ((unsigned int )i <= 11U) {
    goto ldv_48175;
  } else {
  }
  return;
}
}
static void bfa_ioc_hw_sem_init(struct bfa_ioc *ioc )
{
  struct bfi_ioc_image_hdr fwhdr ;
  u32 fwstate ;
  u32 r32 ;
  enum bfi_ioc_state tmp ;
  __u32 tmp___0 ;
  {
  r32 = readl((void const volatile *)ioc->ioc_regs.ioc_init_sem_reg);
  goto ldv_48185;
  ldv_48184:
  __const_udelay(85900UL);
  r32 = readl((void const volatile *)ioc->ioc_regs.ioc_init_sem_reg);
  ldv_48185: ;
  if ((int )r32 & 1) {
    goto ldv_48184;
  } else {
  }
  tmp = (*((ioc->ioc_hwif)->ioc_get_fwstate))(ioc);
  fwstate = (u32 )tmp;
  if (fwstate == 0U) {
    writel(1U, (void volatile *)ioc->ioc_regs.ioc_init_sem_reg);
    return;
  } else {
  }
  bfa_nw_ioc_fwver_get(ioc, & fwhdr);
  tmp___0 = __fswab32(fwhdr.exec);
  if (tmp___0 == 0U) {
    writel(1U, (void volatile *)ioc->ioc_regs.ioc_init_sem_reg);
    return;
  } else {
  }
  bfa_ioc_fwver_clear(ioc);
  (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 0);
  (*((ioc->ioc_hwif)->ioc_set_alt_fwstate))(ioc, 0);
  readl((void const volatile *)ioc->ioc_regs.ioc_sem_reg);
  writel(1U, (void volatile *)ioc->ioc_regs.ioc_sem_reg);
  writel(1U, (void volatile *)ioc->ioc_regs.ioc_init_sem_reg);
  return;
}
}
static void bfa_ioc_hw_sem_get(struct bfa_ioc *ioc )
{
  u32 r32 ;
  unsigned long tmp ;
  {
  r32 = readl((void const volatile *)ioc->ioc_regs.ioc_sem_reg);
  if (r32 == 4294967295U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 12);
    return;
  } else {
  }
  if ((r32 & 1U) == 0U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 10);
    return;
  } else {
  }
  tmp = msecs_to_jiffies(500U);
  ldv_mod_timer_392(& ioc->sem_timer, tmp + (unsigned long )jiffies);
  return;
}
}
void bfa_nw_ioc_hw_sem_release(struct bfa_ioc *ioc )
{
  {
  writel(1U, (void volatile *)ioc->ioc_regs.ioc_sem_reg);
  return;
}
}
static void bfa_ioc_hw_sem_get_cancel(struct bfa_ioc *ioc )
{
  {
  ldv_del_timer_393(& ioc->sem_timer);
  return;
}
}
static void bfa_ioc_lmem_init(struct bfa_ioc *ioc )
{
  u32 pss_ctl ;
  int i ;
  long tmp ;
  {
  pss_ctl = readl((void const volatile *)ioc->ioc_regs.pss_ctl_reg);
  pss_ctl = pss_ctl & 4294966783U;
  pss_ctl = pss_ctl | 256U;
  pss_ctl = pss_ctl | 196608U;
  writel(pss_ctl, (void volatile *)ioc->ioc_regs.pss_ctl_reg);
  i = 0;
  ldv_48202:
  pss_ctl = readl((void const volatile *)ioc->ioc_regs.pss_ctl_reg);
  i = i + 1;
  if ((pss_ctl & 4096U) == 0U && i <= 9999) {
    goto ldv_48202;
  } else {
  }
  tmp = ldv__builtin_expect((pss_ctl & 4096U) == 0U, 0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (1258), "i" (12UL));
    ldv_48204: ;
    goto ldv_48204;
  } else {
  }
  pss_ctl = pss_ctl & 4294962943U;
  writel(pss_ctl, (void volatile *)ioc->ioc_regs.pss_ctl_reg);
  return;
}
}
static void bfa_ioc_lpu_start(struct bfa_ioc *ioc )
{
  u32 pss_ctl ;
  {
  pss_ctl = readl((void const volatile *)ioc->ioc_regs.pss_ctl_reg);
  pss_ctl = pss_ctl & 4294967294U;
  writel(pss_ctl, (void volatile *)ioc->ioc_regs.pss_ctl_reg);
  return;
}
}
static void bfa_ioc_lpu_stop(struct bfa_ioc *ioc )
{
  u32 pss_ctl ;
  {
  pss_ctl = readl((void const volatile *)ioc->ioc_regs.pss_ctl_reg);
  pss_ctl = pss_ctl | 3U;
  writel(pss_ctl, (void volatile *)ioc->ioc_regs.pss_ctl_reg);
  return;
}
}
void bfa_nw_ioc_fwver_get(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr )
{
  u32 pgnum ;
  u32 loff ;
  int i ;
  u32 *fwsig ;
  unsigned int tmp ;
  __u32 tmp___0 ;
  {
  loff = 0U;
  fwsig = (u32 *)fwhdr;
  pgnum = bfa_ioc_smem_pgnum(ioc, loff);
  writel(pgnum, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  i = 0;
  goto ldv_48222;
  ldv_48221:
  tmp = readl((void const volatile *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  tmp___0 = __fswab32(tmp);
  *(fwsig + (unsigned long )i) = tmp___0;
  loff = loff + 4U;
  i = i + 1;
  ldv_48222: ;
  if ((unsigned int )i <= 11U) {
    goto ldv_48221;
  } else {
  }
  return;
}
}
static bool bfa_ioc_fwver_md5_check(struct bfi_ioc_image_hdr *fwhdr_1 , struct bfi_ioc_image_hdr *fwhdr_2 )
{
  int i ;
  {
  i = 0;
  goto ldv_48230;
  ldv_48229: ;
  if (fwhdr_1->md5sum[i] != fwhdr_2->md5sum[i]) {
    return (0);
  } else {
  }
  i = i + 1;
  ldv_48230: ;
  if (i <= 3) {
    goto ldv_48229;
  } else {
  }
  return (1);
}
}
static bool bfa_ioc_fw_ver_compatible(struct bfi_ioc_image_hdr *drv_fwhdr , struct bfi_ioc_image_hdr *fwhdr_to_cmp )
{
  bool tmp ;
  {
  if (drv_fwhdr->signature != fwhdr_to_cmp->signature) {
    return (0);
  } else {
  }
  if ((int )drv_fwhdr->fwver.major != (int )fwhdr_to_cmp->fwver.major) {
    return (0);
  } else {
  }
  if ((int )drv_fwhdr->fwver.minor != (int )fwhdr_to_cmp->fwver.minor) {
    return (0);
  } else {
  }
  if ((int )drv_fwhdr->fwver.maint != (int )fwhdr_to_cmp->fwver.maint) {
    return (0);
  } else {
  }
  if (((int )drv_fwhdr->fwver.patch == (int )fwhdr_to_cmp->fwver.patch && (int )drv_fwhdr->fwver.phase == (int )fwhdr_to_cmp->fwver.phase) && (int )drv_fwhdr->fwver.build == (int )fwhdr_to_cmp->fwver.build) {
    tmp = bfa_ioc_fwver_md5_check(drv_fwhdr, fwhdr_to_cmp);
    return (tmp);
  } else {
  }
  return (1);
}
}
static bool bfa_ioc_flash_fwver_valid(struct bfi_ioc_image_hdr *flash_fwhdr )
{
  {
  if ((unsigned int )flash_fwhdr->fwver.major == 0U || (unsigned int )flash_fwhdr->fwver.major == 255U) {
    return (0);
  } else {
  }
  return (1);
}
}
static bool fwhdr_is_ga(struct bfi_ioc_image_hdr *fwhdr )
{
  {
  if ((unsigned int )fwhdr->fwver.phase == 0U && (unsigned int )fwhdr->fwver.build == 0U) {
    return (0);
  } else {
  }
  return (1);
}
}
static enum bfi_ioc_img_ver_cmp bfa_ioc_fw_ver_patch_cmp(struct bfi_ioc_image_hdr *base_fwhdr ,
                                                         struct bfi_ioc_image_hdr *fwhdr_to_cmp )
{
  bool tmp ;
  int tmp___0 ;
  bool tmp___1 ;
  bool tmp___2 ;
  bool tmp___3 ;
  {
  tmp = bfa_ioc_fw_ver_compatible(base_fwhdr, fwhdr_to_cmp);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (0);
  } else {
  }
  if ((int )fwhdr_to_cmp->fwver.patch > (int )base_fwhdr->fwver.patch) {
    return (3);
  } else
  if ((int )fwhdr_to_cmp->fwver.patch < (int )base_fwhdr->fwver.patch) {
    return (1);
  } else {
  }
  tmp___3 = fwhdr_is_ga(base_fwhdr);
  if ((int )tmp___3) {
    tmp___1 = fwhdr_is_ga(fwhdr_to_cmp);
    if ((int )tmp___1) {
      return (2);
    } else {
      return (1);
    }
  } else {
    tmp___2 = fwhdr_is_ga(fwhdr_to_cmp);
    if ((int )tmp___2) {
      return (3);
    } else {
    }
  }
  if ((int )fwhdr_to_cmp->fwver.phase > (int )base_fwhdr->fwver.phase) {
    return (3);
  } else
  if ((int )fwhdr_to_cmp->fwver.phase < (int )base_fwhdr->fwver.phase) {
    return (1);
  } else {
  }
  if ((int )fwhdr_to_cmp->fwver.build > (int )base_fwhdr->fwver.build) {
    return (3);
  } else
  if ((int )fwhdr_to_cmp->fwver.build < (int )base_fwhdr->fwver.build) {
    return (1);
  } else {
  }
  return (2);
}
}
static void bfa_flash_set_cmd(void *pci_bar , u8 wr_cnt , u8 rd_cnt , u8 ad_cnt ,
                              u8 op )
{
  union bfa_flash_cmd_reg cmd ;
  {
  cmd.i = 0U;
  cmd.r.act = 1U;
  cmd.r.write_cnt = (unsigned short )wr_cnt;
  cmd.r.read_cnt = (unsigned short )rd_cnt;
  cmd.r.addr_cnt = ad_cnt;
  cmd.r.cmd = op;
  writel(cmd.i, (void volatile *)pci_bar + 118784U);
  return;
}
}
static void bfa_flash_set_addr(void *pci_bar , u32 address )
{
  union bfa_flash_addr_reg addr ;
  {
  addr.r.addr = address & 16777215U;
  addr.r.dummy = 0U;
  writel(addr.i, (void volatile *)pci_bar + 118788U);
  return;
}
}
static int bfa_flash_cmd_act_check(void *pci_bar )
{
  union bfa_flash_cmd_reg cmd ;
  {
  cmd.i = readl((void const volatile *)pci_bar + 118784U);
  if ((unsigned int )*((unsigned char *)(& cmd) + 3UL) != 0U) {
    return (-5);
  } else {
  }
  return (0);
}
}
static u32 bfa_flash_fifo_flush(void *pci_bar )
{
  u32 i ;
  u32 t ;
  union bfa_flash_dev_status_reg dev_status ;
  {
  dev_status.i = readl((void const volatile *)pci_bar + 118804U);
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) == 0U) {
    return (0U);
  } else {
  }
  i = 0U;
  goto ldv_48313;
  ldv_48312:
  t = readl((void const volatile *)pci_bar + 118800U);
  i = i + 1U;
  ldv_48313: ;
  if ((u32 )dev_status.r.fifo_cnt > i) {
    goto ldv_48312;
  } else {
  }
  i = 0U;
  goto ldv_48317;
  ldv_48316:
  dev_status.i = readl((void const volatile *)pci_bar + 118804U);
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) == 0U) {
    goto ldv_48315;
  } else {
  }
  i = i + 1U;
  ldv_48317: ;
  if (i <= 9999U) {
    goto ldv_48316;
  } else {
  }
  ldv_48315: ;
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) != 0U) {
    return (4294967290U);
  } else {
  }
  return (0U);
}
}
static u32 bfa_flash_status_read(void *pci_bar )
{
  union bfa_flash_dev_status_reg dev_status ;
  u32 status ;
  u32 ret_status ;
  int i ;
  int tmp ;
  {
  status = bfa_flash_fifo_flush(pci_bar);
  bfa_flash_set_cmd(pci_bar, 0, 4, 0, 5);
  i = 0;
  goto ldv_48327;
  ldv_48326:
  tmp = bfa_flash_cmd_act_check(pci_bar);
  status = (u32 )tmp;
  if (status == 0U) {
    goto ldv_48325;
  } else {
  }
  i = i + 1;
  ldv_48327: ;
  if (i <= 9999) {
    goto ldv_48326;
  } else {
  }
  ldv_48325: ;
  if (status != 0U) {
    return (status);
  } else {
  }
  dev_status.i = readl((void const volatile *)pci_bar + 118804U);
  if ((unsigned int )*((unsigned short *)(& dev_status) + 0UL) == 0U) {
    return (4294967292U);
  } else {
  }
  ret_status = readl((void const volatile *)pci_bar + 118800U);
  ret_status = ret_status >> 24;
  status = bfa_flash_fifo_flush(pci_bar);
  return (ret_status);
}
}
static u32 bfa_flash_read_start(void *pci_bar , u32 offset , u32 len , char *buf )
{
  u32 status ;
  {
  if ((len == 0U || len > 128U) || (len & 3U) != 0U) {
    return (4294967287U);
  } else {
  }
  status = bfa_flash_status_read(pci_bar);
  if (status == 4294967292U) {
    status = bfa_flash_status_read(pci_bar);
  } else {
  }
  if ((int )status & 1) {
    return (4294967289U);
  } else {
  }
  bfa_flash_set_addr(pci_bar, offset);
  bfa_flash_set_cmd(pci_bar, 0, (int )((unsigned char )len), 4, 11);
  return (0U);
}
}
static u32 bfa_flash_read_check(void *pci_bar )
{
  int tmp ;
  {
  tmp = bfa_flash_cmd_act_check(pci_bar);
  if (tmp != 0) {
    return (1U);
  } else {
  }
  return (0U);
}
}
static void bfa_flash_read_end(void *pci_bar , u32 len , char *buf )
{
  u32 i ;
  u32 w ;
  unsigned int tmp ;
  __u32 tmp___0 ;
  {
  i = 0U;
  goto ldv_48346;
  ldv_48345:
  tmp = readl((void const volatile *)pci_bar + 118800U);
  w = tmp;
  tmp___0 = __fswab32(w);
  *((u32 *)buf + (unsigned long )i) = tmp___0;
  i = i + 4U;
  ldv_48346: ;
  if (i < len) {
    goto ldv_48345;
  } else {
  }
  bfa_flash_fifo_flush(pci_bar);
  return;
}
}
static int bfa_raw_sem_get(void *bar )
{
  int locked ;
  unsigned int tmp ;
  {
  tmp = readl((void const volatile *)bar + 100384U);
  locked = (int )tmp;
  return (locked == 0);
}
}
static enum bfa_status bfa_flash_sem_get(void *bar )
{
  u32 n ;
  unsigned long __ms ;
  unsigned long tmp ;
  int tmp___0 ;
  {
  n = 500U;
  goto ldv_48361;
  ldv_48360:
  n = n - 1U;
  if (n == 0U) {
    return (9);
  } else {
  }
  __ms = 10UL;
  goto ldv_48358;
  ldv_48357:
  __const_udelay(4295000UL);
  ldv_48358:
  tmp = __ms;
  __ms = __ms - 1UL;
  if (tmp != 0UL) {
    goto ldv_48357;
  } else {
  }
  ldv_48361:
  tmp___0 = bfa_raw_sem_get(bar);
  if (tmp___0 == 0) {
    goto ldv_48360;
  } else {
  }
  return (0);
}
}
static void bfa_flash_sem_put(void *bar )
{
  {
  writel(0U, (void volatile *)bar + 100384U);
  return;
}
}
static enum bfa_status bfa_flash_raw_read(void *pci_bar , u32 offset , char *buf ,
                                          u32 len )
{
  u32 n ;
  u32 status ;
  u32 off ;
  u32 l ;
  u32 s ;
  u32 residue ;
  u32 fifo_sz ;
  enum bfa_status tmp ;
  u32 tmp___0 ;
  {
  residue = len;
  off = 0U;
  fifo_sz = 128U;
  tmp = bfa_flash_sem_get(pci_bar);
  status = (u32 )tmp;
  if (status != 0U) {
    return ((enum bfa_status )status);
  } else {
  }
  goto ldv_48383;
  ldv_48382:
  s = offset + off;
  n = s / fifo_sz;
  l = (n + 1U) * fifo_sz - s;
  if (l > residue) {
    l = residue;
  } else {
  }
  status = bfa_flash_read_start(pci_bar, offset + off, l, buf + (unsigned long )off);
  n = 1000000U;
  goto ldv_48380;
  ldv_48379:
  n = n - 1U;
  if (n == 0U) {
    bfa_flash_sem_put(pci_bar);
    return (1);
  } else {
  }
  ldv_48380:
  tmp___0 = bfa_flash_read_check(pci_bar);
  if (tmp___0 != 0U) {
    goto ldv_48379;
  } else {
  }
  bfa_flash_read_end(pci_bar, l, buf + (unsigned long )off);
  residue = residue - l;
  off = off + l;
  ldv_48383: ;
  if (residue != 0U) {
    goto ldv_48382;
  } else {
  }
  bfa_flash_sem_put(pci_bar);
  return (0);
}
}
static enum bfa_status bfa_nw_ioc_flash_img_get_chnk(struct bfa_ioc *ioc , u32 off ,
                                                     u32 *fwimg )
{
  enum bfa_status tmp ;
  {
  tmp = bfa_flash_raw_read(ioc->pcidev.pci_bar_kva, (u32 )((unsigned long )off + 262144UL) * 4U,
                           (char *)fwimg, 256U);
  return (tmp);
}
}
static enum bfi_ioc_img_ver_cmp bfa_ioc_flash_fwver_cmp(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *base_fwhdr )
{
  struct bfi_ioc_image_hdr *flash_fwhdr ;
  enum bfa_status status ;
  u32 fwimg[64U] ;
  enum bfi_ioc_img_ver_cmp tmp ;
  bool tmp___0 ;
  {
  status = bfa_nw_ioc_flash_img_get_chnk(ioc, 0U, (u32 *)(& fwimg));
  if ((unsigned int )status != 0U) {
    return (0);
  } else {
  }
  flash_fwhdr = (struct bfi_ioc_image_hdr *)(& fwimg);
  tmp___0 = bfa_ioc_flash_fwver_valid(flash_fwhdr);
  if ((int )tmp___0) {
    tmp = bfa_ioc_fw_ver_patch_cmp(base_fwhdr, flash_fwhdr);
    return (tmp);
  } else {
    return (0);
  }
}
}
bool bfa_nw_ioc_fwver_cmp(struct bfa_ioc *ioc , struct bfi_ioc_image_hdr *fwhdr )
{
  struct bfi_ioc_image_hdr *drv_fwhdr ;
  enum bfi_ioc_img_ver_cmp smem_flash_cmp ;
  enum bfi_ioc_img_ver_cmp drv_smem_cmp ;
  u32 *tmp ;
  {
  tmp = bfa_cb_image_get_chunk(ioc->asic_gen, 0U);
  drv_fwhdr = (struct bfi_ioc_image_hdr *)tmp;
  drv_smem_cmp = bfa_ioc_fw_ver_patch_cmp(drv_fwhdr, fwhdr);
  if ((unsigned int )drv_smem_cmp == 0U || (unsigned int )drv_smem_cmp == 1U) {
    return (0);
  } else {
  }
  smem_flash_cmp = bfa_ioc_flash_fwver_cmp(ioc, fwhdr);
  if ((unsigned int )smem_flash_cmp == 3U) {
    return (0);
  } else
  if ((unsigned int )smem_flash_cmp == 2U) {
    return (1);
  } else {
    return ((unsigned int )drv_smem_cmp == 2U);
  }
}
}
static bool bfa_ioc_fwver_valid(struct bfa_ioc *ioc , u32 boot_env )
{
  struct bfi_ioc_image_hdr fwhdr ;
  __u32 tmp ;
  bool tmp___0 ;
  {
  bfa_nw_ioc_fwver_get(ioc, & fwhdr);
  tmp = __fswab32(fwhdr.bootenv);
  if (tmp != boot_env) {
    return (0);
  } else {
  }
  tmp___0 = bfa_nw_ioc_fwver_cmp(ioc, & fwhdr);
  return (tmp___0);
}
}
static void bfa_ioc_msgflush(struct bfa_ioc *ioc )
{
  u32 r32 ;
  {
  r32 = readl((void const volatile *)ioc->ioc_regs.lpu_mbox_cmd);
  if (r32 != 0U) {
    writel(1U, (void volatile *)ioc->ioc_regs.lpu_mbox_cmd);
  } else {
  }
  return;
}
}
static void bfa_ioc_hwinit(struct bfa_ioc *ioc , bool force )
{
  enum bfi_ioc_state ioc_fwstate ;
  bool fwvalid ;
  u32 boot_env ;
  bool tmp ;
  int tmp___0 ;
  enum bfa_status tmp___1 ;
  enum bfa_status tmp___2 ;
  {
  ioc_fwstate = (*((ioc->ioc_hwif)->ioc_get_fwstate))(ioc);
  if ((int )force) {
    ioc_fwstate = 0;
  } else {
  }
  boot_env = 0U;
  if ((unsigned int )ioc_fwstate != 0U) {
    tmp = bfa_ioc_fwver_valid(ioc, boot_env);
    if ((int )tmp != 0) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  } else {
    tmp___0 = 0;
  }
  fwvalid = tmp___0;
  if (! fwvalid) {
    tmp___1 = bfa_ioc_boot(ioc, 0, boot_env);
    if ((unsigned int )tmp___1 == 0U) {
      bfa_ioc_poll_fwinit(ioc);
    } else {
    }
    return;
  } else {
  }
  if ((unsigned int )ioc_fwstate == 1U) {
    bfa_ioc_poll_fwinit(ioc);
    return;
  } else {
  }
  if ((unsigned int )ioc_fwstate == 6U || (unsigned int )ioc_fwstate == 4U) {
    bfa_ioc_msgflush(ioc);
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 4);
    return;
  } else {
  }
  tmp___2 = bfa_ioc_boot(ioc, 0, boot_env);
  if ((unsigned int )tmp___2 == 0U) {
    bfa_ioc_poll_fwinit(ioc);
  } else {
  }
  return;
}
}
void bfa_nw_ioc_timeout(struct bfa_ioc *ioc )
{
  {
  (*(ioc->fsm))((void *)ioc, 11);
  return;
}
}
static void bfa_ioc_mbox_send(struct bfa_ioc *ioc , void *ioc_msg , int len )
{
  u32 *msgp ;
  u32 i ;
  long tmp ;
  {
  msgp = (u32 *)ioc_msg;
  tmp = ldv__builtin_expect(len > 32, 0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (1909), "i" (12UL));
    ldv_48430: ;
    goto ldv_48430;
  } else {
  }
  i = 0U;
  goto ldv_48432;
  ldv_48431:
  writel(*(msgp + (unsigned long )i), (void volatile *)(ioc->ioc_regs.hfn_mbox + (unsigned long )i * 4UL));
  i = i + 1U;
  ldv_48432: ;
  if ((unsigned long )i < (unsigned long )len / 4UL) {
    goto ldv_48431;
  } else {
  }
  goto ldv_48435;
  ldv_48434:
  writel(0U, (void volatile *)(ioc->ioc_regs.hfn_mbox + (unsigned long )i * 4UL));
  i = i + 1U;
  ldv_48435: ;
  if (i <= 7U) {
    goto ldv_48434;
  } else {
  }
  writel(1U, (void volatile *)ioc->ioc_regs.hfn_mbox_cmd);
  readl((void const volatile *)ioc->ioc_regs.hfn_mbox_cmd);
  return;
}
}
static void bfa_ioc_send_enable(struct bfa_ioc *ioc )
{
  struct bfi_ioc_ctrl_req enable_req ;
  struct timeval tv ;
  __u16 tmp ;
  __u32 tmp___0 ;
  {
  enable_req.mh.msg_class = 1U;
  enable_req.mh.msg_id = 1U;
  enable_req.mh.mtag.h2i.fn_lpu = ioc->port_id;
  tmp = __fswab16((int )((__u16 )ioc->clscode));
  enable_req.clscode = tmp;
  do_gettimeofday(& tv);
  tmp___0 = __fswab32((unsigned int )tv.tv_sec);
  enable_req.tv_sec = tmp___0;
  bfa_ioc_mbox_send(ioc, (void *)(& enable_req), 12);
  return;
}
}
static void bfa_ioc_send_disable(struct bfa_ioc *ioc )
{
  struct bfi_ioc_ctrl_req disable_req ;
  {
  disable_req.mh.msg_class = 1U;
  disable_req.mh.msg_id = 2U;
  disable_req.mh.mtag.h2i.fn_lpu = ioc->port_id;
  bfa_ioc_mbox_send(ioc, (void *)(& disable_req), 12);
  return;
}
}
static void bfa_ioc_send_getattr(struct bfa_ioc *ioc )
{
  struct bfi_ioc_getattr_req attr_req ;
  {
  attr_req.mh.msg_class = 1U;
  attr_req.mh.msg_id = 3U;
  attr_req.mh.mtag.h2i.fn_lpu = ioc->port_id;
  __bfa_dma_be_addr_set(& attr_req.attr_addr, ioc->attr_dma.pa);
  bfa_ioc_mbox_send(ioc, (void *)(& attr_req), 12);
  return;
}
}
void bfa_nw_ioc_hb_check(struct bfa_ioc *ioc )
{
  u32 hb_count ;
  unsigned long tmp ;
  {
  hb_count = readl((void const volatile *)ioc->ioc_regs.heartbeat);
  if (ioc->hb_count == hb_count) {
    bfa_ioc_recover(ioc);
    return;
  } else {
    ioc->hb_count = hb_count;
  }
  bfa_ioc_mbox_poll(ioc);
  tmp = msecs_to_jiffies(500U);
  ldv_mod_timer_394(& ioc->hb_timer, tmp + (unsigned long )jiffies);
  return;
}
}
static void bfa_ioc_hb_monitor(struct bfa_ioc *ioc )
{
  unsigned long tmp ;
  {
  ioc->hb_count = readl((void const volatile *)ioc->ioc_regs.heartbeat);
  tmp = msecs_to_jiffies(500U);
  ldv_mod_timer_395(& ioc->hb_timer, tmp + (unsigned long )jiffies);
  return;
}
}
static void bfa_ioc_hb_stop(struct bfa_ioc *ioc )
{
  {
  ldv_del_timer_396(& ioc->hb_timer);
  return;
}
}
static enum bfa_status bfa_ioc_download_fw(struct bfa_ioc *ioc , u32 boot_type , u32 boot_env )
{
  u32 *fwimg ;
  u32 pgnum ;
  u32 loff ;
  u32 chunkno ;
  u32 i ;
  u32 asicmode ;
  u32 fwimg_size ;
  u32 fwimg_buf[64U] ;
  enum bfa_status status ;
  __u32 tmp ;
  u32 tmp___0 ;
  {
  loff = 0U;
  chunkno = 0U;
  if (boot_env == 0U && boot_type == 1U) {
    fwimg_size = 262144U;
    status = bfa_nw_ioc_flash_img_get_chnk(ioc, chunkno * 64U, (u32 *)(& fwimg_buf));
    if ((unsigned int )status != 0U) {
      return (status);
    } else {
    }
    fwimg = (u32 *)(& fwimg_buf);
  } else {
    fwimg_size = bfa_cb_image_get_size(ioc->asic_gen);
    fwimg = bfa_cb_image_get_chunk(ioc->asic_gen, chunkno * 64U);
  }
  pgnum = bfa_ioc_smem_pgnum(ioc, loff);
  writel(pgnum, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  i = 0U;
  goto ldv_48475;
  ldv_48474: ;
  if (i / 64U != chunkno) {
    chunkno = i / 64U;
    if (boot_env == 0U && boot_type == 1U) {
      status = bfa_nw_ioc_flash_img_get_chnk(ioc, chunkno * 64U, (u32 *)(& fwimg_buf));
      if ((unsigned int )status != 0U) {
        return (status);
      } else {
      }
      fwimg = (u32 *)(& fwimg_buf);
    } else {
      fwimg = bfa_cb_image_get_chunk(ioc->asic_gen, chunkno * 64U);
    }
  } else {
  }
  tmp = __fswab32(*(fwimg + ((unsigned long )i & 63UL)));
  writel(tmp, (void volatile *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  loff = loff + 4U;
  loff = loff & 32767U;
  if (loff == 0U) {
    pgnum = pgnum + 1U;
    writel(pgnum, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  } else {
  }
  i = i + 1U;
  ldv_48475: ;
  if (i < fwimg_size) {
    goto ldv_48474;
  } else {
  }
  tmp___0 = bfa_ioc_smem_pgnum(ioc, 0U);
  writel(tmp___0, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  if (boot_env == 0U && boot_type == 1U) {
    boot_type = 0U;
  } else {
  }
  asicmode = ((((unsigned int )ioc->asic_gen << 24) | ((unsigned int )ioc->asic_mode << 16)) | ((unsigned int )ioc->port0_mode << 8)) | (unsigned int )ioc->port1_mode;
  writel(asicmode, (void volatile *)ioc->ioc_regs.smem_page_start + 4U);
  writel(boot_type, (void volatile *)ioc->ioc_regs.smem_page_start + 8U);
  writel(boot_env, (void volatile *)ioc->ioc_regs.smem_page_start + 12U);
  return (0);
}
}
static void bfa_ioc_reset(struct bfa_ioc *ioc , bool force )
{
  {
  bfa_ioc_hwinit(ioc, (int )force);
  return;
}
}
static void bfa_ioc_enable_reply(struct bfa_ioc *ioc , enum bfa_mode port_mode , u8 cap_bm )
{
  struct bfa_iocpf *iocpf ;
  u8 tmp ;
  {
  iocpf = & ioc->iocpf;
  tmp = (u8 )port_mode;
  ioc->port_mode_cfg = tmp;
  ioc->port_mode = (enum bfa_mode )tmp;
  ioc->ad_cap_bm = cap_bm;
  (*(iocpf->fsm))((void *)iocpf, 5);
  return;
}
}
static void bfa_ioc_getattr_reply(struct bfa_ioc *ioc )
{
  struct bfi_ioc_attr *attr ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u16 tmp___1 ;
  {
  attr = ioc->attr;
  tmp = __fswab32(attr->adapter_prop);
  attr->adapter_prop = tmp;
  tmp___0 = __fswab32(attr->card_type);
  attr->card_type = tmp___0;
  tmp___1 = __fswab16((int )attr->maxfrsize);
  attr->maxfrsize = tmp___1;
  (*(ioc->fsm))((void *)ioc, 6);
  return;
}
}
static void bfa_ioc_mbox_attach(struct bfa_ioc *ioc )
{
  struct bfa_ioc_mbox_mod *mod ;
  int mc ;
  {
  mod = & ioc->mbox_mod;
  INIT_LIST_HEAD(& mod->cmd_q);
  mc = 0;
  goto ldv_48497;
  ldv_48496:
  mod->mbhdlr[mc].cbfn = (void (*)(void * , struct bfi_mbmsg * ))0;
  mod->mbhdlr[mc].cbarg = (void *)ioc->bfa;
  mc = mc + 1;
  ldv_48497: ;
  if (mc <= 33) {
    goto ldv_48496;
  } else {
  }
  return;
}
}
static void bfa_ioc_mbox_poll(struct bfa_ioc *ioc )
{
  struct bfa_ioc_mbox_mod *mod ;
  struct bfa_mbox_cmd *cmd ;
  void (*cbfn)(void * ) ;
  void *cbarg ;
  u32 stat ;
  int tmp ;
  struct list_head const *__mptr ;
  {
  mod = & ioc->mbox_mod;
  tmp = list_empty((struct list_head const *)(& mod->cmd_q));
  if (tmp != 0) {
    return;
  } else {
  }
  stat = readl((void const volatile *)ioc->ioc_regs.hfn_mbox_cmd);
  if (stat != 0U) {
    return;
  } else {
  }
  __mptr = (struct list_head const *)mod->cmd_q.next;
  cmd = (struct bfa_mbox_cmd *)__mptr;
  list_del(& cmd->qe);
  bfa_ioc_mbox_send(ioc, (void *)(& cmd->msg), 32);
  if ((unsigned long )cmd->cbfn != (unsigned long )((void (*)(void * ))0)) {
    cbfn = cmd->cbfn;
    cbarg = cmd->cbarg;
    cmd->cbfn = (void (*)(void * ))0;
    (*cbfn)(cbarg);
  } else {
  }
  return;
}
}
static void bfa_ioc_mbox_flush(struct bfa_ioc *ioc )
{
  struct bfa_ioc_mbox_mod *mod ;
  struct bfa_mbox_cmd *cmd ;
  struct list_head const *__mptr ;
  int tmp ;
  {
  mod = & ioc->mbox_mod;
  goto ldv_48517;
  ldv_48516:
  __mptr = (struct list_head const *)mod->cmd_q.next;
  cmd = (struct bfa_mbox_cmd *)__mptr;
  list_del(& cmd->qe);
  ldv_48517:
  tmp = list_empty((struct list_head const *)(& mod->cmd_q));
  if (tmp == 0) {
    goto ldv_48516;
  } else {
  }
  return;
}
}
static int bfa_nw_ioc_smem_read(struct bfa_ioc *ioc , void *tbuf , u32 soff , u32 sz )
{
  u32 pgnum ;
  u32 loff ;
  u32 r32 ;
  int i ;
  int len ;
  u32 *buf ;
  bool tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  {
  buf = (u32 *)tbuf;
  pgnum = ioc->ioc_regs.smem_pg0 + (soff >> 15);
  loff = soff & 32767U;
  tmp = bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_init_sem_reg);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (1);
  } else {
  }
  writel(pgnum, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  len = (int )(sz / 4U);
  i = 0;
  goto ldv_48532;
  ldv_48531:
  tmp___1 = readl((void const volatile *)ioc->ioc_regs.smem_page_start + (unsigned long )loff);
  tmp___2 = __fswab32(tmp___1);
  r32 = tmp___2;
  tmp___3 = __fswab32(r32);
  *(buf + (unsigned long )i) = tmp___3;
  loff = loff + 4U;
  loff = loff & 32767U;
  if (loff == 0U) {
    pgnum = pgnum + 1U;
    writel(pgnum, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  } else {
  }
  i = i + 1;
  ldv_48532: ;
  if (i < len) {
    goto ldv_48531;
  } else {
  }
  writel(ioc->ioc_regs.smem_pg0, (void volatile *)ioc->ioc_regs.host_page_num_fn);
  readl((void const volatile *)ioc->ioc_regs.ioc_init_sem_reg);
  writel(1U, (void volatile *)ioc->ioc_regs.ioc_init_sem_reg);
  return (0);
}
}
int bfa_nw_ioc_debug_fwtrc(struct bfa_ioc *ioc , void *trcdata , int *trclen )
{
  u32 loff ;
  int tlen ;
  int status ;
  {
  loff = (u32 )((int )ioc->port_id * 4128 + 19200);
  status = 0;
  tlen = *trclen;
  if (tlen > 4128) {
    tlen = 4128;
  } else {
  }
  status = bfa_nw_ioc_smem_read(ioc, trcdata, loff, (u32 )tlen);
  *trclen = tlen;
  return (status);
}
}
static void bfa_nw_ioc_debug_save_ftrc(struct bfa_ioc *ioc )
{
  int tlen ;
  {
  if ((int )ioc->dbg_fwsave_once) {
    ioc->dbg_fwsave_once = 0;
    if (ioc->dbg_fwsave_len != 0) {
      tlen = ioc->dbg_fwsave_len;
      bfa_nw_ioc_debug_fwtrc(ioc, ioc->dbg_fwsave, & tlen);
    } else {
    }
  } else {
  }
  return;
}
}
int bfa_nw_ioc_debug_fwsave(struct bfa_ioc *ioc , void *trcdata , int *trclen )
{
  int tlen ;
  {
  if (ioc->dbg_fwsave_len == 0) {
    return (78);
  } else {
  }
  tlen = *trclen;
  if (ioc->dbg_fwsave_len < tlen) {
    tlen = ioc->dbg_fwsave_len;
  } else {
  }
  memmove(trcdata, (void const *)ioc->dbg_fwsave, (size_t )tlen);
  *trclen = tlen;
  return (0);
}
}
static void bfa_ioc_fail_notify(struct bfa_ioc *ioc )
{
  {
  (*((ioc->cbfn)->hbfail_cbfn))((void *)ioc->bfa);
  bfa_ioc_event_notify(ioc, 3);
  bfa_nw_ioc_debug_save_ftrc(ioc);
  return;
}
}
static void bfa_ioc_pf_enabled(struct bfa_ioc *ioc )
{
  {
  (*(ioc->fsm))((void *)ioc, 5);
  return;
}
}
static void bfa_ioc_pf_disabled(struct bfa_ioc *ioc )
{
  {
  (*(ioc->fsm))((void *)ioc, 7);
  return;
}
}
static void bfa_ioc_pf_failed(struct bfa_ioc *ioc )
{
  {
  (*(ioc->fsm))((void *)ioc, 8);
  return;
}
}
static void bfa_ioc_pf_hwfailed(struct bfa_ioc *ioc )
{
  {
  (*(ioc->fsm))((void *)ioc, 12);
  return;
}
}
static void bfa_ioc_pf_fwmismatch(struct bfa_ioc *ioc )
{
  {
  (*((ioc->cbfn)->enable_cbfn))((void *)ioc->bfa, 56);
  return;
}
}
static enum bfa_status bfa_ioc_pll_init(struct bfa_ioc *ioc )
{
  {
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_init_sem_reg);
  (*((ioc->ioc_hwif)->ioc_pll_init))(ioc->pcidev.pci_bar_kva, ioc->asic_mode);
  ioc->pllinit = 1;
  bfa_ioc_lmem_init(ioc);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_init_sem_reg);
  return (0);
}
}
static enum bfa_status bfa_ioc_boot(struct bfa_ioc *ioc , enum bfi_fwboot_type boot_type ,
                                    u32 boot_env )
{
  struct bfi_ioc_image_hdr *drv_fwhdr ;
  enum bfa_status status ;
  enum bfa_status tmp ;
  u32 *tmp___0 ;
  enum bfi_ioc_img_ver_cmp tmp___1 ;
  {
  ioc->stats.ioc_boots = ioc->stats.ioc_boots + 1U;
  tmp = bfa_ioc_pll_init(ioc);
  if ((unsigned int )tmp != 0U) {
    return (1);
  } else {
  }
  if (boot_env == 0U && (unsigned int )boot_type == 0U) {
    tmp___0 = bfa_cb_image_get_chunk(ioc->asic_gen, 0U);
    drv_fwhdr = (struct bfi_ioc_image_hdr *)tmp___0;
    tmp___1 = bfa_ioc_flash_fwver_cmp(ioc, drv_fwhdr);
    if ((unsigned int )tmp___1 == 3U) {
      boot_type = 1;
    } else {
    }
  } else {
  }
  if ((unsigned int )boot_type == 2U) {
    (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 9);
    (*((ioc->ioc_hwif)->ioc_set_alt_fwstate))(ioc, 9);
  } else {
    (*((ioc->ioc_hwif)->ioc_set_fwstate))(ioc, 1);
    (*((ioc->ioc_hwif)->ioc_set_alt_fwstate))(ioc, 1);
  }
  bfa_ioc_msgflush(ioc);
  status = bfa_ioc_download_fw(ioc, (u32 )boot_type, boot_env);
  if ((unsigned int )status == 0U) {
    bfa_ioc_lpu_start(ioc);
  } else {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 11);
  }
  return (status);
}
}
void bfa_nw_ioc_auto_recover(bool auto_recover )
{
  {
  bfa_nw_auto_recover = auto_recover;
  return;
}
}
static bool bfa_ioc_msgget(struct bfa_ioc *ioc , void *mbmsg )
{
  u32 *msgp ;
  u32 r32 ;
  int i ;
  __u32 tmp ;
  {
  msgp = (u32 *)mbmsg;
  r32 = readl((void const volatile *)ioc->ioc_regs.lpu_mbox_cmd);
  if ((r32 & 1U) == 0U) {
    return (0);
  } else {
  }
  i = 0;
  goto ldv_48591;
  ldv_48590:
  r32 = readl((void const volatile *)(ioc->ioc_regs.lpu_mbox + (unsigned long )i * 4UL));
  tmp = __fswab32(r32);
  *(msgp + (unsigned long )i) = tmp;
  i = i + 1;
  ldv_48591: ;
  if ((unsigned int )i <= 7U) {
    goto ldv_48590;
  } else {
  }
  writel(1U, (void volatile *)ioc->ioc_regs.lpu_mbox_cmd);
  readl((void const volatile *)ioc->ioc_regs.lpu_mbox_cmd);
  return (1);
}
}
static void bfa_ioc_isr(struct bfa_ioc *ioc , struct bfi_mbmsg *m )
{
  union bfi_ioc_i2h_msg_u *msg ;
  struct bfa_iocpf *iocpf ;
  long tmp ;
  {
  iocpf = & ioc->iocpf;
  msg = (union bfi_ioc_i2h_msg_u *)m;
  ioc->stats.ioc_isrs = ioc->stats.ioc_isrs + 1U;
  switch ((int )msg->mh.msg_id) {
  case 132: ;
  goto ldv_48600;
  case 129:
  bfa_ioc_enable_reply(ioc, (enum bfa_mode )msg->fw_event.port_mode, (int )msg->fw_event.cap_bm);
  goto ldv_48600;
  case 130:
  (*(iocpf->fsm))((void *)iocpf, 6);
  goto ldv_48600;
  case 131:
  bfa_ioc_getattr_reply(ioc);
  goto ldv_48600;
  default:
  tmp = ldv__builtin_expect(1L, 0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2471), "i" (12UL));
    ldv_48605: ;
    goto ldv_48605;
  } else {
  }
  }
  ldv_48600: ;
  return;
}
}
void bfa_nw_ioc_attach(struct bfa_ioc *ioc , void *bfa , struct bfa_ioc_cbfn *cbfn )
{
  {
  ioc->bfa = (struct bfa *)bfa;
  ioc->cbfn = cbfn;
  ioc->fcmode = 0;
  ioc->pllinit = 0;
  ioc->dbg_fwsave_once = 1;
  ioc->iocpf.ioc = ioc;
  bfa_ioc_mbox_attach(ioc);
  INIT_LIST_HEAD(& ioc->notify_q);
  ioc->fsm = (void (*)(void * , int ))(& bfa_ioc_sm_uninit);
  bfa_ioc_sm_uninit_entry(ioc);
  (*(ioc->fsm))((void *)ioc, 1);
  return;
}
}
void bfa_nw_ioc_detach(struct bfa_ioc *ioc )
{
  {
  (*(ioc->fsm))((void *)ioc, 4);
  INIT_LIST_HEAD(& ioc->notify_q);
  return;
}
}
void bfa_nw_ioc_pci_init(struct bfa_ioc *ioc , struct bfa_pcidev *pcidev , enum bfi_pcifn_class clscode )
{
  enum bfi_port_mode tmp ;
  enum bfi_port_mode tmp___0 ;
  enum bfi_port_mode tmp___1 ;
  long tmp___2 ;
  int __ret_warn_on ;
  long tmp___3 ;
  {
  ioc->clscode = clscode;
  ioc->pcidev = *pcidev;
  tmp = 1;
  ioc->port1_mode = tmp;
  ioc->port0_mode = tmp;
  ioc->asic_mode = 1;
  switch ((int )pcidev->device_id) {
  case 20:
  ioc->asic_gen = 2;
  tmp___0 = 2;
  ioc->port1_mode = tmp___0;
  ioc->port0_mode = tmp___0;
  ioc->asic_mode = 3;
  ioc->port_mode_cfg = 2U;
  ioc->port_mode = 2;
  ioc->ad_cap_bm = 2U;
  goto ldv_48620;
  case 34:
  ioc->asic_gen = 3;
  if ((unsigned int )clscode == 3076U && (unsigned int )pcidev->ssid == 36U) {
    ioc->asic_mode = 2;
    ioc->fcmode = 1;
    ioc->port_mode_cfg = 1U;
    ioc->port_mode = 1;
    ioc->ad_cap_bm = 1U;
  } else {
    tmp___1 = 2;
    ioc->port1_mode = tmp___1;
    ioc->port0_mode = tmp___1;
    ioc->asic_mode = 3;
    if ((unsigned int )pcidev->ssid == 34U) {
      ioc->port_mode_cfg = 2U;
      ioc->port_mode = 2;
      ioc->ad_cap_bm = 2U;
    } else {
      ioc->port_mode_cfg = 3U;
      ioc->port_mode = 3;
      ioc->ad_cap_bm = 4U;
    }
  }
  goto ldv_48620;
  default:
  tmp___2 = ldv__builtin_expect(1L, 0L);
  if (tmp___2 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2559), "i" (12UL));
    ldv_48623: ;
    goto ldv_48623;
  } else {
  }
  }
  ldv_48620: ;
  if ((unsigned int )ioc->asic_gen == 2U) {
    bfa_nw_ioc_set_ct_hwif(ioc);
  } else {
    __ret_warn_on = (unsigned int )ioc->asic_gen != 3U;
    tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
    if (tmp___3 != 0L) {
      warn_slowpath_null("/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
                         2568);
    } else {
    }
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
    bfa_nw_ioc_set_ct2_hwif(ioc);
    bfa_nw_ioc_ct2_poweron(ioc);
  }
  (*((ioc->ioc_hwif)->ioc_map_port))(ioc);
  (*((ioc->ioc_hwif)->ioc_reg_init))(ioc);
  return;
}
}
void bfa_nw_ioc_mem_claim(struct bfa_ioc *ioc , u8 *dm_kva , u64 dm_pa )
{
  {
  ioc->attr_dma.kva = (void *)dm_kva;
  ioc->attr_dma.pa = dm_pa;
  ioc->attr = (struct bfi_ioc_attr *)dm_kva;
  return;
}
}
u32 bfa_nw_ioc_meminfo(void)
{
  int __y ;
  {
  __y = 256;
  return ((u32 )((((unsigned long )(__y + -1) + 732UL) / (unsigned long )__y) * (unsigned long )__y));
}
}
void bfa_nw_ioc_enable(struct bfa_ioc *ioc )
{
  {
  ioc->stats.ioc_enables = ioc->stats.ioc_enables + 1U;
  ioc->dbg_fwsave_once = 1;
  (*(ioc->fsm))((void *)ioc, 2);
  return;
}
}
void bfa_nw_ioc_disable(struct bfa_ioc *ioc )
{
  {
  ioc->stats.ioc_disables = ioc->stats.ioc_disables + 1U;
  (*(ioc->fsm))((void *)ioc, 3);
  return;
}
}
void bfa_nw_ioc_debug_memclaim(struct bfa_ioc *ioc , void *dbg_fwsave )
{
  {
  ioc->dbg_fwsave = dbg_fwsave;
  ioc->dbg_fwsave_len = (int )ioc->iocpf.auto_recover ? 4128 : 0;
  return;
}
}
static u32 bfa_ioc_smem_pgnum(struct bfa_ioc *ioc , u32 fmaddr )
{
  {
  return (ioc->ioc_regs.smem_pg0 + (fmaddr >> 15));
}
}
void bfa_nw_ioc_mbox_regisr(struct bfa_ioc *ioc , enum bfi_mclass mc , void (*cbfn)(void * ,
                                                                                    struct bfi_mbmsg * ) ,
                            void *cbarg )
{
  struct bfa_ioc_mbox_mod *mod ;
  {
  mod = & ioc->mbox_mod;
  mod->mbhdlr[(unsigned int )mc].cbfn = cbfn;
  mod->mbhdlr[(unsigned int )mc].cbarg = cbarg;
  return;
}
}
bool bfa_nw_ioc_mbox_queue(struct bfa_ioc *ioc , struct bfa_mbox_cmd *cmd , void (*cbfn)(void * ) ,
                           void *cbarg )
{
  struct bfa_ioc_mbox_mod *mod ;
  u32 stat ;
  int tmp ;
  {
  mod = & ioc->mbox_mod;
  cmd->cbfn = cbfn;
  cmd->cbarg = cbarg;
  tmp = list_empty((struct list_head const *)(& mod->cmd_q));
  if (tmp == 0) {
    list_add_tail(& cmd->qe, & mod->cmd_q);
    return (1);
  } else {
  }
  stat = readl((void const volatile *)ioc->ioc_regs.hfn_mbox_cmd);
  if (stat != 0U) {
    list_add_tail(& cmd->qe, & mod->cmd_q);
    return (1);
  } else {
  }
  bfa_ioc_mbox_send(ioc, (void *)(& cmd->msg), 32);
  return (0);
}
}
void bfa_nw_ioc_mbox_isr(struct bfa_ioc *ioc )
{
  struct bfa_ioc_mbox_mod *mod ;
  struct bfi_mbmsg m ;
  int mc ;
  bool tmp ;
  {
  mod = & ioc->mbox_mod;
  tmp = bfa_ioc_msgget(ioc, (void *)(& m));
  if ((int )tmp) {
    mc = (int )m.mh.msg_class;
    if (mc == 1) {
      bfa_ioc_isr(ioc, & m);
      return;
    } else {
    }
    if (mc > 33 || (unsigned long )mod->mbhdlr[mc].cbfn == (unsigned long )((void (*)(void * ,
                                                                                      struct bfi_mbmsg * ))0)) {
      return;
    } else {
    }
    (*(mod->mbhdlr[mc].cbfn))(mod->mbhdlr[mc].cbarg, & m);
  } else {
  }
  if ((unsigned long )(ioc->ioc_hwif)->ioc_lpu_read_stat != (unsigned long )((bool (* )(struct bfa_ioc * ))0)) {
    (*((ioc->ioc_hwif)->ioc_lpu_read_stat))(ioc);
  } else {
  }
  bfa_ioc_mbox_poll(ioc);
  return;
}
}
void bfa_nw_ioc_error_isr(struct bfa_ioc *ioc )
{
  {
  ioc->stats.ioc_hbfails = ioc->stats.ioc_hbfails + 1U;
  ioc->stats.hb_count = ioc->hb_count;
  (*(ioc->fsm))((void *)ioc, 10);
  return;
}
}
bool bfa_nw_ioc_is_disabled(struct bfa_ioc *ioc )
{
  {
  return ((bool )((unsigned long )ioc->fsm == (unsigned long )((void (*)(void * ,
                                                                         int ))(& bfa_ioc_sm_disabling)) || (unsigned long )ioc->fsm == (unsigned long )((void (*)(void * ,
                                                                                                                                                                    int ))(& bfa_ioc_sm_disabled))));
}
}
bool bfa_nw_ioc_is_operational(struct bfa_ioc *ioc )
{
  {
  return ((unsigned long )ioc->fsm == (unsigned long )((void (*)(void * , int ))(& bfa_ioc_sm_op)));
}
}
void bfa_nw_ioc_notify_register(struct bfa_ioc *ioc , struct bfa_ioc_notify *notify )
{
  {
  list_add_tail(& notify->qe, & ioc->notify_q);
  return;
}
}
static void bfa_ioc_get_adapter_attr(struct bfa_ioc *ioc , struct bfa_adapter_attr *ad_attr )
{
  struct bfi_ioc_attr *ioc_attr ;
  {
  ioc_attr = ioc->attr;
  bfa_ioc_get_adapter_serial_num(ioc, (char *)(& ad_attr->serial_num));
  bfa_ioc_get_adapter_fw_ver(ioc, (char *)(& ad_attr->fw_ver));
  bfa_ioc_get_adapter_optrom_ver(ioc, (char *)(& ad_attr->optrom_ver));
  bfa_ioc_get_adapter_manufacturer(ioc, (char *)(& ad_attr->manufacturer));
  memcpy((void *)(& ad_attr->vpd), (void const *)(& ioc_attr->vpd), 520UL);
  ad_attr->nports = (u8 )(((ioc->attr)->adapter_prop & 65280U) >> 8);
  ad_attr->max_speed = (u8 )(ioc->attr)->adapter_prop;
  bfa_ioc_get_adapter_model(ioc, (char *)(& ad_attr->model));
  bfa_ioc_get_adapter_model(ioc, (char *)(& ad_attr->model_descr));
  ad_attr->card_type = ioc_attr->card_type;
  ad_attr->is_mezz = (u8 )(((((ioc_attr->card_type == 804U || ioc_attr->card_type == 1007U) || ioc_attr->card_type == 807U) || ioc_attr->card_type == 902U) || ioc_attr->card_type == 1741U) || ioc_attr->card_type == 1867U);
  if ((ioc_attr->adapter_prop & 7340032U) != 0U) {
    ad_attr->prototype = 1U;
  } else {
    ad_attr->prototype = 0U;
  }
  ad_attr->pwwn = bfa_ioc_get_pwwn(ioc);
  bfa_nw_ioc_get_mac(ioc, (u8 *)(& ad_attr->mac));
  ad_attr->pcie_gen = ioc_attr->pcie_gen;
  ad_attr->pcie_lanes = ioc_attr->pcie_lanes;
  ad_attr->pcie_lanes_orig = ioc_attr->pcie_lanes_orig;
  ad_attr->asic_rev = ioc_attr->asic_rev;
  bfa_ioc_get_pci_chip_rev(ioc, (char *)(& ad_attr->hw_ver));
  return;
}
}
static enum bfa_ioc_type bfa_ioc_get_type(struct bfa_ioc *ioc )
{
  long tmp ;
  {
  if ((unsigned int )ioc->clscode == 512U) {
    return (3);
  } else {
  }
  tmp = ldv__builtin_expect((unsigned int )ioc->clscode != 3076U, 0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2798), "i" (12UL));
    ldv_48692: ;
    goto ldv_48692;
  } else {
  }
  return ((unsigned int )(ioc->attr)->port_mode == 1U ? 1 : 2);
}
}
static void bfa_ioc_get_adapter_serial_num(struct bfa_ioc *ioc , char *serial_num )
{
  {
  memcpy((void *)serial_num, (void const *)(& (ioc->attr)->brcd_serialnum), 12UL);
  return;
}
}
static void bfa_ioc_get_adapter_fw_ver(struct bfa_ioc *ioc , char *fw_ver )
{
  {
  memcpy((void *)fw_ver, (void const *)(& (ioc->attr)->fw_version), 64UL);
  return;
}
}
static void bfa_ioc_get_pci_chip_rev(struct bfa_ioc *ioc , char *chip_rev )
{
  long tmp ;
  {
  tmp = ldv__builtin_expect((unsigned long )chip_rev == (unsigned long )((char *)0),
                         0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2821), "i" (12UL));
    ldv_48705: ;
    goto ldv_48705;
  } else {
  }
  memset((void *)chip_rev, 0, 8UL);
  *chip_rev = 82;
  *(chip_rev + 1UL) = 101;
  *(chip_rev + 2UL) = 118;
  *(chip_rev + 3UL) = 45;
  *(chip_rev + 4UL) = (ioc->attr)->asic_rev;
  *(chip_rev + 5UL) = 0;
  return;
}
}
static void bfa_ioc_get_adapter_optrom_ver(struct bfa_ioc *ioc , char *optrom_ver )
{
  {
  memcpy((void *)optrom_ver, (void const *)(& (ioc->attr)->optrom_version), 64UL);
  return;
}
}
static void bfa_ioc_get_adapter_manufacturer(struct bfa_ioc *ioc , char *manufacturer )
{
  {
  memcpy((void *)manufacturer, (void const *)"QLogic", 8UL);
  return;
}
}
static void bfa_ioc_get_adapter_model(struct bfa_ioc *ioc , char *model )
{
  struct bfi_ioc_attr *ioc_attr ;
  long tmp ;
  {
  tmp = ldv__builtin_expect((unsigned long )model == (unsigned long )((char *)0), 0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c"),
                         "i" (2851), "i" (12UL));
    ldv_48719: ;
    goto ldv_48719;
  } else {
  }
  memset((void *)model, 0, 16UL);
  ioc_attr = ioc->attr;
  snprintf(model, 16UL, "%s-%u", (char *)"QLogic", ioc_attr->card_type);
  return;
}
}
static enum bfa_ioc_state bfa_ioc_get_state(struct bfa_ioc *ioc )
{
  enum bfa_iocpf_state iocpf_st ;
  enum bfa_ioc_state ioc_st ;
  int tmp ;
  int tmp___0 ;
  {
  tmp = bfa_sm_to_state((struct bfa_sm_table const *)(& ioc_sm_table), ioc->fsm);
  ioc_st = (enum bfa_ioc_state )tmp;
  if (((unsigned int )ioc_st == 12U || (unsigned int )ioc_st == 8U) || (unsigned int )ioc_st == 7U) {
    tmp___0 = bfa_sm_to_state((struct bfa_sm_table const *)(& iocpf_sm_table), ioc->iocpf.fsm);
    iocpf_st = (enum bfa_iocpf_state )tmp___0;
    switch ((unsigned int )iocpf_st) {
    case 2U:
    ioc_st = 3;
    goto ldv_48726;
    case 3U:
    ioc_st = 4;
    goto ldv_48726;
    case 9U:
    ioc_st = 11;
    goto ldv_48726;
    case 6U:
    ioc_st = 8;
    goto ldv_48726;
    case 5U:
    ioc_st = 7;
    goto ldv_48726;
    default: ;
    goto ldv_48726;
    }
    ldv_48726: ;
  } else {
  }
  return (ioc_st);
}
}
void bfa_nw_ioc_get_attr(struct bfa_ioc *ioc , struct bfa_ioc_attr *ioc_attr )
{
  {
  memset((void *)ioc_attr, 0, 1600UL);
  ioc_attr->state = bfa_ioc_get_state(ioc);
  ioc_attr->port_id = ioc->port_id;
  ioc_attr->port_mode = (u8 )ioc->port_mode;
  ioc_attr->port_mode_cfg = ioc->port_mode_cfg;
  ioc_attr->cap_bm = ioc->ad_cap_bm;
  ioc_attr->ioc_type = bfa_ioc_get_type(ioc);
  bfa_ioc_get_adapter_attr(ioc, & ioc_attr->adapter_attr);
  ioc_attr->pci_attr.device_id = ioc->pcidev.device_id;
  ioc_attr->pci_attr.pcifn = (u32 )ioc->pcidev.pci_func;
  ioc_attr->def_fn = (int )ioc->pcidev.pci_func == (int )ioc->port_id;
  bfa_ioc_get_pci_chip_rev(ioc, (char *)(& ioc_attr->pci_attr.chip_rev));
  return;
}
}
static u64 bfa_ioc_get_pwwn(struct bfa_ioc *ioc )
{
  {
  return ((ioc->attr)->pwwn);
}
}
void bfa_nw_ioc_get_mac(struct bfa_ioc *ioc , u8 *mac )
{
  {
  ether_addr_copy(mac, (u8 const *)(& (ioc->attr)->mac));
  return;
}
}
static void bfa_ioc_recover(struct bfa_ioc *ioc )
{
  {
  printk("\nHeart Beat of IOC has failed\n");
  ioc->stats.ioc_hbfails = ioc->stats.ioc_hbfails + 1U;
  ioc->stats.hb_count = ioc->hb_count;
  (*(ioc->fsm))((void *)ioc, 9);
  return;
}
}
static void bfa_iocpf_enable(struct bfa_ioc *ioc )
{
  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 1);
  return;
}
}
static void bfa_iocpf_disable(struct bfa_ioc *ioc )
{
  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 2);
  return;
}
}
static void bfa_iocpf_fail(struct bfa_ioc *ioc )
{
  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 7);
  return;
}
}
static void bfa_iocpf_initfail(struct bfa_ioc *ioc )
{
  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 8);
  return;
}
}
static void bfa_iocpf_getattrfail(struct bfa_ioc *ioc )
{
  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 9);
  return;
}
}
static void bfa_iocpf_stop(struct bfa_ioc *ioc )
{
  {
  (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 3);
  return;
}
}
void bfa_nw_iocpf_timeout(struct bfa_ioc *ioc )
{
  enum bfa_iocpf_state iocpf_st ;
  int tmp ;
  {
  tmp = bfa_sm_to_state((struct bfa_sm_table const *)(& iocpf_sm_table), ioc->iocpf.fsm);
  iocpf_st = (enum bfa_iocpf_state )tmp;
  if ((unsigned int )iocpf_st == 3U) {
    bfa_ioc_poll_fwinit(ioc);
  } else {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 11);
  }
  return;
}
}
void bfa_nw_iocpf_sem_timeout(struct bfa_ioc *ioc )
{
  {
  bfa_ioc_hw_sem_get(ioc);
  return;
}
}
static void bfa_ioc_poll_fwinit(struct bfa_ioc *ioc )
{
  u32 fwstate ;
  enum bfi_ioc_state tmp ;
  unsigned long tmp___0 ;
  {
  tmp = (*((ioc->ioc_hwif)->ioc_get_fwstate))(ioc);
  fwstate = tmp;
  if (fwstate == 6U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 4);
    return;
  } else {
  }
  if (ioc->iocpf.poll_time > 2999U) {
    (*(ioc->iocpf.fsm))((void *)(& ioc->iocpf), 11);
  } else {
    ioc->iocpf.poll_time = ioc->iocpf.poll_time + 200U;
    tmp___0 = msecs_to_jiffies(200U);
    ldv_mod_timer_397(& ioc->iocpf_timer, tmp___0 + (unsigned long )jiffies);
  }
  return;
}
}
static void bfa_flash_cb(struct bfa_flash *flash )
{
  {
  flash->op_busy = 0U;
  if ((unsigned long )flash->cbfn != (unsigned long )((void (*)(void * , enum bfa_status ))0)) {
    (*(flash->cbfn))(flash->cbarg, flash->status);
  } else {
  }
  return;
}
}
static void bfa_flash_notify(void *cbarg , enum bfa_ioc_event event )
{
  struct bfa_flash *flash ;
  {
  flash = (struct bfa_flash *)cbarg;
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: ;
  if (flash->op_busy != 0U) {
    flash->status = 56;
    (*(flash->cbfn))(flash->cbarg, flash->status);
    flash->op_busy = 0U;
  } else {
  }
  goto ldv_48785;
  default: ;
  goto ldv_48785;
  }
  ldv_48785: ;
  return;
}
}
static void bfa_flash_write_send(struct bfa_flash *flash )
{
  struct bfi_flash_write_req *msg ;
  u32 len ;
  __u32 tmp ;
  __u32 tmp___0 ;
  int __y___0 ;
  int __y___1 ;
  __u32 tmp___1 ;
  {
  msg = (struct bfi_flash_write_req *)(& flash->mb.msg);
  tmp = __fswab32(flash->type);
  msg->type = tmp;
  msg->instance = flash->instance;
  tmp___0 = __fswab32(flash->addr_off + flash->offset);
  msg->offset = tmp___0;
  __y___1 = 2048;
  if ((unsigned long )flash->residue < (((unsigned long )(__y___1 + -1) + 65792UL) / (unsigned long )__y___1) * (unsigned long )__y___1) {
    len = flash->residue;
  } else {
    __y___0 = 2048;
    len = (u32 )((((unsigned long )(__y___0 + -1) + 65792UL) / (unsigned long )__y___0) * (unsigned long )__y___0);
  }
  tmp___1 = __fswab32(len);
  msg->length = tmp___1;
  msg->last = flash->residue == len;
  msg->mh.msg_class = 3U;
  msg->mh.msg_id = 3U;
  msg->mh.mtag.h2i.fn_lpu = (flash->ioc)->port_id;
  __bfa_alen_set(& msg->alen, len, flash->dbuf_pa);
  memcpy((void *)flash->dbuf_kva, (void const *)flash->ubuf + (unsigned long )flash->offset,
           (size_t )len);
  bfa_nw_ioc_mbox_queue(flash->ioc, & flash->mb, (void (*)(void * ))0, (void *)0);
  flash->residue = flash->residue - len;
  flash->offset = flash->offset + len;
  return;
}
}
static void bfa_flash_read_send(void *cbarg )
{
  struct bfa_flash *flash ;
  struct bfi_flash_read_req *msg ;
  u32 len ;
  __u32 tmp ;
  __u32 tmp___0 ;
  int __y___0 ;
  int __y___1 ;
  __u32 tmp___1 ;
  {
  flash = (struct bfa_flash *)cbarg;
  msg = (struct bfi_flash_read_req *)(& flash->mb.msg);
  tmp = __fswab32(flash->type);
  msg->type = tmp;
  msg->instance = flash->instance;
  tmp___0 = __fswab32(flash->addr_off + flash->offset);
  msg->offset = tmp___0;
  __y___1 = 2048;
  if ((unsigned long )flash->residue < (((unsigned long )(__y___1 + -1) + 65792UL) / (unsigned long )__y___1) * (unsigned long )__y___1) {
    len = flash->residue;
  } else {
    __y___0 = 2048;
    len = (u32 )((((unsigned long )(__y___0 + -1) + 65792UL) / (unsigned long )__y___0) * (unsigned long )__y___0);
  }
  tmp___1 = __fswab32(len);
  msg->length = tmp___1;
  msg->mh.msg_class = 3U;
  msg->mh.msg_id = 4U;
  msg->mh.mtag.h2i.fn_lpu = (flash->ioc)->port_id;
  __bfa_alen_set(& msg->alen, len, flash->dbuf_pa);
  bfa_nw_ioc_mbox_queue(flash->ioc, & flash->mb, (void (*)(void * ))0, (void *)0);
  return;
}
}
static void bfa_flash_intr(void *flasharg , struct bfi_mbmsg *msg )
{
  struct bfa_flash *flash ;
  u32 status ;
  union __anonunion_m_341 m ;
  __u32 tmp ;
  u32 i ;
  struct bfa_flash_attr *attr ;
  struct bfa_flash_attr *f ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  u32 len ;
  __u32 tmp___10 ;
  int __ret_warn_on ;
  long tmp___11 ;
  {
  flash = (struct bfa_flash *)flasharg;
  m.msg = msg;
  if (flash->op_busy == 0U && (unsigned int )msg->mh.msg_id != 255U) {
    return;
  } else {
  }
  switch ((int )msg->mh.msg_id) {
  case 129:
  tmp = __fswab32((m.query)->status);
  status = tmp;
  if (status == 0U) {
    attr = (struct bfa_flash_attr *)flash->ubuf;
    f = (struct bfa_flash_attr *)flash->dbuf_kva;
    tmp___0 = __fswab32(f->status);
    attr->status = tmp___0;
    tmp___1 = __fswab32(f->npart);
    attr->npart = tmp___1;
    i = 0U;
    goto ldv_48823;
    ldv_48822:
    tmp___2 = __fswab32(f->part[i].part_type);
    attr->part[i].part_type = tmp___2;
    tmp___3 = __fswab32(f->part[i].part_instance);
    attr->part[i].part_instance = tmp___3;
    tmp___4 = __fswab32(f->part[i].part_off);
    attr->part[i].part_off = tmp___4;
    tmp___5 = __fswab32(f->part[i].part_size);
    attr->part[i].part_size = tmp___5;
    tmp___6 = __fswab32(f->part[i].part_len);
    attr->part[i].part_len = tmp___6;
    tmp___7 = __fswab32(f->part[i].part_status);
    attr->part[i].part_status = tmp___7;
    i = i + 1U;
    ldv_48823: ;
    if (attr->npart > i) {
      goto ldv_48822;
    } else {
    }
  } else {
  }
  flash->status = (enum bfa_status )status;
  bfa_flash_cb(flash);
  goto ldv_48825;
  case 131:
  tmp___8 = __fswab32((m.write)->status);
  status = tmp___8;
  if (status != 0U || flash->residue == 0U) {
    flash->status = (enum bfa_status )status;
    bfa_flash_cb(flash);
  } else {
    bfa_flash_write_send(flash);
  }
  goto ldv_48825;
  case 132:
  tmp___9 = __fswab32((m.read)->status);
  status = tmp___9;
  if (status != 0U) {
    flash->status = (enum bfa_status )status;
    bfa_flash_cb(flash);
  } else {
    tmp___10 = __fswab32((m.read)->length);
    len = tmp___10;
    memcpy((void *)flash->ubuf + (unsigned long )flash->offset, (void const *)flash->dbuf_kva,
             (size_t )len);
    flash->residue = flash->residue - len;
    flash->offset = flash->offset + len;
    if (flash->residue == 0U) {
      flash->status = (enum bfa_status )status;
      bfa_flash_cb(flash);
    } else {
      bfa_flash_read_send((void *)flash);
    }
  }
  goto ldv_48825;
  case 133: ;
  case 255: ;
  goto ldv_48825;
  default:
  __ret_warn_on = 1;
  tmp___11 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
  if (tmp___11 != 0L) {
    warn_slowpath_null("/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc.c",
                       3199);
  } else {
  }
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
  }
  ldv_48825: ;
  return;
}
}
u32 bfa_nw_flash_meminfo(void)
{
  int __y ;
  int __y___0 ;
  {
  __y = 256;
  __y___0 = 2048;
  return ((u32 )((((((unsigned long )(__y___0 + -1) + 65792UL) / (unsigned long )__y___0) * (unsigned long )__y___0 + (unsigned long )(__y + -1)) / (unsigned long )__y) * (unsigned long )__y));
}
}
void bfa_nw_flash_attach(struct bfa_flash *flash , struct bfa_ioc *ioc , void *dev )
{
  {
  flash->ioc = ioc;
  flash->cbfn = (void (*)(void * , enum bfa_status ))0;
  flash->cbarg = (void *)0;
  flash->op_busy = 0U;
  bfa_nw_ioc_mbox_regisr(flash->ioc, 3, & bfa_flash_intr, (void *)flash);
  flash->ioc_notify.cbfn = & bfa_flash_notify;
  flash->ioc_notify.cbarg = (void *)flash;
  list_add_tail(& flash->ioc_notify.qe, & (flash->ioc)->notify_q);
  return;
}
}
void bfa_nw_flash_memclaim(struct bfa_flash *flash , u8 *dm_kva , u64 dm_pa )
{
  int __y ;
  int __y___0 ;
  int __y___1 ;
  int __y___2 ;
  int __y___3 ;
  {
  flash->dbuf_kva = dm_kva;
  flash->dbuf_pa = dm_pa;
  __y = 2048;
  memset((void *)flash->dbuf_kva, 0, (((unsigned long )(__y + -1) + 65792UL) / (unsigned long )__y) * (unsigned long )__y);
  __y___0 = 256;
  __y___1 = 2048;
  dm_kva = dm_kva + (((((unsigned long )(__y___1 + -1) + 65792UL) / (unsigned long )__y___1) * (unsigned long )__y___1 + (unsigned long )(__y___0 + -1)) / (unsigned long )__y___0) * (unsigned long )__y___0;
  __y___2 = 256;
  __y___3 = 2048;
  dm_pa = (unsigned long long )((((((unsigned long )(__y___3 + -1) + 65792UL) / (unsigned long )__y___3) * (unsigned long )__y___3 + (unsigned long )(__y___2 + -1)) / (unsigned long )__y___2) * (unsigned long )__y___2) + dm_pa;
  return;
}
}
enum bfa_status bfa_nw_flash_get_attr(struct bfa_flash *flash , struct bfa_flash_attr *attr ,
                                      void (*cbfn)(void * , enum bfa_status ) , void *cbarg )
{
  struct bfi_flash_query_req *msg ;
  bool tmp ;
  int tmp___0 ;
  {
  msg = (struct bfi_flash_query_req *)(& flash->mb.msg);
  tmp = bfa_nw_ioc_is_operational(flash->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (61);
  } else {
  }
  if (flash->op_busy != 0U) {
    return (13);
  } else {
  }
  flash->op_busy = 1U;
  flash->cbfn = cbfn;
  flash->cbarg = cbarg;
  flash->ubuf = (u8 *)attr;
  msg->mh.msg_class = 3U;
  msg->mh.msg_id = 1U;
  msg->mh.mtag.h2i.fn_lpu = (flash->ioc)->port_id;
  __bfa_alen_set(& msg->alen, 1032U, flash->dbuf_pa);
  bfa_nw_ioc_mbox_queue(flash->ioc, & flash->mb, (void (*)(void * ))0, (void *)0);
  return (0);
}
}
enum bfa_status bfa_nw_flash_update_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                         void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                         enum bfa_status ) ,
                                         void *cbarg )
{
  bool tmp ;
  int tmp___0 ;
  {
  tmp = bfa_nw_ioc_is_operational(flash->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (61);
  } else {
  }
  if (len == 0U || (len & 3U) != 0U) {
    return (17);
  } else {
  }
  if (type == 7U) {
    return (2);
  } else {
  }
  if (flash->op_busy != 0U) {
    return (13);
  } else {
  }
  flash->op_busy = 1U;
  flash->cbfn = cbfn;
  flash->cbarg = cbarg;
  flash->type = type;
  flash->instance = instance;
  flash->residue = len;
  flash->offset = 0U;
  flash->addr_off = offset;
  flash->ubuf = (u8 *)buf;
  bfa_flash_write_send(flash);
  return (0);
}
}
enum bfa_status bfa_nw_flash_read_part(struct bfa_flash *flash , u32 type , u8 instance ,
                                       void *buf , u32 len , u32 offset , void (*cbfn)(void * ,
                                                                                       enum bfa_status ) ,
                                       void *cbarg )
{
  bool tmp ;
  int tmp___0 ;
  {
  tmp = bfa_nw_ioc_is_operational(flash->ioc);
  if (tmp) {
    tmp___0 = 0;
  } else {
    tmp___0 = 1;
  }
  if (tmp___0) {
    return (61);
  } else {
  }
  if (len == 0U || (len & 3U) != 0U) {
    return (17);
  } else {
  }
  if (flash->op_busy != 0U) {
    return (13);
  } else {
  }
  flash->op_busy = 1U;
  flash->cbfn = cbfn;
  flash->cbarg = cbarg;
  flash->type = type;
  flash->instance = instance;
  flash->residue = len;
  flash->offset = 0U;
  flash->addr_off = offset;
  flash->ubuf = (u8 *)buf;
  bfa_flash_read_send((void *)flash);
  return (0);
}
}
bool ldv_queue_work_on_348(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_349(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_350(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_351(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_352(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_358(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_364(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_366(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_368(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_369(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_370(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_371(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_372(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_373(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_374(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_mod_timer_375(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_376(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___7 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_377(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___8 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_378(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___9 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_379(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___10 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_380(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___11 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_381(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___12 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_382(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___13 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_383(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___14 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_384(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___15 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_385(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___16 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_386(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___17 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_387(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___18 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_388(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___19 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_389(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___20 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_390(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___21 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_del_timer_391(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___22 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_392(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___23 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_393(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___24 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_394(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___25 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_395(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___26 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
int ldv_del_timer_396(struct timer_list *ldv_func_arg1 )
{
  ldv_func_ret_type___27 ldv_func_res ;
  int tmp ;
  {
  tmp = del_timer(ldv_func_arg1);
  ldv_func_res = tmp;
  disable_suitable_timer_7(ldv_func_arg1);
  return (ldv_func_res);
}
}
int ldv_mod_timer_397(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 )
{
  ldv_func_ret_type___28 ldv_func_res ;
  int tmp ;
  {
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
  ldv_func_res = tmp;
  activate_pending_timer_7(ldv_func_arg1, ldv_func_arg2, 1);
  return (ldv_func_res);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
bool ldv_queue_work_on_440(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_442(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_441(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_444(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_443(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_450(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_458(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_466(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_460(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_456(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_464(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_465(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_461(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_462(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_463(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
static bool bfa_ioc_ct_firmware_lock(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_firmware_unlock(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_reg_init(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct2_reg_init(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_map_port(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct2_map_port(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_isr_mode_set(struct bfa_ioc *ioc , bool msix ) ;
static void bfa_ioc_ct_notify_fail(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_ownership_reset(struct bfa_ioc *ioc ) ;
static bool bfa_ioc_ct_sync_start(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_sync_join(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_sync_leave(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_sync_ack(struct bfa_ioc *ioc ) ;
static bool bfa_ioc_ct_sync_complete(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_set_cur_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate ) ;
static enum bfi_ioc_state bfa_ioc_ct_get_cur_ioc_fwstate(struct bfa_ioc *ioc ) ;
static void bfa_ioc_ct_set_alt_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate ) ;
static enum bfi_ioc_state bfa_ioc_ct_get_alt_ioc_fwstate(struct bfa_ioc *ioc ) ;
static enum bfa_status bfa_ioc_ct_pll_init(void *rb , enum bfi_asic_mode asic_mode ) ;
static enum bfa_status bfa_ioc_ct2_pll_init(void *rb , enum bfi_asic_mode asic_mode ) ;
static bool bfa_ioc_ct2_lpu_read_stat(struct bfa_ioc *ioc ) ;
static struct bfa_ioc_hwif const nw_hwif_ct =
     {& bfa_ioc_ct_pll_init, & bfa_ioc_ct_firmware_lock, & bfa_ioc_ct_firmware_unlock,
    & bfa_ioc_ct_reg_init, & bfa_ioc_ct_map_port, & bfa_ioc_ct_isr_mode_set, & bfa_ioc_ct_notify_fail,
    & bfa_ioc_ct_ownership_reset, & bfa_ioc_ct_sync_start, & bfa_ioc_ct_sync_join,
    & bfa_ioc_ct_sync_leave, & bfa_ioc_ct_sync_ack, & bfa_ioc_ct_sync_complete, 0,
    & bfa_ioc_ct_set_cur_ioc_fwstate, & bfa_ioc_ct_get_cur_ioc_fwstate, & bfa_ioc_ct_set_alt_ioc_fwstate,
    & bfa_ioc_ct_get_alt_ioc_fwstate};
static struct bfa_ioc_hwif const nw_hwif_ct2 =
     {& bfa_ioc_ct2_pll_init, & bfa_ioc_ct_firmware_lock, & bfa_ioc_ct_firmware_unlock,
    & bfa_ioc_ct2_reg_init, & bfa_ioc_ct2_map_port, (void (*)(struct bfa_ioc * , bool ))0,
    & bfa_ioc_ct_notify_fail, & bfa_ioc_ct_ownership_reset, & bfa_ioc_ct_sync_start,
    & bfa_ioc_ct_sync_join, & bfa_ioc_ct_sync_leave, & bfa_ioc_ct_sync_ack, & bfa_ioc_ct_sync_complete,
    & bfa_ioc_ct2_lpu_read_stat, & bfa_ioc_ct_set_cur_ioc_fwstate, & bfa_ioc_ct_get_cur_ioc_fwstate,
    & bfa_ioc_ct_set_alt_ioc_fwstate, & bfa_ioc_ct_get_alt_ioc_fwstate};
void bfa_nw_ioc_set_ct_hwif(struct bfa_ioc *ioc )
{
  {
  ioc->ioc_hwif = & nw_hwif_ct;
  return;
}
}
void bfa_nw_ioc_set_ct2_hwif(struct bfa_ioc *ioc )
{
  {
  ioc->ioc_hwif = & nw_hwif_ct2;
  return;
}
}
static bool bfa_ioc_ct_firmware_lock(struct bfa_ioc *ioc )
{
  enum bfi_ioc_state ioc_fwstate ;
  u32 usecnt ;
  struct bfi_ioc_image_hdr fwhdr ;
  u32 tmp ;
  unsigned int tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  int tmp___3 ;
  {
  tmp = bfa_cb_image_get_size(ioc->asic_gen);
  if (tmp <= 16383U) {
    return (1);
  } else {
  }
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_usage_sem_reg);
  usecnt = readl((void const volatile *)ioc->ioc_regs.ioc_usage_reg);
  if (usecnt == 0U) {
    writel(1U, (void volatile *)ioc->ioc_regs.ioc_usage_reg);
    bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
    writel(0U, (void volatile *)ioc->ioc_regs.ioc_fail_sync);
    return (1);
  } else {
  }
  tmp___0 = readl((void const volatile *)ioc->ioc_regs.ioc_fwstate);
  ioc_fwstate = (enum bfi_ioc_state )tmp___0;
  tmp___1 = ldv__builtin_expect((unsigned int )ioc_fwstate == 0U, 0L);
  if (tmp___1 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                         "i" (150), "i" (12UL));
    ldv_47530: ;
    goto ldv_47530;
  } else {
  }
  bfa_nw_ioc_fwver_get(ioc, & fwhdr);
  tmp___2 = bfa_nw_ioc_fwver_cmp(ioc, & fwhdr);
  if (tmp___2) {
    tmp___3 = 0;
  } else {
    tmp___3 = 1;
  }
  if (tmp___3) {
    bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
    return (0);
  } else {
  }
  usecnt = usecnt + 1U;
  writel(usecnt, (void volatile *)ioc->ioc_regs.ioc_usage_reg);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
  return (1);
}
}
static void bfa_ioc_ct_firmware_unlock(struct bfa_ioc *ioc )
{
  u32 usecnt ;
  u32 tmp ;
  long tmp___0 ;
  {
  tmp = bfa_cb_image_get_size(ioc->asic_gen);
  if (tmp <= 16383U) {
    return;
  } else {
  }
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_usage_sem_reg);
  usecnt = readl((void const volatile *)ioc->ioc_regs.ioc_usage_reg);
  tmp___0 = ldv__builtin_expect(usecnt == 0U, 0L);
  if (tmp___0 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                         "i" (187), "i" (12UL));
    ldv_47535: ;
    goto ldv_47535;
  } else {
  }
  usecnt = usecnt - 1U;
  writel(usecnt, (void volatile *)ioc->ioc_regs.ioc_usage_reg);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
  return;
}
}
static void bfa_ioc_ct_notify_fail(struct bfa_ioc *ioc )
{
  {
  writel(1U, (void volatile *)ioc->ioc_regs.ll_halt);
  writel(1U, (void volatile *)ioc->ioc_regs.alt_ll_halt);
  readl((void const volatile *)ioc->ioc_regs.ll_halt);
  readl((void const volatile *)ioc->ioc_regs.alt_ll_halt);
  return;
}
}
static struct __anonstruct_ct_fnreg_337 const ct_fnreg[4U] = { {102912U, 103040U, 81928U},
        {103008U, 103136U, 82184U},
        {103424U, 103552U, 82696U},
        {103520U, 103648U, 82952U}};
static struct __anonstruct_ct_p0reg_338 const ct_p0reg[4U] = { {102400U, 102408U},
        {102416U, 102424U},
        {102736U, 102744U},
        {102752U, 102760U}};
static struct __anonstruct_ct_p1reg_339 const ct_p1reg[4U] = { {102404U, 102412U},
        {102420U, 102428U},
        {102740U, 102748U},
        {102756U, 102764U}};
static struct __anonstruct_ct2_reg_340 const ct2_reg[2U] = { {196608U, 196672U, 196888U, 196736U, 196744U, 196752U},
        {196640U, 196704U, 196888U, 196740U, 196748U, 196756U}};
static void bfa_ioc_ct_reg_init(struct bfa_ioc *ioc )
{
  void *rb ;
  int pcifn ;
  {
  pcifn = (int )ioc->pcidev.pci_func;
  rb = ioc->pcidev.pci_bar_kva;
  ioc->ioc_regs.hfn_mbox = rb + (unsigned long )ct_fnreg[pcifn].hfn_mbox;
  ioc->ioc_regs.lpu_mbox = rb + (unsigned long )ct_fnreg[pcifn].lpu_mbox;
  ioc->ioc_regs.host_page_num_fn = rb + (unsigned long )ct_fnreg[pcifn].hfn_pgn;
  if ((unsigned int )ioc->port_id == 0U) {
    ioc->ioc_regs.heartbeat = rb + 82496UL;
    ioc->ioc_regs.ioc_fwstate = rb + 82500UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 82508UL;
    ioc->ioc_regs.hfn_mbox_cmd = rb + (unsigned long )ct_p0reg[pcifn].hfn;
    ioc->ioc_regs.lpu_mbox_cmd = rb + (unsigned long )ct_p0reg[pcifn].lpu;
    ioc->ioc_regs.ll_halt = rb + 102828UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102844UL;
  } else {
    ioc->ioc_regs.heartbeat = rb + 82504UL;
    ioc->ioc_regs.ioc_fwstate = rb + 82508UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 82500UL;
    ioc->ioc_regs.hfn_mbox_cmd = rb + (unsigned long )ct_p1reg[pcifn].hfn;
    ioc->ioc_regs.lpu_mbox_cmd = rb + (unsigned long )ct_p1reg[pcifn].lpu;
    ioc->ioc_regs.ll_halt = rb + 102844UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102828UL;
  }
  ioc->ioc_regs.pss_ctl_reg = rb + 100352UL;
  ioc->ioc_regs.pss_err_status_reg = rb + 100368UL;
  ioc->ioc_regs.app_pll_fast_ctl_reg = rb + 82436UL;
  ioc->ioc_regs.app_pll_slow_ctl_reg = rb + 82440UL;
  ioc->ioc_regs.ioc_sem_reg = rb + 82480UL;
  ioc->ioc_regs.ioc_usage_sem_reg = rb + 82484UL;
  ioc->ioc_regs.ioc_init_sem_reg = rb + 82488UL;
  ioc->ioc_regs.ioc_usage_reg = rb + 83488UL;
  ioc->ioc_regs.ioc_fail_sync = rb + 83492UL;
  ioc->ioc_regs.smem_page_start = rb + 32768UL;
  ioc->ioc_regs.smem_pg0 = 384U;
  ioc->ioc_regs.err_set = rb + 100376UL;
  return;
}
}
static void bfa_ioc_ct2_reg_init(struct bfa_ioc *ioc )
{
  void *rb ;
  int port ;
  {
  port = (int )ioc->port_id;
  rb = ioc->pcidev.pci_bar_kva;
  ioc->ioc_regs.hfn_mbox = rb + (unsigned long )ct2_reg[port].hfn_mbox;
  ioc->ioc_regs.lpu_mbox = rb + (unsigned long )ct2_reg[port].lpu_mbox;
  ioc->ioc_regs.host_page_num_fn = rb + (unsigned long )ct2_reg[port].hfn_pgn;
  ioc->ioc_regs.hfn_mbox_cmd = rb + (unsigned long )ct2_reg[port].hfn;
  ioc->ioc_regs.lpu_mbox_cmd = rb + (unsigned long )ct2_reg[port].lpu;
  ioc->ioc_regs.lpu_read_stat = rb + (unsigned long )ct2_reg[port].lpu_read;
  if (port == 0) {
    ioc->ioc_regs.heartbeat = rb + 84144UL;
    ioc->ioc_regs.ioc_fwstate = rb + 84148UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 84156UL;
    ioc->ioc_regs.ll_halt = rb + 102828UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102844UL;
  } else {
    ioc->ioc_regs.heartbeat = rb + 84152UL;
    ioc->ioc_regs.ioc_fwstate = rb + 84156UL;
    ioc->ioc_regs.alt_ioc_fwstate = rb + 84148UL;
    ioc->ioc_regs.ll_halt = rb + 102844UL;
    ioc->ioc_regs.alt_ll_halt = rb + 102828UL;
  }
  ioc->ioc_regs.pss_ctl_reg = rb + 100352UL;
  ioc->ioc_regs.pss_err_status_reg = rb + 100368UL;
  ioc->ioc_regs.app_pll_fast_ctl_reg = rb + 83976UL;
  ioc->ioc_regs.app_pll_slow_ctl_reg = rb + 83980UL;
  ioc->ioc_regs.ioc_sem_reg = rb + 84208UL;
  ioc->ioc_regs.ioc_usage_sem_reg = rb + 84212UL;
  ioc->ioc_regs.ioc_init_sem_reg = rb + 84216UL;
  ioc->ioc_regs.ioc_usage_reg = rb + 84160UL;
  ioc->ioc_regs.ioc_fail_sync = rb + 84164UL;
  ioc->ioc_regs.smem_page_start = rb + 32768UL;
  ioc->ioc_regs.smem_pg0 = 384U;
  ioc->ioc_regs.err_set = rb + 100376UL;
  return;
}
}
static void bfa_ioc_ct_map_port(struct bfa_ioc *ioc )
{
  void *rb ;
  u32 r32 ;
  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile *)rb + 83460U);
  r32 = r32 >> (int )ioc->pcidev.pci_func * 8;
  ioc->port_id = (u8 )((r32 & 48U) >> 4);
  return;
}
}
static void bfa_ioc_ct2_map_port(struct bfa_ioc *ioc )
{
  void *rb ;
  u32 r32 ;
  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile *)rb + 196872U);
  ioc->port_id = (u8 )((r32 & 393216U) >> 17);
  return;
}
}
static void bfa_ioc_ct_isr_mode_set(struct bfa_ioc *ioc , bool msix )
{
  void *rb ;
  u32 r32 ;
  u32 mode ;
  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile *)rb + 83460U);
  mode = (r32 >> (int )ioc->pcidev.pci_func * 8) & 7U;
  if ((! msix && mode != 0U) || ((int )msix && mode == 0U)) {
    return;
  } else {
  }
  if ((int )msix) {
    mode = 0U;
  } else {
    mode = 1U;
  }
  r32 = (u32 )(~ (7 << (int )ioc->pcidev.pci_func * 8)) & r32;
  r32 = (mode << (int )ioc->pcidev.pci_func * 8) | r32;
  writel(r32, (void volatile *)rb + 83460U);
  return;
}
}
static bool bfa_ioc_ct2_lpu_read_stat(struct bfa_ioc *ioc )
{
  u32 r32 ;
  {
  r32 = readl((void const volatile *)ioc->ioc_regs.lpu_read_stat);
  if (r32 != 0U) {
    writel(1U, (void volatile *)ioc->ioc_regs.lpu_read_stat);
    return (1);
  } else {
  }
  return (0);
}
}
void bfa_nw_ioc_ct2_poweron(struct bfa_ioc *ioc )
{
  void *rb ;
  u32 r32 ;
  {
  rb = ioc->pcidev.pci_bar_kva;
  r32 = readl((void const volatile *)rb + 196924U);
  if ((r32 & 4192256U) != 0U) {
    writel(r32 & 2047U, (void volatile *)rb + 196920U);
    return;
  } else {
  }
  writel((unsigned int )((int )ioc->pcidev.pci_func * 64 | 129024), (void volatile *)rb + 196924U);
  writel((unsigned int )((int )ioc->pcidev.pci_func * 64), (void volatile *)rb + 196920U);
  return;
}
}
static void bfa_ioc_ct_ownership_reset(struct bfa_ioc *ioc )
{
  {
  bfa_nw_ioc_sem_get(ioc->ioc_regs.ioc_usage_sem_reg);
  writel(0U, (void volatile *)ioc->ioc_regs.ioc_usage_reg);
  bfa_nw_ioc_sem_release(ioc->ioc_regs.ioc_usage_sem_reg);
  readl((void const volatile *)ioc->ioc_regs.ioc_sem_reg);
  bfa_nw_ioc_hw_sem_release(ioc);
  return;
}
}
static bool bfa_ioc_ct_sync_start(struct bfa_ioc *ioc )
{
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_reqd ;
  bool tmp___0 ;
  {
  tmp = readl((void const volatile *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_reqd = r32 >> 16;
  if ((int )((unsigned long )sync_reqd >> (int )ioc->pcidev.pci_func) & 1) {
    writel(0U, (void volatile *)ioc->ioc_regs.ioc_fail_sync);
    writel(1U, (void volatile *)ioc->ioc_regs.ioc_usage_reg);
    writel(0U, (void volatile *)ioc->ioc_regs.ioc_fwstate);
    writel(0U, (void volatile *)ioc->ioc_regs.alt_ioc_fwstate);
    return (1);
  } else {
  }
  tmp___0 = bfa_ioc_ct_sync_complete(ioc);
  return (tmp___0);
}
}
static void bfa_ioc_ct_sync_join(struct bfa_ioc *ioc )
{
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_pos ;
  {
  tmp = readl((void const volatile *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_pos = (u32 )(1UL << (int )ioc->pcidev.pci_func) << 16U;
  writel(r32 | sync_pos, (void volatile *)ioc->ioc_regs.ioc_fail_sync);
  return;
}
}
static void bfa_ioc_ct_sync_leave(struct bfa_ioc *ioc )
{
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_msk ;
  {
  tmp = readl((void const volatile *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_msk = ((u32 )(1UL << (int )ioc->pcidev.pci_func) << 16U) | (u32 )(1UL << (int )ioc->pcidev.pci_func);
  writel(~ sync_msk & r32, (void volatile *)ioc->ioc_regs.ioc_fail_sync);
  return;
}
}
static void bfa_ioc_ct_sync_ack(struct bfa_ioc *ioc )
{
  u32 r32 ;
  unsigned int tmp ;
  {
  tmp = readl((void const volatile *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  writel((unsigned int )(1UL << (int )ioc->pcidev.pci_func) | r32, (void volatile *)ioc->ioc_regs.ioc_fail_sync);
  return;
}
}
static bool bfa_ioc_ct_sync_complete(struct bfa_ioc *ioc )
{
  u32 r32 ;
  unsigned int tmp ;
  u32 sync_reqd ;
  u32 sync_ackd ;
  u32 tmp_ackd ;
  {
  tmp = readl((void const volatile *)ioc->ioc_regs.ioc_fail_sync);
  r32 = tmp;
  sync_reqd = r32 >> 16;
  sync_ackd = r32 & 65535U;
  if (sync_ackd == 0U) {
    return (1);
  } else {
  }
  tmp_ackd = sync_ackd;
  if ((int )((unsigned long )sync_reqd >> (int )ioc->pcidev.pci_func) & 1 && (((unsigned long )sync_ackd >> (int )ioc->pcidev.pci_func) & 1UL) == 0UL) {
    sync_ackd = (u32 )(1UL << (int )ioc->pcidev.pci_func) | sync_ackd;
  } else {
  }
  if (sync_reqd == sync_ackd) {
    writel(r32 & 4294901760U, (void volatile *)ioc->ioc_regs.ioc_fail_sync);
    writel(8U, (void volatile *)ioc->ioc_regs.ioc_fwstate);
    writel(8U, (void volatile *)ioc->ioc_regs.alt_ioc_fwstate);
    return (1);
  } else {
  }
  if (tmp_ackd != sync_ackd) {
    writel(r32 | sync_ackd, (void volatile *)ioc->ioc_regs.ioc_fail_sync);
  } else {
  }
  return (0);
}
}
static void bfa_ioc_ct_set_cur_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate )
{
  {
  writel((unsigned int )fwstate, (void volatile *)ioc->ioc_regs.ioc_fwstate);
  return;
}
}
static enum bfi_ioc_state bfa_ioc_ct_get_cur_ioc_fwstate(struct bfa_ioc *ioc )
{
  unsigned int tmp ;
  {
  tmp = readl((void const volatile *)ioc->ioc_regs.ioc_fwstate);
  return ((enum bfi_ioc_state )tmp);
}
}
static void bfa_ioc_ct_set_alt_ioc_fwstate(struct bfa_ioc *ioc , enum bfi_ioc_state fwstate )
{
  {
  writel((unsigned int )fwstate, (void volatile *)ioc->ioc_regs.alt_ioc_fwstate);
  return;
}
}
static enum bfi_ioc_state bfa_ioc_ct_get_alt_ioc_fwstate(struct bfa_ioc *ioc )
{
  unsigned int tmp ;
  {
  tmp = readl((void const volatile *)ioc->ioc_regs.alt_ioc_fwstate);
  return ((enum bfi_ioc_state )tmp);
}
}
static enum bfa_status bfa_ioc_ct_pll_init(void *rb , enum bfi_asic_mode asic_mode )
{
  u32 pll_sclk ;
  u32 pll_fclk ;
  u32 r32 ;
  bool fcmode ;
  {
  fcmode = (unsigned int )asic_mode == 1U;
  pll_sclk = 29466U;
  pll_fclk = 29466U;
  if ((int )fcmode) {
    writel(0U, (void volatile *)rb + 83468U);
    writel(13U, (void volatile *)rb + 82568U);
  } else {
    writel(1U, (void volatile *)rb + 83468U);
    writel(2U, (void volatile *)rb + 82568U);
  }
  writel(0U, (void volatile *)rb + 82500U);
  writel(0U, (void volatile *)rb + 82508U);
  writel(4294967295U, (void volatile *)rb + 81924U);
  writel(4294967295U, (void volatile *)rb + 82180U);
  writel(4294967295U, (void volatile *)rb + 81920U);
  writel(4294967295U, (void volatile *)rb + 82176U);
  writel(4294967295U, (void volatile *)rb + 81924U);
  writel(4294967295U, (void volatile *)rb + 82180U);
  writel(pll_sclk | 65536U, (void volatile *)rb + 82440U);
  writel(pll_fclk | 65536U, (void volatile *)rb + 82436U);
  writel(pll_sclk | 65537U, (void volatile *)rb + 82440U);
  writel(pll_fclk | 65537U, (void volatile *)rb + 82436U);
  readl((void const volatile *)rb + 81924U);
  __const_udelay(8590000UL);
  writel(4294967295U, (void volatile *)rb + 81920U);
  writel(4294967295U, (void volatile *)rb + 82176U);
  writel(pll_sclk | 1U, (void volatile *)rb + 82440U);
  writel(pll_fclk | 1U, (void volatile *)rb + 82436U);
  if (! fcmode) {
    writel(1U, (void volatile *)rb + 145436U);
    writel(1U, (void volatile *)rb + 146460U);
  } else {
  }
  r32 = readl((void const volatile *)rb + 100352U);
  r32 = r32 & 4294966783U;
  writel(r32, (void volatile *)rb + 100352U);
  __const_udelay(4295000UL);
  if (! fcmode) {
    writel(0U, (void volatile *)rb + 145436U);
    writel(0U, (void volatile *)rb + 146460U);
  } else {
  }
  writel(4U, (void volatile *)rb + 82464U);
  __const_udelay(4295000UL);
  r32 = readl((void const volatile *)rb + 82468U);
  writel(0U, (void volatile *)rb + 82464U);
  return (0);
}
}
static void bfa_ioc_ct2_sclk_init(void *rb )
{
  u32 r32 ;
  {
  r32 = readl((void const volatile *)rb + 83980U);
  r32 = r32 & 4294967292U;
  r32 = r32 | 65548U;
  writel(r32, (void volatile *)rb + 83980U);
  r32 = readl((void const volatile *)rb + 83980U);
  r32 = r32 & 2684354559U;
  writel(r32, (void volatile *)rb + 83980U);
  r32 = readl((void const volatile *)rb + 84132U);
  writel(r32 | 16384U, (void volatile *)rb + 84132U);
  r32 = readl((void const volatile *)rb + 83972U);
  writel(r32 | 16U, (void volatile *)rb + 83972U);
  r32 = readl((void const volatile *)rb + 83980U);
  r32 = r32 & 3758096384U;
  writel(r32 | 274821915U, (void volatile *)rb + 83980U);
  __const_udelay(4295000UL);
  return;
}
}
static void bfa_ioc_ct2_lclk_init(void *rb )
{
  u32 r32 ;
  {
  r32 = readl((void const volatile *)rb + 83976U);
  r32 = r32 & 4294967292U;
  r32 = r32 | 65548U;
  writel(r32, (void volatile *)rb + 83976U);
  r32 = readl((void const volatile *)rb + 84132U);
  writel(r32, (void volatile *)rb + 84132U);
  r32 = readl((void const volatile *)rb + 83976U);
  writel(r32, (void volatile *)rb + 83976U);
  r32 = readl((void const volatile *)rb + 83976U);
  r32 = r32 & 3221225472U;
  r32 = r32 | 549548827U;
  writel(r32, (void volatile *)rb + 83976U);
  __const_udelay(4295000UL);
  return;
}
}
static void bfa_ioc_ct2_mem_init(void *rb )
{
  u32 r32 ;
  {
  r32 = readl((void const volatile *)rb + 100352U);
  r32 = r32 & 4294966783U;
  writel(r32, (void volatile *)rb + 100352U);
  __const_udelay(4295000UL);
  writel(4U, (void volatile *)rb + 83996U);
  __const_udelay(4295000UL);
  writel(0U, (void volatile *)rb + 83996U);
  return;
}
}
static void bfa_ioc_ct2_mac_reset(void *rb )
{
  u32 volatile r32 ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  {
  bfa_ioc_ct2_sclk_init(rb);
  bfa_ioc_ct2_lclk_init(rb);
  tmp = readl((void const volatile *)rb + 83980U);
  r32 = tmp;
  writel((unsigned int )r32 & 4294901759U, (void volatile *)rb + 83980U);
  tmp___0 = readl((void const volatile *)rb + 83976U);
  r32 = tmp___0;
  writel((unsigned int )r32 & 4294901759U, (void volatile *)rb + 83976U);
  writel(24U, (void volatile *)rb + 159952U);
  writel(24U, (void volatile *)rb + 159956U);
  return;
}
}
static bool bfa_ioc_ct2_nfc_halted(void *rb )
{
  u32 volatile r32 ;
  unsigned int tmp ;
  {
  tmp = readl((void const volatile *)rb + 160804U);
  r32 = tmp;
  if (((unsigned int )r32 & 4096U) != 0U) {
    return (1);
  } else {
  }
  return (0);
}
}
static void bfa_ioc_ct2_nfc_resume(void *rb )
{
  u32 volatile r32 ;
  int i ;
  unsigned int tmp ;
  long tmp___0 ;
  {
  writel(2U, (void volatile *)rb + 160800U);
  i = 0;
  goto ldv_47673;
  ldv_47672:
  tmp = readl((void const volatile *)rb + 160804U);
  r32 = tmp;
  if (((unsigned int )r32 & 4096U) == 0U) {
    return;
  } else {
  }
  __const_udelay(4295000UL);
  i = i + 1;
  ldv_47673: ;
  if (i <= 999) {
    goto ldv_47672;
  } else {
  }
  tmp___0 = ldv__builtin_expect(1L, 0L);
  if (tmp___0 != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                         "i" (850), "i" (12UL));
    ldv_47675: ;
    goto ldv_47675;
  } else {
  }
  return;
}
}
static enum bfa_status bfa_ioc_ct2_pll_init(void *rb , enum bfi_asic_mode asic_mode )
{
  u32 volatile wgn ;
  u32 volatile r32 ;
  u32 nfc_ver ;
  u32 i ;
  unsigned int tmp ;
  bool tmp___0 ;
  unsigned int tmp___1 ;
  long tmp___2 ;
  unsigned int tmp___3 ;
  long tmp___4 ;
  unsigned int tmp___5 ;
  long tmp___6 ;
  unsigned int tmp___7 ;
  unsigned int tmp___8 ;
  unsigned int tmp___9 ;
  unsigned int tmp___10 ;
  unsigned int tmp___11 ;
  unsigned int tmp___12 ;
  unsigned int tmp___13 ;
  unsigned int tmp___14 ;
  {
  tmp = readl((void const volatile *)rb + 84368U);
  wgn = tmp;
  nfc_ver = readl((void const volatile *)rb + 161372U);
  if ((unsigned int )wgn == 3072U && nfc_ver > 322U) {
    tmp___0 = bfa_ioc_ct2_nfc_halted(rb);
    if ((int )tmp___0) {
      bfa_ioc_ct2_nfc_resume(rb);
    } else {
    }
    writel(65536U, (void volatile *)rb + 159880U);
    i = 0U;
    goto ldv_47686;
    ldv_47685:
    tmp___1 = readl((void const volatile *)rb + 83976U);
    r32 = tmp___1;
    if (((unsigned int )r32 & 65536U) != 0U) {
      goto ldv_47684;
    } else {
    }
    i = i + 1U;
    ldv_47686: ;
    if (i <= 999999U) {
      goto ldv_47685;
    } else {
    }
    ldv_47684:
    tmp___2 = ldv__builtin_expect(((unsigned int )r32 & 65536U) == 0U, 0L);
    if (tmp___2 != 0L) {
      __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                           "i" (875), "i" (12UL));
      ldv_47687: ;
      goto ldv_47687;
    } else {
    }
    i = 0U;
    goto ldv_47690;
    ldv_47689:
    tmp___3 = readl((void const volatile *)rb + 83976U);
    r32 = tmp___3;
    if (((unsigned int )r32 & 65536U) == 0U) {
      goto ldv_47688;
    } else {
    }
    i = i + 1U;
    ldv_47690: ;
    if (i <= 999999U) {
      goto ldv_47689;
    } else {
    }
    ldv_47688:
    tmp___4 = ldv__builtin_expect(((unsigned int )r32 & 65536U) != 0U, 0L);
    if (tmp___4 != 0L) {
      __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                           "i" (882), "i" (12UL));
      ldv_47691: ;
      goto ldv_47691;
    } else {
    }
    __const_udelay(4295000UL);
    tmp___5 = readl((void const volatile *)rb + 159872U);
    r32 = tmp___5;
    tmp___6 = ldv__builtin_expect(((unsigned int )r32 & 65536U) != 0U, 0L);
    if (tmp___6 != 0L) {
      __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_ioc_ct.c"),
                           "i" (886), "i" (12UL));
      ldv_47692: ;
      goto ldv_47692;
    } else {
    }
  } else {
    writel(2U, (void volatile *)rb + 160804U);
    i = 0U;
    goto ldv_47695;
    ldv_47694:
    tmp___7 = readl((void const volatile *)rb + 160804U);
    r32 = tmp___7;
    if (((unsigned int )r32 & 4096U) != 0U) {
      goto ldv_47693;
    } else {
    }
    __const_udelay(4295000UL);
    i = i + 1U;
    ldv_47695: ;
    if (i <= 999U) {
      goto ldv_47694;
    } else {
    }
    ldv_47693:
    bfa_ioc_ct2_mac_reset(rb);
    bfa_ioc_ct2_sclk_init(rb);
    bfa_ioc_ct2_lclk_init(rb);
    tmp___8 = readl((void const volatile *)rb + 83980U);
    r32 = tmp___8;
    writel((unsigned int )r32 & 4294901759U, (void volatile *)rb + 83980U);
    tmp___9 = readl((void const volatile *)rb + 83976U);
    r32 = tmp___9;
    writel((unsigned int )r32 & 4294901759U, (void volatile *)rb + 83976U);
  }
  if ((unsigned int )wgn == 1536U) {
    tmp___10 = readl((void const volatile *)rb + 100544U);
    r32 = tmp___10;
    writel((unsigned int )r32 & 4294967294U, (void volatile *)rb + 100544U);
    tmp___11 = readl((void const volatile *)rb + 100552U);
    r32 = tmp___11;
    writel((unsigned int )r32 | 1U, (void volatile *)rb + 100552U);
  } else {
  }
  writel(1U, (void volatile *)rb + 196760U);
  writel(1U, (void volatile *)rb + 196764U);
  tmp___12 = readl((void const volatile *)rb + 83476U);
  r32 = tmp___12;
  if ((int )r32 & 1) {
    tmp___13 = readl((void const volatile *)rb + 196744U);
    r32 = tmp___13;
    if ((unsigned int )r32 == 1U) {
      writel(1U, (void volatile *)rb + 196744U);
      readl((void const volatile *)rb + 196744U);
    } else {
    }
    tmp___14 = readl((void const volatile *)rb + 196748U);
    r32 = tmp___14;
    if ((unsigned int )r32 == 1U) {
      writel(1U, (void volatile *)rb + 196748U);
      readl((void const volatile *)rb + 196748U);
    } else {
    }
  } else {
  }
  bfa_ioc_ct2_mem_init(rb);
  writel(0U, (void volatile *)rb + 84148U);
  writel(0U, (void volatile *)rb + 84156U);
  return (0);
}
}
extern int ldv_release_11(void) ;
extern int ldv_probe_11(void) ;
void ldv_initialize_bfa_ioc_hwif_11(void)
{
  void *tmp ;
  {
  tmp = ldv_init_zalloc(1512UL);
  nw_hwif_ct2_group0 = (struct bfa_ioc *)tmp;
  return;
}
}
void ldv_initialize_bfa_ioc_hwif_12(void)
{
  void *tmp ;
  {
  tmp = ldv_init_zalloc(1512UL);
  nw_hwif_ct_group0 = (struct bfa_ioc *)tmp;
  return;
}
}
void ldv_main_exported_11(void)
{
  enum bfi_asic_mode ldvarg2 ;
  enum bfi_ioc_state ldvarg0 ;
  enum bfi_ioc_state ldvarg3 ;
  void *ldvarg1 ;
  void *tmp ;
  int tmp___0 ;
  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg1 = tmp;
  ldv_memset((void *)(& ldvarg2), 0, 4UL);
  ldv_memset((void *)(& ldvarg0), 0, 4UL);
  ldv_memset((void *)(& ldvarg3), 0, 4UL);
  tmp___0 = __VERIFIER_nondet_int();
  switch (tmp___0) {
  case 0: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_ownership_reset(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_ownership_reset(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 1: ;
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_lpu_read_stat(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 2: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_join(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_join(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 3: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_notify_fail(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_notify_fail(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 4: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_firmware_lock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_firmware_lock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 5: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_get_cur_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_get_cur_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 6: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_firmware_unlock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_firmware_unlock(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 7: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_set_cur_ioc_fwstate(nw_hwif_ct2_group0, ldvarg3);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_set_cur_ioc_fwstate(nw_hwif_ct2_group0, ldvarg3);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 8: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_complete(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_complete(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 9: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_ack(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_ack(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 10: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_start(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_start(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 11: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct2_pll_init(ldvarg1, ldvarg2);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_pll_init(ldvarg1, ldvarg2);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 12: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_set_alt_ioc_fwstate(nw_hwif_ct2_group0, ldvarg0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_set_alt_ioc_fwstate(nw_hwif_ct2_group0, ldvarg0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 13: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct2_reg_init(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_reg_init(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 14: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_sync_leave(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_sync_leave(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 15: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct2_map_port(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct2_map_port(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 16: ;
  if (ldv_state_variable_11 == 1) {
    bfa_ioc_ct_get_alt_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 1;
  } else {
  }
  if (ldv_state_variable_11 == 2) {
    bfa_ioc_ct_get_alt_ioc_fwstate(nw_hwif_ct2_group0);
    ldv_state_variable_11 = 2;
  } else {
  }
  goto ldv_47714;
  case 17: ;
  if (ldv_state_variable_11 == 2) {
    ldv_release_11();
    ldv_state_variable_11 = 1;
    ref_cnt = ref_cnt - 1;
  } else {
  }
  goto ldv_47714;
  case 18: ;
  if (ldv_state_variable_11 == 1) {
    ldv_probe_11();
    ldv_state_variable_11 = 2;
    ref_cnt = ref_cnt + 1;
  } else {
  }
  goto ldv_47714;
  default:
  ldv_stop();
  }
  ldv_47714: ;
  return;
}
}
void ldv_main_exported_12(void)
{
  enum bfi_asic_mode ldvarg38 ;
  bool ldvarg40 ;
  enum bfi_ioc_state ldvarg36 ;
  void *ldvarg37 ;
  void *tmp ;
  enum bfi_ioc_state ldvarg39 ;
  int tmp___0 ;
  {
  tmp = ldv_init_zalloc(1UL);
  ldvarg37 = tmp;
  ldv_memset((void *)(& ldvarg38), 0, 4UL);
  ldv_memset((void *)(& ldvarg40), 0, 1UL);
  ldv_memset((void *)(& ldvarg36), 0, 4UL);
  ldv_memset((void *)(& ldvarg39), 0, 4UL);
  tmp___0 = __VERIFIER_nondet_int();
  switch (tmp___0) {
  case 0: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_ownership_reset(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 1: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_isr_mode_set(nw_hwif_ct_group0, (int )ldvarg40);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 2: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_join(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 3: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_notify_fail(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 4: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_firmware_lock(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 5: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_get_cur_ioc_fwstate(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 6: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_firmware_unlock(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 7: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_set_cur_ioc_fwstate(nw_hwif_ct_group0, ldvarg39);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 8: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_complete(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 9: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_ack(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 10: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_start(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 11: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_pll_init(ldvarg37, ldvarg38);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 12: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_set_alt_ioc_fwstate(nw_hwif_ct_group0, ldvarg36);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 13: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_reg_init(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 14: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_sync_leave(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 15: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_map_port(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  case 16: ;
  if (ldv_state_variable_12 == 1) {
    bfa_ioc_ct_get_alt_ioc_fwstate(nw_hwif_ct_group0);
    ldv_state_variable_12 = 1;
  } else {
  }
  goto ldv_47743;
  default:
  ldv_stop();
  }
  ldv_47743: ;
  return;
}
}
bool ldv_queue_work_on_440(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_441(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_442(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_443(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_444(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_450(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_456(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_458(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_460(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_461(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_462(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_463(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_464(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_465(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_466(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
__inline static long ldv__builtin_expect(long exp , long c ) ;
bool ldv_queue_work_on_486(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_488(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_487(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_490(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_489(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_496(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_504(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_512(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_506(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_502(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_510(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_511(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_507(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_508(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_509(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
static void bfa_cee_format_lldp_cfg(struct bfa_cee_lldp_cfg *lldp_cfg ) ;
static void bfa_cee_format_cee_cfg(void *buffer ) ;
static void bfa_cee_format_cee_cfg(void *buffer )
{
  struct bfa_cee_attr *cee_cfg ;
  {
  cee_cfg = (struct bfa_cee_attr *)buffer;
  bfa_cee_format_lldp_cfg(& cee_cfg->lldp_remote);
  return;
}
}
static void bfa_cee_stats_swap(struct bfa_cee_stats *stats )
{
  u32 *buffer ;
  int i ;
  __u32 tmp ;
  {
  buffer = (u32 *)stats;
  i = 0;
  goto ldv_47731;
  ldv_47730:
  tmp = __fswab32(*(buffer + (unsigned long )i));
  *(buffer + (unsigned long )i) = tmp;
  i = i + 1;
  ldv_47731: ;
  if ((unsigned int )i <= 17U) {
    goto ldv_47730;
  } else {
  }
  return;
}
}
static void bfa_cee_format_lldp_cfg(struct bfa_cee_lldp_cfg *lldp_cfg )
{
  __u16 tmp ;
  __u16 tmp___0 ;
  {
  tmp = __fswab16((int )lldp_cfg->time_to_live);
  lldp_cfg->time_to_live = tmp;
  tmp___0 = __fswab16((int )lldp_cfg->enabled_system_cap);
  lldp_cfg->enabled_system_cap = tmp___0;
  return;
}
}
static u32 bfa_cee_attr_meminfo(void)
{
  int __y ;
  {
  __y = 256;
  return ((u32 )((((unsigned long )(__y + -1) + 832UL) / (unsigned long )__y) * (unsigned long )__y));
}
}
static u32 bfa_cee_stats_meminfo(void)
{
  int __y ;
  {
  __y = 256;
  return ((u32 )((((unsigned long )(__y + -1) + 72UL) / (unsigned long )__y) * (unsigned long )__y));
}
}
static void bfa_cee_get_attr_isr(struct bfa_cee *cee , enum bfa_status status )
{
  {
  cee->get_attr_status = status;
  if ((unsigned int )status == 0U) {
    memcpy((void *)cee->attr, (void const *)cee->attr_dma.kva, 832UL);
    bfa_cee_format_cee_cfg((void *)cee->attr);
  } else {
  }
  cee->get_attr_pending = 0;
  if ((unsigned long )cee->cbfn.get_attr_cbfn != (unsigned long )((void (*)(void * ,
                                                                            enum bfa_status ))0)) {
    (*(cee->cbfn.get_attr_cbfn))(cee->cbfn.get_attr_cbarg, status);
  } else {
  }
  return;
}
}
static void bfa_cee_get_stats_isr(struct bfa_cee *cee , enum bfa_status status )
{
  {
  cee->get_stats_status = status;
  if ((unsigned int )status == 0U) {
    memcpy((void *)cee->stats, (void const *)cee->stats_dma.kva, 72UL);
    bfa_cee_stats_swap(cee->stats);
  } else {
  }
  cee->get_stats_pending = 0;
  if ((unsigned long )cee->cbfn.get_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                             enum bfa_status ))0)) {
    (*(cee->cbfn.get_stats_cbfn))(cee->cbfn.get_stats_cbarg, status);
  } else {
  }
  return;
}
}
static void bfa_cee_reset_stats_isr(struct bfa_cee *cee , enum bfa_status status )
{
  {
  cee->reset_stats_status = status;
  cee->reset_stats_pending = 0;
  if ((unsigned long )cee->cbfn.reset_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                               enum bfa_status ))0)) {
    (*(cee->cbfn.reset_stats_cbfn))(cee->cbfn.reset_stats_cbarg, status);
  } else {
  }
  return;
}
}
u32 bfa_nw_cee_meminfo(void)
{
  u32 tmp ;
  u32 tmp___0 ;
  {
  tmp = bfa_cee_attr_meminfo();
  tmp___0 = bfa_cee_stats_meminfo();
  return (tmp + tmp___0);
}
}
void bfa_nw_cee_mem_claim(struct bfa_cee *cee , u8 *dma_kva , u64 dma_pa )
{
  u32 tmp ;
  u32 tmp___0 ;
  u32 tmp___1 ;
  {
  cee->attr_dma.kva = (void *)dma_kva;
  cee->attr_dma.pa = dma_pa;
  tmp = bfa_cee_attr_meminfo();
  cee->stats_dma.kva = (void *)dma_kva + (unsigned long )tmp;
  tmp___0 = bfa_cee_attr_meminfo();
  cee->stats_dma.pa = (u64 )tmp___0 + dma_pa;
  cee->attr = (struct bfa_cee_attr *)dma_kva;
  tmp___1 = bfa_cee_attr_meminfo();
  cee->stats = (struct bfa_cee_stats *)dma_kva + (unsigned long )tmp___1;
  return;
}
}
enum bfa_status bfa_nw_cee_get_attr(struct bfa_cee *cee , struct bfa_cee_attr *attr ,
                                    void (*cbfn)(void * , enum bfa_status ) , void *cbarg )
{
  struct bfi_cee_get_req *cmd ;
  long tmp ;
  bool tmp___0 ;
  int tmp___1 ;
  {
  tmp = ldv__builtin_expect((long )((unsigned long )cee == (unsigned long )((struct bfa_cee *)0) || (unsigned long )cee->ioc == (unsigned long )((struct bfa_ioc *)0)),
                         0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_cee.c"),
                         "i" (171), "i" (12UL));
    ldv_47773: ;
    goto ldv_47773;
  } else {
  }
  tmp___0 = bfa_nw_ioc_is_operational(cee->ioc);
  if (tmp___0) {
    tmp___1 = 0;
  } else {
    tmp___1 = 1;
  }
  if (tmp___1) {
    return (56);
  } else {
  }
  if ((int )cee->get_attr_pending) {
    return (13);
  } else {
  }
  cee->get_attr_pending = 1;
  cmd = (struct bfi_cee_get_req *)(& cee->get_cfg_mb.msg);
  cee->attr = attr;
  cee->cbfn.get_attr_cbfn = cbfn;
  cee->cbfn.get_attr_cbarg = cbarg;
  cmd->mh.msg_class = 4U;
  cmd->mh.msg_id = 1U;
  cmd->mh.mtag.h2i.fn_lpu = (cee->ioc)->port_id;
  __bfa_dma_be_addr_set(& cmd->dma_addr, cee->attr_dma.pa);
  bfa_nw_ioc_mbox_queue(cee->ioc, & cee->get_cfg_mb, (void (*)(void * ))0, (void *)0);
  return (0);
}
}
static void bfa_cee_isr(void *cbarg , struct bfi_mbmsg *m )
{
  union bfi_cee_i2h_msg_u *msg ;
  struct bfi_cee_get_rsp *get_rsp ;
  struct bfa_cee *cee ;
  long tmp ;
  {
  cee = (struct bfa_cee *)cbarg;
  msg = (union bfi_cee_i2h_msg_u *)m;
  get_rsp = (struct bfi_cee_get_rsp *)m;
  switch ((int )msg->mh.msg_id) {
  case 129:
  bfa_cee_get_attr_isr(cee, (enum bfa_status )get_rsp->cmd_status);
  goto ldv_47782;
  case 131:
  bfa_cee_get_stats_isr(cee, (enum bfa_status )get_rsp->cmd_status);
  goto ldv_47782;
  case 130:
  bfa_cee_reset_stats_isr(cee, (enum bfa_status )get_rsp->cmd_status);
  goto ldv_47782;
  default:
  tmp = ldv__builtin_expect(1L, 0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_cee.c"),
                         "i" (214), "i" (12UL));
    ldv_47786: ;
    goto ldv_47786;
  } else {
  }
  }
  ldv_47782: ;
  return;
}
}
static void bfa_cee_notify(void *arg , enum bfa_ioc_event event )
{
  struct bfa_cee *cee ;
  {
  cee = (struct bfa_cee *)arg;
  switch ((unsigned int )event) {
  case 2U: ;
  case 3U: ;
  if ((int )cee->get_attr_pending) {
    cee->get_attr_status = 1;
    cee->get_attr_pending = 0;
    if ((unsigned long )cee->cbfn.get_attr_cbfn != (unsigned long )((void (*)(void * ,
                                                                              enum bfa_status ))0)) {
      (*(cee->cbfn.get_attr_cbfn))(cee->cbfn.get_attr_cbarg, 1);
    } else {
    }
  } else {
  }
  if ((int )cee->get_stats_pending) {
    cee->get_stats_status = 1;
    cee->get_stats_pending = 0;
    if ((unsigned long )cee->cbfn.get_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                               enum bfa_status ))0)) {
      (*(cee->cbfn.get_stats_cbfn))(cee->cbfn.get_stats_cbarg, 1);
    } else {
    }
  } else {
  }
  if ((int )cee->reset_stats_pending) {
    cee->reset_stats_status = 1;
    cee->reset_stats_pending = 0;
    if ((unsigned long )cee->cbfn.reset_stats_cbfn != (unsigned long )((void (*)(void * ,
                                                                                 enum bfa_status ))0)) {
      (*(cee->cbfn.reset_stats_cbfn))(cee->cbfn.reset_stats_cbarg, 1);
    } else {
    }
  } else {
  }
  goto ldv_47794;
  default: ;
  goto ldv_47794;
  }
  ldv_47794: ;
  return;
}
}
void bfa_nw_cee_attach(struct bfa_cee *cee , struct bfa_ioc *ioc , void *dev )
{
  long tmp ;
  {
  tmp = ldv__builtin_expect((unsigned long )cee == (unsigned long )((struct bfa_cee *)0),
                         0L);
  if (tmp != 0L) {
    __asm__ volatile ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/home/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--43_2a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/10625/dscv_tempdir/dscv/ri/43_2a/drivers/net/ethernet/brocade/bna/bfa_cee.c"),
                         "i" (280), "i" (12UL));
    ldv_47801: ;
    goto ldv_47801;
  } else {
  }
  cee->dev = dev;
  cee->ioc = ioc;
  bfa_nw_ioc_mbox_regisr(cee->ioc, 4, & bfa_cee_isr, (void *)cee);
  cee->ioc_notify.cbfn = & bfa_cee_notify;
  cee->ioc_notify.cbarg = (void *)cee;
  bfa_nw_ioc_notify_register(cee->ioc, & cee->ioc_notify);
  return;
}
}
bool ldv_queue_work_on_486(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_487(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_488(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_489(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_490(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_496(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_502(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_504(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_506(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_507(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_508(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_509(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_510(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_511(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_512(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
bool ldv_queue_work_on_532(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_work_on_534(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
bool ldv_queue_delayed_work_on_533(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
bool ldv_queue_delayed_work_on_536(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
void ldv_flush_workqueue_535(struct workqueue_struct *ldv_func_arg1 ) ;
void *ldv_kmem_cache_alloc_542(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
void *ldv_kmem_cache_alloc_559(struct kmem_cache *ldv_func_arg1 , gfp_t flags ) ;
extern void dev_alert(struct device const * , char const * , ...) ;
struct sk_buff *ldv_skb_clone_550(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_clone_558(struct sk_buff *ldv_func_arg1 , gfp_t flags ) ;
struct sk_buff *ldv_skb_copy_552(struct sk_buff const *ldv_func_arg1 , gfp_t flags ) ;
int ldv_pskb_expand_head_548(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_556(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
int ldv_pskb_expand_head_557(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_553(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_554(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct sk_buff *ldv___netdev_alloc_skb_555(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags ) ;
struct firmware const *bfi_fw ;
static u32 *bfi_image_ct_cna ;
static u32 *bfi_image_ct2_cna ;
static u32 bfi_image_ct_cna_size ;
static u32 bfi_image_ct2_cna_size ;
static u32 *cna_read_firmware(struct pci_dev *pdev , u32 **bfi_image , u32 *bfi_image_size ,
                              char *fw_name )
{
  struct firmware const *fw ;
  u32 n ;
  int tmp ;
  {
  tmp = request_firmware(& fw, (char const *)fw_name, & pdev->dev);
  if (tmp != 0) {
    dev_alert((struct device const *)(& pdev->dev), "can\'t load firmware %s\n",
              fw_name);
    goto error;
  } else {
  }
  *bfi_image = (u32 *)fw->data;
  *bfi_image_size = (u32 )((unsigned long )fw->size / 4UL);
  bfi_fw = fw;
  n = 0U;
  goto ldv_58171;
  ldv_58170:
  n = n + 1U;
  ldv_58171: ;
  if (*bfi_image_size > n) {
    goto ldv_58170;
  } else {
  }
  return (*bfi_image);
  error: ;
  return ((u32 *)0U);
}
}
u32 *cna_get_firmware_buf(struct pci_dev *pdev )
{
  {
  if ((unsigned int )pdev->device == 34U) {
    if (bfi_image_ct2_cna_size == 0U) {
      cna_read_firmware(pdev, & bfi_image_ct2_cna, & bfi_image_ct2_cna_size, (char *)"ct2fw-3.2.5.1.bin");
    } else {
    }
    return (bfi_image_ct2_cna);
  } else
  if ((unsigned int )pdev->device == 20U || (unsigned int )pdev->device == 33U) {
    if (bfi_image_ct_cna_size == 0U) {
      cna_read_firmware(pdev, & bfi_image_ct_cna, & bfi_image_ct_cna_size, (char *)"ctfw-3.2.5.1.bin");
    } else {
    }
    return (bfi_image_ct_cna);
  } else {
  }
  return ((u32 *)0U);
}
}
u32 *bfa_cb_image_get_chunk(enum bfi_asic_gen asic_gen , u32 off )
{
  {
  switch ((unsigned int )asic_gen) {
  case 2U: ;
  return (bfi_image_ct_cna + (unsigned long )off);
  case 3U: ;
  return (bfi_image_ct2_cna + (unsigned long )off);
  default: ;
  return ((u32 *)0U);
  }
}
}
u32 bfa_cb_image_get_size(enum bfi_asic_gen asic_gen )
{
  {
  switch ((unsigned int )asic_gen) {
  case 2U: ;
  return (bfi_image_ct_cna_size);
  case 3U: ;
  return (bfi_image_ct2_cna_size);
  default: ;
  return (0U);
  }
}
}
bool ldv_queue_work_on_532(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_delayed_work_on_533(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___3 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
bool ldv_queue_work_on_534(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 )
{
  ldv_func_ret_type___4 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
  ldv_func_res = tmp;
  activate_work_3(ldv_func_arg3, 2);
  return (ldv_func_res);
}
}
void ldv_flush_workqueue_535(struct workqueue_struct *ldv_func_arg1 )
{
  {
  flush_workqueue(ldv_func_arg1);
  call_and_disable_all_3(2);
  return;
}
}
bool ldv_queue_delayed_work_on_536(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 )
{
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;
  {
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
  ldv_func_res = tmp;
  activate_work_3(& ldv_func_arg3->work, 2);
  return (ldv_func_res);
}
}
void *ldv_kmem_cache_alloc_542(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
int ldv_pskb_expand_head_548(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_550(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv_skb_copy_552(struct sk_buff const *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_553(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_554(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
struct sk_buff *ldv___netdev_alloc_skb_555(struct net_device *ldv_func_arg1 , unsigned int ldv_func_arg2 ,
                                           gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
int ldv_pskb_expand_head_556(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
int ldv_pskb_expand_head_557(struct sk_buff *ldv_func_arg1 , int ldv_func_arg2 , int ldv_func_arg3 ,
                             gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((int )((long )tmp));
}
}
struct sk_buff *ldv_skb_clone_558(struct sk_buff *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return ((struct sk_buff *)tmp);
}
}
void *ldv_kmem_cache_alloc_559(struct kmem_cache *ldv_func_arg1 , gfp_t flags )
{
  void *tmp ;
  {
  ldv_check_alloc_flags(flags);
  tmp = ldv_undef_ptr();
  return (tmp);
}
}
bool ldv_is_err(void const *ptr )
{
  {
  return ((unsigned long )ptr > 2012UL);
}
}
void *ldv_err_ptr(long error )
{
  {
  return ((void *)(2012L - error));
}
}
long ldv_ptr_err(void const *ptr )
{
  {
  return ((long )(2012UL - (unsigned long )ptr));
}
}
bool ldv_is_err_or_null(void const *ptr )
{
  bool tmp ;
  int tmp___0 ;
  {
  if ((unsigned long )ptr == (unsigned long )((void const *)0)) {
    tmp___0 = 1;
  } else {
    tmp = ldv_is_err(ptr);
    if ((int )tmp) {
      tmp___0 = 1;
    } else {
      tmp___0 = 0;
    }
  }
  return ((bool )tmp___0);
}
}
int ldv_spin = 0;
void ldv_check_alloc_flags(gfp_t flags )
{
  {
  if (ldv_spin != 0 && (flags & 16U) != 0U) {
    ldv_error();
  } else {
  }
  return;
}
}
extern struct page *ldv_some_page(void) ;
struct page *ldv_check_alloc_flags_and_return_some_page(gfp_t flags )
{
  struct page *tmp ;
  {
  if (ldv_spin != 0 && (flags & 16U) != 0U) {
    ldv_error();
  } else {
  }
  tmp = ldv_some_page();
  return (tmp);
}
}
void ldv_check_alloc_nonatomic(void)
{
  {
  if (ldv_spin != 0) {
    ldv_error();
  } else {
  }
  return;
}
}
void ldv_spin_lock(void)
{
  {
  ldv_spin = 1;
  return;
}
}
void ldv_spin_unlock(void)
{
  {
  ldv_spin = 0;
  return;
}
}
int ldv_spin_trylock(void)
{
  int is_lock ;
  {
  is_lock = ldv_undef_int();
  if (is_lock != 0) {
    return (0);
  } else {
    ldv_spin = 1;
    return (1);
  }
}
}
void *external_alloc(void);
struct workqueue_struct *__alloc_workqueue_key(const char *arg0, unsigned int arg1, int arg2, struct lock_class_key *arg3, const char *arg4, ...) {
  return (struct workqueue_struct *)external_alloc();
}
int __VERIFIER_nondet_int(void);
int __bitmap_weight(const unsigned long *arg0, unsigned int arg1) {
  return __VERIFIER_nondet_int();
}
void __const_udelay(unsigned long arg0) {
  return;
}
void __dev_kfree_skb_any(struct sk_buff *arg0, enum skb_free_reason arg1) {
  return;
}
bool __VERIFIER_nondet_bool(void);
bool __get_page_tail(struct page *arg0) {
  return __VERIFIER_nondet_bool();
}
void __init_waitqueue_head(wait_queue_head_t *arg0, const char *arg1, struct lock_class_key *arg2) {
  return;
}
void __init_work(struct work_struct *arg0, int arg1) {
  return;
}
void __list_add(struct list_head *arg0, struct list_head *arg1, struct list_head *arg2) {
  return;
}
void __list_del_entry(struct list_head *arg0) {
  return;
}
unsigned long __VERIFIER_nondet_ulong(void);
unsigned long int __msecs_to_jiffies(const unsigned int arg0) {
  return __VERIFIER_nondet_ulong();
}
void __mutex_init(struct mutex *arg0, const char *arg1, struct lock_class_key *arg2) {
  return;
}
void __napi_schedule(struct napi_struct *arg0) {
  return;
}
int __VERIFIER_nondet_int(void);
int __pci_register_driver(struct pci_driver *arg0, struct module *arg1, const char *arg2) {
  return __VERIFIER_nondet_int();
}
unsigned long __VERIFIER_nondet_ulong(void);
unsigned long int __phys_addr(unsigned long arg0) {
  return __VERIFIER_nondet_ulong();
}
void *external_alloc(void);
unsigned char *__pskb_pull_tail(struct sk_buff *arg0, int arg1) {
  return (unsigned char *)external_alloc();
}
void __raw_spin_lock_init(raw_spinlock_t *arg0, const char *arg1, struct lock_class_key *arg2) {
  return;
}
void _dev_info(const struct device *arg0, const char *arg1, ...) {
  return;
}
void _raw_spin_lock_irq(raw_spinlock_t *arg0) {
  return;
}
void _raw_spin_unlock_irq(raw_spinlock_t *arg0) {
  return;
}
void _raw_spin_unlock_irqrestore(raw_spinlock_t *arg0, unsigned long arg1) {
  return;
}
void *external_alloc(void);
struct net_device *alloc_etherdev_mqs(int arg0, unsigned int arg1, unsigned int arg2) {
  return (struct net_device *)external_alloc();
}
void complete(struct completion *arg0) {
  return;
}
unsigned short __VERIFIER_nondet_ushort(void);
__sum16 csum_ipv6_magic(const struct in6_addr *arg0, const struct in6_addr *arg1, __u32 arg2, unsigned short arg3, __wsum arg4) {
  return __VERIFIER_nondet_ushort();
}
void debug_dma_map_page(struct device *arg0, struct page *arg1, size_t arg2, size_t arg3, int arg4, dma_addr_t arg5, bool arg6) {
  return;
}
void debug_dma_unmap_page(struct device *arg0, dma_addr_t arg1, size_t arg2, int arg3, bool arg4) {
  return;
}
void *external_alloc(void);
struct dentry *debugfs_create_dir(const char *arg0, struct dentry *arg1) {
  return (struct dentry *)external_alloc();
}
void *external_alloc(void);
struct dentry *debugfs_create_file(const char *arg0, umode_t arg1, struct dentry *arg2, void *arg3, const struct file_operations *arg4) {
  return (struct dentry *)external_alloc();
}
void debugfs_remove(struct dentry *arg0) {
  return;
}
int __VERIFIER_nondet_int(void);
int del_timer(struct timer_list *arg0) {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int del_timer_sync(struct timer_list *arg0) {
  return __VERIFIER_nondet_int();
}
void destroy_workqueue(struct workqueue_struct *arg0) {
  return;
}
void dev_alert(const struct device *arg0, const char *arg1, ...) {
  return;
}
void dev_err(const struct device *arg0, const char *arg1, ...) {
  return;
}
void dev_warn(const struct device *arg0, const char *arg1, ...) {
  return;
}
void *external_alloc(void);
void *dma_alloc_attrs(struct device *arg0, size_t arg1, dma_addr_t *arg2, gfp_t arg3, struct dma_attrs *arg4) {
  return (void *)external_alloc();
}
void dma_free_attrs(struct device *arg0, size_t arg1, void *arg2, dma_addr_t arg3, struct dma_attrs *arg4) {
  return;
}
int __VERIFIER_nondet_int(void);
int dma_set_mask(struct device *arg0, u64 arg1) {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int dma_supported(struct device *arg0, u64 arg1) {
  return __VERIFIER_nondet_int();
}
void do_gettimeofday(struct timeval *arg0) {
  return;
}
void dump_page(struct page *arg0, const char *arg1) {
  return;
}
unsigned short __VERIFIER_nondet_ushort(void);
__be16 eth_type_trans(struct sk_buff *arg0, struct net_device *arg1) {
  return __VERIFIER_nondet_ushort();
}
int __VERIFIER_nondet_int(void);
int eth_validate_addr(struct net_device *arg0) {
  return __VERIFIER_nondet_int();
}
unsigned int __VERIFIER_nondet_uint(void);
u32 ethtool_op_get_link(struct net_device *arg0) {
  return __VERIFIER_nondet_uint();
}
int __VERIFIER_nondet_int(void);
int ethtool_op_get_ts_info(struct net_device *arg0, struct ethtool_ts_info *arg1) {
  return __VERIFIER_nondet_int();
}
unsigned long __VERIFIER_nondet_ulong(void);
unsigned long int find_first_bit(const unsigned long *arg0, unsigned long arg1) {
  return __VERIFIER_nondet_ulong();
}
unsigned long __VERIFIER_nondet_ulong(void);
unsigned long int find_next_bit(const unsigned long *arg0, unsigned long arg1, unsigned long arg2) {
  return __VERIFIER_nondet_ulong();
}
long __VERIFIER_nondet_long(void);
loff_t fixed_size_llseek(struct file *arg0, loff_t arg1, int arg2, loff_t arg3) {
  return __VERIFIER_nondet_long();
}
void flush_workqueue(struct workqueue_struct *arg0) {
  return;
}
void free_irq(unsigned int arg0, void *arg1) {
  return;
}
void free_netdev(struct net_device *arg0) {
  return;
}
void init_timer_key(struct timer_list *arg0, unsigned int arg1, const char *arg2, struct lock_class_key *arg3) {
  return;
}
void *external_alloc(void);
void *ioremap_nocache(resource_size_t arg0, unsigned long arg1) {
  return (void *)external_alloc();
}
void iounmap(volatile void *arg0) {
  return;
}
void ldv_check_final_state() {
  return;
}
void ldv_initialize() {
  return;
}
int __VERIFIER_nondet_int(void);
int ldv_ndo_init_21() {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int ldv_ndo_uninit_21() {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int ldv_probe_11() {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int ldv_release_11() {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int ldv_shutdown_20() {
  return __VERIFIER_nondet_int();
}
void *external_alloc(void);
struct page *ldv_some_page() {
  return (struct page *)external_alloc();
}
void list_del(struct list_head *arg0) {
  return;
}
void lockdep_init_map(struct lockdep_map *arg0, const char *arg1, struct lock_class_key *arg2, int arg3) {
  return;
}
void *external_alloc(void);
void *memdup_user(const void *arg0, size_t arg1) {
  return (void *)external_alloc();
}
int __VERIFIER_nondet_int(void);
int mod_timer(struct timer_list *arg0, unsigned long arg1) {
  return __VERIFIER_nondet_int();
}
void mutex_destroy(struct mutex *arg0) {
  return;
}
void mutex_lock_nested(struct mutex *arg0, unsigned int arg1) {
  return;
}
void mutex_unlock(struct mutex *arg0) {
  return;
}
void napi_disable(struct napi_struct *arg0) {
  return;
}
void *external_alloc(void);
struct sk_buff *napi_get_frags(struct napi_struct *arg0) {
  return (struct sk_buff *)external_alloc();
}
void napi_gro_flush(struct napi_struct *arg0, bool arg1) {
  return;
}
int __VERIFIER_nondet_int(void);
gro_result_t napi_gro_frags(struct napi_struct *arg0) {
  return __VERIFIER_nondet_int();
}
void netdev_err(const struct net_device *arg0, const char *arg1, ...) {
  return;
}
void netdev_info(const struct net_device *arg0, const char *arg1, ...) {
  return;
}
void netdev_rss_key_fill(void *arg0, size_t arg1) {
  return;
}
void netdev_warn(const struct net_device *arg0, const char *arg1, ...) {
  return;
}
void netif_carrier_off(struct net_device *arg0) {
  return;
}
void netif_carrier_on(struct net_device *arg0) {
  return;
}
void netif_napi_add(struct net_device *arg0, struct napi_struct *arg1, int (*arg2)(struct napi_struct *, int), int arg3) {
  return;
}
void netif_napi_del(struct napi_struct *arg0) {
  return;
}
int __VERIFIER_nondet_int(void);
int netif_receive_skb_sk(struct sock *arg0, struct sk_buff *arg1) {
  return __VERIFIER_nondet_int();
}
void netif_tx_wake_queue(struct netdev_queue *arg0) {
  return;
}
void netif_wake_subqueue(struct net_device *arg0, u16 arg1) {
  return;
}
void pci_disable_device(struct pci_dev *arg0) {
  return;
}
void pci_disable_msix(struct pci_dev *arg0) {
  return;
}
int __VERIFIER_nondet_int(void);
int pci_enable_device(struct pci_dev *arg0) {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int pci_enable_msix_range(struct pci_dev *arg0, struct msix_entry *arg1, int arg2, int arg3) {
  return __VERIFIER_nondet_int();
}
void pci_intx(struct pci_dev *arg0, int arg1) {
  return;
}
void pci_release_regions(struct pci_dev *arg0) {
  return;
}
int __VERIFIER_nondet_int(void);
int pci_request_regions(struct pci_dev *arg0, const char *arg1) {
  return __VERIFIER_nondet_int();
}
void pci_set_master(struct pci_dev *arg0) {
  return;
}
void pci_unregister_driver(struct pci_driver *arg0) {
  return;
}
int __VERIFIER_nondet_int(void);
int printk(const char *arg0, ...) {
  return __VERIFIER_nondet_int();
}
void put_page(struct page *arg0) {
  return;
}
bool __VERIFIER_nondet_bool(void);
bool queue_delayed_work_on(int arg0, struct workqueue_struct *arg1, struct delayed_work *arg2, unsigned long arg3) {
  return __VERIFIER_nondet_bool();
}
bool __VERIFIER_nondet_bool(void);
bool queue_work_on(int arg0, struct workqueue_struct *arg1, struct work_struct *arg2) {
  return __VERIFIER_nondet_bool();
}
int __VERIFIER_nondet_int(void);
int register_netdev(struct net_device *arg0) {
  return __VERIFIER_nondet_int();
}
void release_firmware(const struct firmware *arg0) {
  return;
}
int __VERIFIER_nondet_int(void);
int request_firmware(const struct firmware **arg0, const char *arg1, struct device *arg2) {
  return __VERIFIER_nondet_int();
}
int __VERIFIER_nondet_int(void);
int request_threaded_irq(unsigned int arg0, irqreturn_t (*arg1)(int, void *), irqreturn_t (*arg2)(int, void *), unsigned long arg3, const char *arg4, void *arg5) {
  return __VERIFIER_nondet_int();
}
long __VERIFIER_nondet_long(void);
ssize_t simple_read_from_buffer(void *arg0, size_t arg1, loff_t *arg2, const void *arg3, size_t arg4) {
  return __VERIFIER_nondet_long();
}
void skb_clone_tx_timestamp(struct sk_buff *arg0) {
  return;
}
void *external_alloc(void);
unsigned char *skb_put(struct sk_buff *arg0, unsigned int arg1) {
  return (unsigned char *)external_alloc();
}
void skb_tstamp_tx(struct sk_buff *arg0, struct skb_shared_hwtstamps *arg1) {
  return;
}
unsigned long __VERIFIER_nondet_ulong(void);
size_t strlcpy(char *arg0, const char *arg1, size_t arg2) {
  return __VERIFIER_nondet_ulong();
}
void synchronize_irq(unsigned int arg0) {
  return;
}
void unregister_netdev(struct net_device *arg0) {
  return;
}
void wait_for_completion(struct completion *arg0) {
  return;
}
unsigned long __VERIFIER_nondet_ulong(void);
unsigned long int wait_for_completion_timeout(struct completion *arg0, unsigned long arg1) {
  return __VERIFIER_nondet_ulong();
}
void warn_slowpath_null(const char *arg0, const int arg1) {
  return;
}
void *__VERIFIER_external_alloc(void);
void *external_alloc(void) {
  return __VERIFIER_external_alloc();
}
void free(void *);
void kfree(void const *p) {
  free((void *)p);
}
